import os
from uuid import uuid4

# --------------------------------------------------
# ìµœì‹  Pinecone SDK ë°©ì‹ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
# --------------------------------------------------
from pinecone import Pinecone, ServerlessSpec

from dotenv import load_dotenv
load_dotenv()  # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# --------------------------------------------------
# ìµœì‹  OpenAI í´ë¼ì´ì–¸íŠ¸ (>=1.0.0) ë°©ì‹ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
# --------------------------------------------------
from openai import OpenAI

# --------------------------------------------------
# 1) Pinecone ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# --------------------------------------------------
def init_clients():
    # 1-1) OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        raise ValueError("âš ï¸ í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    # OpenAI ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë§Œë“­ë‹ˆë‹¤.
    openai_client = OpenAI(api_key=openai_api_key)
    print("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì™„ë£Œ")

    # 1-2) Pinecone ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    pinecone_api_key = os.getenv("PINECONE_API_KEY")
    pinecone_env     = os.getenv("PINECONE_ENVIRONMENT")   # ì˜ˆ: "us-east1-gcp" ë˜ëŠ” "us-west1-gcp" ë“±
    if not pinecone_api_key or not pinecone_env:
        raise ValueError("âš ï¸ í™˜ê²½ë³€ìˆ˜ PINECONE_API_KEY ë˜ëŠ” PINECONE_ENVê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")

    pc = Pinecone(api_key=pinecone_api_key, environment=pinecone_env)
    print("âœ… Pinecone í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì™„ë£Œ")

    # 1-3) ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    index_name = "dense-index"  # ì‹¤ì œ ì‚¬ìš© ì¤‘ì¸ ì¸ë±ìŠ¤ ì´ë¦„ìœ¼ë¡œ êµì²´í•˜ì„¸ìš”
    existing_indexes = pc.list_indexes().names()
    if index_name not in existing_indexes:
        raise ValueError(f"âš ï¸ ì¸ë±ìŠ¤ '{index_name}'ê°€ Pineconeì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í˜„ì¬ ì¸ë±ìŠ¤ ëª©ë¡: {existing_indexes}")

    # 1-4) í•´ë‹¹ ì¸ë±ìŠ¤ ê°ì²´ ê°€ì ¸ì˜¤ê¸°
    index = pc.Index(index_name)
    print(f"âœ… Pinecone ì¸ë±ìŠ¤ '{index_name}' ì—°ê²° ì™„ë£Œ (Namespaces: {len(index.describe_index_stats().namespaces)})")

    return openai_client, index


# --------------------------------------------------
# 2) ì§ˆë¬¸ ë¬¸ì¥ì„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜
# --------------------------------------------------
def embed_query(openai_client: OpenAI, text: str) -> list:
    """
    ìµœì‹  OpenAI í´ë¼ì´ì–¸íŠ¸ì—ì„œëŠ” resp.data[0].embedding ìœ¼ë¡œ ë²¡í„°ì— ì ‘ê·¼í•´ì•¼ í•©ë‹ˆë‹¤.
    """
    resp = openai_client.embeddings.create(
        model="text-embedding-3-large",
        input=text
    )
    return resp.data[0].embedding


# --------------------------------------------------
# 3) ì—¬ëŸ¬ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì¤‘ â€œê°€ì¥ ë†’ì€ ìœ ì‚¬ë„â€ë¥¼ ì¤€ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì™€ ë§¤ì¹­ ê²°ê³¼ ë°˜í™˜
# --------------------------------------------------
def retrieve_best_namespace(index, query_vector: list, top_k: int = 5):
    """
    1) index.describe_index_stats()ë¥¼ í†µí•´ ëª¨ë“  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ëª©ë¡ì„ ì–»ëŠ”ë‹¤.
    2) ê° ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë³„ë¡œ query_vectorë¥¼ index.query()ë¡œ ê²€ìƒ‰í•˜ê³ ,
       matches[0].score ë¥¼ ë¹„êµí•´ì„œ â€œìµœê³  ìœ ì‚¬ë„â€ë¥¼ ì°¾ëŠ”ë‹¤.
    3) ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ë¥¼ ì¤€ ë„¤ì„ìŠ¤í˜ì´ìŠ¤(best_ns)ì™€ í•´ë‹¹ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ ì „ì²´ ë§¤ì¹­ ê²°ê³¼(best_matches)ë¥¼ ë°˜í™˜.
    """
    stats = index.describe_index_stats()
    available_namespaces = list(stats.namespaces.keys())
    if not available_namespaces:
        raise ValueError("âš ï¸ ì¸ë±ìŠ¤ì— ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    best_ns = None
    best_score = -1.0
    best_matches = None

    for ns in available_namespaces:
        count = stats.namespaces[ns]["vector_count"]
        if count == 0:
            # ë¹„ì–´ ìˆëŠ” ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê±´ë„ˆë›°ê¸°
            continue

        res = index.query(
            vector=query_vector,
            namespace=ns,
            top_k=top_k,
            include_metadata=True
        )
        if not res.matches:
            continue

        top_score = res.matches[0].score
        if top_score > best_score:
            best_score = top_score
            best_ns = ns
            best_matches = res.matches

    if best_ns is None:
        raise ValueError("âš ï¸ ì–´ë–¤ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œë„ ë§¤ì¹­ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    print(f"ğŸ” ì„ íƒëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤: '{best_ns}' (ìµœê³  ìœ ì‚¬ë„: {best_score:.4f})")
    return best_ns, best_matches


# --------------------------------------------------
# 4) ê²€ìƒ‰ëœ ë§¤ì¹­ ê²°ê³¼ì—ì„œ ì‹¤ì œ í…ìŠ¤íŠ¸(ë©”íƒ€ë°ì´í„°)ë¥¼ êº¼ë‚´ Context ë¡œ ê²°í•©
# --------------------------------------------------
def build_context_from_matches(matches):
    """
    res.matches ë¦¬ìŠ¤íŠ¸ ì•ˆì˜ ê° item.metadata ì— ë“¤ì–´ ìˆëŠ” í…ìŠ¤íŠ¸ í•„ë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    ì—…ë¡œë“œ ì‹œ metadata í‚¤ê°€ "text"ì˜€ë‹¤ê³  ê°€ì •í–ˆìŠµë‹ˆë‹¤.
    """
    contexts = []
    for m in matches:
        chunk_text = m.metadata.get("text", "")
        if chunk_text:
            contexts.append(chunk_text)

    return "\n---\n".join(contexts)


# --------------------------------------------------
# 5) LLM ChatCompletion í˜¸ì¶œí•˜ì—¬ ë‹µë³€ ìƒì„±
# --------------------------------------------------
def generate_answer_with_context(openai_client: OpenAI, question: str, context: str) -> str:
    """
    ìµœì‹  OpenAI í´ë¼ì´ì–¸íŠ¸ì—ì„œëŠ” client.chat.completions.create(...) í˜•íƒœë¥¼ ì”ë‹ˆë‹¤.
    """
    prompt = f"""ì•„ë˜ Contextë¥¼ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

Context:
{context}

ì§ˆë¬¸:
{question}
"""
    resp = openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.0,
        max_tokens=1024
    )
    # resp.choices[0].message.content ìœ¼ë¡œ ë‹µë³€ ì¶”ì¶œ
    return resp.choices[0].message.content.strip()


# --------------------------------------------------
# 6) ë©”ì¸ ë£¨í”„
# --------------------------------------------------
def main():
    # 6-1) í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    openai_client, index = init_clients()

    while True:
        question = input("ğŸ” ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (â€˜exitâ€™ ì…ë ¥ ì‹œ ì¢…ë£Œ): ").strip()
        if question.lower() in ("exit", "quit"):
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        if not question:
            continue

        # 6-2) ì§ˆë¬¸ â†’ ì„ë² ë”© ë²¡í„°
        try:
            q_vec = embed_query(openai_client, question)
        except Exception as e:
            print(f"âš ï¸ ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
            continue

        # 6-3) ì—¬ëŸ¬ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì¤‘ ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì™€ match ë¶ˆëŸ¬ì˜¤ê¸°
        try:
            chosen_ns, matches = retrieve_best_namespace(index, q_vec, top_k=5)
        except ValueError as e:
            print(str(e))
            continue
        except Exception as e:
            print(f"âš ï¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue

        # 6-4) matchesì—ì„œ context í…ìŠ¤íŠ¸ ê²°í•©
        context = build_context_from_matches(matches)
        if not context:
            print("âš ï¸ ì„ íƒëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì—ì„œë„ ë©”íƒ€ë°ì´í„° ë‚´ í…ìŠ¤íŠ¸ë¥¼ ì½ì–´ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            continue

        # 6-5) LLM í˜¸ì¶œí•˜ì—¬ ë‹µë³€ ìƒì„±
        try:
            answer = generate_answer_with_context(openai_client, question, context)
        except Exception as e:
            print(f"âš ï¸ LLM ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            continue

        # 6-6) ê²°ê³¼ ì¶œë ¥
        print("\nğŸ† ìµœì¢… ë‹µë³€:\n" + answer + "\n")


if __name__ == "__main__":
    main()
