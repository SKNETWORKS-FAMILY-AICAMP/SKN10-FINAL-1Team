# final_bot.py

import os
import re
import requests
import discord
import pandas as pd
from datetime import datetime, timedelta, time as dtime
from collections import Counter
from discord.ext import commands, tasks
from dotenv import load_dotenv

# â”€â”€â”€ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
TOKEN         = os.getenv("DISCORD_BOT_TOKEN")
CHANNEL_ID    = int(os.getenv("DISCORD_CHANNEL_ID", 0))
NAVER_API_KEY = os.getenv("API_KEY")   # DeepSearch News v2 í‚¤
BASE_URL      = "https://api-v2.deepsearch.com/v1/articles"
HEADERS       = {"Authorization": f"Bearer {NAVER_API_KEY}"}

if not TOKEN or not NAVER_API_KEY:
    raise ValueError("âŒ .envì— DISCORD_BOT_TOKEN ë˜ëŠ” API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")

# â”€â”€â”€ ë””ìŠ¤ì½”ë“œ ë´‡ ì„¸íŒ… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix="!", intents=intents)

# â”€â”€â”€ 1) í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_top_keywords_from_articles(limit=10):
    date_to   = datetime.today().date()
    date_from = date_to - timedelta(days=1)
    payload = {
        "keyword":    "í†µì‹ ì‚¬ OR SKT OR KT OR LG OR LG U+",
        "date_from":  str(date_from),
        "date_to":    str(date_to),
        "page_size":  100
    }
    res      = requests.get(BASE_URL, headers=HEADERS, params=payload, timeout=30)
    articles = res.json().get("data", [])

    today_kw = f"{datetime.today().day}ì¼"
    stopwords = {
        "ìˆë‹¤","ê¸°ì","ë³´ë„","ì´ë‚ ","ìœ„í•´","ëŒ€í•œ","ì œ","ì¤‘","ê´€ë ¨","í–ˆë‹¤","ë°í˜”ë‹¤",
        "ì´ë²ˆ","ë˜í•œ","ì§€ë‚œ","í†µí•´","ìˆìœ¼ë©°","ê²ƒìœ¼ë¡œ","ë“±","ë°","ì—ì„œ","í•˜ëŠ”","í•˜ê³ ",
        "ìœ¼ë¡œ","ë˜ì–´","ëë‹¤","ìˆ˜","ê²ƒ","ë”","ê°™ì€", today_kw
    }

    counter = Counter()
    for art in articles:
        text  = art.get("title","") + " " + art.get("summary","")
        clean = re.sub(r"[^\uAC00-\uD7A3a-zA-Z0-9\s]", "", text)
        for w in clean.split():
            if len(w) > 1 and w not in stopwords:
                counter[w] += 1

    return [w for w,_ in counter.most_common(limit)]

# â”€â”€â”€ 2) ë‰´ìŠ¤ ìš”ì•½ ìˆ˜ì§‘ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch_news_for_keywords(keywords, limit=10):
    date_to   = datetime.today().date()
    date_from = date_to - timedelta(days=1)
    now       = datetime.now()
    date_str  = now.strftime("%Y-%m-%d")
    time_str  = now.strftime("%H:%M:%S")
    results   = []

    for kw in keywords[:limit]:
        payload = {
            "keyword":    kw,
            "date_from":  str(date_from),
            "date_to":    str(date_to),
            "page_size":  1
        }
        res      = requests.get(BASE_URL, headers=HEADERS, params=payload, timeout=30)
        articles = res.json().get("data", [])

        if articles:
            art = articles[0]
            results.append({
                "ë‚ ì§œ":      date_str,
                "ìƒì„±ì‹œê°„":   time_str,
                "í‚¤ì›Œë“œ":     kw,
                "ê¸°ì‚¬ ì œëª©":  art.get("title","(ì œëª© ì—†ìŒ)"),
                "ìš”ì•½":      art.get("summary","(ìš”ì•½ ì—†ìŒ)"),
                "URL":       art.get("content_url","")
            })
        else:
            results.append({
                "ë‚ ì§œ":      date_str,
                "ìƒì„±ì‹œê°„":   time_str,
                "í‚¤ì›Œë“œ":     kw,
                "ê¸°ì‚¬ ì œëª©":  "ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ",
                "ìš”ì•½":      "",
                "URL":       ""
            })

    return results

# â”€â”€â”€ 3) ë´‡ ì¤€ë¹„ ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@bot.event
async def on_ready():
    print(f"ğŸ¤– Bot ë¡œê·¸ì¸ ì™„ë£Œ: {bot.user} (ID: {bot.user.id})")
    if not daily_pipeline.is_running():
        daily_pipeline.start()
        # ë´‡ ì‹œì‘ ì§í›„ ì¦‰ì‹œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        await daily_pipeline()

@tasks.loop(time=dtime(hour=16, minute=0, second=0))  # UTC16:00 â†’ KST01:00
async def daily_pipeline():
    key    = datetime.now().strftime("%Y%m%d")
    print(f"â³ Pipeline ì‹œì‘: {key}")

    kws     = get_top_keywords_from_articles(limit=10)
    summaries = fetch_news_for_keywords(kws, limit=10)

    df    = pd.DataFrame(summaries)
    fname = f"summary_news_keywords_{key}.csv"
    df.to_csv(fname, index=False, encoding="utf-8-sig")
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {fname}")

# â”€â”€â”€ 4) ë””ìŠ¤ì½”ë“œ ì»¤ë§¨ë“œ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@bot.command(name="ìš”ì•½")
async def send_summary(ctx):
    key  = datetime.now().strftime("%Y%m%d")
    path = f"summary_news_keywords_{key}.csv"
    if os.path.isfile(path):
        await ctx.send(file=discord.File(path))
    else:
        await ctx.send(f"âš ï¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: `{path}`")

@bot.command(name="í‚¤ì›Œë“œ")
async def send_keywords(ctx):
    key  = datetime.now().strftime("%Y%m%d")
    path = f"summary_news_keywords_{key}.csv"
    if not os.path.isfile(path):
        return await ctx.send("âŒ ìš”ì•½ íŒŒì¼ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    df   = pd.read_csv(path)
    if "í‚¤ì›Œë“œ" not in df.columns:
        return await ctx.send("âŒ 'í‚¤ì›Œë“œ' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    kws  = df["í‚¤ì›Œë“œ"].dropna().unique().tolist()[:10]
    await ctx.send("ğŸ”‘ ì˜¤ëŠ˜ì˜ ìƒìœ„ í‚¤ì›Œë“œ:\n" + ", ".join(kws))

# â”€â”€â”€ 5) ë´‡ ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    bot.run(TOKEN)
