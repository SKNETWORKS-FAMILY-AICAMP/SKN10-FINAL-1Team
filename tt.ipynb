{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb7d6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Access Key ID: AKIAQVXVSODU425T62G4\n",
      "AWS Secret Access Key: **********\n",
      "AWS Default Region: us-east-1\n",
      "GitHub Token: **********\n",
      "S3 Bucket Name: code-agent\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import boto3\n",
    "from botocore.errorfactory import ClientError\n",
    "import logging\n",
    "import tempfile\n",
    "from github import Github\n",
    "from git import Repo as GitRepo\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# .env 파일에서 환경 변수를 로드합니다.\n",
    "# load_dotenv()는 기본적으로 현재 작업 디렉토리 또는 상위 디렉토리에서 .env 파일을 찾습니다.\n",
    "# 특정 경로를 지정하려면 load_dotenv(dotenv_path='/path/to/.env') 와 같이 사용합니다.\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수 사용\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "aws_default_region = os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "github_token = os.getenv(\"GITHUB_TOKEN\") # .env 파일에 GITHUB_TOKEN이 있다면 로드됨\n",
    "s3_bucket_name = os.getenv(\"S3_BUCKET_NAME\")\n",
    "# 로드된 값 확인 (실제 운영 코드에서는 민감 정보 직접 출력은 피하세요)\n",
    "print(f\"AWS Access Key ID: {aws_access_key_id}\")\n",
    "print(f\"AWS Secret Access Key: {'*' * 10 if aws_secret_access_key else None}\") # 시크릿 키는 직접 출력하지 않는 것이 좋습니다.\n",
    "print(f\"AWS Default Region: {aws_default_region}\")\n",
    "print(f\"GitHub Token: {'*' * 10 if github_token else None}\")\n",
    "print(f\"S3 Bucket Name: {s3_bucket_name}\")\n",
    "\n",
    "\n",
    "\n",
    "# --- AWS S3 헬퍼 함수 ---\n",
    "def _get_s3_client():\n",
    "    \"\"\"S3 클라이언트 객체를 반환합니다.\n",
    "    AWS 자격 증명은 환경 변수(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION),\n",
    "    IAM 역할 등을 통해 Boto3가 자동으로 로드하도록 설정되어 있어야 합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s3 = boto3.client('s3')\n",
    "        # 간단한 연결 테스트 (선택 사항)\n",
    "        s3.list_buckets() # 올바른 자격증명이 없으면 여기서 에러 발생\n",
    "        logging.info(\"S3 클라이언트 생성 성공.\")\n",
    "        return s3\n",
    "    except NoCredentialsError:\n",
    "        logging.error(\"AWS 자격 증명을 찾을 수 없습니다. 환경 변수 또는 IAM 역할을 설정하세요.\")\n",
    "        raise\n",
    "    except ClientError as e:\n",
    "        logging.error(f\"S3 클라이언트 생성 중 오류 발생: {e}\")\n",
    "        raise\n",
    "\n",
    "def _upload_directory_to_s3(local_directory: str, bucket_name: str, s3_prefix: str):\n",
    "    \"\"\"\n",
    "    로컬 디렉토리를 S3에 업로드하되, 코드 관련 파일만 필터링하여 업로드합니다.\n",
    "    디렉토리 구조는 유지합니다.\n",
    "    \n",
    "    Args:\n",
    "        local_directory (str): 업로드할 로컬 디렉토리 경로\n",
    "        bucket_name (str): S3 버킷 이름\n",
    "        s3_prefix (str): S3 내 저장될 경로 접두사\n",
    "    \"\"\"\n",
    "    # 코드 관련 확장자 목록\n",
    "    code_extensions = [\n",
    "        '.py', '.ipynb',  # Python\n",
    "        '.html', '.htm', '.css', '.js', '.jsx', '.ts', '.tsx',  # Web\n",
    "        '.md', '.markdown', '.rst',  # Documentation\n",
    "        '.java', '.kt', '.scala',  # JVM\n",
    "        '.c', '.cpp', '.h', '.hpp',  # C/C++\n",
    "        '.cs',  # C#\n",
    "        '.go',  # Go\n",
    "        '.rb',  # Ruby\n",
    "        '.php',  # PHP\n",
    "        '.swift',  # Swift\n",
    "        '.rs',  # Rust\n",
    "        '.sh', '.bash',  # Shell\n",
    "        '.sql',  # SQL\n",
    "        '.json', '.yml', '.yaml', '.xml', '.toml',  # Config\n",
    "        '.txt',  # Text\n",
    "    ]\n",
    "    \n",
    "    # 확장자 없는 특수 파일 이름 목록\n",
    "    special_filenames = [\n",
    "        '.gitignore', '.dockerignore',  # Git/Docker\n",
    "        'Dockerfile', 'docker-compose.yml',  # Docker\n",
    "        'requirements.txt', 'Pipfile', 'pyproject.toml',  # Python deps\n",
    "        'package.json', 'package-lock.json', 'yarn.lock',  # JS deps\n",
    "        'Gemfile', 'Gemfile.lock',  # Ruby deps\n",
    "        'build.gradle', 'pom.xml',  # Java/Kotlin deps\n",
    "        'Makefile', 'CMakeLists.txt',  # Build files\n",
    "        'LICENSE', 'README'  # Common project files\n",
    "    ]\n",
    "    \n",
    "    # S3 클라이언트 생성\n",
    "    s3 = _get_s3_client()\n",
    "    \n",
    "    # 파일 수 카운트\n",
    "    total_files = 0\n",
    "    uploaded_files = 0\n",
    "    skipped_files = 0\n",
    "    \n",
    "    for root, _, files in os.walk(local_directory):\n",
    "        for filename in files:\n",
    "            # 파일 경로 및 확장자 처리\n",
    "            local_path = os.path.join(root, filename)\n",
    "            relative_path = os.path.relpath(local_path, local_directory)\n",
    "            s3_key = os.path.join(s3_prefix, relative_path).replace(\"\\\\\", \"/\")\n",
    "            \n",
    "            # 확장자 확인 (확장자가 없는 파일도 이름을 검사)\n",
    "            _, file_extension = os.path.splitext(filename)\n",
    "            total_files += 1\n",
    "            \n",
    "            # 파일이 코드 관련 확장자를 가지거나 특수 파일명과 일치하는지 확인\n",
    "            is_code_file = file_extension.lower() in code_extensions\n",
    "            is_special_file = filename in special_filenames\n",
    "            \n",
    "            # .git 디렉토리 내 파일은 제외 \n",
    "            if '.git' in relative_path:\n",
    "                skipped_files += 1\n",
    "                continue\n",
    "                \n",
    "            if is_code_file or is_special_file:\n",
    "                try:\n",
    "                    logging.info(f\"Uploading {local_path} to s3://{bucket_name}/{s3_key}\")\n",
    "                    s3.upload_file(local_path, bucket_name, s3_key)\n",
    "                    uploaded_files += 1\n",
    "                except ClientError as e:\n",
    "                    logging.warning(f\"Failed to upload {local_path} to {s3_key}: {e}\")\n",
    "                    # 부분적 실패 시 어떻게 처리할지 결정 (예: 계속 진행)\n",
    "                except FileNotFoundError:\n",
    "                    logging.error(f\"업로드할 로컬 파일 없음 ({local_path})\")\n",
    "            else:\n",
    "                skipped_files += 1\n",
    "                \n",
    "    logging.info(f\"업로드 완료. 총 {total_files}개 파일 중 {uploaded_files}개 업로드됨, {skipped_files}개 건너뜀\")\n",
    "\n",
    "\n",
    "# --- GitHub 및 S3 연동 도구 함수 ---\n",
    "\n",
    "def clone_all_user_repos_to_s3(github_token: str, s3_bucket_name: str, s3_base_path: str = \"user_github_repos\") -> dict:\n",
    "    \"\"\"\n",
    "    사용자의 GitHub 토큰을 사용하여 해당 사용자의 모든 (접근 가능한) 공개 및 비공개 리포지토리를\n",
    "    S3의 지정된 경로에 복제(clone)합니다.\n",
    "\n",
    "    Args:\n",
    "        github_token (str): GitHub 개인용 액세스 토큰 (PAT). 'repo' 스코프 권한 필요.\n",
    "        s3_bucket_name (str): 대상 S3 버킷 이름.\n",
    "        s3_base_path (str, optional): S3 버킷 내 리포지토리가 저장될 기본 경로.\n",
    "                                      기본값은 \"user_github_repos\" 입니다.\n",
    "                                      최종 경로는 's3_base_path/username/repo_name' 형태가 됩니다.\n",
    "\n",
    "    Returns:\n",
    "        dict: 성공 여부, 메시지, 클론된 리포지토리의 S3 경로 목록을 포함하는 딕셔너리.\n",
    "              예: {\"success\": True, \"message\": \"...\", \"cloned_repos\": [\"s3://bucket/path/repo1\", ...]}\n",
    "    \"\"\"\n",
    "    cloned_s3_paths = []\n",
    "    try:\n",
    "        g = Github(github_token)\n",
    "        user = g.get_user() # 토큰에 해당하는 사용자\n",
    "        username = user.login\n",
    "        logging.info(f\"사용자 '{username}'의 리포지토리 목록을 가져옵니다...\")\n",
    "\n",
    "        repos_cloned_count = 0\n",
    "        for repo in user.get_repos(): # 사용자의 모든 리포지토리 순회\n",
    "            repo_name = repo.name\n",
    "            # GitPython은 clone_url에 토큰을 직접 포함하는 것보다 SSH 키 또는 Git 자격 증명 헬퍼 사용을 권장.\n",
    "            # HTTPS URL에 토큰을 포함하는 방식은 간단하지만 보안에 유의해야 함.\n",
    "            clone_url_with_token = f\"https://oauth2:{github_token}@github.com/{username}/{repo_name}.git\"\n",
    "            s3_repo_path = os.path.join(s3_base_path, username, repo_name).replace(\"\\\\\", \"/\")\n",
    "\n",
    "            with tempfile.TemporaryDirectory() as tmpdir:\n",
    "                local_repo_path = os.path.join(tmpdir, repo_name)\n",
    "                logging.info(f\"'{repo_name}' 리포지토리를 로컬에 복제 중... ({repo.clone_url})\")\n",
    "                try:\n",
    "                    GitRepo.clone_from(clone_url_with_token, local_repo_path)\n",
    "                    logging.info(f\"'{repo_name}' 복제 완료. S3에 업로드 중... (s3://{s3_bucket_name}/{s3_repo_path})\")\n",
    "                    _upload_directory_to_s3(local_repo_path, s3_bucket_name, s3_repo_path)\n",
    "                    cloned_s3_paths.append(f\"s3://{s3_bucket_name}/{s3_repo_path}\")\n",
    "                    repos_cloned_count += 1\n",
    "                except Exception as e: # git.exc.GitCommandError 등\n",
    "                    logging.warning(f\"'{repo_name}' 처리 중 오류 발생: {e}\")\n",
    "                    # 특정 리포지토리 실패 시 계속 진행\n",
    "\n",
    "        if repos_cloned_count > 0:\n",
    "            msg = f\"{repos_cloned_count}개의 리포지토리를 S3에 성공적으로 복제했습니다.\"\n",
    "            logging.info(msg)\n",
    "            return {\"success\": True, \"message\": msg, \"cloned_repos\": cloned_s3_paths}\n",
    "        else:\n",
    "            msg = \"복제할 수 있는 리포지토리가 없거나 모든 리포지토리 복제에 실패했습니다.\"\n",
    "            logging.info(msg)\n",
    "            return {\"success\": False, \"message\": msg, \"cloned_repos\": []}\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"모든 리포지토리 복제 중 오류 발생: {e}\")\n",
    "        return {\"success\": False, \"message\": f\"오류 발생: {e}\", \"cloned_repos\": []}\n",
    "\n",
    "def clone_specific_repo_to_s3(github_token: str, repo_identifier: str, s3_bucket_name: str, s3_base_path: str = \"user_github_repos\") -> dict:\n",
    "    \"\"\"\n",
    "    지정된 GitHub 리포지토리를 S3의 지정된 경로에 복제합니다.\n",
    "    repo_identifier는 'username/repo_name' 형식입니다.\n",
    "\n",
    "    Args:\n",
    "        github_token (str): GitHub 개인용 액세스 토큰 (비공개 리포지토리 접근 시 필요).\n",
    "        repo_identifier (str): 복제할 GitHub 리포지토리 식별자 (\"username/repo_name\" 형식).\n",
    "        s3_bucket_name (str): 대상 S3 버킷 이름.\n",
    "        s3_base_path (str, optional): S3 버킷 내 리포지토리가 저장될 기본 경로.\n",
    "                                      기본값은 \"user_github_repos\" 입니다.\n",
    "\n",
    "    Returns:\n",
    "        dict: 성공 여부, 메시지, 복제된 리포지토리의 S3 경로를 포함하는 딕셔너리.\n",
    "              예: {\"success\": True, \"message\": \"...\", \"s3_path\": \"s3://bucket/path/repo_name\"}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if '/' not in repo_identifier:\n",
    "            raise ValueError(\"잘못된 repo_identifier 형식입니다. 'username/repo_name' 형식을 사용하세요.\")\n",
    "\n",
    "        username, repo_name = repo_identifier.split('/', 1)\n",
    "        clone_url_with_token = f\"https://oauth2:{github_token}@github.com/{username}/{repo_name}.git\"\n",
    "        s3_repo_path = os.path.join(s3_base_path, username, repo_name).replace(\"\\\\\", \"/\")\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            local_repo_path = os.path.join(tmpdir, repo_name)\n",
    "            logging.info(f\"'{repo_identifier}' 리포지토리를 로컬에 복제 중... ({clone_url_with_token.replace(github_token, '****')})\")\n",
    "            GitRepo.clone_from(clone_url_with_token, local_repo_path)\n",
    "            logging.info(f\"'{repo_identifier}' 복제 완료. S3에 업로드 중... (s3://{s3_bucket_name}/{s3_repo_path})\")\n",
    "            _upload_directory_to_s3(local_repo_path, s3_bucket_name, s3_repo_path)\n",
    "            s3_full_path = f\"s3://{s3_bucket_name}/{s3_repo_path}\"\n",
    "            msg = f\"'{repo_identifier}' 리포지토리를 S3에 성공적으로 복제했습니다.\"\n",
    "            logging.info(msg)\n",
    "            return {\"success\": True, \"message\": msg, \"s3_path\": s3_full_path}\n",
    "\n",
    "    except ValueError as ve:\n",
    "        logging.error(f\"입력값 오류: {ve}\")\n",
    "        return {\"success\": False, \"message\": f\"입력값 오류: {ve}\", \"s3_path\": None}\n",
    "    except Exception as e: # git.exc.GitCommandError, ClientError 등\n",
    "        logging.error(f\"특정 리포지토리({repo_identifier}) 복제 중 오류 발생: {e}\")\n",
    "        return {\"success\": False, \"message\": f\"오류 발생: {e}\", \"s3_path\": None}\n",
    "\n",
    "def search_code_in_s3_repos(s3_bucket_name: str, s3_search_prefix: str, search_keyword: str, max_results: int = 10) -> dict:\n",
    "    \"\"\"\n",
    "    S3의 지정된 경로(prefix)에 저장된 파일들 내에서 특정 코드 내용을 검색하고,\n",
    "    해당 키워드가 포함된 파일의 S3 경로 목록을 반환합니다.\n",
    "    주의: 매우 큰 파일이나 많은 파일이 있는 경우 성능에 영향을 줄 수 있습니다.\n",
    "\n",
    "    Args:\n",
    "        s3_bucket_name (str): 검색할 S3 버킷 이름.\n",
    "        s3_search_prefix (str): 리포지토리 또는 파일들이 저장된 S3 내 검색 대상 경로 (prefix).\n",
    "                                예: \"user_github_repos/username/repo_name/\" 또는 \"user_github_repos/username/\"\n",
    "        search_keyword (str): 검색할 코드 문자열.\n",
    "        max_results (int, optional): 반환할 최대 결과 수. 기본값은 10.\n",
    "\n",
    "    Returns:\n",
    "        dict: 성공 여부, 메시지, 검색된 파일의 S3 경로 목록을 포함하는 딕셔너리.\n",
    "              예: {\"success\": True, \"message\": \"...\", \"found_files\": [\"s3://bucket/path/file1.py\", ...]}\n",
    "    \"\"\"\n",
    "    s3 = _get_s3_client()\n",
    "    found_files_s3_paths = []\n",
    "    files_processed_count = 0\n",
    "    search_keyword_lower = search_keyword.lower() # 대소문자 구분 없는 검색\n",
    "\n",
    "    try:\n",
    "        paginator = s3.get_paginator('list_objects_v2')\n",
    "        page_iterator = paginator.paginate(Bucket=s3_bucket_name, Prefix=s3_search_prefix)\n",
    "\n",
    "        logging.info(f\"S3 경로 's3://{s3_bucket_name}/{s3_search_prefix}'에서 '{search_keyword}' 검색 시작...\")\n",
    "        for page in page_iterator:\n",
    "            if 'Contents' not in page:\n",
    "                continue\n",
    "            for obj in page['Contents']:\n",
    "                s3_object_key = obj['Key']\n",
    "                if obj['Size'] == 0 or s3_object_key.endswith('/'): # 디렉토리 또는 빈 파일 건너뛰기\n",
    "                    continue\n",
    "\n",
    "                files_processed_count += 1\n",
    "                # logging.debug(f\"Searching in s3://{s3_bucket_name}/{s3_object_key}...\")\n",
    "                try:\n",
    "                    file_obj = s3.get_object(Bucket=s3_bucket_name, Key=s3_object_key)\n",
    "                    file_content_bytes = file_obj['Body'].read()\n",
    "\n",
    "                    # 다양한 인코딩 시도\n",
    "                    encodings_to_try = ['utf-8', 'euc-kr', 'cp949', 'latin-1', 'iso-8859-1']\n",
    "                    decoded_content = None\n",
    "                    for enc in encodings_to_try:\n",
    "                        try:\n",
    "                            decoded_content = file_content_bytes.decode(enc)\n",
    "                            break\n",
    "                        except UnicodeDecodeError:\n",
    "                            continue\n",
    "                    \n",
    "                    if decoded_content is None:\n",
    "                        # logging.warning(f\"파일 {s3_object_key} 디코딩 실패. 건너뜁니다.\")\n",
    "                        continue\n",
    "\n",
    "                    if search_keyword_lower in decoded_content.lower():\n",
    "                        s3_full_path = f\"s3://{s3_bucket_name}/{s3_object_key}\"\n",
    "                        found_files_s3_paths.append(s3_full_path)\n",
    "                        # logging.info(f\"키워드 '{search_keyword}' 발견: {s3_full_path}\")\n",
    "                        if len(found_files_s3_paths) >= max_results:\n",
    "                            msg = f\"{len(found_files_s3_paths)}개의 파일을 찾았습니다 (최대 결과 {max_results} 도달).\"\n",
    "                            logging.info(msg)\n",
    "                            return {\"success\": True, \"message\": msg, \"found_files\": found_files_s3_paths}\n",
    "                except ClientError as e:\n",
    "                    logging.warning(f\"S3 객체 ({s3_object_key}) 접근 중 오류: {e}\")\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"파일 ({s3_object_key}) 처리 중 오류: {e}\")\n",
    "        \n",
    "        if found_files_s3_paths:\n",
    "            msg = f\"총 {files_processed_count}개 파일 검색, {len(found_files_s3_paths)}개의 파일에서 키워드 발견.\"\n",
    "            logging.info(msg)\n",
    "            return {\"success\": True, \"message\": msg, \"found_files\": found_files_s3_paths}\n",
    "        else:\n",
    "            msg = f\"총 {files_processed_count}개 파일 검색, 키워드 '{search_keyword}'를 포함하는 파일을 찾지 못했습니다.\"\n",
    "            logging.info(msg)\n",
    "            return {\"success\": True, \"message\": msg, \"found_files\": []}\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"코드 검색 중 오류 발생: {e}\")\n",
    "        return {\"success\": False, \"message\": f\"코드 검색 중 오류 발생: {e}\", \"found_files\": []}\n",
    "\n",
    "def get_code_from_s3_path(s3_full_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    S3 파일 경로 (s3://bucket_name/path/to/object_key)를 입력받아\n",
    "    해당 파일의 전체 내용을 문자열로 반환합니다.\n",
    "\n",
    "    Args:\n",
    "        s3_full_path (str): S3 파일의 전체 경로 (예: \"s3://my-bucket/user_repos/username/repo/file.py\").\n",
    "\n",
    "    Returns:\n",
    "        dict: 성공 여부, 메시지, 파일 내용(문자열), 감지된 인코딩, S3 경로를 포함하는 딕셔너리.\n",
    "              예: {\"success\": True, \"message\":\"...\", \"content\": \"코드 내용...\", \"encoding\":\"utf-8\", \"s3_path\": \"...\"}\n",
    "    \"\"\"\n",
    "    if not s3_full_path.startswith(\"s3://\"):\n",
    "        msg = \"잘못된 S3 경로 형식입니다. 's3://bucket_name/object_key' 형식으로 입력해주세요.\"\n",
    "        logging.warning(msg)\n",
    "        return {\"success\": False, \"message\": msg, \"content\": None}\n",
    "\n",
    "    try:\n",
    "        path_parts = s3_full_path.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "        if len(path_parts) < 2: # 버킷 이름만 있고 키가 없는 경우\n",
    "            msg = \"S3 경로에 객체 키(파일 경로)가 누락되었습니다.\"\n",
    "            logging.warning(msg)\n",
    "            return {\"success\": False, \"message\": msg, \"content\": None}\n",
    "        s3_bucket_name, s3_object_key = path_parts\n",
    "\n",
    "        s3 = _get_s3_client()\n",
    "        logging.info(f\"S3에서 파일 가져오는 중: s3://{s3_bucket_name}/{s3_object_key}\")\n",
    "        file_obj = s3.get_object(Bucket=s3_bucket_name, Key=s3_object_key)\n",
    "        file_content_bytes = file_obj['Body'].read()\n",
    "\n",
    "        encodings_to_try = ['utf-8', 'euc-kr', 'cp949', 'latin-1', 'iso-8859-1']\n",
    "        decoded_content = None\n",
    "        detected_encoding = None\n",
    "        for enc in encodings_to_try:\n",
    "            try:\n",
    "                decoded_content = file_content_bytes.decode(enc)\n",
    "                detected_encoding = enc\n",
    "                break\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "        \n",
    "        if decoded_content is None:\n",
    "            msg = f\"파일 내용을 일반적인 인코딩으로 디코딩할 수 없습니다: {s3_full_path}. 원본 바이트를 반환 시도할 수 있으나, 여기서는 오류로 처리합니다.\"\n",
    "            logging.warning(msg)\n",
    "            # 필요시 file_content_bytes.hex() 또는 base64 인코딩된 문자열 반환 고려\n",
    "            return {\"success\": False, \"message\": msg, \"content\": None, \"s3_path\": s3_full_path}\n",
    "\n",
    "        msg = f\"파일 내용 가져오기 성공 (감지된 인코딩: {detected_encoding}).\"\n",
    "        logging.info(msg)\n",
    "        return {\"success\": True, \"message\": msg, \"content\": decoded_content, \"encoding\": detected_encoding, \"s3_path\": s3_full_path}\n",
    "\n",
    "    except ClientError as e:\n",
    "        error_code = e.response.get('Error', {}).get('Code')\n",
    "        if error_code == 'NoSuchKey':\n",
    "            msg = f\"S3에서 파일을 찾을 수 없습니다: {s3_full_path}\"\n",
    "            logging.warning(msg)\n",
    "            return {\"success\": False, \"message\": msg, \"content\": None}\n",
    "        elif error_code == 'NoSuchBucket':\n",
    "            msg = f\"S3 버킷 '{s3_bucket_name}'을 찾을 수 없습니다.\"\n",
    "            logging.error(msg)\n",
    "            return {\"success\": False, \"message\": msg, \"content\": None}\n",
    "        else:\n",
    "            logging.error(f\"S3에서 파일 가져오는 중 ClientError 발생 ({s3_full_path}): {e}\")\n",
    "            return {\"success\": False, \"message\": f\"S3 파일 접근 오류: {e}\", \"content\": None}\n",
    "    except Exception as e:\n",
    "        logging.error(f\"S3 파일 내용 가져오는 중 예외 발생 ({s3_full_path}): {e}\")\n",
    "        return {\"success\": False, \"message\": f\"파일 내용 처리 중 오류: {e}\", \"content\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605a1a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 18:30:55,422 - INFO - 사용자 'HIHO999'의 리포지토리 목록을 가져옵니다...\n",
      "2025-06-05 18:30:56,412 - INFO - '-' 리포지토리를 로컬에 복제 중... (https://github.com/HIHO999/-.git)\n",
      "2025-06-05 18:30:57,872 - INFO - '-' 복제 완료. S3에 업로드 중... (s3://code-agent/user_github_repos/HIHO999/-)\n",
      "2025-06-05 18:30:57,881 - INFO - Found credentials in environment variables.\n",
      "2025-06-05 18:30:58,945 - INFO - S3 클라이언트 생성 성공.\n",
      "2025-06-05 18:30:58,946 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\README.md to s3://code-agent/user_github_repos/HIHO999/-/README.md\n",
      "2025-06-05 18:31:00,008 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\config to s3://code-agent/user_github_repos/HIHO999/-/.git/config\n",
      "2025-06-05 18:31:00,484 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\description to s3://code-agent/user_github_repos/HIHO999/-/.git/description\n",
      "2025-06-05 18:31:00,936 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\HEAD to s3://code-agent/user_github_repos/HIHO999/-/.git/HEAD\n",
      "2025-06-05 18:31:01,378 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\index to s3://code-agent/user_github_repos/HIHO999/-/.git/index\n",
      "2025-06-05 18:31:01,820 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\packed-refs to s3://code-agent/user_github_repos/HIHO999/-/.git/packed-refs\n",
      "2025-06-05 18:31:02,283 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\hooks\\applypatch-msg.sample to s3://code-agent/user_github_repos/HIHO999/-/.git/hooks/applypatch-msg.sample\n",
      "2025-06-05 18:31:02,899 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\hooks\\commit-msg.sample to s3://code-agent/user_github_repos/HIHO999/-/.git/hooks/commit-msg.sample\n",
      "2025-06-05 18:31:03,352 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\hooks\\fsmonitor-watchman.sample to s3://code-agent/user_github_repos/HIHO999/-/.git/hooks/fsmonitor-watchman.sample\n",
      "2025-06-05 18:31:03,797 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\hooks\\post-update.sample to s3://code-agent/user_github_repos/HIHO999/-/.git/hooks/post-update.sample\n",
      "2025-06-05 18:31:04,287 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\hooks\\pre-applypatch.sample to s3://code-agent/user_github_repos/HIHO999/-/.git/hooks/pre-applypatch.sample\n",
      "2025-06-05 18:31:04,725 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\hooks\\pre-commit.sample to s3://code-agent/user_github_repos/HIHO999/-/.git/hooks/pre-commit.sample\n",
      "2025-06-05 18:31:05,173 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\hooks\\pre-merge-commit.sample to s3://code-agent/user_github_repos/HIHO999/-/.git/hooks/pre-merge-commit.sample\n",
      "2025-06-05 18:31:05,617 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\hooks\\pre-push.sample to s3://code-agent/user_github_repos/HIHO999/-/.git/hooks/pre-push.sample\n",
      "2025-06-05 18:31:06,080 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\hooks\\pre-rebase.sample to s3://code-agent/user_github_repos/HIHO999/-/.git/hooks/pre-rebase.sample\n",
      "2025-06-05 18:31:06,541 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\hooks\\pre-receive.sample to s3://code-agent/user_github_repos/HIHO999/-/.git/hooks/pre-receive.sample\n",
      "2025-06-05 18:31:06,982 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\hooks\\prepare-commit-msg.sample to s3://code-agent/user_github_repos/HIHO999/-/.git/hooks/prepare-commit-msg.sample\n",
      "2025-06-05 18:31:07,488 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\hooks\\push-to-checkout.sample to s3://code-agent/user_github_repos/HIHO999/-/.git/hooks/push-to-checkout.sample\n",
      "2025-06-05 18:31:07,947 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\hooks\\sendemail-validate.sample to s3://code-agent/user_github_repos/HIHO999/-/.git/hooks/sendemail-validate.sample\n",
      "2025-06-05 18:31:08,388 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\hooks\\update.sample to s3://code-agent/user_github_repos/HIHO999/-/.git/hooks/update.sample\n",
      "2025-06-05 18:31:08,834 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\info\\exclude to s3://code-agent/user_github_repos/HIHO999/-/.git/info/exclude\n",
      "2025-06-05 18:31:09,277 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\logs\\HEAD to s3://code-agent/user_github_repos/HIHO999/-/.git/logs/HEAD\n",
      "2025-06-05 18:31:09,721 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\logs\\refs\\heads\\main to s3://code-agent/user_github_repos/HIHO999/-/.git/logs/refs/heads/main\n",
      "2025-06-05 18:31:10,144 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\logs\\refs\\remotes\\origin\\HEAD to s3://code-agent/user_github_repos/HIHO999/-/.git/logs/refs/remotes/origin/HEAD\n",
      "2025-06-05 18:31:10,603 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\objects\\pack\\pack-d90899964f065137739f6861c4a614df235a02a4.idx to s3://code-agent/user_github_repos/HIHO999/-/.git/objects/pack/pack-d90899964f065137739f6861c4a614df235a02a4.idx\n",
      "2025-06-05 18:31:11,042 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\objects\\pack\\pack-d90899964f065137739f6861c4a614df235a02a4.pack to s3://code-agent/user_github_repos/HIHO999/-/.git/objects/pack/pack-d90899964f065137739f6861c4a614df235a02a4.pack\n",
      "2025-06-05 18:31:11,733 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\objects\\pack\\pack-d90899964f065137739f6861c4a614df235a02a4.rev to s3://code-agent/user_github_repos/HIHO999/-/.git/objects/pack/pack-d90899964f065137739f6861c4a614df235a02a4.rev\n",
      "2025-06-05 18:31:12,515 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\refs\\heads\\main to s3://code-agent/user_github_repos/HIHO999/-/.git/refs/heads/main\n",
      "2025-06-05 18:31:13,287 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpwbvsp6fa\\-\\.git\\refs\\remotes\\origin\\HEAD to s3://code-agent/user_github_repos/HIHO999/-/.git/refs/remotes/origin/HEAD\n",
      "2025-06-05 18:31:13,798 - INFO - '250122' 리포지토리를 로컬에 복제 중... (https://github.com/HIHO999/250122.git)\n",
      "2025-06-05 18:31:15,459 - INFO - '250122' 복제 완료. S3에 업로드 중... (s3://code-agent/user_github_repos/HIHO999/250122)\n",
      "2025-06-05 18:31:16,784 - INFO - S3 클라이언트 생성 성공.\n",
      "2025-06-05 18:31:16,786 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpks9lkdtd\\250122\\.git\\config to s3://code-agent/user_github_repos/HIHO999/250122/.git/config\n",
      "2025-06-05 18:31:18,255 - INFO - Uploading C:\\Users\\in904\\AppData\\Local\\Temp\\tmpks9lkdtd\\250122\\.git\\description to s3://code-agent/user_github_repos/HIHO999/250122/.git/description\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m s3_bucket_name = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mS3_BUCKET_NAME\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m s3_base_path = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mS3_BASE_PATH\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33muser_github_repos\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mclone_all_user_repos_to_s3\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgithub_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgithub_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43ms3_bucket_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43ms3_bucket_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43ms3_base_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43ms3_base_path\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m upload_directory_to_s3()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 108\u001b[39m, in \u001b[36mclone_all_user_repos_to_s3\u001b[39m\u001b[34m(github_token, s3_bucket_name, s3_base_path)\u001b[39m\n\u001b[32m    106\u001b[39m GitRepo.clone_from(clone_url_with_token, local_repo_path)\n\u001b[32m    107\u001b[39m logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m 복제 완료. S3에 업로드 중... (s3://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms3_bucket_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms3_repo_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m \u001b[43m_upload_directory_to_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_repo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3_bucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3_repo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m cloned_s3_paths.append(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33ms3://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms3_bucket_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms3_repo_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    110\u001b[39m repos_cloned_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36m_upload_directory_to_s3\u001b[39m\u001b[34m(local_directory, bucket_name, s3_prefix)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     60\u001b[39m     logging.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUploading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to s3://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms3_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     \u001b[43ms3\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     63\u001b[39m     logging.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mS3 업로드 실패 (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\SKN10-FINAL-1Team\\.venv\\Lib\\site-packages\\botocore\\context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\SKN10-FINAL-1Team\\.venv\\Lib\\site-packages\\boto3\\s3\\inject.py:175\u001b[39m, in \u001b[36mupload_file\u001b[39m\u001b[34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Upload a file to an S3 object.\u001b[39;00m\n\u001b[32m    141\u001b[39m \n\u001b[32m    142\u001b[39m \u001b[33;03mUsage::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    172\u001b[39m \u001b[33;03m    transfer.\u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\SKN10-FINAL-1Team\\.venv\\Lib\\site-packages\\boto3\\s3\\transfer.py:372\u001b[39m, in \u001b[36mS3Transfer.upload_file\u001b[39m\u001b[34m(self, filename, bucket, key, callback, extra_args)\u001b[39m\n\u001b[32m    368\u001b[39m future = \u001b[38;5;28mself\u001b[39m._manager.upload(\n\u001b[32m    369\u001b[39m     filename, bucket, key, extra_args, subscribers\n\u001b[32m    370\u001b[39m )\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[32m    376\u001b[39m \u001b[38;5;66;03m# client error.\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\SKN10-FINAL-1Team\\.venv\\Lib\\site-packages\\s3transfer\\futures.py:114\u001b[39m, in \u001b[36mTransferFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m.cancel()\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\SKN10-FINAL-1Team\\.venv\\Lib\\site-packages\\s3transfer\\futures.py:111\u001b[39m, in \u001b[36mTransferFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    108\u001b[39m         \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[32m    109\u001b[39m         \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[32m    110\u001b[39m         \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_coordinator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    113\u001b[39m         \u001b[38;5;28mself\u001b[39m.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\SKN10-FINAL-1Team\\.venv\\Lib\\site-packages\\s3transfer\\futures.py:282\u001b[39m, in \u001b[36mTransferCoordinator.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Waits until TransferFuture is done and returns the result\u001b[39;00m\n\u001b[32m    273\u001b[39m \n\u001b[32m    274\u001b[39m \u001b[33;03mIf the TransferFuture succeeded, it will return the result. If the\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[33;03mTransferFuture failed, it will raise the exception associated to the\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[33;03mfailure.\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    278\u001b[39m \u001b[38;5;66;03m# Doing a wait() with no timeout cannot be interrupted in python2 but\u001b[39;00m\n\u001b[32m    279\u001b[39m \u001b[38;5;66;03m# can be interrupted in python3 so we just wait with the largest\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[38;5;66;03m# possible value integer value, which is on the scale of billions of\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[38;5;66;03m# years...\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_done_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMAXINT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Once done waiting, raise an exception if present or return the\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[38;5;66;03m# final result.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\threading.py:629\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    627\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "github_token = os.getenv(\"GITHUB_TOKEN\", \"\")\n",
    "s3_bucket_name = os.getenv(\"S3_BUCKET_NAME\", \"\")\n",
    "s3_base_path = os.getenv(\"S3_BASE_PATH\", \"user_github_repos\")\n",
    "\n",
    "clone_all_user_repos_to_s3(\n",
    "    github_token=github_token,\n",
    "    s3_bucket_name=s3_bucket_name,\n",
    "    s3_base_path=s3_base_path\n",
    ")\n",
    "upload_directory_to_s3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b414e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS environment variables present: ['AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'AWS_DEFAULT_REGION']\n",
      "Successfully connected to S3. Available buckets: ['code-agent']\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Print the available environment variables for AWS (without showing actual secrets)\n",
    "aws_env_vars = [key for key in os.environ.keys() if 'AWS' in key]\n",
    "print(f\"AWS environment variables present: {aws_env_vars}\")\n",
    "\n",
    "# Test if your credentials can list buckets (requires minimal permissions)\n",
    "try:\n",
    "    s3 = boto3.client('s3')\n",
    "    buckets = s3.list_buckets()\n",
    "    print(f\"Successfully connected to S3. Available buckets: {[b['Name'] for b in buckets['Buckets']]}\")\n",
    "except Exception as e:\n",
    "    print(f\"S3 connection test failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bd810f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'code-agent' exists and is accessible\n"
     ]
    }
   ],
   "source": [
    "# Add this to your script to check specific bucket permissions\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "bucket_name = \"code-agent\"\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Check if bucket exists and is accessible\n",
    "try:\n",
    "    s3_client.head_bucket(Bucket=bucket_name)\n",
    "    print(f\"Bucket '{bucket_name}' exists and is accessible\")\n",
    "except ClientError as e:\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if error_code == '404':\n",
    "        print(f\"Bucket '{bucket_name}' does not exist\")\n",
    "    elif error_code == '403':\n",
    "        print(f\"You don't have access to bucket '{bucket_name}'\")\n",
    "    else:\n",
    "        print(f\"Error checking bucket: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
