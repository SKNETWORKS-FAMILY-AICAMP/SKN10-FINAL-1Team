2025-06-29 20:29:00,127 - INFO - PROMPT: 
Analyze the following codebase for the project 'SKN10-1st-4Team'.

Available files (total 11):
- 0 # 1_연도별_자동차_등록_현황.py
- 1 # README.md
- 2 # common/insert_data.py
- 3 # common/insert_data_city.py
- 4 # crawling/danawa.py
- 5 # crawling/genesis_faq.py
- 6 # crawling/hyundai_faq.py
- 7 # crawling/kia_faq.py
- 8 # pages/2_지역별_자동차_등록_현황.py
- 9 # pages/3_브랜드별_자동차_판매_현황.py
- 10 # pages/4_주요_3개_기업_차량_구매_FAQ.py

Full context of all files:
--- File Index 0: 1_연도별_자동차_등록_현황.py ---
#test
import streamlit as st
import pandas as pd
import plotly.express as px
import pymysql
from common.insert_data import insert_data
from common.insert_data_city import insert_data_city

insert_data()
insert_data_city()

st.set_page_config(layout="centered")

st.title("📊 연도별 자동차 등록 현황")
st.divider()

# 데이터베이스 연결 설정
connection = pymysql.connect(
    host="localhost",
    user="SKN10_4team",
    password="skn1234",
    database="SKN10_4team_1st",
    charset="utf8"
)

# SQL 데이터 가져오기
year_data = "select Year FROM Car"
ef = pd.read_sql(year_data, connection)

car_data = """
SELECT Year, SUM(CarCount) YearofCar
FROM SKN10_4team_1st.Car
GROUP BY Year
ORDER BY Year;
"""
cf = pd.read_sql(car_data, connection)

# Streamlit 컨테이너
with st.container():
    # 컬럼 레이아웃 사용
    col1, col2 = st.columns(2)
    # 년도 리스트 생성 및 선택
    years = ef['Year'].unique().tolist()

    # 디폴트 값 설정
    default_start_year_index = 0  # 첫 번째 연도를 디폴트로 설정
    default_end_year_index = len(years) - 1  # 마지막 연도를 디폴트로 설정

    with col1:
        start_year = st.selectbox(
            '첫번째 년도를 선택해주세요.', 
            years, 
            index=default_start_year_index
        )

    with col2:
        end_year = st.selectbox(
            '마지막 년도를 선택해주세요.', 
            years, 
            index=default_end_year_index
        )

# 연도 범위 확인 및 데이터 필터링
if start_year > end_year:
    st.error("Error: The start year cannot be greater than the end year.")
else:
    with st.container():
        # 사용자 입력 값으로 데이터 필터링
        filtered_data = cf[(cf["Year"] >= start_year) & (cf["Year"] <= end_year)]

        # Plotly로 그래프 생성
        fig = px.bar(
            filtered_data, 
            x="Year", 
            y="YearofCar", 
            title="조회결과"
        )

        # axis title 업데이트
        fig.update_xaxes(title_text="연도")
        fig.update_yaxes(title_text="차량 수 (만대)")

        # 그래프 출력
        st.plotly_chart(fig)

}]}

--- File Index 1: README.md ---
# SKN10-1st-4Team
<br/>

![](https://cdn.imweb.me/upload/S20240314bd10436a7991a/41a9769cc44e6.png)
<br/>
<br/>

## ⭐ 프로젝트 팀
<br/>

| 좌민서 | 김민혜 | 박예슬 | 신민주 | 홍승표 | 황인호 |
| :---: | :---: | :---: | :---: | :---: | :---: |
| - 팀장<br/>- 지역별 자동차 등록 현황<br/>(그래프) | - ERD 설계<br/>- DB 구현 | - ERD 설계<br/>- 현대자동차 FAQ | - 화면 설계<br/>- 제네시스 FAQ | - 라이브러리 조사<br/>- 연도별 자동차 등록 현황 | - 화면 설계<br/>- 기아자동차 FAQ<br/>- 지역별 자동차 등록 현황<br/>(지도)<br/>- 브랜드별 자동차 판매 현황
| [@INe](https://github.com/INe904) | [@kkminhye](https://github.com/kkminhye) | [@yeseulnim](https://github.com/yeseulnim) | [@sinminju](https://github.com/sinminju) | [@redwin02](https://github.com/redwin-02) | [@HIHO9999](https://github.com/HIHO999) |
<br/>

## 📌 프로젝트 개요
<br/>

### 프로젝트 주제
<br/>

**전국 자동차 등록 현황 및 기업 FAQ 조회 시스템**
<br/>
<br/>

### 프로젝트 목적
<br/>

1. 전국 자동차 등록 현황을 연도별 및 지역별로 분석하여, **자동차 증가 추세와 지역별 특성을 파악**한다. 이를 통해 **교통 정책 수립 및 지역 발전 전략**에 기여할 수 있는 정보를 제공한다.
<br/>

2. 국내 브랜드별 자동차 구매통계 및 3대 자동차 기업의 차량구매 관련 FAQ 정보를 한 곳에 모아, **자동차 구매 예정 소비자에게 필요한 정보**를 제공한다.
<br/>
<br/>

### 프로젝트 필요성
<br/>

1. 자동차 등록 현황은 도시 교통 문제, 환경 정책, 도로 인프라 계획 등과 밀접하게 연관되어 있다.
<br/>

2. 연도별 및 지역별 자동차 등록 현황 데이터를 시각화하여, 공공 및 민간 부분에서 데이터 기반 정책 결정을 지원한다.
<br/>

3. 자동차 구매를 고려하는 소비자는 브랜드별 차량 등록 현황과 차량 구매 관련 정보를 한눈에 확인하기 어려운 경우가 많다. 국내 브랜드별 자동차 구매 통계와 주요 자동차 기업의 FAQ 정보를 통합 제공함으로써, 소비자들이 보다 신속하고 정확한 의사 결정을 할 수 있도록 돕는다.
<br/>

### 프로젝트 내용
<br/>

 1. **데이터 수집 및 가공**
<br/>

- <b>[지표누리](https://www.index.go.kr/unity/potal/main/EachDtlPageDetail.do?idx_cd=1257)</b>에서 제공하는 연도별 및 지역별 자동차 등록 현황 데이터를 수집하여 목적에 맞게 가공한 후, 데이터베이스에 저장한다.
<br/>

- 국내 판매율이 가장 높은 주요 3개 자동차 회사(<b>[현대](https://www.hyundai.com/kr/ko/e/customer/center/faq)</b>, <b>[기아](https://www.kia.com/kr/customer-service/center/faq)</b>, <b>[제네시스](https://www.genesis.com/kr/ko/support/faq.html)</b>)의 차량 구매 FAQ를 Selenium을 이용하여 크롤링한 뒤 JSON 파일로 저장한다.
<br/>

- 다나와의 <b>[자동차 판매 실적](https://auto.danawa.com/auto/?Work=record&pcUse=y)</b> 페이지에서 제공하는 브랜드별 자동차 판매 실적을 Selenium을 이용하여 크롤링한 뒤 CSV 파일로 저장한다.

<br/>

2. **데이터 시각화**
<br/>

- 수집한 자동차 통계 관련 데이터를 Python의 **Plotly**, **MatPlotLib** 및 **Folium** 라이브러리를 통해 시각화한다.
<br/>

3. **FAQ 제공**
<br/>

- 크롤링한 주요 자동차 브랜드의 FAQ 내용을 한곳에 모아, 검색 기능과 함께 제공한다.
<br/>

### 프로젝트 기대 효과
<br/>

1. **연도별 및 지역별 자동차 등록 현황의 시각적 자료**를 제공하여 데이터를 직관적으로 파악할 수 있다.
<br/>

2. **교통 및 환경 정책 수립**을 위한 기초 데이터를 제공한다.
<br/>

3. **브랜드별 차량 판매량** 및 **기업 FAQ 조회 시스템**을 통해 소비자의 정보 접근성을 높인다.
<br/>
<br/>

## 📌 설치/사용 방법
<br/>

### 1. GitHub에서 Repository Clone
<br/>

```python
    git clone https://github.com/SKNETWORKS-FAMILY-AICAMP/SKN10-1st-4Team.git
```
<br/>

### 2. 라이브러리 설치
<br/>

```python
    pip install -r requirements.txt
```
<br/>

### 3. 데이터베이스 구축
DBeaver 실행 후, 계정생성 권한 있는 계정에서 sql\create_tables.sql 파일의 코드 실행
<br/>

### 4. (생략 가능) 정보 수집 - 웹 크롤링 코드 실행
<br/>

※ 웹 크롤링 결과물은 data 폴더에 json 파일로 저장되어 있으므로, 별도의 크롤링 없이 바로 실행이 가능하다. 다만, 신규 데이터 확인을 위해 웹 크롤링이 필요한 경우 아래 코드를 사용할 수 있다.
<br/>

```python
    python crawling/kia_faq.py
```
```python
    python crawling/hyundai_faq.py
```
```python
    python crawling/genesis_faq.py
```
```python
    python crawling/danawa.py
```
<br/>

### 5. 서비스 실행
<br/>

```python
    streamlit run 1_연도별_자동차_등록_현황.py
```
<br/>
<br/>

## 📌 기술 스택
<br/>

### 화면 설계
<br/>

![](https://img.shields.io/badge/Figma-F24E1E?style=for-the-badge&logo=figma&logoColor=white)
<br/>

### 데이터 가공 및 처리
<br/>

![](https://img.shields.io/badge/MySQL-4479A1?style=for-the-badge&logo=mysql&logoColor=white) &nbsp; ![](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=white)
<br/>

### 화면 구현
<br/>

![](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=white) &nbsp; ![](https://img.shields.io/badge/streamlit-FF0000?style=for-the-badge&logo=streamlit&logoColor=white)
<br/>

### 버전 관리 및 협업
<br/>

![](https://img.shields.io/badge/github-000000?style=for-the-badge&logo=github&logoColor=white)
<br/>
<br/>

## 💻 화면 설계
<br/>

### 0. 메뉴
<br/>

![](/images/menu_design.png)
<br/>

### 1. 연도별 자동차 등록 현황
<br/>

![](/images/year_design.png)
<br/>

### 2. 지역별 자동차 등록 현황
<br/>

![](/images/region_design.png)
<br/>

### 3. 주요 3개 기업 차량 구매 FAQ
<br/>

![](/images/faq_design.png)
<br/>
<br/>

## 💻 데이터 가공 및 처리
<br/>

### ERD
<br/>

![](/images/erd.png)
<br/>
<br/>

### 실제 데이터 가공 및 처리

1. **자동차 등록 현황**
<br/>

- 자료 출처 : <b>[지표누리 자동차 등록 현황](https://www.index.go.kr/unity/potal/main/EachDtlPageDetail.do?idx_cd=1257)</b> (*2012 ~ 2022)
<br/>

- 자료 가공 : 개별 Excel 파일 다운로드 -> CSV로 변경 -> MySQL 데이터베이스 테이블로 저장
<br/>

2. **주요 3개 기업 차량 구매 FAQ**
<br/>

- 자료 출처 : 국내 3대 자동차 기업 (<b>[현대](https://www.hyundai.com/kr/ko/e/customer/center/faq)</b>, <b>[기아](https://www.kia.com/kr/customer-service/center/faq)</b>, <b>[제네시스](https://www.genesis.com/kr/ko/support/faq.html)</b>) 홈페이지 'FAQ' 중 '차량 구매' 항목
<br/>

- 자료 가공 : Selenium으로 웹크롤링 -> JSON으로 저장 
<br/>

3. **브랜드별 자동차 판매 실적**
<br/>

- 자료 출처 : 다나와 <b>[자동차 판매 실적](https://auto.danawa.com/auto/?Work=record&pcUse=y)</b> 페이지 (*2021.01 ~ 2024.12)
<br/>

- 자료 가공 : Selenium으로 웹크롤링 -> CSV로 저장
<br/>
<br/>

## 📌 프로젝트 최종 결과
<br/>

### 1. 연도별 자동차 등록 현황
<br/>

![](/images/final_screen1.png)
<br/>

### 2. 지역별 자동차 등록 현황
<br/>

![](/images/final_screen2.png)
<br/>

![](/images/final_screen3.png)
<br/>

### 3. 주요 3개 기업 차량 구매 FAQ
<br/>

![](/images/final_screen4.png)
<br/>

### 4. 브랜드별 자동차 판매 순위
<br/>

![](/images/final_screen5.png)
<br/>
<br/>

## 🖥️개발과정에서 발생한 이슈 및 해결방법
<br/>

### 1. SQL DB 구축
<br/>

**문제**
<br/>

MySQL DB는 깃헙으로 동기화되지 않고 각 인원이 각자 구축해야 했기에 그 과정에서 시행착오가 있었음.
<br/>

**해결**
<br/>

실수방지를 위해 최종 코드에서는 DB및 테이블 생성 SQL코드를 별도파일로 두고, 테이블 내용 생성은 함수로 만들어 자동 실행되도록 함.
<br/>

### 2. 복잡한 SQL 저장 구조
<br/>

**문제**
<br/>

최초 기획한 ERD 구조에는 FAQ가 포함되어 있었으나, 실제 구현시 FAQ를 별도 JSON 파일에 담고 그를 MySQL 테이블로 만든뒤 이를 불러오는 과정이 비효율적이라 판단되었음. 
<br/>

**해결**
<br/>

ERD구조를 수정하여 FAQ를 ERD에서 빼고, FAQ페이지의 내용은 JSON파일에서 바로 불러오기로 함.
<br/>

### 3. 기능구현 완료후 오류 발생
<br/>

**문제**
<br/>

'현대차 FAQ' 페이지에서 검색기능 이용시, 검색결과가 없을 경우, '기아차 FAQ' 등 다른 탭으로 이동하면 탭의 내용이 나타나지 않는 버그 발생
<br/>

**해결**
<br/>

AI의 디버깅 보조를 이용, 코드를 수정하여 해결함.
<br/>
<br/>

## ✍️팀원별 느낀점
<br/>

### 좌민서
<br/>

지금까지 배운 내용을 바탕으로 응용된 내용을 활용할 수 있었던 좋은 기회가 되었습니다. 어쩌다 보니 이번에 팀장을 맡게 되었는데 많이 부족함에도 불구하고 팀원분들이 잘 따라와 주시고 도와주셔서 이번 프로젝트를 무사히 마칠 수 있었던 것 같습니다.

<br/>

### 신민주
<br/>

체계적인 프로젝트를 처음 진행해봤는데 팀워크의 중요성을 느꼈습니다. 제가 부족한 부분이 많았지만 다들 친절히 알려주셔서 배우면서 프로젝트에 참여할 수 있었습니다. 앞으로의 활동에도 좋은 경험이 될 것 같습니다.

<br/>

### 박예슬
<br/>

다인 프로젝트 깃 관리의 어려움과 중요성을 체감했습니다. 고생하신 팀장님과 팀원들에게 박수를 보냅니다.

<br/>

### 김민혜
<br/>

팀장을 맡으신 민서님이 프로젝트 전반적인 과정을 꼼꼼하게 정리하고 원할하게 진행해주셨다고 생각합니다. 각 팀원이 맡은 역할에 충실할 뿐만 아니라 가진 역량을 빛내고 서로 도와 문제를 해결하는 과정을 경험할 수 있어서 정말 좋았습니다.

<br/>

### 황인호
<br/>

팀프로젝트를  제대로 수행해본적이 처음이었지만 팀장분께서 역할분담 잘해주셔서 맡은바 열심히 그리고 만족스럽게 수행한것같습니다. 앞으로의 협력 업무에 있어서 좋은 경험이 되었습니다.

<br/>

### 홍승표
<br/>

저는 사람이 아닙니다. 몽키입니다. 아닙니다. 코드도 못치니 그냥 몽키입니다. 열심히 배워서 코드몽키라도 될 수 있도록 노력하겠습니다. 그리고 능력자이신 팀원분들을 만나 너무 좋았습니다. 몽키 한 마리 만나서 고생한 팀원들에게 너무 고맙고 다음 프로젝트때는 버스 타기실 기도하겠습니다. 
<br/>


--- File Index 2: common/insert_data.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "Car.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "Car"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (Year, CityID, CarCount) VALUES (%s, %s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[2], row[3])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File Index 3: common/insert_data_city.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data_city():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "City.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "City"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (CityID, CityName) VALUES (%s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[1])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File Index 4: crawling/danawa.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By


import pandas as pd
import time

# 크롬 드라이버 설정

driver = webdriver.Chrome()

# 데이터 저장 리스트
domestic_data = []
foreign_data = []

# 2021년 1월부터 2024년 12월까지의 URL 생성 및 데이터 크롤링
for year in range(2021, 2025):
    for month in range(1, 13):
        if year == 2024 and month > 12:
            break
        month_str = f"{year}-{month:02d}-00"
        url = f"https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month={month_str}&MonthTo="
        driver.get(url)
        time.sleep(0.5)  # 페이지 로딩 대기

        # 국산차 순위 데이터 크롤링
        rank_elements = driver.find_elements(By.CSS_SELECTOR, "ul.sideRankR li")

        for index, rank_element in enumerate(rank_elements):
            rank = rank_element.find_element(By.CSS_SELECTOR, "span.rank").text
            brand = rank_element.find_element(By.CSS_SELECTOR, "span.title").text.strip()
            sales = rank_element.find_element(By.CSS_SELECTOR, "span.sales").text
            rate = rank_element.find_element(By.CSS_SELECTOR, "span.rate").text
            logo_img = rank_element.find_element(By.CSS_SELECTOR, "span.title img").get_attribute("src")
            data = [year, month, rank, brand, sales, rate, logo_img]
            if index < 6:
                domestic_data.append(data)
            else:
                foreign_data.append(data)

# 데이터프레임으로 변환
domestic_df = pd.DataFrame(domestic_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])
foreign_df = pd.DataFrame(foreign_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])

# 데이터프레임 저장
domestic_df.to_csv("data\국산차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')
foreign_df.to_csv("data\해외차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')

# 드라이버 종료
driver.quit()

print("크롤링 완료 및 데이터 저장 완료")
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo=
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo= 에서 2021-01은 21년 1월 데이터를 받아온다는 의미


--- File Index 5: crawling/genesis_faq.py ---

# 제네시스 크롤링
from selenium import webdriver
from bs4 import BeautifulSoup
import json

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.genesis.com/kr/ko/support/faq/vehicle-purchase.html?anchorID=faq_tab"
driver.get(url)

# 페이지 소스 가져오기
html_source = driver.page_source

# HTML 파일로 저장
#with open("genesis_faq.html", "w", encoding="utf-8") as file:
#    file.write(html_source)

# 드라이버 종료
driver.quit()

# BeautifulSoup을 사용하여 페이지 소스 파싱
soup = BeautifulSoup(html_source, 'html.parser')

# FAQ 질문과 답변 추출
faqs = []
faq_items = soup.select('.cp-faq__accordion-item')  # FAQ 항목을 감싸는 클래스 이름을 사용하여 선택

for item in faq_items:
    question = item.select_one('.accordion-title').get_text(strip=True)
    answer = item.select_one('.accordion-panel-inner').get_text(strip=True)
    faqs.append({'question': question, 'answer': answer})

# 추출한 FAQ를 파일로 저장
with open("data\genesis_faq.json", "w", encoding="utf-8") as file:
    json.dump(faqs, file, ensure_ascii=False, indent=4)

--- File Index 6: crawling/hyundai_faq.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from time import sleep

#import pandas as pd
import json


URL = "https://www.hyundai.com/kr/ko/e/customer/center/faq"

driver = webdriver.Chrome()
driver.get(URL)
# 리스트에 딕셔너리로 내용 저장
qna_list = []

for page_id in range(4):
    for question_id in range(1,11):
        try:
            #엘리먼트 찾기
            faq_list = driver.find_element(By.CSS_SELECTOR, "div[data-v-28d34f54].list-wrap")

            try:
                # 플로팅 메뉴 제거
                floating_menu = driver.find_element(By.CSS_SELECTOR, "div[data-v-1ea4ba2d].inner_wrap")
                driver.execute_script("arguments[0].remove();", floating_menu)
            except:
                pass
            faq_title = faq_list.find_elements(By.CSS_SELECTOR,f"div[data-id='{question_id}'] button.list-title")
            driver.execute_script("arguments[0].scrollIntoView({block:'center'});",faq_title[0])
            sleep(0.5)

            #질문타이틀 클릭하기
            faq_title[0].click()
            sleep(0.5)

            #질문타이틀 텍스트 받아오기
            faq_question = faq_title[0].find_element(By.CSS_SELECTOR, "span.list-content[data-v-28d34f54]")
            faq_question_text = faq_question.text
            #print(faq_question_text)

            #질문답변 텍스트 받아오기
            faq_answer = driver.find_element(By.CLASS_NAME, "conts")
            faq_answer_text = faq_answer.text
            #print("전체 답변:", faq_answer_text)

            # 링크 URL 가져오기
            try:
                link_whole = faq_answer.find_elements(By.TAG_NAME, "a")
                link = {
                    "url" : link_whole[0].get_attribute("href"),
                    "text" : link_whole[0].text
                    }
            except:
                link = ""
            #print("링크 URL:", url)
            
            qna_list.append({"question": faq_question_text, "answer": faq_answer_text, "link": link})

        except TimeoutException:
            print("Timed out waiting for page to load")
        except NoSuchElementException:
            print("Could not find the element")
        except IndexError:
            pass

    next_button = driver.find_element(By.CSS_SELECTOR, "button.btn-next")
    next_button.click()
    sleep(1)
 
#qna_df = pd.DataFrame(qna_list, columns = ["page_num","question_num","question","answer","link"])
#qna_df.to_csv(path_or_buf="data/hyundai_qna.csv")

# 결과를 JSON 파일로 저장
with open("data\hyundai_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(qna_list, json_file, ensure_ascii=False, indent=4)

--- File Index 7: crawling/kia_faq.py ---
import json
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.kia.com/kr/customer-service/center/faq"
driver.get(url)

# 페이지가 완전히 로드될 때까지 대기
WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, "body")))

# "TOP 10" 버튼 클릭
top_10_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//button[contains(text(), 'TOP 10')]"))
)
top_10_button.click()

# "차량 구매" 버튼 클릭
car_purchase_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//li[button/span[text()='차량 구매']]"))
)
car_purchase_button.click()

# 3초 텀을 둠
time.sleep(3)

# 각 질문 클릭하여 답변 가져오기
faq_data = []

def get_faq_data():
    # FAQ 항목이 로드될 때까지 대기
    WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

    # FAQ 항목들 찾기
    faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")

    for i in range(len(faq_items)):
        # 각 질문을 클릭하기 전에 요소를 다시 찾음
        faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")
        item = faq_items[i]
        question = item.find_element(By.CSS_SELECTOR, ".cmp-accordion__title").text
        item.click()  # 질문 클릭하여 답변 표시

        # 답변이 로드될 때까지 대기
        panel_id = item.get_attribute("aria-controls")
        WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.ID, panel_id)))
        answer_element = driver.find_element(By.ID, panel_id)
        answer = answer_element.text

        # 하이퍼링크 정보 가져오기
        links = []
        link_elements = answer_element.find_elements(By.TAG_NAME, "a")
        for link in link_elements:
            links.append({
                "href": link.get_attribute("href"),
                "text": link.text
            })

        # 이미지 링크 정보 가져오기
        images = []
        image_elements = answer_element.find_elements(By.TAG_NAME, "img")
        for img in image_elements:
            images.append({
                "src": img.get_attribute("src"),
                "alt": img.get_attribute("alt")
            })

        faq_data.append({
            "question": question,
            "answer": answer,
            "links": links,
            "images": images
        })

    # 스크롤을 맨 위로 올리기
    driver.execute_script("window.scrollTo(0, 0);")

# 첫 페이지의 FAQ 데이터 가져오기
get_faq_data()

# 페이지 넘기기
current_page = 1
while current_page < 4:
    try:
        next_page = str(current_page + 1)

        # 다음 페이지 번호 클릭
        next_page_element = driver.find_element(By.XPATH, f"//ul[@class='paging-list']//a[text()='{next_page}']")
        next_page_element.click()

        # 3초 텀을 둠
        time.sleep(3)

        # 다음 페이지가 로드될 때까지 대기
        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

        # 각 페이지의 FAQ 데이터를 가져오기 전에 요소를 다시 찾음
        get_faq_data()

        current_page += 1
    except Exception as e:
        print(f"Error: {e}")
        break

# 드라이버 종료
driver.quit()

# 결과를 JSON 파일로 저장
with open("/data/kia_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(faq_data, json_file, ensure_ascii=False, indent=4)

# 결과 출력
'''
for faq in faq_data:
    print(f"Question: {faq['question']}")
    print(f"Answer: {faq['answer']}")
    print(f"Links: {faq['links']}")
    print(f"Images: {faq['images']}\n")
'''

--- File Index 8: pages/2_지역별_자동차_등록_현황.py ---
import streamlit as st
import pymysql
import pandas as pd
import plotly.express as px
import folium
import random
from streamlit_folium import folium_static

st.set_page_config(layout="wide")

st.title("📊 지역별 자동차 등록 현황")

tab1, tab2 = st.tabs(['차트', '지도'])

with tab1:
    # Database 연결
    connection = pymysql.connect(
        host = "localhost",
        user = "SKN10_4team",
        password = "skn1234",
        database = "SKN10_4team_1st",
        charset = "utf8"
    )

    cursor = connection.cursor(pymysql.cursors.DictCursor)

    year_data = """
    SELECT DISTINCT year
    FROM Car
    ;
    """
    cursor.execute(year_data)
    years = cursor.fetchall()
    year_list = [year['year'] for year in years]

    with st.container(border=True):
        selected_year = st.selectbox("연도를 선택하세요:", year_list, index=year_list.index('2022'))

    car_data = f"""
    SELECT City.CityName, Car.CarCount, Car.CityID
    FROM Car
    JOIN City ON Car.CityID = City.CityID
    WHERE Car.Year = {selected_year}
    ;
    """
    cursor.execute(car_data)
    result = cursor.fetchall()

    df = pd.DataFrame(result)

    df['CityID_Number'] = df['CityID'].str.extract(r'(\d+)').astype(int)
    df = df.sort_values(by='CityID_Number')

    fig = px.pie(df, names = "CityName", values="CarCount",
                hover_data={'CarCount': True}, labels={'CarCount': 'CarCount'})
    fig.update_traces(textposition='outside', textinfo='label+value+percent', textfont_color="black", hole=.4,
                    direction='counterclockwise')
    fig.add_annotation(dict(text=f"{selected_year}", x=0.5, y=0.5, font_color="black", font_size=25, showarrow=False))
    fig.add_annotation(dict(text="단위: 만 대", x=0.5, y=0.45, font_color="gray", font_size=13, showarrow=False))

    fig.update_layout(width=1600, height=850, legend=dict(
        yanchor="top",
        y=1.05
    ))
    st.plotly_chart(fig)

with tab2:
    # CSV 파일 경로
    car_file_path = 'data/Car.csv'
    city_file_path = 'data/City_m.csv'

    # CSV 파일 읽기
    car_df = pd.read_csv(car_file_path)
    city_df = pd.read_csv(city_file_path)

    # 연도 선택
    years = car_df['연도'].unique()
    selected_year = st.selectbox('연도를 선택하세요:', years)

    # 선택된 연도에 따라 데이터 필터링
    filtered_car_df = car_df[car_df['연도'] == selected_year]

    # 지도 생성
    m = folium.Map(location=[36.5, 127.5], zoom_start=7)

    # 색상 팔레트 생성
    colors = ['#%06X' % random.randint(0, 0xFFFFFF) for _ in range(len(city_df))]

    # 각 도시의 좌표에 등록대수를 반영한 원 추가
    for i, (_, row) in enumerate(filtered_car_df.iterrows()):
        city_id = row['지역ID']
        city_data = city_df[city_df['CityID'] == city_id].iloc[0]
        folium.Circle(
            location=[city_data['Latitude'], city_data['Longitude']],
            radius=row['등록대수'] * 100,  # 등록대수에 비례한 반경
            color=colors[i],
            fill=True,
            fill_color=colors[i],
            fill_opacity=0.6,
            popup=f"{city_data['CityName']} ({row['등록대수']} 만대)"
        ).add_to(m)

    # 지도 표시
    folium_static(m)

    # 색상 레이블 표시

    legend_html = """
    <div style="border:1px solid black; padding:5px; width: 200px;">
        <b>지역별 색상 레이블</b><br>
    """
    for i, city in city_df.iterrows():
        legend_html += f"<div style='display: flex; align-items: center; margin-bottom: 5px;'><div style='width: 15px; height: 15px; background-color: {colors[i]}; margin-right: 5px;'></div>{city['CityName']}</div>"
    legend_html += "</div>"
    st.markdown(legend_html, unsafe_allow_html=True)

--- File Index 9: pages/3_브랜드별_자동차_판매_현황.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc

st.set_page_config(layout="centered")

st.title("📊 브랜드별 자동차 판매 현황")

# 한글 폰트 설정
font_path = 'C:/Windows/Fonts/malgun.ttf'  # Windows의 경우
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)

# CSV 파일 경로
domestic_file_path = 'data/국산차_순위_2021_2024.csv'
foreign_file_path = 'data/해외차_순위_2021_2024.csv'

# CSV 파일 읽기
domestic_df = pd.read_csv(domestic_file_path)
foreign_df = pd.read_csv(foreign_file_path)

def create_cards(data):
    for index, row in data.iterrows():
        st.markdown(f"""
        <div style="border: 1px solid #ddd; border-radius: 10px; padding: 10px; margin: 10px 0;">
            <h3 style="margin: 0;">{row['순위']}위 - {row['브랜드']}</h3>
            <img src="{row['로고 이미지 링크']}" width="50" style="float: right; margin-left: 10px;">
            <p>판매량: {row['판매량']}</p>
            <p>비율: {row['비율']}</p>
        </div>
        """, unsafe_allow_html=True)

def create_pie_chart(data, title, top_n, total_sales):
    st.subheader(title)
    fig, ax = plt.subplots()
    top_brands = data.iloc[:top_n]
    others = data.iloc[top_n:]
    labels = top_brands['브랜드'].tolist() + ['기타 브랜드']
    sizes = top_brands['판매량'].str.replace(',', '').astype(int).tolist() + [others['판매량'].str.replace(',', '').astype(int).sum()]
    colors = plt.get_cmap('tab20').colors  # 다양한 색상 사용
    ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3))
    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

    # 도넛 차트의 가운데에 총 판매량 표시
    ax.text(0, 0, f"{total_sales:,} 대", ha='center', va='center', fontsize=12, fontweight='bold')

    # 파이 차트 표시
    st.pyplot(fig)

def display_tab(title, df, top_n):

    # 연도와 월 선택
    years = df['연도'].unique()
    months = df['월'].unique()

    with st.container(border=True):
        selected_year = st.selectbox('연도를 선택하세요:', years, key=f'{title}_year')
        selected_month = st.selectbox('월을 선택하세요:', months, key=f'{title}_month')

    # 선택된 연도와 월에 따라 데이터 필터링
    filtered_data = df[(df['연도'] == selected_year) & (df['월'] == selected_month)]

    # 주요 지표 강조
    total_sales = filtered_data['판매량'].str.replace(',', '').astype(int).sum()
    

    # 도넛 모양의 파이 차트 생성
    create_pie_chart(filtered_data, f'{title} 브랜드별 판매 비율', top_n, total_sales)

    # 데이터 카드 형식으로 표시
    st.subheader(f'{title} 순위 데이터')
    create_cards(filtered_data)

# 탭 생성
tab1, tab2 = st.tabs(['국산차', '수입차'])

with tab1:
    display_tab('국산차', domestic_df, 3)

with tab2:
    display_tab('수입차', foreign_df, 5)

--- File Index 10: pages/4_주요_3개_기업_차량_구매_FAQ.py ---
import streamlit as st
import json

st.set_page_config(layout="centered")

# 제목 및 탭 구성
st.title("❓ 주요 3개 기업 차량 구매 FAQ")

tab1, tab2, tab3 = st.tabs(['현대', '기아', '제네시스'])

with tab1:
    st.image("images/hyundai.png")

    file_path = 'data\hyundai_faq.json'  # 경로설정

    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            h_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        h_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(h_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        st.stop()


    # 검색 기능
    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    search_query = st.text_input("", key="hd_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if search_query:
        filtered_data  = [item for item in h_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = h_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="hd_prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="hd_next_page"):
                st.session_state.page = page + 1

with tab2:
    st.image("images/kia.jpg")

    file_path = 'data\kia_faq.json'  # 경로설정
    with open(file_path, 'r', encoding='utf-8') as file:
        k_faq_data = json.load(file)

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    st.text_input("", key="search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if 'search_query' in st.session_state and st.session_state.search_query:
        filtered_data = [item for item in k_faq_data if st.session_state.search_query.lower() in item['question'].lower() or st.session_state.search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = k_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 페이지네이션 설정
    items_per_page = 10
    total_pages = (len(filtered_data) + items_per_page - 1) // items_per_page


    # 페이지 번호 선택
    if 'page' not in st.session_state or st.session_state.page > total_pages:
        st.session_state.page = 1

    def change_page(page):
        st.session_state.page = page

    page = st.session_state.page
    start_idx = (page - 1) * items_per_page
    end_idx = start_idx + items_per_page
    current_page_data = filtered_data[start_idx:end_idx]

    for item in current_page_data:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")

        # 하이퍼링크 처리
        for link in item.get("links", []):
            answer = answer.replace(link["text"], f"[{link['text']}]({link['href']})")

        with st.expander(f"❓ {question}"):
            st.write(answer)

            # 이미지 처리
            for image in item.get("images", []):
                st.image(image["src"], caption=image.get("alt", ""))

    page_numbers = [i for i in range(1, total_pages + 1)]
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()
    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page_tab2"):
                change_page(page - 1)
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page_tab2"):
                change_page(page + 1)


with tab3:
    st.image("images\jenesis.png")

    # JSON 파일 로드
    file_path = 'data\genesis_faq.json'
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            j_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        j_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(j_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        #st.stop()

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    # 검색 기능
    def search():
        st.session_state.search_query = st.session_state.search_input
        st.session_state.page = 1 

    search_query = st.text_input("", key="j_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)
    if search_query:
        filtered_data  = [item for item in j_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = j_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page"):
                st.session_state.page = page + 1



Based on the provided codebase, identify the key abstractions that are central to understanding this project. 
These abstractions should represent the core components, modules, or concepts.

Desired output format is a YAML list of objects, where each object has:
- 'name': A concise name for the abstraction (in korean).
- 'description': A brief explanation of what this abstraction represents and its role (in korean).
- 'file_indices': A list of integer file indices that are most relevant to this abstraction. Choose from the file list above.

Return at most 10 key abstractions.

Example for a different project (simple web server):
```yaml
- name: "HTTP 요청 핸들러 (HTTP Request Handler)"
  description: "수신 HTTP 요청을 처리하고 적절한 응답을 생성하는 구성 요소입니다. (Component that processes incoming HTTP requests and generates appropriate responses.)"
  file_indices: [0, 2]
- name: "라우팅 설정 (Routing Configuration)"
  description: "URL 경로를 특정 요청 핸들러 함수에 매핑하는 규칙을 정의합니다. (Defines rules for mapping URL paths to specific request handler functions.)"
  file_indices: [1]
```

Your response should be only the YAML list, enclosed in triple backticks (```yaml ... ```).
Ensure the output is valid YAML.

2025-06-29 20:29:00,464 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:29:09,270 - INFO - RESPONSE: ```yaml
- name: "데이터베이스 삽입 모듈"
  description: "CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 기능을 제공하는 모듈입니다."
  file_indices: [2, 3]
- name: "연도별 자동차 등록 현황 페이지"
  description: "연도별 자동차 등록 데이터를 시각화하여 사용자에게 제공하는 스트림릿 웹 페이지입니다."
  file_indices: [0]
- name: "지역별 자동차 등록 현황 페이지"
  description: "지역별 자동차 등록 데이터를 차트 및 지도 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다."
  file_indices: [8]
- name: "브랜드별 자동차 판매 현황 페이지"
  description: "브랜드별 자동차 판매 데이터를 카드 및 파이 차트 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다."
  file_indices: [9]
- name: "차량 구매 FAQ 페이지"
  description: "주요 자동차 브랜드의 차량 구매 관련 FAQ 데이터를 제공하고 검색 기능을 갖춘 스트림릿 웹 페이지입니다."
  file_indices: [10]
- name: "FAQ 크롤링 모듈"
  description: "주요 자동차 브랜드 웹사이트로부터 FAQ 데이터를 크롤링하여 JSON 파일로 저장하는 모듈입니다."
  file_indices: [5, 6, 7]
- name: "자동차 판매 실적 크롤링 모듈"
  description: "다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하여 CSV 파일로 저장하는 모듈입니다."
  file_indices: [4]
- name: "데이터베이스 연결 설정"
  description: "MySQL 데이터베이스에 연결하기 위한 설정 및 쿼리를 실행하여 데이터를 가져오는 기능을 제공합니다."
  file_indices: [0, 8]
- name: "시각화 라이브러리 사용"
  description: "데이터를 차트와 그래프로 시각화하기 위해 Plotly, Matplotlib, Folium 등의 라이브러리를 사용합니다."
  file_indices: [0, 8, 9]
- name: "검색 및 페이지네이션 기능"
  description: "FAQ 페이지에서 검색 기능과 페이지네이션을 제공하여 사용자가 원하는 정보를 쉽게 찾아볼 수 있도록 지원합니다."
  file_indices: [10]
```
2025-06-29 20:29:09,276 - INFO - PROMPT: 
Based on the following abstractions and relevant code snippets from the project `SKN10-1st-4Team`:

List of Abstraction Indices and Names (Names might be in Korean):
0 # 데이터베이스 삽입 모듈
1 # 연도별 자동차 등록 현황 페이지
2 # 지역별 자동차 등록 현황 페이지
3 # 브랜드별 자동차 판매 현황 페이지
4 # 차량 구매 FAQ 페이지
5 # FAQ 크롤링 모듈
6 # 자동차 판매 실적 크롤링 모듈
7 # 데이터베이스 연결 설정
8 # 시각화 라이브러리 사용
9 # 검색 및 페이지네이션 기능

Context (Abstractions, Descriptions, Code):
Identified Abstractions:
- Index 0: 데이터베이스 삽입 모듈 (Relevant file indices: [2, 3])
  Description: CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 기능을 제공하는 모듈입니다.
- Index 1: 연도별 자동차 등록 현황 페이지 (Relevant file indices: [0])
  Description: 연도별 자동차 등록 데이터를 시각화하여 사용자에게 제공하는 스트림릿 웹 페이지입니다.
- Index 2: 지역별 자동차 등록 현황 페이지 (Relevant file indices: [8])
  Description: 지역별 자동차 등록 데이터를 차트 및 지도 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.
- Index 3: 브랜드별 자동차 판매 현황 페이지 (Relevant file indices: [9])
  Description: 브랜드별 자동차 판매 데이터를 카드 및 파이 차트 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.
- Index 4: 차량 구매 FAQ 페이지 (Relevant file indices: [10])
  Description: 주요 자동차 브랜드의 차량 구매 관련 FAQ 데이터를 제공하고 검색 기능을 갖춘 스트림릿 웹 페이지입니다.
- Index 5: FAQ 크롤링 모듈 (Relevant file indices: [5, 6, 7])
  Description: 주요 자동차 브랜드 웹사이트로부터 FAQ 데이터를 크롤링하여 JSON 파일로 저장하는 모듈입니다.
- Index 6: 자동차 판매 실적 크롤링 모듈 (Relevant file indices: [4])
  Description: 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하여 CSV 파일로 저장하는 모듈입니다.
- Index 7: 데이터베이스 연결 설정 (Relevant file indices: [0, 8])
  Description: MySQL 데이터베이스에 연결하기 위한 설정 및 쿼리를 실행하여 데이터를 가져오는 기능을 제공합니다.
- Index 8: 시각화 라이브러리 사용 (Relevant file indices: [0, 8, 9])
  Description: 데이터를 차트와 그래프로 시각화하기 위해 Plotly, Matplotlib, Folium 등의 라이브러리를 사용합니다.
- Index 9: 검색 및 페이지네이션 기능 (Relevant file indices: [10])
  Description: FAQ 페이지에서 검색 기능과 페이지네이션을 제공하여 사용자가 원하는 정보를 쉽게 찾아볼 수 있도록 지원합니다.

Relevant File Snippets (Referenced by Index and Path):
--- File: 0 # 1_연도별_자동차_등록_현황.py ---
#test
import streamlit as st
import pandas as pd
import plotly.express as px
import pymysql
from common.insert_data import insert_data
from common.insert_data_city import insert_data_city

insert_data()
insert_data_city()

st.set_page_config(layout="centered")

st.title("📊 연도별 자동차 등록 현황")
st.divider()

# 데이터베이스 연결 설정
connection = pymysql.connect(
    host="localhost",
    user="SKN10_4team",
    password="skn1234",
    database="SKN10_4team_1st",
    charset="utf8"
)

# SQL 데이터 가져오기
year_data = "select Year FROM Car"
ef = pd.read_sql(year_data, connection)

car_data = """
SELECT Year, SUM(CarCount) YearofCar
FROM SKN10_4team_1st.Car
GROUP BY Year
ORDER BY Year;
"""
cf = pd.read_sql(car_data, connection)

# Streamlit 컨테이너
with st.container():
    # 컬럼 레이아웃 사용
    col1, col2 = st.columns(2)
    # 년도 리스트 생성 및 선택
    years = ef['Year'].unique().tolist()

    # 디폴트 값 설정
    default_start_year_index = 0  # 첫 번째 연도를 디폴트로 설정
    default_end_year_index = len(years) - 1  # 마지막 연도를 디폴트로 설정

    with col1:
        start_year = st.selectbox(
            '첫번째 년도를 선택해주세요.', 
            years, 
            index=default_start_year_index
        )

    with col2:
        end_year = st.selectbox(
            '마지막 년도를 선택해주세요.', 
            years, 
            index=default_end_year_index
        )

# 연도 범위 확인 및 데이터 필터링
if start_year > end_year:
    st.error("Error: The start year cannot be greater than the end year.")
else:
    with st.container():
        # 사용자 입력 값으로 데이터 필터링
        filtered_data = cf[(cf["Year"] >= start_year) & (cf["Year"] <= end_year)]

        # Plotly로 그래프 생성
        fig = px.bar(
            filtered_data, 
            x="Year", 
            y="YearofCar", 
            title="조회결과"
        )

        # axis title 업데이트
        fig.update_xaxes(title_text="연도")
        fig.update_yaxes(title_text="차량 수 (만대)")

        # 그래프 출력
        st.plotly_chart(fig)

}]}

--- File: 2 # common/insert_data.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "Car.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "Car"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (Year, CityID, CarCount) VALUES (%s, %s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[2], row[3])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File: 3 # common/insert_data_city.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data_city():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "City.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "City"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (CityID, CityName) VALUES (%s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[1])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File: 4 # crawling/danawa.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By


import pandas as pd
import time

# 크롬 드라이버 설정

driver = webdriver.Chrome()

# 데이터 저장 리스트
domestic_data = []
foreign_data = []

# 2021년 1월부터 2024년 12월까지의 URL 생성 및 데이터 크롤링
for year in range(2021, 2025):
    for month in range(1, 13):
        if year == 2024 and month > 12:
            break
        month_str = f"{year}-{month:02d}-00"
        url = f"https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month={month_str}&MonthTo="
        driver.get(url)
        time.sleep(0.5)  # 페이지 로딩 대기

        # 국산차 순위 데이터 크롤링
        rank_elements = driver.find_elements(By.CSS_SELECTOR, "ul.sideRankR li")

        for index, rank_element in enumerate(rank_elements):
            rank = rank_element.find_element(By.CSS_SELECTOR, "span.rank").text
            brand = rank_element.find_element(By.CSS_SELECTOR, "span.title").text.strip()
            sales = rank_element.find_element(By.CSS_SELECTOR, "span.sales").text
            rate = rank_element.find_element(By.CSS_SELECTOR, "span.rate").text
            logo_img = rank_element.find_element(By.CSS_SELECTOR, "span.title img").get_attribute("src")
            data = [year, month, rank, brand, sales, rate, logo_img]
            if index < 6:
                domestic_data.append(data)
            else:
                foreign_data.append(data)

# 데이터프레임으로 변환
domestic_df = pd.DataFrame(domestic_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])
foreign_df = pd.DataFrame(foreign_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])

# 데이터프레임 저장
domestic_df.to_csv("data\국산차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')
foreign_df.to_csv("data\해외차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')

# 드라이버 종료
driver.quit()

print("크롤링 완료 및 데이터 저장 완료")
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo=
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo= 에서 2021-01은 21년 1월 데이터를 받아온다는 의미


--- File: 5 # crawling/genesis_faq.py ---

# 제네시스 크롤링
from selenium import webdriver
from bs4 import BeautifulSoup
import json

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.genesis.com/kr/ko/support/faq/vehicle-purchase.html?anchorID=faq_tab"
driver.get(url)

# 페이지 소스 가져오기
html_source = driver.page_source

# HTML 파일로 저장
#with open("genesis_faq.html", "w", encoding="utf-8") as file:
#    file.write(html_source)

# 드라이버 종료
driver.quit()

# BeautifulSoup을 사용하여 페이지 소스 파싱
soup = BeautifulSoup(html_source, 'html.parser')

# FAQ 질문과 답변 추출
faqs = []
faq_items = soup.select('.cp-faq__accordion-item')  # FAQ 항목을 감싸는 클래스 이름을 사용하여 선택

for item in faq_items:
    question = item.select_one('.accordion-title').get_text(strip=True)
    answer = item.select_one('.accordion-panel-inner').get_text(strip=True)
    faqs.append({'question': question, 'answer': answer})

# 추출한 FAQ를 파일로 저장
with open("data\genesis_faq.json", "w", encoding="utf-8") as file:
    json.dump(faqs, file, ensure_ascii=False, indent=4)

--- File: 6 # crawling/hyundai_faq.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from time import sleep

#import pandas as pd
import json


URL = "https://www.hyundai.com/kr/ko/e/customer/center/faq"

driver = webdriver.Chrome()
driver.get(URL)
# 리스트에 딕셔너리로 내용 저장
qna_list = []

for page_id in range(4):
    for question_id in range(1,11):
        try:
            #엘리먼트 찾기
            faq_list = driver.find_element(By.CSS_SELECTOR, "div[data-v-28d34f54].list-wrap")

            try:
                # 플로팅 메뉴 제거
                floating_menu = driver.find_element(By.CSS_SELECTOR, "div[data-v-1ea4ba2d].inner_wrap")
                driver.execute_script("arguments[0].remove();", floating_menu)
            except:
                pass
            faq_title = faq_list.find_elements(By.CSS_SELECTOR,f"div[data-id='{question_id}'] button.list-title")
            driver.execute_script("arguments[0].scrollIntoView({block:'center'});",faq_title[0])
            sleep(0.5)

            #질문타이틀 클릭하기
            faq_title[0].click()
            sleep(0.5)

            #질문타이틀 텍스트 받아오기
            faq_question = faq_title[0].find_element(By.CSS_SELECTOR, "span.list-content[data-v-28d34f54]")
            faq_question_text = faq_question.text
            #print(faq_question_text)

            #질문답변 텍스트 받아오기
            faq_answer = driver.find_element(By.CLASS_NAME, "conts")
            faq_answer_text = faq_answer.text
            #print("전체 답변:", faq_answer_text)

            # 링크 URL 가져오기
            try:
                link_whole = faq_answer.find_elements(By.TAG_NAME, "a")
                link = {
                    "url" : link_whole[0].get_attribute("href"),
                    "text" : link_whole[0].text
                    }
            except:
                link = ""
            #print("링크 URL:", url)
            
            qna_list.append({"question": faq_question_text, "answer": faq_answer_text, "link": link})

        except TimeoutException:
            print("Timed out waiting for page to load")
        except NoSuchElementException:
            print("Could not find the element")
        except IndexError:
            pass

    next_button = driver.find_element(By.CSS_SELECTOR, "button.btn-next")
    next_button.click()
    sleep(1)
 
#qna_df = pd.DataFrame(qna_list, columns = ["page_num","question_num","question","answer","link"])
#qna_df.to_csv(path_or_buf="data/hyundai_qna.csv")

# 결과를 JSON 파일로 저장
with open("data\hyundai_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(qna_list, json_file, ensure_ascii=False, indent=4)

--- File: 7 # crawling/kia_faq.py ---
import json
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.kia.com/kr/customer-service/center/faq"
driver.get(url)

# 페이지가 완전히 로드될 때까지 대기
WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, "body")))

# "TOP 10" 버튼 클릭
top_10_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//button[contains(text(), 'TOP 10')]"))
)
top_10_button.click()

# "차량 구매" 버튼 클릭
car_purchase_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//li[button/span[text()='차량 구매']]"))
)
car_purchase_button.click()

# 3초 텀을 둠
time.sleep(3)

# 각 질문 클릭하여 답변 가져오기
faq_data = []

def get_faq_data():
    # FAQ 항목이 로드될 때까지 대기
    WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

    # FAQ 항목들 찾기
    faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")

    for i in range(len(faq_items)):
        # 각 질문을 클릭하기 전에 요소를 다시 찾음
        faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")
        item = faq_items[i]
        question = item.find_element(By.CSS_SELECTOR, ".cmp-accordion__title").text
        item.click()  # 질문 클릭하여 답변 표시

        # 답변이 로드될 때까지 대기
        panel_id = item.get_attribute("aria-controls")
        WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.ID, panel_id)))
        answer_element = driver.find_element(By.ID, panel_id)
        answer = answer_element.text

        # 하이퍼링크 정보 가져오기
        links = []
        link_elements = answer_element.find_elements(By.TAG_NAME, "a")
        for link in link_elements:
            links.append({
                "href": link.get_attribute("href"),
                "text": link.text
            })

        # 이미지 링크 정보 가져오기
        images = []
        image_elements = answer_element.find_elements(By.TAG_NAME, "img")
        for img in image_elements:
            images.append({
                "src": img.get_attribute("src"),
                "alt": img.get_attribute("alt")
            })

        faq_data.append({
            "question": question,
            "answer": answer,
            "links": links,
            "images": images
        })

    # 스크롤을 맨 위로 올리기
    driver.execute_script("window.scrollTo(0, 0);")

# 첫 페이지의 FAQ 데이터 가져오기
get_faq_data()

# 페이지 넘기기
current_page = 1
while current_page < 4:
    try:
        next_page = str(current_page + 1)

        # 다음 페이지 번호 클릭
        next_page_element = driver.find_element(By.XPATH, f"//ul[@class='paging-list']//a[text()='{next_page}']")
        next_page_element.click()

        # 3초 텀을 둠
        time.sleep(3)

        # 다음 페이지가 로드될 때까지 대기
        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

        # 각 페이지의 FAQ 데이터를 가져오기 전에 요소를 다시 찾음
        get_faq_data()

        current_page += 1
    except Exception as e:
        print(f"Error: {e}")
        break

# 드라이버 종료
driver.quit()

# 결과를 JSON 파일로 저장
with open("/data/kia_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(faq_data, json_file, ensure_ascii=False, indent=4)

# 결과 출력
'''
for faq in faq_data:
    print(f"Question: {faq['question']}")
    print(f"Answer: {faq['answer']}")
    print(f"Links: {faq['links']}")
    print(f"Images: {faq['images']}\n")
'''

--- File: 8 # pages/2_지역별_자동차_등록_현황.py ---
import streamlit as st
import pymysql
import pandas as pd
import plotly.express as px
import folium
import random
from streamlit_folium import folium_static

st.set_page_config(layout="wide")

st.title("📊 지역별 자동차 등록 현황")

tab1, tab2 = st.tabs(['차트', '지도'])

with tab1:
    # Database 연결
    connection = pymysql.connect(
        host = "localhost",
        user = "SKN10_4team",
        password = "skn1234",
        database = "SKN10_4team_1st",
        charset = "utf8"
    )

    cursor = connection.cursor(pymysql.cursors.DictCursor)

    year_data = """
    SELECT DISTINCT year
    FROM Car
    ;
    """
    cursor.execute(year_data)
    years = cursor.fetchall()
    year_list = [year['year'] for year in years]

    with st.container(border=True):
        selected_year = st.selectbox("연도를 선택하세요:", year_list, index=year_list.index('2022'))

    car_data = f"""
    SELECT City.CityName, Car.CarCount, Car.CityID
    FROM Car
    JOIN City ON Car.CityID = City.CityID
    WHERE Car.Year = {selected_year}
    ;
    """
    cursor.execute(car_data)
    result = cursor.fetchall()

    df = pd.DataFrame(result)

    df['CityID_Number'] = df['CityID'].str.extract(r'(\d+)').astype(int)
    df = df.sort_values(by='CityID_Number')

    fig = px.pie(df, names = "CityName", values="CarCount",
                hover_data={'CarCount': True}, labels={'CarCount': 'CarCount'})
    fig.update_traces(textposition='outside', textinfo='label+value+percent', textfont_color="black", hole=.4,
                    direction='counterclockwise')
    fig.add_annotation(dict(text=f"{selected_year}", x=0.5, y=0.5, font_color="black", font_size=25, showarrow=False))
    fig.add_annotation(dict(text="단위: 만 대", x=0.5, y=0.45, font_color="gray", font_size=13, showarrow=False))

    fig.update_layout(width=1600, height=850, legend=dict(
        yanchor="top",
        y=1.05
    ))
    st.plotly_chart(fig)

with tab2:
    # CSV 파일 경로
    car_file_path = 'data/Car.csv'
    city_file_path = 'data/City_m.csv'

    # CSV 파일 읽기
    car_df = pd.read_csv(car_file_path)
    city_df = pd.read_csv(city_file_path)

    # 연도 선택
    years = car_df['연도'].unique()
    selected_year = st.selectbox('연도를 선택하세요:', years)

    # 선택된 연도에 따라 데이터 필터링
    filtered_car_df = car_df[car_df['연도'] == selected_year]

    # 지도 생성
    m = folium.Map(location=[36.5, 127.5], zoom_start=7)

    # 색상 팔레트 생성
    colors = ['#%06X' % random.randint(0, 0xFFFFFF) for _ in range(len(city_df))]

    # 각 도시의 좌표에 등록대수를 반영한 원 추가
    for i, (_, row) in enumerate(filtered_car_df.iterrows()):
        city_id = row['지역ID']
        city_data = city_df[city_df['CityID'] == city_id].iloc[0]
        folium.Circle(
            location=[city_data['Latitude'], city_data['Longitude']],
            radius=row['등록대수'] * 100,  # 등록대수에 비례한 반경
            color=colors[i],
            fill=True,
            fill_color=colors[i],
            fill_opacity=0.6,
            popup=f"{city_data['CityName']} ({row['등록대수']} 만대)"
        ).add_to(m)

    # 지도 표시
    folium_static(m)

    # 색상 레이블 표시

    legend_html = """
    <div style="border:1px solid black; padding:5px; width: 200px;">
        <b>지역별 색상 레이블</b><br>
    """
    for i, city in city_df.iterrows():
        legend_html += f"<div style='display: flex; align-items: center; margin-bottom: 5px;'><div style='width: 15px; height: 15px; background-color: {colors[i]}; margin-right: 5px;'></div>{city['CityName']}</div>"
    legend_html += "</div>"
    st.markdown(legend_html, unsafe_allow_html=True)

--- File: 9 # pages/3_브랜드별_자동차_판매_현황.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc

st.set_page_config(layout="centered")

st.title("📊 브랜드별 자동차 판매 현황")

# 한글 폰트 설정
font_path = 'C:/Windows/Fonts/malgun.ttf'  # Windows의 경우
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)

# CSV 파일 경로
domestic_file_path = 'data/국산차_순위_2021_2024.csv'
foreign_file_path = 'data/해외차_순위_2021_2024.csv'

# CSV 파일 읽기
domestic_df = pd.read_csv(domestic_file_path)
foreign_df = pd.read_csv(foreign_file_path)

def create_cards(data):
    for index, row in data.iterrows():
        st.markdown(f"""
        <div style="border: 1px solid #ddd; border-radius: 10px; padding: 10px; margin: 10px 0;">
            <h3 style="margin: 0;">{row['순위']}위 - {row['브랜드']}</h3>
            <img src="{row['로고 이미지 링크']}" width="50" style="float: right; margin-left: 10px;">
            <p>판매량: {row['판매량']}</p>
            <p>비율: {row['비율']}</p>
        </div>
        """, unsafe_allow_html=True)

def create_pie_chart(data, title, top_n, total_sales):
    st.subheader(title)
    fig, ax = plt.subplots()
    top_brands = data.iloc[:top_n]
    others = data.iloc[top_n:]
    labels = top_brands['브랜드'].tolist() + ['기타 브랜드']
    sizes = top_brands['판매량'].str.replace(',', '').astype(int).tolist() + [others['판매량'].str.replace(',', '').astype(int).sum()]
    colors = plt.get_cmap('tab20').colors  # 다양한 색상 사용
    ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3))
    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

    # 도넛 차트의 가운데에 총 판매량 표시
    ax.text(0, 0, f"{total_sales:,} 대", ha='center', va='center', fontsize=12, fontweight='bold')

    # 파이 차트 표시
    st.pyplot(fig)

def display_tab(title, df, top_n):

    # 연도와 월 선택
    years = df['연도'].unique()
    months = df['월'].unique()

    with st.container(border=True):
        selected_year = st.selectbox('연도를 선택하세요:', years, key=f'{title}_year')
        selected_month = st.selectbox('월을 선택하세요:', months, key=f'{title}_month')

    # 선택된 연도와 월에 따라 데이터 필터링
    filtered_data = df[(df['연도'] == selected_year) & (df['월'] == selected_month)]

    # 주요 지표 강조
    total_sales = filtered_data['판매량'].str.replace(',', '').astype(int).sum()
    

    # 도넛 모양의 파이 차트 생성
    create_pie_chart(filtered_data, f'{title} 브랜드별 판매 비율', top_n, total_sales)

    # 데이터 카드 형식으로 표시
    st.subheader(f'{title} 순위 데이터')
    create_cards(filtered_data)

# 탭 생성
tab1, tab2 = st.tabs(['국산차', '수입차'])

with tab1:
    display_tab('국산차', domestic_df, 3)

with tab2:
    display_tab('수입차', foreign_df, 5)

--- File: 10 # pages/4_주요_3개_기업_차량_구매_FAQ.py ---
import streamlit as st
import json

st.set_page_config(layout="centered")

# 제목 및 탭 구성
st.title("❓ 주요 3개 기업 차량 구매 FAQ")

tab1, tab2, tab3 = st.tabs(['현대', '기아', '제네시스'])

with tab1:
    st.image("images/hyundai.png")

    file_path = 'data\hyundai_faq.json'  # 경로설정

    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            h_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        h_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(h_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        st.stop()


    # 검색 기능
    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    search_query = st.text_input("", key="hd_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if search_query:
        filtered_data  = [item for item in h_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = h_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="hd_prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="hd_next_page"):
                st.session_state.page = page + 1

with tab2:
    st.image("images/kia.jpg")

    file_path = 'data\kia_faq.json'  # 경로설정
    with open(file_path, 'r', encoding='utf-8') as file:
        k_faq_data = json.load(file)

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    st.text_input("", key="search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if 'search_query' in st.session_state and st.session_state.search_query:
        filtered_data = [item for item in k_faq_data if st.session_state.search_query.lower() in item['question'].lower() or st.session_state.search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = k_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 페이지네이션 설정
    items_per_page = 10
    total_pages = (len(filtered_data) + items_per_page - 1) // items_per_page


    # 페이지 번호 선택
    if 'page' not in st.session_state or st.session_state.page > total_pages:
        st.session_state.page = 1

    def change_page(page):
        st.session_state.page = page

    page = st.session_state.page
    start_idx = (page - 1) * items_per_page
    end_idx = start_idx + items_per_page
    current_page_data = filtered_data[start_idx:end_idx]

    for item in current_page_data:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")

        # 하이퍼링크 처리
        for link in item.get("links", []):
            answer = answer.replace(link["text"], f"[{link['text']}]({link['href']})")

        with st.expander(f"❓ {question}"):
            st.write(answer)

            # 이미지 처리
            for image in item.get("images", []):
                st.image(image["src"], caption=image.get("alt", ""))

    page_numbers = [i for i in range(1, total_pages + 1)]
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()
    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page_tab2"):
                change_page(page - 1)
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page_tab2"):
                change_page(page + 1)


with tab3:
    st.image("images\jenesis.png")

    # JSON 파일 로드
    file_path = 'data\genesis_faq.json'
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            j_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        j_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(j_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        #st.stop()

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    # 검색 기능
    def search():
        st.session_state.search_query = st.session_state.search_input
        st.session_state.page = 1 

    search_query = st.text_input("", key="j_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)
    if search_query:
        filtered_data  = [item for item in j_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = j_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page"):
                st.session_state.page = page + 1

IMPORTANT: Generate the `summary` and relationship `label` fields in **Korean** language. Do NOT use English for these fields.

Please provide:
1. A high-level `summary` of the project's main purpose and functionality in a few beginner-friendly sentences (in Korean). Use markdown formatting with **bold** and *italic* text to highlight important concepts.
2. A list (`relationships`) describing the key interactions between these abstractions. For each relationship, specify:
    - `from_abstraction`: Index of the source abstraction (e.g., `0 # AbstractionName1`)
    - `to_abstraction`: Index of the target abstraction (e.g., `1 # AbstractionName2`)
    - `label`: A brief label for the interaction **in just a few words** (in Korean) (e.g., "Manages", "Inherits", "Uses").
    Ideally the relationship should be backed by one abstraction calling or passing parameters to another.
    Simplify the relationship and exclude those non-important ones.

IMPORTANT: Make sure EVERY abstraction is involved in at least ONE relationship (either as source or target). Each abstraction index must appear at least once across all relationships.

Format the output as YAML:

```yaml
summary: |
  A brief, simple explanation of the project (in Korean).
  Can span multiple lines with **bold** and *italic* for emphasis.
relationships:
  - from_abstraction: 0 # AbstractionName1
    to_abstraction: 1 # AbstractionName2
    label: "Manages" (in Korean)
  - from_abstraction: 2 # AbstractionName3
    to_abstraction: 0 # AbstractionName1
    label: "Provides config" (in Korean)
  # ... other relationships
```

Now, provide the YAML output:

2025-06-29 20:29:09,445 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:29:14,804 - INFO - RESPONSE: ```yaml
summary: |
  **SKN10-1st-4Team** 프로젝트는 자동차 등록 및 판매 현황 데이터를 관리하고 *시각화*하는 웹 애플리케이션입니다. **Streamlit**을 사용하여 각종 **연도별, 지역별, 브랜드별** 데이터를 **시각화**하며, **크롤링** 모듈을 통해 주요 브랜드의 **FAQ 데이터를 자동으로 수집**합니다. 또한, 데이터는 **MySQL 데이터베이스**에 저장되고 **검색 및 페이지네이션** 기능을 통해 사용자는 필요한 정보를 쉽게 찾을 수 있습니다.

relationships:
  - from_abstraction: 0 # 데이터베이스 삽입 모듈
    to_abstraction: 7 # 데이터베이스 연결 설정
    label: "사용"
  - from_abstraction: 1 # 연도별 자동차 등록 현황 페이지
    to_abstraction: 0 # 데이터베이스 삽입 모듈
    label: "데이터 읽기"
  - from_abstraction: 2 # 지역별 자동차 등록 현황 페이지
    to_abstraction: 7 # 데이터베이스 연결 설정
    label: "사용"
  - from_abstraction: 3 # 브랜드별 자동차 판매 현황 페이지
    to_abstraction: 6 # 자동차 판매 실적 크롤링 모듈
    label: "데이터 사용"
  - from_abstraction: 4 # 차량 구매 FAQ 페이지
    to_abstraction: 9 # 검색 및 페이지네이션 기능
    label: "활용"
  - from_abstraction: 5 # FAQ 크롤링 모듈
    to_abstraction: 4 # 차량 구매 FAQ 페이지
    label: "데이터 공급"
  - from_abstraction: 6 # 자동차 판매 실적 크롤링 모듈
    to_abstraction: 9 # 검색 및 페이지네이션 기능
    label: "활용"
  - from_abstraction: 8 # 시각화 라이브러리 사용
    to_abstraction: 2 # 지역별 자동차 등록 현황 페이지
    label: "적용"
  - from_abstraction: 9 # 검색 및 페이지네이션 기능
    to_abstraction: 4 # 차량 구매 FAQ 페이지
    label: "지원"
```
2025-06-29 20:29:14,806 - INFO - PROMPT: 
Given the following project abstractions and their relationships for the project ```` SKN10-1st-4Team ````:

Abstractions (Index # Name) (Names might be in Korean):
- 0 # 데이터베이스 삽입 모듈
- 1 # 연도별 자동차 등록 현황 페이지
- 2 # 지역별 자동차 등록 현황 페이지
- 3 # 브랜드별 자동차 판매 현황 페이지
- 4 # 차량 구매 FAQ 페이지
- 5 # FAQ 크롤링 모듈
- 6 # 자동차 판매 실적 크롤링 모듈
- 7 # 데이터베이스 연결 설정
- 8 # 시각화 라이브러리 사용
- 9 # 검색 및 페이지네이션 기능

Context about relationships and project summary:
Project Summary (Note: Project Summary might be in Korean):
**SKN10-1st-4Team** 프로젝트는 자동차 등록 및 판매 현황 데이터를 관리하고 *시각화*하는 웹 애플리케이션입니다. **Streamlit**을 사용하여 각종 **연도별, 지역별, 브랜드별** 데이터를 **시각화**하며, **크롤링** 모듈을 통해 주요 브랜드의 **FAQ 데이터를 자동으로 수집**합니다. 또한, 데이터는 **MySQL 데이터베이스**에 저장되고 **검색 및 페이지네이션** 기능을 통해 사용자는 필요한 정보를 쉽게 찾을 수 있습니다.


Relationships (Indices refer to abstractions above):
- From 0 (데이터베이스 삽입 모듈) to 7 (데이터베이스 연결 설정): 사용
- From 1 (연도별 자동차 등록 현황 페이지) to 0 (데이터베이스 삽입 모듈): 데이터 읽기
- From 2 (지역별 자동차 등록 현황 페이지) to 7 (데이터베이스 연결 설정): 사용
- From 3 (브랜드별 자동차 판매 현황 페이지) to 6 (자동차 판매 실적 크롤링 모듈): 데이터 사용
- From 4 (차량 구매 FAQ 페이지) to 9 (검색 및 페이지네이션 기능): 활용
- From 5 (FAQ 크롤링 모듈) to 4 (차량 구매 FAQ 페이지): 데이터 공급
- From 6 (자동차 판매 실적 크롤링 모듈) to 9 (검색 및 페이지네이션 기능): 활용
- From 8 (시각화 라이브러리 사용) to 2 (지역별 자동차 등록 현황 페이지): 적용
- From 9 (검색 및 페이지네이션 기능) to 4 (차량 구매 FAQ 페이지): 지원


If you are going to make a tutorial for ```` SKN10-1st-4Team ````, what is the best order to explain these abstractions, from first to last?
Ideally, first explain those that are the most important or foundational, perhaps user-facing concepts or entry points. Then move to more detailed, lower-level implementation details or supporting concepts.

Output the ordered list of abstraction indices, including the name in a comment for clarity. Use the format `idx # AbstractionName`.

```yaml
- 2 # FoundationalConcept
- 0 # CoreClassA
- 1 # CoreClassB (uses CoreClassA)
- ...
```

Now, provide the YAML output:

2025-06-29 20:29:14,970 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:29:17,336 - INFO - RESPONSE: ```yaml
- 8 # 시각화 라이브러리 사용
- 2 # 지역별 자동차 등록 현황 페이지
- 1 # 연도별 자동차 등록 현황 페이지
- 3 # 브랜드별 자동차 판매 현황 페이지
- 4 # 차량 구매 FAQ 페이지
- 9 # 검색 및 페이지네이션 기능
- 5 # FAQ 크롤링 모듈
- 6 # 자동차 판매 실적 크롤링 모듈
- 0 # 데이터베이스 삽입 모듈
- 7 # 데이터베이스 연결 설정
```
2025-06-29 20:29:17,338 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "시각화 라이브러리 사용". This is Chapter 1.

Concept Details (Note: Provided in Korean):
- Name: 시각화 라이브러리 사용
- Description:
데이터를 차트와 그래프로 시각화하기 위해 Plotly, Matplotlib, Folium 등의 라이브러리를 사용합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
This is the first chapter.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 1: 시각화 라이브러리 사용`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:29:17,510 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:29:27,202 - INFO - RESPONSE: # Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
2025-06-29 20:29:27,204 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "지역별 자동차 등록 현황 페이지". This is Chapter 2.

Concept Details (Note: Provided in Korean):
- Name: 지역별 자동차 등록 현황 페이지
- Description:
지역별 자동차 등록 데이터를 차트 및 지도 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 2: 지역별 자동차 등록 현황 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:29:27,369 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:29:40,270 - INFO - RESPONSE: # 제 2 장: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
2025-06-29 20:29:40,273 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "연도별 자동차 등록 현황 페이지". This is Chapter 3.

Concept Details (Note: Provided in Korean):
- Name: 연도별 자동차 등록 현황 페이지
- Description:
연도별 자동차 등록 데이터를 시각화하여 사용자에게 제공하는 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 3: 연도별 자동차 등록 현황 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:29:40,444 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:29:49,502 - INFO - RESPONSE: # Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
2025-06-29 20:29:49,504 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "브랜드별 자동차 판매 현황 페이지". This is Chapter 4.

Concept Details (Note: Provided in Korean):
- Name: 브랜드별 자동차 판매 현황 페이지
- Description:
브랜드별 자동차 판매 데이터를 카드 및 파이 차트 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 4: 브랜드별 자동차 판매 현황 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:29:49,670 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:29:59,147 - INFO - RESPONSE: # 제4장: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
2025-06-29 20:29:59,150 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "차량 구매 FAQ 페이지". This is Chapter 5.

Concept Details (Note: Provided in Korean):
- Name: 차량 구매 FAQ 페이지
- Description:
주요 자동차 브랜드의 차량 구매 관련 FAQ 데이터를 제공하고 검색 기능을 갖춘 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 5: 차량 구매 FAQ 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:29:59,312 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:30:08,523 - INFO - RESPONSE: # Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
2025-06-29 20:30:08,525 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "검색 및 페이지네이션 기능". This is Chapter 6.

Concept Details (Note: Provided in Korean):
- Name: 검색 및 페이지네이션 기능
- Description:
FAQ 페이지에서 검색 기능과 페이지네이션을 제공하여 사용자가 원하는 정보를 쉽게 찾아볼 수 있도록 지원합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 6: 검색 및 페이지네이션 기능`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:30:08,691 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:30:19,833 - INFO - RESPONSE: # Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
2025-06-29 20:30:19,836 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "FAQ 크롤링 모듈". This is Chapter 7.

Concept Details (Note: Provided in Korean):
- Name: FAQ 크롤링 모듈
- Description:
주요 자동차 브랜드 웹사이트로부터 FAQ 데이터를 크롤링하여 JSON 파일로 저장하는 모듈입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 7: FAQ 크롤링 모듈`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:30:19,997 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:30:31,511 - INFO - RESPONSE: # Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.
2025-06-29 20:30:31,514 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "자동차 판매 실적 크롤링 모듈". This is Chapter 8.

Concept Details (Note: Provided in Korean):
- Name: 자동차 판매 실적 크롤링 모듈
- Description:
다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하여 CSV 파일로 저장하는 모듈입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
---
# Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 8: 자동차 판매 실적 크롤링 모듈`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:30:31,678 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:30:43,141 - INFO - RESPONSE: # Chapter 8: 자동차 판매 실적 크롤링 모듈

이전 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동차 관련 웹사이트에서 FAQ 데이터를 자동으로 수집하고 저장하는 방법을 배웠습니다. 이번 장에서는 `자동차 판매 실적 크롤링 모듈`을 구축하여 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하고, 이를 CSV 파일로 저장하는 방법을 알아보겠습니다.

## 동기 부여

자동차 판매 실적을 분석하는 것은 시장 동향을 파악하고, 신차 개발 및 판매 전략을 수립하는 데 중요한 역할을 합니다. 만약 특정 브랜드의 판매 실적이 급격히 증가했다면, 그 이유를 파악하여 다른 브랜드에도 적용할 수 있는 영감을 얻을 수 있습니다. 이때 매번 웹사이트를 방문해 수작업으로 데이터를 정리하는 대신, 크롤러를 사용하면 실적 데이터를 자동으로 수집 및 저장할 수 있습니다.

## 주요 개념

### 웹 크롤링

웹 크롤링은 특정 웹사이트의 정보를 자동으로 수집하는 방법입니다. 일반적으로 원하는 페이지의 HTML 코드를 가져와 필요한 데이터를 추출합니다. 다나와의 판매 실적 페이지를 탐색하고 데이터를 추출할 수 있습니다.

### CSV 형식

CSV는 데이터를 쉽고 효율적으로 저장할 수 있는 포맷입니다. 각 행은 하나의 데이터 레코드를 나타내며, 각 값은 쉼표로 구분됩니다. 추출한 판매 실적 데이터를 CSV 파일에 저장하면 데이터를 분석하고 사용할 때 유용합니다.

## 자동차 판매 실적 크롤링 모듈 구현하기

다나와의 자동차 판매 실적 데이터를 수집하기 위한 방법을 살펴보겠습니다.

### 1단계: 기본 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# 판매 실적 페이지 URL
url = 'http://example.com/sales'

# 웹 페이지 요청 및 HTML 파싱
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
```

이 코드는 requests를 사용하여 특정 URL에서 HTML 페이지를 가져오고, BeautifulSoup을 통해 HTML을 파싱하는 기본 크롤러의 구조를 설명합니다. 이 과정은 크롤링의 첫 단계를 나타냅니다.

### 2단계: 판매 실적 데이터 추출

```python
sales_data = []

# 테이블에서 데이터 추출
for row in soup.find_all('tr'):
    cols = row.find_all('td')
    if cols:
        brand = cols[0].get_text()
        sales = cols[1].get_text()
        sales_data.append({'브랜드': brand.strip(), '판매량': sales.strip()})
```

위 코드는 HTML 테이블에서 브랜드와 판매량 데이터를 추출하는 예를 보여줍니다. 여기서는 `find_all`을 통해 테이블 행과 열을 순회하며 데이터를 모읍니다.

### 3단계: 데이터 CSV 파일 저장

```python
import csv

# CSV 파일로 데이터 저장
with open('sales_data.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=['브랜드', '판매량'])
    writer.writeheader()
    writer.writerows(sales_data)
```

크롤링한 데이터를 CSV 파일로 저장합니다. 이를 통해 데이터를 쉽게 접근하고 여러 도구에서 활용할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 전체 과정을 이해하기 위한 단계별 설명입니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant CSV파일

  사용자 ->> 크롤러: URL 설정
  크롤러 ->> 웹사이트: 데이터 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> CSV파일: 가공한 데이터 저장
  사용자 -->> CSV파일: 실적 데이터 분석
```

크롤러가 웹사이트에 HTTP 요청을 보내고, HTML 응답에서 데이터를 추출 및 처리하여 CSV 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 자동차 판매 실적을 다나와 웹사이트에서 자동으로 수집하고 이를 CSV 형식으로 저장하는 방법을 알아보았습니다. 이러한 크롤링 모듈은 데이터 분석 및 비즈니스 전략 수립에 필수적인 요소입니다. 다음은 데이터베이스에 수집한 데이터를 효율적으로 저장하고 관리하는 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md) 입니다. 이를 통해 데이터 관리의 효율성을 더욱 높일 수 있습니다.
2025-06-29 20:30:43,144 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "데이터베이스 삽입 모듈". This is Chapter 9.

Concept Details (Note: Provided in Korean):
- Name: 데이터베이스 삽입 모듈
- Description:
CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 기능을 제공하는 모듈입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
---
# Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.
---
# Chapter 8: 자동차 판매 실적 크롤링 모듈

이전 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동차 관련 웹사이트에서 FAQ 데이터를 자동으로 수집하고 저장하는 방법을 배웠습니다. 이번 장에서는 `자동차 판매 실적 크롤링 모듈`을 구축하여 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하고, 이를 CSV 파일로 저장하는 방법을 알아보겠습니다.

## 동기 부여

자동차 판매 실적을 분석하는 것은 시장 동향을 파악하고, 신차 개발 및 판매 전략을 수립하는 데 중요한 역할을 합니다. 만약 특정 브랜드의 판매 실적이 급격히 증가했다면, 그 이유를 파악하여 다른 브랜드에도 적용할 수 있는 영감을 얻을 수 있습니다. 이때 매번 웹사이트를 방문해 수작업으로 데이터를 정리하는 대신, 크롤러를 사용하면 실적 데이터를 자동으로 수집 및 저장할 수 있습니다.

## 주요 개념

### 웹 크롤링

웹 크롤링은 특정 웹사이트의 정보를 자동으로 수집하는 방법입니다. 일반적으로 원하는 페이지의 HTML 코드를 가져와 필요한 데이터를 추출합니다. 다나와의 판매 실적 페이지를 탐색하고 데이터를 추출할 수 있습니다.

### CSV 형식

CSV는 데이터를 쉽고 효율적으로 저장할 수 있는 포맷입니다. 각 행은 하나의 데이터 레코드를 나타내며, 각 값은 쉼표로 구분됩니다. 추출한 판매 실적 데이터를 CSV 파일에 저장하면 데이터를 분석하고 사용할 때 유용합니다.

## 자동차 판매 실적 크롤링 모듈 구현하기

다나와의 자동차 판매 실적 데이터를 수집하기 위한 방법을 살펴보겠습니다.

### 1단계: 기본 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# 판매 실적 페이지 URL
url = 'http://example.com/sales'

# 웹 페이지 요청 및 HTML 파싱
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
```

이 코드는 requests를 사용하여 특정 URL에서 HTML 페이지를 가져오고, BeautifulSoup을 통해 HTML을 파싱하는 기본 크롤러의 구조를 설명합니다. 이 과정은 크롤링의 첫 단계를 나타냅니다.

### 2단계: 판매 실적 데이터 추출

```python
sales_data = []

# 테이블에서 데이터 추출
for row in soup.find_all('tr'):
    cols = row.find_all('td')
    if cols:
        brand = cols[0].get_text()
        sales = cols[1].get_text()
        sales_data.append({'브랜드': brand.strip(), '판매량': sales.strip()})
```

위 코드는 HTML 테이블에서 브랜드와 판매량 데이터를 추출하는 예를 보여줍니다. 여기서는 `find_all`을 통해 테이블 행과 열을 순회하며 데이터를 모읍니다.

### 3단계: 데이터 CSV 파일 저장

```python
import csv

# CSV 파일로 데이터 저장
with open('sales_data.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=['브랜드', '판매량'])
    writer.writeheader()
    writer.writerows(sales_data)
```

크롤링한 데이터를 CSV 파일로 저장합니다. 이를 통해 데이터를 쉽게 접근하고 여러 도구에서 활용할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 전체 과정을 이해하기 위한 단계별 설명입니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant CSV파일

  사용자 ->> 크롤러: URL 설정
  크롤러 ->> 웹사이트: 데이터 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> CSV파일: 가공한 데이터 저장
  사용자 -->> CSV파일: 실적 데이터 분석
```

크롤러가 웹사이트에 HTTP 요청을 보내고, HTML 응답에서 데이터를 추출 및 처리하여 CSV 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 자동차 판매 실적을 다나와 웹사이트에서 자동으로 수집하고 이를 CSV 형식으로 저장하는 방법을 알아보았습니다. 이러한 크롤링 모듈은 데이터 분석 및 비즈니스 전략 수립에 필수적인 요소입니다. 다음은 데이터베이스에 수집한 데이터를 효율적으로 저장하고 관리하는 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md) 입니다. 이를 통해 데이터 관리의 효율성을 더욱 높일 수 있습니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 9: 데이터베이스 삽입 모듈`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:30:43,352 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:30:53,864 - INFO - RESPONSE: # Chapter 9: 데이터베이스 삽입 모듈

이전 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 다나와 웹사이트에서 자동차 판매 실적 데이터를 수집하여 CSV 파일로 저장하는 방법을 배웠습니다. 이번 장에서는 `데이터베이스 삽입 모듈`을 구현하여 CSV 파일의 데이터를 MySQL 데이터베이스에 자동으로 업로드하는 방법을 알아보겠습니다.

## 동기 부여

현대의 많은 애플리케이션은 데이터를 보다 효율적이고 안정적으로 관리하기 위해 데이터베이스를 사용합니다. 특히 대량의 데이터를 처리할 때는 CSV 파일에 저장하는 것보다 데이터베이스에 저장하는 것이 효율적입니다. 이번 데이터베이스 삽입 모듈은 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입함으로써 데이터를 보다 구조적이고 신뢰성 있게 관리할 수 있도록 해줍니다.

## 주요 개념

### CSV 파일 처리

CSV 파일은 간단한 데이터 포맷이며 텍스트 데이터를 쉼표로 구분하여 저장합니다. 파이썬의 `csv` 모듈을 활용하면 CSV 파일의 데이터를 손쉽게 읽어올 수 있습니다.

### MySQL 데이터베이스 연결

MySQL 데이터베이스는 관계형 데이터베이스로, 대량의 데이터를 구조적으로 저장할 수 있게 해줍니다. 파이썬에서는 `MySQL Connector` 라이브러리를 사용하여 데이터베이스에 연결하고 데이터를 삽입할 수 있습니다.

## 데이터베이스 삽입 모듈 사용하기

이제 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 단계별로 살펴보겠습니다.

### 1단계: CSV 파일 읽기

```python
import csv

# CSV 파일 읽기
data = []
with open('sales_data.csv', mode='r', encoding='utf-8') as file:
    reader = csv.DictReader(file)
    for row in reader:
        data.append(row)
```

이 코드에서는 `csv.DictReader`를 사용하여 CSV 파일의 데이터를 읽어 목록에 저장합니다. 각 행은 딕셔너리로 변환되어 `data` 리스트에 추가됩니다.

### 2단계: 데이터베이스 연결 및 데이터 삽입

```python
import mysql.connector

# 데이터베이스 연결 설정
connection = mysql.connector.connect(
    host='localhost',
    user='user',
    password='password',
    database='car_sales_db'
)

cursor = connection.cursor()

# 데이터 삽입
for entry in data:
    sql = "INSERT INTO sales (brand, sales) VALUES (%s, %s)"
    cursor.execute(sql, (entry['브랜드'], entry['판매량']))

# 변경사항 저장
connection.commit()
```

위 코드에서는 `mysql.connector`를 사용하여 MySQL 데이터베이스에 연결한 후, 각 데이터 항목을 반복적으로 삽입합니다. 삽입 문법 `INSERT INTO`를 통해 데이터베이스에 데이터를 추가합니다. 마지막으로, `commit` 메서드로 변경 사항을 저장합니다.

## 내부 구현 이해

데이터베이스 삽입 모듈이 어떻게 작동하는지 이해하기 쉽게 시퀀스 다이어그램으로 설명하겠습니다.

```mermaid
sequenceDiagram
  participant User
  participant CSV파일
  participant Python프로그램
  participant MySQLDB

  User ->> Python프로그램: CSV 파일 읽기 요청
  Python프로그램 ->> CSV파일: 데이터 읽기
  CSV파일 -->> Python프로그램: 데이터 반환
  Python프로그램 ->> MySQLDB: 데이터베이스에 데이터 삽입
  MySQLDB -->> Python프로그램: 삽입 완료
  Python프로그램 -->> User: 완료 메시지 제공
```

이 다이어그램은 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 과정을 확인할 수 있습니다.

## 결론

이번 장에서는 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 배웠습니다. 이를 통해 데이터를 보다 구조적으로 관리하고 활용할 수 있습니다. 다음 [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)에서는 데이터베이스 연결 설정에 대해 더욱 상세히 알아보겠습니다. 데이터베이스와의 원활한 연결은 안정적인 데이터 처리에 필수적입니다. 

---

이번 과정을 통해 데이터베이스 활용 능력이 한 단계 업그레이드될 것입니다. 지속적인 실습을 통해 데이터 관리자 및 개발자로서의 역량을 키워보세요!
2025-06-29 20:30:53,868 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "데이터베이스 연결 설정". This is Chapter 10.

Concept Details (Note: Provided in Korean):
- Name: 데이터베이스 연결 설정
- Description:
MySQL 데이터베이스에 연결하기 위한 설정 및 쿼리를 실행하여 데이터를 가져오는 기능을 제공합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
---
# Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.
---
# Chapter 8: 자동차 판매 실적 크롤링 모듈

이전 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동차 관련 웹사이트에서 FAQ 데이터를 자동으로 수집하고 저장하는 방법을 배웠습니다. 이번 장에서는 `자동차 판매 실적 크롤링 모듈`을 구축하여 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하고, 이를 CSV 파일로 저장하는 방법을 알아보겠습니다.

## 동기 부여

자동차 판매 실적을 분석하는 것은 시장 동향을 파악하고, 신차 개발 및 판매 전략을 수립하는 데 중요한 역할을 합니다. 만약 특정 브랜드의 판매 실적이 급격히 증가했다면, 그 이유를 파악하여 다른 브랜드에도 적용할 수 있는 영감을 얻을 수 있습니다. 이때 매번 웹사이트를 방문해 수작업으로 데이터를 정리하는 대신, 크롤러를 사용하면 실적 데이터를 자동으로 수집 및 저장할 수 있습니다.

## 주요 개념

### 웹 크롤링

웹 크롤링은 특정 웹사이트의 정보를 자동으로 수집하는 방법입니다. 일반적으로 원하는 페이지의 HTML 코드를 가져와 필요한 데이터를 추출합니다. 다나와의 판매 실적 페이지를 탐색하고 데이터를 추출할 수 있습니다.

### CSV 형식

CSV는 데이터를 쉽고 효율적으로 저장할 수 있는 포맷입니다. 각 행은 하나의 데이터 레코드를 나타내며, 각 값은 쉼표로 구분됩니다. 추출한 판매 실적 데이터를 CSV 파일에 저장하면 데이터를 분석하고 사용할 때 유용합니다.

## 자동차 판매 실적 크롤링 모듈 구현하기

다나와의 자동차 판매 실적 데이터를 수집하기 위한 방법을 살펴보겠습니다.

### 1단계: 기본 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# 판매 실적 페이지 URL
url = 'http://example.com/sales'

# 웹 페이지 요청 및 HTML 파싱
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
```

이 코드는 requests를 사용하여 특정 URL에서 HTML 페이지를 가져오고, BeautifulSoup을 통해 HTML을 파싱하는 기본 크롤러의 구조를 설명합니다. 이 과정은 크롤링의 첫 단계를 나타냅니다.

### 2단계: 판매 실적 데이터 추출

```python
sales_data = []

# 테이블에서 데이터 추출
for row in soup.find_all('tr'):
    cols = row.find_all('td')
    if cols:
        brand = cols[0].get_text()
        sales = cols[1].get_text()
        sales_data.append({'브랜드': brand.strip(), '판매량': sales.strip()})
```

위 코드는 HTML 테이블에서 브랜드와 판매량 데이터를 추출하는 예를 보여줍니다. 여기서는 `find_all`을 통해 테이블 행과 열을 순회하며 데이터를 모읍니다.

### 3단계: 데이터 CSV 파일 저장

```python
import csv

# CSV 파일로 데이터 저장
with open('sales_data.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=['브랜드', '판매량'])
    writer.writeheader()
    writer.writerows(sales_data)
```

크롤링한 데이터를 CSV 파일로 저장합니다. 이를 통해 데이터를 쉽게 접근하고 여러 도구에서 활용할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 전체 과정을 이해하기 위한 단계별 설명입니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant CSV파일

  사용자 ->> 크롤러: URL 설정
  크롤러 ->> 웹사이트: 데이터 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> CSV파일: 가공한 데이터 저장
  사용자 -->> CSV파일: 실적 데이터 분석
```

크롤러가 웹사이트에 HTTP 요청을 보내고, HTML 응답에서 데이터를 추출 및 처리하여 CSV 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 자동차 판매 실적을 다나와 웹사이트에서 자동으로 수집하고 이를 CSV 형식으로 저장하는 방법을 알아보았습니다. 이러한 크롤링 모듈은 데이터 분석 및 비즈니스 전략 수립에 필수적인 요소입니다. 다음은 데이터베이스에 수집한 데이터를 효율적으로 저장하고 관리하는 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md) 입니다. 이를 통해 데이터 관리의 효율성을 더욱 높일 수 있습니다.
---
# Chapter 9: 데이터베이스 삽입 모듈

이전 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 다나와 웹사이트에서 자동차 판매 실적 데이터를 수집하여 CSV 파일로 저장하는 방법을 배웠습니다. 이번 장에서는 `데이터베이스 삽입 모듈`을 구현하여 CSV 파일의 데이터를 MySQL 데이터베이스에 자동으로 업로드하는 방법을 알아보겠습니다.

## 동기 부여

현대의 많은 애플리케이션은 데이터를 보다 효율적이고 안정적으로 관리하기 위해 데이터베이스를 사용합니다. 특히 대량의 데이터를 처리할 때는 CSV 파일에 저장하는 것보다 데이터베이스에 저장하는 것이 효율적입니다. 이번 데이터베이스 삽입 모듈은 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입함으로써 데이터를 보다 구조적이고 신뢰성 있게 관리할 수 있도록 해줍니다.

## 주요 개념

### CSV 파일 처리

CSV 파일은 간단한 데이터 포맷이며 텍스트 데이터를 쉼표로 구분하여 저장합니다. 파이썬의 `csv` 모듈을 활용하면 CSV 파일의 데이터를 손쉽게 읽어올 수 있습니다.

### MySQL 데이터베이스 연결

MySQL 데이터베이스는 관계형 데이터베이스로, 대량의 데이터를 구조적으로 저장할 수 있게 해줍니다. 파이썬에서는 `MySQL Connector` 라이브러리를 사용하여 데이터베이스에 연결하고 데이터를 삽입할 수 있습니다.

## 데이터베이스 삽입 모듈 사용하기

이제 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 단계별로 살펴보겠습니다.

### 1단계: CSV 파일 읽기

```python
import csv

# CSV 파일 읽기
data = []
with open('sales_data.csv', mode='r', encoding='utf-8') as file:
    reader = csv.DictReader(file)
    for row in reader:
        data.append(row)
```

이 코드에서는 `csv.DictReader`를 사용하여 CSV 파일의 데이터를 읽어 목록에 저장합니다. 각 행은 딕셔너리로 변환되어 `data` 리스트에 추가됩니다.

### 2단계: 데이터베이스 연결 및 데이터 삽입

```python
import mysql.connector

# 데이터베이스 연결 설정
connection = mysql.connector.connect(
    host='localhost',
    user='user',
    password='password',
    database='car_sales_db'
)

cursor = connection.cursor()

# 데이터 삽입
for entry in data:
    sql = "INSERT INTO sales (brand, sales) VALUES (%s, %s)"
    cursor.execute(sql, (entry['브랜드'], entry['판매량']))

# 변경사항 저장
connection.commit()
```

위 코드에서는 `mysql.connector`를 사용하여 MySQL 데이터베이스에 연결한 후, 각 데이터 항목을 반복적으로 삽입합니다. 삽입 문법 `INSERT INTO`를 통해 데이터베이스에 데이터를 추가합니다. 마지막으로, `commit` 메서드로 변경 사항을 저장합니다.

## 내부 구현 이해

데이터베이스 삽입 모듈이 어떻게 작동하는지 이해하기 쉽게 시퀀스 다이어그램으로 설명하겠습니다.

```mermaid
sequenceDiagram
  participant User
  participant CSV파일
  participant Python프로그램
  participant MySQLDB

  User ->> Python프로그램: CSV 파일 읽기 요청
  Python프로그램 ->> CSV파일: 데이터 읽기
  CSV파일 -->> Python프로그램: 데이터 반환
  Python프로그램 ->> MySQLDB: 데이터베이스에 데이터 삽입
  MySQLDB -->> Python프로그램: 삽입 완료
  Python프로그램 -->> User: 완료 메시지 제공
```

이 다이어그램은 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 과정을 확인할 수 있습니다.

## 결론

이번 장에서는 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 배웠습니다. 이를 통해 데이터를 보다 구조적으로 관리하고 활용할 수 있습니다. 다음 [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)에서는 데이터베이스 연결 설정에 대해 더욱 상세히 알아보겠습니다. 데이터베이스와의 원활한 연결은 안정적인 데이터 처리에 필수적입니다. 

---

이번 과정을 통해 데이터베이스 활용 능력이 한 단계 업그레이드될 것입니다. 지속적인 실습을 통해 데이터 관리자 및 개발자로서의 역량을 키워보세요!

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 10: 데이터베이스 연결 설정`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:30:54,034 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:31:05,501 - INFO - RESPONSE: # 제10장: 데이터베이스 연결 설정

이전 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)에서 우리는 CSV 파일로부터 읽은 데이터를 MySQL 데이터베이스에 삽입하는 방법을 배웠습니다. 이번 장에서는 `데이터베이스 연결 설정`에 대해 자세히 알아보겠습니다. 이는 MySQL 데이터베이스와의 안정적인 연결을 위해 반드시 필요한 설정입니다.

## 동기 부여

데이터를 효과적으로 관리하기 위해서는 데이터베이스와의 연결이 매우 중요합니다. 데이터베이스 연결 설정이 제대로 되어 있지 않으면 데이터를 저장하거나 불러올 때 문제가 발생할 수 있습니다. 예를 들어, 자동차 판매 실적 데이터를 분석하고자 할 때 MySQL 데이터베이스에 연결할 수 없거나 연결이 불안정하면 분석에 차질이 생깁니다. 안정적인 데이터베이스 연결을 위해 필요한 주요 설정과 절차를 배워봅시다.

## 주요 개념

### MySQL 데이터베이스 서버

MySQL은 인기 있는 오픈 소스 데이터베이스 관리 시스템으로, 데이터를 효율적으로 저장하고 검색할 수 있습니다. 이를 활용하기 위해서는 데이터베이스 서버와의 연결을 적절히 설정해야 합니다.

### 연결 문자열

연결 문자열은 데이터베이스 서버의 주소, 사용자 이름, 비밀번호 등 연결에 필요한 정보를 포함합니다. Python의 `mysql.connector` 라이브러리를 통해 MySQL에 연결할 수 있습니다. 이를 통해 원하는 데이터를 가져오거나 저장할 수 있습니다.

## 데이터베이스 연결 설정

데이터베이스 연결을 설정하는 방법을 단계적으로 살펴보겠습니다.

### 1단계: MySQL Connector 설치

먼저 MySQL Connector를 설치해야 합니다. 터미널이나 커맨드 라인에서 다음 명령어를 사용하세요.

```bash
pip install mysql-connector-python
```

이 명령어를 실행하면 MySQL 데이터베이스와의 연결을 위한 라이브러리가 설치됩니다.

### 2단계: 데이터베이스 연결 설정 코드

MySQL에 연결하려면 다음과 같이 연결 설정을 할 수 있습니다.

```python
import mysql.connector

# MySQL 데이터베이스에 연결
connection = mysql.connector.connect(
    host='localhost',     # 데이터베이스 서버 주소
    user='user',          # 사용자 이름
    password='password',  # 비밀번호
    database='my_database' # 사용할 데이터베이스 이름
)

# 연결 확인
if connection.is_connected():
    print("연결 성공!")
```

이 코드는 MySQL 데이터베이스와의 연결을 설정하는 가장 기본적인 방법입니다. 데이터베이스 서버 주소, 사용자 이름, 비밀번호, 데이터베이스 이름을 올바르게 입력하면 됩니다.

### 내부 작동 방식 이해

데이터베이스 연결의 내부 작동 방식을 이해하는 것은 중요합니다. 다음은 연결 설정이 이루어지는 과정을 설명합니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant Python프로그램
  participant MySQLDB

  사용자 ->> Python프로그램: 연결 설정 요청
  Python프로그램 ->> MySQLDB: 연결 시도
  MySQLDB -->> Python프로그램: 연결 승인
  Python프로그램 -->> 사용자: 연결 성공 메시지
```

이 다이어그램은 사용자로부터 연결 설정 요청을 받아, Python 프로그램이 MySQL 데이터베이스에 연결을 시도하고, 연결 여부를 사용자에게 알리는 과정을 보여줍니다.

## 결론

이번 장에서는 MySQL 데이터베이스와의 연결을 설정하는 방법에 대해 학습했습니다. MySQL Connector를 설치하고, 필요한 정보를 사용하여 연결을 설정하였습니다. 안정적인 연결 설정을 통해 데이터를 보다 효율적으로 관리할 수 있습니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md) 장에서는 데이터를 효율적으로 탐색할 수 있는 검색 및 페이지네이션 기능을 구현하는 방법을 배워보겠습니다.

데이터베이스 활용의 기초를 다지며 계속해서 발전해 나가시길 바랍니다!
2025-06-29 20:33:26,961 - INFO - PROMPT: 
Analyze the following codebase for the project 'SKN10-1st-4Team'.

Available files (total 11):
- 0 # 1_연도별_자동차_등록_현황.py
- 1 # README.md
- 2 # common/insert_data.py
- 3 # common/insert_data_city.py
- 4 # crawling/danawa.py
- 5 # crawling/genesis_faq.py
- 6 # crawling/hyundai_faq.py
- 7 # crawling/kia_faq.py
- 8 # pages/2_지역별_자동차_등록_현황.py
- 9 # pages/3_브랜드별_자동차_판매_현황.py
- 10 # pages/4_주요_3개_기업_차량_구매_FAQ.py

Full context of all files:
--- File Index 0: 1_연도별_자동차_등록_현황.py ---
#test
import streamlit as st
import pandas as pd
import plotly.express as px
import pymysql
from common.insert_data import insert_data
from common.insert_data_city import insert_data_city

insert_data()
insert_data_city()

st.set_page_config(layout="centered")

st.title("📊 연도별 자동차 등록 현황")
st.divider()

# 데이터베이스 연결 설정
connection = pymysql.connect(
    host="localhost",
    user="SKN10_4team",
    password="skn1234",
    database="SKN10_4team_1st",
    charset="utf8"
)

# SQL 데이터 가져오기
year_data = "select Year FROM Car"
ef = pd.read_sql(year_data, connection)

car_data = """
SELECT Year, SUM(CarCount) YearofCar
FROM SKN10_4team_1st.Car
GROUP BY Year
ORDER BY Year;
"""
cf = pd.read_sql(car_data, connection)

# Streamlit 컨테이너
with st.container():
    # 컬럼 레이아웃 사용
    col1, col2 = st.columns(2)
    # 년도 리스트 생성 및 선택
    years = ef['Year'].unique().tolist()

    # 디폴트 값 설정
    default_start_year_index = 0  # 첫 번째 연도를 디폴트로 설정
    default_end_year_index = len(years) - 1  # 마지막 연도를 디폴트로 설정

    with col1:
        start_year = st.selectbox(
            '첫번째 년도를 선택해주세요.', 
            years, 
            index=default_start_year_index
        )

    with col2:
        end_year = st.selectbox(
            '마지막 년도를 선택해주세요.', 
            years, 
            index=default_end_year_index
        )

# 연도 범위 확인 및 데이터 필터링
if start_year > end_year:
    st.error("Error: The start year cannot be greater than the end year.")
else:
    with st.container():
        # 사용자 입력 값으로 데이터 필터링
        filtered_data = cf[(cf["Year"] >= start_year) & (cf["Year"] <= end_year)]

        # Plotly로 그래프 생성
        fig = px.bar(
            filtered_data, 
            x="Year", 
            y="YearofCar", 
            title="조회결과"
        )

        # axis title 업데이트
        fig.update_xaxes(title_text="연도")
        fig.update_yaxes(title_text="차량 수 (만대)")

        # 그래프 출력
        st.plotly_chart(fig)

}]}

--- File Index 1: README.md ---
# SKN10-1st-4Team
<br/>

![](https://cdn.imweb.me/upload/S20240314bd10436a7991a/41a9769cc44e6.png)
<br/>
<br/>

## ⭐ 프로젝트 팀
<br/>

| 좌민서 | 김민혜 | 박예슬 | 신민주 | 홍승표 | 황인호 |
| :---: | :---: | :---: | :---: | :---: | :---: |
| - 팀장<br/>- 지역별 자동차 등록 현황<br/>(그래프) | - ERD 설계<br/>- DB 구현 | - ERD 설계<br/>- 현대자동차 FAQ | - 화면 설계<br/>- 제네시스 FAQ | - 라이브러리 조사<br/>- 연도별 자동차 등록 현황 | - 화면 설계<br/>- 기아자동차 FAQ<br/>- 지역별 자동차 등록 현황<br/>(지도)<br/>- 브랜드별 자동차 판매 현황
| [@INe](https://github.com/INe904) | [@kkminhye](https://github.com/kkminhye) | [@yeseulnim](https://github.com/yeseulnim) | [@sinminju](https://github.com/sinminju) | [@redwin02](https://github.com/redwin-02) | [@HIHO9999](https://github.com/HIHO999) |
<br/>

## 📌 프로젝트 개요
<br/>

### 프로젝트 주제
<br/>

**전국 자동차 등록 현황 및 기업 FAQ 조회 시스템**
<br/>
<br/>

### 프로젝트 목적
<br/>

1. 전국 자동차 등록 현황을 연도별 및 지역별로 분석하여, **자동차 증가 추세와 지역별 특성을 파악**한다. 이를 통해 **교통 정책 수립 및 지역 발전 전략**에 기여할 수 있는 정보를 제공한다.
<br/>

2. 국내 브랜드별 자동차 구매통계 및 3대 자동차 기업의 차량구매 관련 FAQ 정보를 한 곳에 모아, **자동차 구매 예정 소비자에게 필요한 정보**를 제공한다.
<br/>
<br/>

### 프로젝트 필요성
<br/>

1. 자동차 등록 현황은 도시 교통 문제, 환경 정책, 도로 인프라 계획 등과 밀접하게 연관되어 있다.
<br/>

2. 연도별 및 지역별 자동차 등록 현황 데이터를 시각화하여, 공공 및 민간 부분에서 데이터 기반 정책 결정을 지원한다.
<br/>

3. 자동차 구매를 고려하는 소비자는 브랜드별 차량 등록 현황과 차량 구매 관련 정보를 한눈에 확인하기 어려운 경우가 많다. 국내 브랜드별 자동차 구매 통계와 주요 자동차 기업의 FAQ 정보를 통합 제공함으로써, 소비자들이 보다 신속하고 정확한 의사 결정을 할 수 있도록 돕는다.
<br/>

### 프로젝트 내용
<br/>

 1. **데이터 수집 및 가공**
<br/>

- <b>[지표누리](https://www.index.go.kr/unity/potal/main/EachDtlPageDetail.do?idx_cd=1257)</b>에서 제공하는 연도별 및 지역별 자동차 등록 현황 데이터를 수집하여 목적에 맞게 가공한 후, 데이터베이스에 저장한다.
<br/>

- 국내 판매율이 가장 높은 주요 3개 자동차 회사(<b>[현대](https://www.hyundai.com/kr/ko/e/customer/center/faq)</b>, <b>[기아](https://www.kia.com/kr/customer-service/center/faq)</b>, <b>[제네시스](https://www.genesis.com/kr/ko/support/faq.html)</b>)의 차량 구매 FAQ를 Selenium을 이용하여 크롤링한 뒤 JSON 파일로 저장한다.
<br/>

- 다나와의 <b>[자동차 판매 실적](https://auto.danawa.com/auto/?Work=record&pcUse=y)</b> 페이지에서 제공하는 브랜드별 자동차 판매 실적을 Selenium을 이용하여 크롤링한 뒤 CSV 파일로 저장한다.

<br/>

2. **데이터 시각화**
<br/>

- 수집한 자동차 통계 관련 데이터를 Python의 **Plotly**, **MatPlotLib** 및 **Folium** 라이브러리를 통해 시각화한다.
<br/>

3. **FAQ 제공**
<br/>

- 크롤링한 주요 자동차 브랜드의 FAQ 내용을 한곳에 모아, 검색 기능과 함께 제공한다.
<br/>

### 프로젝트 기대 효과
<br/>

1. **연도별 및 지역별 자동차 등록 현황의 시각적 자료**를 제공하여 데이터를 직관적으로 파악할 수 있다.
<br/>

2. **교통 및 환경 정책 수립**을 위한 기초 데이터를 제공한다.
<br/>

3. **브랜드별 차량 판매량** 및 **기업 FAQ 조회 시스템**을 통해 소비자의 정보 접근성을 높인다.
<br/>
<br/>

## 📌 설치/사용 방법
<br/>

### 1. GitHub에서 Repository Clone
<br/>

```python
    git clone https://github.com/SKNETWORKS-FAMILY-AICAMP/SKN10-1st-4Team.git
```
<br/>

### 2. 라이브러리 설치
<br/>

```python
    pip install -r requirements.txt
```
<br/>

### 3. 데이터베이스 구축
DBeaver 실행 후, 계정생성 권한 있는 계정에서 sql\create_tables.sql 파일의 코드 실행
<br/>

### 4. (생략 가능) 정보 수집 - 웹 크롤링 코드 실행
<br/>

※ 웹 크롤링 결과물은 data 폴더에 json 파일로 저장되어 있으므로, 별도의 크롤링 없이 바로 실행이 가능하다. 다만, 신규 데이터 확인을 위해 웹 크롤링이 필요한 경우 아래 코드를 사용할 수 있다.
<br/>

```python
    python crawling/kia_faq.py
```
```python
    python crawling/hyundai_faq.py
```
```python
    python crawling/genesis_faq.py
```
```python
    python crawling/danawa.py
```
<br/>

### 5. 서비스 실행
<br/>

```python
    streamlit run 1_연도별_자동차_등록_현황.py
```
<br/>
<br/>

## 📌 기술 스택
<br/>

### 화면 설계
<br/>

![](https://img.shields.io/badge/Figma-F24E1E?style=for-the-badge&logo=figma&logoColor=white)
<br/>

### 데이터 가공 및 처리
<br/>

![](https://img.shields.io/badge/MySQL-4479A1?style=for-the-badge&logo=mysql&logoColor=white) &nbsp; ![](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=white)
<br/>

### 화면 구현
<br/>

![](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=white) &nbsp; ![](https://img.shields.io/badge/streamlit-FF0000?style=for-the-badge&logo=streamlit&logoColor=white)
<br/>

### 버전 관리 및 협업
<br/>

![](https://img.shields.io/badge/github-000000?style=for-the-badge&logo=github&logoColor=white)
<br/>
<br/>

## 💻 화면 설계
<br/>

### 0. 메뉴
<br/>

![](/images/menu_design.png)
<br/>

### 1. 연도별 자동차 등록 현황
<br/>

![](/images/year_design.png)
<br/>

### 2. 지역별 자동차 등록 현황
<br/>

![](/images/region_design.png)
<br/>

### 3. 주요 3개 기업 차량 구매 FAQ
<br/>

![](/images/faq_design.png)
<br/>
<br/>

## 💻 데이터 가공 및 처리
<br/>

### ERD
<br/>

![](/images/erd.png)
<br/>
<br/>

### 실제 데이터 가공 및 처리

1. **자동차 등록 현황**
<br/>

- 자료 출처 : <b>[지표누리 자동차 등록 현황](https://www.index.go.kr/unity/potal/main/EachDtlPageDetail.do?idx_cd=1257)</b> (*2012 ~ 2022)
<br/>

- 자료 가공 : 개별 Excel 파일 다운로드 -> CSV로 변경 -> MySQL 데이터베이스 테이블로 저장
<br/>

2. **주요 3개 기업 차량 구매 FAQ**
<br/>

- 자료 출처 : 국내 3대 자동차 기업 (<b>[현대](https://www.hyundai.com/kr/ko/e/customer/center/faq)</b>, <b>[기아](https://www.kia.com/kr/customer-service/center/faq)</b>, <b>[제네시스](https://www.genesis.com/kr/ko/support/faq.html)</b>) 홈페이지 'FAQ' 중 '차량 구매' 항목
<br/>

- 자료 가공 : Selenium으로 웹크롤링 -> JSON으로 저장 
<br/>

3. **브랜드별 자동차 판매 실적**
<br/>

- 자료 출처 : 다나와 <b>[자동차 판매 실적](https://auto.danawa.com/auto/?Work=record&pcUse=y)</b> 페이지 (*2021.01 ~ 2024.12)
<br/>

- 자료 가공 : Selenium으로 웹크롤링 -> CSV로 저장
<br/>
<br/>

## 📌 프로젝트 최종 결과
<br/>

### 1. 연도별 자동차 등록 현황
<br/>

![](/images/final_screen1.png)
<br/>

### 2. 지역별 자동차 등록 현황
<br/>

![](/images/final_screen2.png)
<br/>

![](/images/final_screen3.png)
<br/>

### 3. 주요 3개 기업 차량 구매 FAQ
<br/>

![](/images/final_screen4.png)
<br/>

### 4. 브랜드별 자동차 판매 순위
<br/>

![](/images/final_screen5.png)
<br/>
<br/>

## 🖥️개발과정에서 발생한 이슈 및 해결방법
<br/>

### 1. SQL DB 구축
<br/>

**문제**
<br/>

MySQL DB는 깃헙으로 동기화되지 않고 각 인원이 각자 구축해야 했기에 그 과정에서 시행착오가 있었음.
<br/>

**해결**
<br/>

실수방지를 위해 최종 코드에서는 DB및 테이블 생성 SQL코드를 별도파일로 두고, 테이블 내용 생성은 함수로 만들어 자동 실행되도록 함.
<br/>

### 2. 복잡한 SQL 저장 구조
<br/>

**문제**
<br/>

최초 기획한 ERD 구조에는 FAQ가 포함되어 있었으나, 실제 구현시 FAQ를 별도 JSON 파일에 담고 그를 MySQL 테이블로 만든뒤 이를 불러오는 과정이 비효율적이라 판단되었음. 
<br/>

**해결**
<br/>

ERD구조를 수정하여 FAQ를 ERD에서 빼고, FAQ페이지의 내용은 JSON파일에서 바로 불러오기로 함.
<br/>

### 3. 기능구현 완료후 오류 발생
<br/>

**문제**
<br/>

'현대차 FAQ' 페이지에서 검색기능 이용시, 검색결과가 없을 경우, '기아차 FAQ' 등 다른 탭으로 이동하면 탭의 내용이 나타나지 않는 버그 발생
<br/>

**해결**
<br/>

AI의 디버깅 보조를 이용, 코드를 수정하여 해결함.
<br/>
<br/>

## ✍️팀원별 느낀점
<br/>

### 좌민서
<br/>

지금까지 배운 내용을 바탕으로 응용된 내용을 활용할 수 있었던 좋은 기회가 되었습니다. 어쩌다 보니 이번에 팀장을 맡게 되었는데 많이 부족함에도 불구하고 팀원분들이 잘 따라와 주시고 도와주셔서 이번 프로젝트를 무사히 마칠 수 있었던 것 같습니다.

<br/>

### 신민주
<br/>

체계적인 프로젝트를 처음 진행해봤는데 팀워크의 중요성을 느꼈습니다. 제가 부족한 부분이 많았지만 다들 친절히 알려주셔서 배우면서 프로젝트에 참여할 수 있었습니다. 앞으로의 활동에도 좋은 경험이 될 것 같습니다.

<br/>

### 박예슬
<br/>

다인 프로젝트 깃 관리의 어려움과 중요성을 체감했습니다. 고생하신 팀장님과 팀원들에게 박수를 보냅니다.

<br/>

### 김민혜
<br/>

팀장을 맡으신 민서님이 프로젝트 전반적인 과정을 꼼꼼하게 정리하고 원할하게 진행해주셨다고 생각합니다. 각 팀원이 맡은 역할에 충실할 뿐만 아니라 가진 역량을 빛내고 서로 도와 문제를 해결하는 과정을 경험할 수 있어서 정말 좋았습니다.

<br/>

### 황인호
<br/>

팀프로젝트를  제대로 수행해본적이 처음이었지만 팀장분께서 역할분담 잘해주셔서 맡은바 열심히 그리고 만족스럽게 수행한것같습니다. 앞으로의 협력 업무에 있어서 좋은 경험이 되었습니다.

<br/>

### 홍승표
<br/>

저는 사람이 아닙니다. 몽키입니다. 아닙니다. 코드도 못치니 그냥 몽키입니다. 열심히 배워서 코드몽키라도 될 수 있도록 노력하겠습니다. 그리고 능력자이신 팀원분들을 만나 너무 좋았습니다. 몽키 한 마리 만나서 고생한 팀원들에게 너무 고맙고 다음 프로젝트때는 버스 타기실 기도하겠습니다. 
<br/>


--- File Index 2: common/insert_data.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "Car.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "Car"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (Year, CityID, CarCount) VALUES (%s, %s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[2], row[3])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File Index 3: common/insert_data_city.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data_city():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "City.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "City"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (CityID, CityName) VALUES (%s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[1])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File Index 4: crawling/danawa.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By


import pandas as pd
import time

# 크롬 드라이버 설정

driver = webdriver.Chrome()

# 데이터 저장 리스트
domestic_data = []
foreign_data = []

# 2021년 1월부터 2024년 12월까지의 URL 생성 및 데이터 크롤링
for year in range(2021, 2025):
    for month in range(1, 13):
        if year == 2024 and month > 12:
            break
        month_str = f"{year}-{month:02d}-00"
        url = f"https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month={month_str}&MonthTo="
        driver.get(url)
        time.sleep(0.5)  # 페이지 로딩 대기

        # 국산차 순위 데이터 크롤링
        rank_elements = driver.find_elements(By.CSS_SELECTOR, "ul.sideRankR li")

        for index, rank_element in enumerate(rank_elements):
            rank = rank_element.find_element(By.CSS_SELECTOR, "span.rank").text
            brand = rank_element.find_element(By.CSS_SELECTOR, "span.title").text.strip()
            sales = rank_element.find_element(By.CSS_SELECTOR, "span.sales").text
            rate = rank_element.find_element(By.CSS_SELECTOR, "span.rate").text
            logo_img = rank_element.find_element(By.CSS_SELECTOR, "span.title img").get_attribute("src")
            data = [year, month, rank, brand, sales, rate, logo_img]
            if index < 6:
                domestic_data.append(data)
            else:
                foreign_data.append(data)

# 데이터프레임으로 변환
domestic_df = pd.DataFrame(domestic_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])
foreign_df = pd.DataFrame(foreign_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])

# 데이터프레임 저장
domestic_df.to_csv("data\국산차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')
foreign_df.to_csv("data\해외차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')

# 드라이버 종료
driver.quit()

print("크롤링 완료 및 데이터 저장 완료")
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo=
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo= 에서 2021-01은 21년 1월 데이터를 받아온다는 의미


--- File Index 5: crawling/genesis_faq.py ---

# 제네시스 크롤링
from selenium import webdriver
from bs4 import BeautifulSoup
import json

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.genesis.com/kr/ko/support/faq/vehicle-purchase.html?anchorID=faq_tab"
driver.get(url)

# 페이지 소스 가져오기
html_source = driver.page_source

# HTML 파일로 저장
#with open("genesis_faq.html", "w", encoding="utf-8") as file:
#    file.write(html_source)

# 드라이버 종료
driver.quit()

# BeautifulSoup을 사용하여 페이지 소스 파싱
soup = BeautifulSoup(html_source, 'html.parser')

# FAQ 질문과 답변 추출
faqs = []
faq_items = soup.select('.cp-faq__accordion-item')  # FAQ 항목을 감싸는 클래스 이름을 사용하여 선택

for item in faq_items:
    question = item.select_one('.accordion-title').get_text(strip=True)
    answer = item.select_one('.accordion-panel-inner').get_text(strip=True)
    faqs.append({'question': question, 'answer': answer})

# 추출한 FAQ를 파일로 저장
with open("data\genesis_faq.json", "w", encoding="utf-8") as file:
    json.dump(faqs, file, ensure_ascii=False, indent=4)

--- File Index 6: crawling/hyundai_faq.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from time import sleep

#import pandas as pd
import json


URL = "https://www.hyundai.com/kr/ko/e/customer/center/faq"

driver = webdriver.Chrome()
driver.get(URL)
# 리스트에 딕셔너리로 내용 저장
qna_list = []

for page_id in range(4):
    for question_id in range(1,11):
        try:
            #엘리먼트 찾기
            faq_list = driver.find_element(By.CSS_SELECTOR, "div[data-v-28d34f54].list-wrap")

            try:
                # 플로팅 메뉴 제거
                floating_menu = driver.find_element(By.CSS_SELECTOR, "div[data-v-1ea4ba2d].inner_wrap")
                driver.execute_script("arguments[0].remove();", floating_menu)
            except:
                pass
            faq_title = faq_list.find_elements(By.CSS_SELECTOR,f"div[data-id='{question_id}'] button.list-title")
            driver.execute_script("arguments[0].scrollIntoView({block:'center'});",faq_title[0])
            sleep(0.5)

            #질문타이틀 클릭하기
            faq_title[0].click()
            sleep(0.5)

            #질문타이틀 텍스트 받아오기
            faq_question = faq_title[0].find_element(By.CSS_SELECTOR, "span.list-content[data-v-28d34f54]")
            faq_question_text = faq_question.text
            #print(faq_question_text)

            #질문답변 텍스트 받아오기
            faq_answer = driver.find_element(By.CLASS_NAME, "conts")
            faq_answer_text = faq_answer.text
            #print("전체 답변:", faq_answer_text)

            # 링크 URL 가져오기
            try:
                link_whole = faq_answer.find_elements(By.TAG_NAME, "a")
                link = {
                    "url" : link_whole[0].get_attribute("href"),
                    "text" : link_whole[0].text
                    }
            except:
                link = ""
            #print("링크 URL:", url)
            
            qna_list.append({"question": faq_question_text, "answer": faq_answer_text, "link": link})

        except TimeoutException:
            print("Timed out waiting for page to load")
        except NoSuchElementException:
            print("Could not find the element")
        except IndexError:
            pass

    next_button = driver.find_element(By.CSS_SELECTOR, "button.btn-next")
    next_button.click()
    sleep(1)
 
#qna_df = pd.DataFrame(qna_list, columns = ["page_num","question_num","question","answer","link"])
#qna_df.to_csv(path_or_buf="data/hyundai_qna.csv")

# 결과를 JSON 파일로 저장
with open("data\hyundai_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(qna_list, json_file, ensure_ascii=False, indent=4)

--- File Index 7: crawling/kia_faq.py ---
import json
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.kia.com/kr/customer-service/center/faq"
driver.get(url)

# 페이지가 완전히 로드될 때까지 대기
WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, "body")))

# "TOP 10" 버튼 클릭
top_10_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//button[contains(text(), 'TOP 10')]"))
)
top_10_button.click()

# "차량 구매" 버튼 클릭
car_purchase_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//li[button/span[text()='차량 구매']]"))
)
car_purchase_button.click()

# 3초 텀을 둠
time.sleep(3)

# 각 질문 클릭하여 답변 가져오기
faq_data = []

def get_faq_data():
    # FAQ 항목이 로드될 때까지 대기
    WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

    # FAQ 항목들 찾기
    faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")

    for i in range(len(faq_items)):
        # 각 질문을 클릭하기 전에 요소를 다시 찾음
        faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")
        item = faq_items[i]
        question = item.find_element(By.CSS_SELECTOR, ".cmp-accordion__title").text
        item.click()  # 질문 클릭하여 답변 표시

        # 답변이 로드될 때까지 대기
        panel_id = item.get_attribute("aria-controls")
        WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.ID, panel_id)))
        answer_element = driver.find_element(By.ID, panel_id)
        answer = answer_element.text

        # 하이퍼링크 정보 가져오기
        links = []
        link_elements = answer_element.find_elements(By.TAG_NAME, "a")
        for link in link_elements:
            links.append({
                "href": link.get_attribute("href"),
                "text": link.text
            })

        # 이미지 링크 정보 가져오기
        images = []
        image_elements = answer_element.find_elements(By.TAG_NAME, "img")
        for img in image_elements:
            images.append({
                "src": img.get_attribute("src"),
                "alt": img.get_attribute("alt")
            })

        faq_data.append({
            "question": question,
            "answer": answer,
            "links": links,
            "images": images
        })

    # 스크롤을 맨 위로 올리기
    driver.execute_script("window.scrollTo(0, 0);")

# 첫 페이지의 FAQ 데이터 가져오기
get_faq_data()

# 페이지 넘기기
current_page = 1
while current_page < 4:
    try:
        next_page = str(current_page + 1)

        # 다음 페이지 번호 클릭
        next_page_element = driver.find_element(By.XPATH, f"//ul[@class='paging-list']//a[text()='{next_page}']")
        next_page_element.click()

        # 3초 텀을 둠
        time.sleep(3)

        # 다음 페이지가 로드될 때까지 대기
        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

        # 각 페이지의 FAQ 데이터를 가져오기 전에 요소를 다시 찾음
        get_faq_data()

        current_page += 1
    except Exception as e:
        print(f"Error: {e}")
        break

# 드라이버 종료
driver.quit()

# 결과를 JSON 파일로 저장
with open("/data/kia_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(faq_data, json_file, ensure_ascii=False, indent=4)

# 결과 출력
'''
for faq in faq_data:
    print(f"Question: {faq['question']}")
    print(f"Answer: {faq['answer']}")
    print(f"Links: {faq['links']}")
    print(f"Images: {faq['images']}\n")
'''

--- File Index 8: pages/2_지역별_자동차_등록_현황.py ---
import streamlit as st
import pymysql
import pandas as pd
import plotly.express as px
import folium
import random
from streamlit_folium import folium_static

st.set_page_config(layout="wide")

st.title("📊 지역별 자동차 등록 현황")

tab1, tab2 = st.tabs(['차트', '지도'])

with tab1:
    # Database 연결
    connection = pymysql.connect(
        host = "localhost",
        user = "SKN10_4team",
        password = "skn1234",
        database = "SKN10_4team_1st",
        charset = "utf8"
    )

    cursor = connection.cursor(pymysql.cursors.DictCursor)

    year_data = """
    SELECT DISTINCT year
    FROM Car
    ;
    """
    cursor.execute(year_data)
    years = cursor.fetchall()
    year_list = [year['year'] for year in years]

    with st.container(border=True):
        selected_year = st.selectbox("연도를 선택하세요:", year_list, index=year_list.index('2022'))

    car_data = f"""
    SELECT City.CityName, Car.CarCount, Car.CityID
    FROM Car
    JOIN City ON Car.CityID = City.CityID
    WHERE Car.Year = {selected_year}
    ;
    """
    cursor.execute(car_data)
    result = cursor.fetchall()

    df = pd.DataFrame(result)

    df['CityID_Number'] = df['CityID'].str.extract(r'(\d+)').astype(int)
    df = df.sort_values(by='CityID_Number')

    fig = px.pie(df, names = "CityName", values="CarCount",
                hover_data={'CarCount': True}, labels={'CarCount': 'CarCount'})
    fig.update_traces(textposition='outside', textinfo='label+value+percent', textfont_color="black", hole=.4,
                    direction='counterclockwise')
    fig.add_annotation(dict(text=f"{selected_year}", x=0.5, y=0.5, font_color="black", font_size=25, showarrow=False))
    fig.add_annotation(dict(text="단위: 만 대", x=0.5, y=0.45, font_color="gray", font_size=13, showarrow=False))

    fig.update_layout(width=1600, height=850, legend=dict(
        yanchor="top",
        y=1.05
    ))
    st.plotly_chart(fig)

with tab2:
    # CSV 파일 경로
    car_file_path = 'data/Car.csv'
    city_file_path = 'data/City_m.csv'

    # CSV 파일 읽기
    car_df = pd.read_csv(car_file_path)
    city_df = pd.read_csv(city_file_path)

    # 연도 선택
    years = car_df['연도'].unique()
    selected_year = st.selectbox('연도를 선택하세요:', years)

    # 선택된 연도에 따라 데이터 필터링
    filtered_car_df = car_df[car_df['연도'] == selected_year]

    # 지도 생성
    m = folium.Map(location=[36.5, 127.5], zoom_start=7)

    # 색상 팔레트 생성
    colors = ['#%06X' % random.randint(0, 0xFFFFFF) for _ in range(len(city_df))]

    # 각 도시의 좌표에 등록대수를 반영한 원 추가
    for i, (_, row) in enumerate(filtered_car_df.iterrows()):
        city_id = row['지역ID']
        city_data = city_df[city_df['CityID'] == city_id].iloc[0]
        folium.Circle(
            location=[city_data['Latitude'], city_data['Longitude']],
            radius=row['등록대수'] * 100,  # 등록대수에 비례한 반경
            color=colors[i],
            fill=True,
            fill_color=colors[i],
            fill_opacity=0.6,
            popup=f"{city_data['CityName']} ({row['등록대수']} 만대)"
        ).add_to(m)

    # 지도 표시
    folium_static(m)

    # 색상 레이블 표시

    legend_html = """
    <div style="border:1px solid black; padding:5px; width: 200px;">
        <b>지역별 색상 레이블</b><br>
    """
    for i, city in city_df.iterrows():
        legend_html += f"<div style='display: flex; align-items: center; margin-bottom: 5px;'><div style='width: 15px; height: 15px; background-color: {colors[i]}; margin-right: 5px;'></div>{city['CityName']}</div>"
    legend_html += "</div>"
    st.markdown(legend_html, unsafe_allow_html=True)

--- File Index 9: pages/3_브랜드별_자동차_판매_현황.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc

st.set_page_config(layout="centered")

st.title("📊 브랜드별 자동차 판매 현황")

# 한글 폰트 설정
font_path = 'C:/Windows/Fonts/malgun.ttf'  # Windows의 경우
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)

# CSV 파일 경로
domestic_file_path = 'data/국산차_순위_2021_2024.csv'
foreign_file_path = 'data/해외차_순위_2021_2024.csv'

# CSV 파일 읽기
domestic_df = pd.read_csv(domestic_file_path)
foreign_df = pd.read_csv(foreign_file_path)

def create_cards(data):
    for index, row in data.iterrows():
        st.markdown(f"""
        <div style="border: 1px solid #ddd; border-radius: 10px; padding: 10px; margin: 10px 0;">
            <h3 style="margin: 0;">{row['순위']}위 - {row['브랜드']}</h3>
            <img src="{row['로고 이미지 링크']}" width="50" style="float: right; margin-left: 10px;">
            <p>판매량: {row['판매량']}</p>
            <p>비율: {row['비율']}</p>
        </div>
        """, unsafe_allow_html=True)

def create_pie_chart(data, title, top_n, total_sales):
    st.subheader(title)
    fig, ax = plt.subplots()
    top_brands = data.iloc[:top_n]
    others = data.iloc[top_n:]
    labels = top_brands['브랜드'].tolist() + ['기타 브랜드']
    sizes = top_brands['판매량'].str.replace(',', '').astype(int).tolist() + [others['판매량'].str.replace(',', '').astype(int).sum()]
    colors = plt.get_cmap('tab20').colors  # 다양한 색상 사용
    ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3))
    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

    # 도넛 차트의 가운데에 총 판매량 표시
    ax.text(0, 0, f"{total_sales:,} 대", ha='center', va='center', fontsize=12, fontweight='bold')

    # 파이 차트 표시
    st.pyplot(fig)

def display_tab(title, df, top_n):

    # 연도와 월 선택
    years = df['연도'].unique()
    months = df['월'].unique()

    with st.container(border=True):
        selected_year = st.selectbox('연도를 선택하세요:', years, key=f'{title}_year')
        selected_month = st.selectbox('월을 선택하세요:', months, key=f'{title}_month')

    # 선택된 연도와 월에 따라 데이터 필터링
    filtered_data = df[(df['연도'] == selected_year) & (df['월'] == selected_month)]

    # 주요 지표 강조
    total_sales = filtered_data['판매량'].str.replace(',', '').astype(int).sum()
    

    # 도넛 모양의 파이 차트 생성
    create_pie_chart(filtered_data, f'{title} 브랜드별 판매 비율', top_n, total_sales)

    # 데이터 카드 형식으로 표시
    st.subheader(f'{title} 순위 데이터')
    create_cards(filtered_data)

# 탭 생성
tab1, tab2 = st.tabs(['국산차', '수입차'])

with tab1:
    display_tab('국산차', domestic_df, 3)

with tab2:
    display_tab('수입차', foreign_df, 5)

--- File Index 10: pages/4_주요_3개_기업_차량_구매_FAQ.py ---
import streamlit as st
import json

st.set_page_config(layout="centered")

# 제목 및 탭 구성
st.title("❓ 주요 3개 기업 차량 구매 FAQ")

tab1, tab2, tab3 = st.tabs(['현대', '기아', '제네시스'])

with tab1:
    st.image("images/hyundai.png")

    file_path = 'data\hyundai_faq.json'  # 경로설정

    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            h_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        h_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(h_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        st.stop()


    # 검색 기능
    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    search_query = st.text_input("", key="hd_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if search_query:
        filtered_data  = [item for item in h_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = h_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="hd_prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="hd_next_page"):
                st.session_state.page = page + 1

with tab2:
    st.image("images/kia.jpg")

    file_path = 'data\kia_faq.json'  # 경로설정
    with open(file_path, 'r', encoding='utf-8') as file:
        k_faq_data = json.load(file)

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    st.text_input("", key="search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if 'search_query' in st.session_state and st.session_state.search_query:
        filtered_data = [item for item in k_faq_data if st.session_state.search_query.lower() in item['question'].lower() or st.session_state.search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = k_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 페이지네이션 설정
    items_per_page = 10
    total_pages = (len(filtered_data) + items_per_page - 1) // items_per_page


    # 페이지 번호 선택
    if 'page' not in st.session_state or st.session_state.page > total_pages:
        st.session_state.page = 1

    def change_page(page):
        st.session_state.page = page

    page = st.session_state.page
    start_idx = (page - 1) * items_per_page
    end_idx = start_idx + items_per_page
    current_page_data = filtered_data[start_idx:end_idx]

    for item in current_page_data:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")

        # 하이퍼링크 처리
        for link in item.get("links", []):
            answer = answer.replace(link["text"], f"[{link['text']}]({link['href']})")

        with st.expander(f"❓ {question}"):
            st.write(answer)

            # 이미지 처리
            for image in item.get("images", []):
                st.image(image["src"], caption=image.get("alt", ""))

    page_numbers = [i for i in range(1, total_pages + 1)]
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()
    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page_tab2"):
                change_page(page - 1)
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page_tab2"):
                change_page(page + 1)


with tab3:
    st.image("images\jenesis.png")

    # JSON 파일 로드
    file_path = 'data\genesis_faq.json'
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            j_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        j_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(j_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        #st.stop()

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    # 검색 기능
    def search():
        st.session_state.search_query = st.session_state.search_input
        st.session_state.page = 1 

    search_query = st.text_input("", key="j_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)
    if search_query:
        filtered_data  = [item for item in j_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = j_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page"):
                st.session_state.page = page + 1



Based on the provided codebase, identify the key abstractions that are central to understanding this project. 
These abstractions should represent the core components, modules, or concepts.

Desired output format is a YAML list of objects, where each object has:
- 'name': A concise name for the abstraction (in korean).
- 'description': A brief explanation of what this abstraction represents and its role (in korean).
- 'file_indices': A list of integer file indices that are most relevant to this abstraction. Choose from the file list above.

Return at most 10 key abstractions.

Example for a different project (simple web server):
```yaml
- name: "HTTP 요청 핸들러 (HTTP Request Handler)"
  description: "수신 HTTP 요청을 처리하고 적절한 응답을 생성하는 구성 요소입니다. (Component that processes incoming HTTP requests and generates appropriate responses.)"
  file_indices: [0, 2]
- name: "라우팅 설정 (Routing Configuration)"
  description: "URL 경로를 특정 요청 핸들러 함수에 매핑하는 규칙을 정의합니다. (Defines rules for mapping URL paths to specific request handler functions.)"
  file_indices: [1]
```

Your response should be only the YAML list, enclosed in triple backticks (```yaml ... ```).
Ensure the output is valid YAML.

2025-06-29 20:33:26,971 - INFO - RESPONSE (from cache): ```yaml
- name: "데이터베이스 삽입 모듈"
  description: "CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 기능을 제공하는 모듈입니다."
  file_indices: [2, 3]
- name: "연도별 자동차 등록 현황 페이지"
  description: "연도별 자동차 등록 데이터를 시각화하여 사용자에게 제공하는 스트림릿 웹 페이지입니다."
  file_indices: [0]
- name: "지역별 자동차 등록 현황 페이지"
  description: "지역별 자동차 등록 데이터를 차트 및 지도 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다."
  file_indices: [8]
- name: "브랜드별 자동차 판매 현황 페이지"
  description: "브랜드별 자동차 판매 데이터를 카드 및 파이 차트 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다."
  file_indices: [9]
- name: "차량 구매 FAQ 페이지"
  description: "주요 자동차 브랜드의 차량 구매 관련 FAQ 데이터를 제공하고 검색 기능을 갖춘 스트림릿 웹 페이지입니다."
  file_indices: [10]
- name: "FAQ 크롤링 모듈"
  description: "주요 자동차 브랜드 웹사이트로부터 FAQ 데이터를 크롤링하여 JSON 파일로 저장하는 모듈입니다."
  file_indices: [5, 6, 7]
- name: "자동차 판매 실적 크롤링 모듈"
  description: "다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하여 CSV 파일로 저장하는 모듈입니다."
  file_indices: [4]
- name: "데이터베이스 연결 설정"
  description: "MySQL 데이터베이스에 연결하기 위한 설정 및 쿼리를 실행하여 데이터를 가져오는 기능을 제공합니다."
  file_indices: [0, 8]
- name: "시각화 라이브러리 사용"
  description: "데이터를 차트와 그래프로 시각화하기 위해 Plotly, Matplotlib, Folium 등의 라이브러리를 사용합니다."
  file_indices: [0, 8, 9]
- name: "검색 및 페이지네이션 기능"
  description: "FAQ 페이지에서 검색 기능과 페이지네이션을 제공하여 사용자가 원하는 정보를 쉽게 찾아볼 수 있도록 지원합니다."
  file_indices: [10]
```
2025-06-29 20:33:26,975 - INFO - PROMPT: 
Based on the following abstractions and relevant code snippets from the project `SKN10-1st-4Team`:

List of Abstraction Indices and Names (Names might be in Korean):
0 # 데이터베이스 삽입 모듈
1 # 연도별 자동차 등록 현황 페이지
2 # 지역별 자동차 등록 현황 페이지
3 # 브랜드별 자동차 판매 현황 페이지
4 # 차량 구매 FAQ 페이지
5 # FAQ 크롤링 모듈
6 # 자동차 판매 실적 크롤링 모듈
7 # 데이터베이스 연결 설정
8 # 시각화 라이브러리 사용
9 # 검색 및 페이지네이션 기능

Context (Abstractions, Descriptions, Code):
Identified Abstractions:
- Index 0: 데이터베이스 삽입 모듈 (Relevant file indices: [2, 3])
  Description: CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 기능을 제공하는 모듈입니다.
- Index 1: 연도별 자동차 등록 현황 페이지 (Relevant file indices: [0])
  Description: 연도별 자동차 등록 데이터를 시각화하여 사용자에게 제공하는 스트림릿 웹 페이지입니다.
- Index 2: 지역별 자동차 등록 현황 페이지 (Relevant file indices: [8])
  Description: 지역별 자동차 등록 데이터를 차트 및 지도 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.
- Index 3: 브랜드별 자동차 판매 현황 페이지 (Relevant file indices: [9])
  Description: 브랜드별 자동차 판매 데이터를 카드 및 파이 차트 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.
- Index 4: 차량 구매 FAQ 페이지 (Relevant file indices: [10])
  Description: 주요 자동차 브랜드의 차량 구매 관련 FAQ 데이터를 제공하고 검색 기능을 갖춘 스트림릿 웹 페이지입니다.
- Index 5: FAQ 크롤링 모듈 (Relevant file indices: [5, 6, 7])
  Description: 주요 자동차 브랜드 웹사이트로부터 FAQ 데이터를 크롤링하여 JSON 파일로 저장하는 모듈입니다.
- Index 6: 자동차 판매 실적 크롤링 모듈 (Relevant file indices: [4])
  Description: 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하여 CSV 파일로 저장하는 모듈입니다.
- Index 7: 데이터베이스 연결 설정 (Relevant file indices: [0, 8])
  Description: MySQL 데이터베이스에 연결하기 위한 설정 및 쿼리를 실행하여 데이터를 가져오는 기능을 제공합니다.
- Index 8: 시각화 라이브러리 사용 (Relevant file indices: [0, 8, 9])
  Description: 데이터를 차트와 그래프로 시각화하기 위해 Plotly, Matplotlib, Folium 등의 라이브러리를 사용합니다.
- Index 9: 검색 및 페이지네이션 기능 (Relevant file indices: [10])
  Description: FAQ 페이지에서 검색 기능과 페이지네이션을 제공하여 사용자가 원하는 정보를 쉽게 찾아볼 수 있도록 지원합니다.

Relevant File Snippets (Referenced by Index and Path):
--- File: 0 # 1_연도별_자동차_등록_현황.py ---
#test
import streamlit as st
import pandas as pd
import plotly.express as px
import pymysql
from common.insert_data import insert_data
from common.insert_data_city import insert_data_city

insert_data()
insert_data_city()

st.set_page_config(layout="centered")

st.title("📊 연도별 자동차 등록 현황")
st.divider()

# 데이터베이스 연결 설정
connection = pymysql.connect(
    host="localhost",
    user="SKN10_4team",
    password="skn1234",
    database="SKN10_4team_1st",
    charset="utf8"
)

# SQL 데이터 가져오기
year_data = "select Year FROM Car"
ef = pd.read_sql(year_data, connection)

car_data = """
SELECT Year, SUM(CarCount) YearofCar
FROM SKN10_4team_1st.Car
GROUP BY Year
ORDER BY Year;
"""
cf = pd.read_sql(car_data, connection)

# Streamlit 컨테이너
with st.container():
    # 컬럼 레이아웃 사용
    col1, col2 = st.columns(2)
    # 년도 리스트 생성 및 선택
    years = ef['Year'].unique().tolist()

    # 디폴트 값 설정
    default_start_year_index = 0  # 첫 번째 연도를 디폴트로 설정
    default_end_year_index = len(years) - 1  # 마지막 연도를 디폴트로 설정

    with col1:
        start_year = st.selectbox(
            '첫번째 년도를 선택해주세요.', 
            years, 
            index=default_start_year_index
        )

    with col2:
        end_year = st.selectbox(
            '마지막 년도를 선택해주세요.', 
            years, 
            index=default_end_year_index
        )

# 연도 범위 확인 및 데이터 필터링
if start_year > end_year:
    st.error("Error: The start year cannot be greater than the end year.")
else:
    with st.container():
        # 사용자 입력 값으로 데이터 필터링
        filtered_data = cf[(cf["Year"] >= start_year) & (cf["Year"] <= end_year)]

        # Plotly로 그래프 생성
        fig = px.bar(
            filtered_data, 
            x="Year", 
            y="YearofCar", 
            title="조회결과"
        )

        # axis title 업데이트
        fig.update_xaxes(title_text="연도")
        fig.update_yaxes(title_text="차량 수 (만대)")

        # 그래프 출력
        st.plotly_chart(fig)

}]}

--- File: 2 # common/insert_data.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "Car.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "Car"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (Year, CityID, CarCount) VALUES (%s, %s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[2], row[3])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File: 3 # common/insert_data_city.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data_city():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "City.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "City"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (CityID, CityName) VALUES (%s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[1])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File: 4 # crawling/danawa.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By


import pandas as pd
import time

# 크롬 드라이버 설정

driver = webdriver.Chrome()

# 데이터 저장 리스트
domestic_data = []
foreign_data = []

# 2021년 1월부터 2024년 12월까지의 URL 생성 및 데이터 크롤링
for year in range(2021, 2025):
    for month in range(1, 13):
        if year == 2024 and month > 12:
            break
        month_str = f"{year}-{month:02d}-00"
        url = f"https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month={month_str}&MonthTo="
        driver.get(url)
        time.sleep(0.5)  # 페이지 로딩 대기

        # 국산차 순위 데이터 크롤링
        rank_elements = driver.find_elements(By.CSS_SELECTOR, "ul.sideRankR li")

        for index, rank_element in enumerate(rank_elements):
            rank = rank_element.find_element(By.CSS_SELECTOR, "span.rank").text
            brand = rank_element.find_element(By.CSS_SELECTOR, "span.title").text.strip()
            sales = rank_element.find_element(By.CSS_SELECTOR, "span.sales").text
            rate = rank_element.find_element(By.CSS_SELECTOR, "span.rate").text
            logo_img = rank_element.find_element(By.CSS_SELECTOR, "span.title img").get_attribute("src")
            data = [year, month, rank, brand, sales, rate, logo_img]
            if index < 6:
                domestic_data.append(data)
            else:
                foreign_data.append(data)

# 데이터프레임으로 변환
domestic_df = pd.DataFrame(domestic_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])
foreign_df = pd.DataFrame(foreign_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])

# 데이터프레임 저장
domestic_df.to_csv("data\국산차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')
foreign_df.to_csv("data\해외차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')

# 드라이버 종료
driver.quit()

print("크롤링 완료 및 데이터 저장 완료")
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo=
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo= 에서 2021-01은 21년 1월 데이터를 받아온다는 의미


--- File: 5 # crawling/genesis_faq.py ---

# 제네시스 크롤링
from selenium import webdriver
from bs4 import BeautifulSoup
import json

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.genesis.com/kr/ko/support/faq/vehicle-purchase.html?anchorID=faq_tab"
driver.get(url)

# 페이지 소스 가져오기
html_source = driver.page_source

# HTML 파일로 저장
#with open("genesis_faq.html", "w", encoding="utf-8") as file:
#    file.write(html_source)

# 드라이버 종료
driver.quit()

# BeautifulSoup을 사용하여 페이지 소스 파싱
soup = BeautifulSoup(html_source, 'html.parser')

# FAQ 질문과 답변 추출
faqs = []
faq_items = soup.select('.cp-faq__accordion-item')  # FAQ 항목을 감싸는 클래스 이름을 사용하여 선택

for item in faq_items:
    question = item.select_one('.accordion-title').get_text(strip=True)
    answer = item.select_one('.accordion-panel-inner').get_text(strip=True)
    faqs.append({'question': question, 'answer': answer})

# 추출한 FAQ를 파일로 저장
with open("data\genesis_faq.json", "w", encoding="utf-8") as file:
    json.dump(faqs, file, ensure_ascii=False, indent=4)

--- File: 6 # crawling/hyundai_faq.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from time import sleep

#import pandas as pd
import json


URL = "https://www.hyundai.com/kr/ko/e/customer/center/faq"

driver = webdriver.Chrome()
driver.get(URL)
# 리스트에 딕셔너리로 내용 저장
qna_list = []

for page_id in range(4):
    for question_id in range(1,11):
        try:
            #엘리먼트 찾기
            faq_list = driver.find_element(By.CSS_SELECTOR, "div[data-v-28d34f54].list-wrap")

            try:
                # 플로팅 메뉴 제거
                floating_menu = driver.find_element(By.CSS_SELECTOR, "div[data-v-1ea4ba2d].inner_wrap")
                driver.execute_script("arguments[0].remove();", floating_menu)
            except:
                pass
            faq_title = faq_list.find_elements(By.CSS_SELECTOR,f"div[data-id='{question_id}'] button.list-title")
            driver.execute_script("arguments[0].scrollIntoView({block:'center'});",faq_title[0])
            sleep(0.5)

            #질문타이틀 클릭하기
            faq_title[0].click()
            sleep(0.5)

            #질문타이틀 텍스트 받아오기
            faq_question = faq_title[0].find_element(By.CSS_SELECTOR, "span.list-content[data-v-28d34f54]")
            faq_question_text = faq_question.text
            #print(faq_question_text)

            #질문답변 텍스트 받아오기
            faq_answer = driver.find_element(By.CLASS_NAME, "conts")
            faq_answer_text = faq_answer.text
            #print("전체 답변:", faq_answer_text)

            # 링크 URL 가져오기
            try:
                link_whole = faq_answer.find_elements(By.TAG_NAME, "a")
                link = {
                    "url" : link_whole[0].get_attribute("href"),
                    "text" : link_whole[0].text
                    }
            except:
                link = ""
            #print("링크 URL:", url)
            
            qna_list.append({"question": faq_question_text, "answer": faq_answer_text, "link": link})

        except TimeoutException:
            print("Timed out waiting for page to load")
        except NoSuchElementException:
            print("Could not find the element")
        except IndexError:
            pass

    next_button = driver.find_element(By.CSS_SELECTOR, "button.btn-next")
    next_button.click()
    sleep(1)
 
#qna_df = pd.DataFrame(qna_list, columns = ["page_num","question_num","question","answer","link"])
#qna_df.to_csv(path_or_buf="data/hyundai_qna.csv")

# 결과를 JSON 파일로 저장
with open("data\hyundai_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(qna_list, json_file, ensure_ascii=False, indent=4)

--- File: 7 # crawling/kia_faq.py ---
import json
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.kia.com/kr/customer-service/center/faq"
driver.get(url)

# 페이지가 완전히 로드될 때까지 대기
WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, "body")))

# "TOP 10" 버튼 클릭
top_10_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//button[contains(text(), 'TOP 10')]"))
)
top_10_button.click()

# "차량 구매" 버튼 클릭
car_purchase_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//li[button/span[text()='차량 구매']]"))
)
car_purchase_button.click()

# 3초 텀을 둠
time.sleep(3)

# 각 질문 클릭하여 답변 가져오기
faq_data = []

def get_faq_data():
    # FAQ 항목이 로드될 때까지 대기
    WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

    # FAQ 항목들 찾기
    faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")

    for i in range(len(faq_items)):
        # 각 질문을 클릭하기 전에 요소를 다시 찾음
        faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")
        item = faq_items[i]
        question = item.find_element(By.CSS_SELECTOR, ".cmp-accordion__title").text
        item.click()  # 질문 클릭하여 답변 표시

        # 답변이 로드될 때까지 대기
        panel_id = item.get_attribute("aria-controls")
        WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.ID, panel_id)))
        answer_element = driver.find_element(By.ID, panel_id)
        answer = answer_element.text

        # 하이퍼링크 정보 가져오기
        links = []
        link_elements = answer_element.find_elements(By.TAG_NAME, "a")
        for link in link_elements:
            links.append({
                "href": link.get_attribute("href"),
                "text": link.text
            })

        # 이미지 링크 정보 가져오기
        images = []
        image_elements = answer_element.find_elements(By.TAG_NAME, "img")
        for img in image_elements:
            images.append({
                "src": img.get_attribute("src"),
                "alt": img.get_attribute("alt")
            })

        faq_data.append({
            "question": question,
            "answer": answer,
            "links": links,
            "images": images
        })

    # 스크롤을 맨 위로 올리기
    driver.execute_script("window.scrollTo(0, 0);")

# 첫 페이지의 FAQ 데이터 가져오기
get_faq_data()

# 페이지 넘기기
current_page = 1
while current_page < 4:
    try:
        next_page = str(current_page + 1)

        # 다음 페이지 번호 클릭
        next_page_element = driver.find_element(By.XPATH, f"//ul[@class='paging-list']//a[text()='{next_page}']")
        next_page_element.click()

        # 3초 텀을 둠
        time.sleep(3)

        # 다음 페이지가 로드될 때까지 대기
        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

        # 각 페이지의 FAQ 데이터를 가져오기 전에 요소를 다시 찾음
        get_faq_data()

        current_page += 1
    except Exception as e:
        print(f"Error: {e}")
        break

# 드라이버 종료
driver.quit()

# 결과를 JSON 파일로 저장
with open("/data/kia_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(faq_data, json_file, ensure_ascii=False, indent=4)

# 결과 출력
'''
for faq in faq_data:
    print(f"Question: {faq['question']}")
    print(f"Answer: {faq['answer']}")
    print(f"Links: {faq['links']}")
    print(f"Images: {faq['images']}\n")
'''

--- File: 8 # pages/2_지역별_자동차_등록_현황.py ---
import streamlit as st
import pymysql
import pandas as pd
import plotly.express as px
import folium
import random
from streamlit_folium import folium_static

st.set_page_config(layout="wide")

st.title("📊 지역별 자동차 등록 현황")

tab1, tab2 = st.tabs(['차트', '지도'])

with tab1:
    # Database 연결
    connection = pymysql.connect(
        host = "localhost",
        user = "SKN10_4team",
        password = "skn1234",
        database = "SKN10_4team_1st",
        charset = "utf8"
    )

    cursor = connection.cursor(pymysql.cursors.DictCursor)

    year_data = """
    SELECT DISTINCT year
    FROM Car
    ;
    """
    cursor.execute(year_data)
    years = cursor.fetchall()
    year_list = [year['year'] for year in years]

    with st.container(border=True):
        selected_year = st.selectbox("연도를 선택하세요:", year_list, index=year_list.index('2022'))

    car_data = f"""
    SELECT City.CityName, Car.CarCount, Car.CityID
    FROM Car
    JOIN City ON Car.CityID = City.CityID
    WHERE Car.Year = {selected_year}
    ;
    """
    cursor.execute(car_data)
    result = cursor.fetchall()

    df = pd.DataFrame(result)

    df['CityID_Number'] = df['CityID'].str.extract(r'(\d+)').astype(int)
    df = df.sort_values(by='CityID_Number')

    fig = px.pie(df, names = "CityName", values="CarCount",
                hover_data={'CarCount': True}, labels={'CarCount': 'CarCount'})
    fig.update_traces(textposition='outside', textinfo='label+value+percent', textfont_color="black", hole=.4,
                    direction='counterclockwise')
    fig.add_annotation(dict(text=f"{selected_year}", x=0.5, y=0.5, font_color="black", font_size=25, showarrow=False))
    fig.add_annotation(dict(text="단위: 만 대", x=0.5, y=0.45, font_color="gray", font_size=13, showarrow=False))

    fig.update_layout(width=1600, height=850, legend=dict(
        yanchor="top",
        y=1.05
    ))
    st.plotly_chart(fig)

with tab2:
    # CSV 파일 경로
    car_file_path = 'data/Car.csv'
    city_file_path = 'data/City_m.csv'

    # CSV 파일 읽기
    car_df = pd.read_csv(car_file_path)
    city_df = pd.read_csv(city_file_path)

    # 연도 선택
    years = car_df['연도'].unique()
    selected_year = st.selectbox('연도를 선택하세요:', years)

    # 선택된 연도에 따라 데이터 필터링
    filtered_car_df = car_df[car_df['연도'] == selected_year]

    # 지도 생성
    m = folium.Map(location=[36.5, 127.5], zoom_start=7)

    # 색상 팔레트 생성
    colors = ['#%06X' % random.randint(0, 0xFFFFFF) for _ in range(len(city_df))]

    # 각 도시의 좌표에 등록대수를 반영한 원 추가
    for i, (_, row) in enumerate(filtered_car_df.iterrows()):
        city_id = row['지역ID']
        city_data = city_df[city_df['CityID'] == city_id].iloc[0]
        folium.Circle(
            location=[city_data['Latitude'], city_data['Longitude']],
            radius=row['등록대수'] * 100,  # 등록대수에 비례한 반경
            color=colors[i],
            fill=True,
            fill_color=colors[i],
            fill_opacity=0.6,
            popup=f"{city_data['CityName']} ({row['등록대수']} 만대)"
        ).add_to(m)

    # 지도 표시
    folium_static(m)

    # 색상 레이블 표시

    legend_html = """
    <div style="border:1px solid black; padding:5px; width: 200px;">
        <b>지역별 색상 레이블</b><br>
    """
    for i, city in city_df.iterrows():
        legend_html += f"<div style='display: flex; align-items: center; margin-bottom: 5px;'><div style='width: 15px; height: 15px; background-color: {colors[i]}; margin-right: 5px;'></div>{city['CityName']}</div>"
    legend_html += "</div>"
    st.markdown(legend_html, unsafe_allow_html=True)

--- File: 9 # pages/3_브랜드별_자동차_판매_현황.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc

st.set_page_config(layout="centered")

st.title("📊 브랜드별 자동차 판매 현황")

# 한글 폰트 설정
font_path = 'C:/Windows/Fonts/malgun.ttf'  # Windows의 경우
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)

# CSV 파일 경로
domestic_file_path = 'data/국산차_순위_2021_2024.csv'
foreign_file_path = 'data/해외차_순위_2021_2024.csv'

# CSV 파일 읽기
domestic_df = pd.read_csv(domestic_file_path)
foreign_df = pd.read_csv(foreign_file_path)

def create_cards(data):
    for index, row in data.iterrows():
        st.markdown(f"""
        <div style="border: 1px solid #ddd; border-radius: 10px; padding: 10px; margin: 10px 0;">
            <h3 style="margin: 0;">{row['순위']}위 - {row['브랜드']}</h3>
            <img src="{row['로고 이미지 링크']}" width="50" style="float: right; margin-left: 10px;">
            <p>판매량: {row['판매량']}</p>
            <p>비율: {row['비율']}</p>
        </div>
        """, unsafe_allow_html=True)

def create_pie_chart(data, title, top_n, total_sales):
    st.subheader(title)
    fig, ax = plt.subplots()
    top_brands = data.iloc[:top_n]
    others = data.iloc[top_n:]
    labels = top_brands['브랜드'].tolist() + ['기타 브랜드']
    sizes = top_brands['판매량'].str.replace(',', '').astype(int).tolist() + [others['판매량'].str.replace(',', '').astype(int).sum()]
    colors = plt.get_cmap('tab20').colors  # 다양한 색상 사용
    ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3))
    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

    # 도넛 차트의 가운데에 총 판매량 표시
    ax.text(0, 0, f"{total_sales:,} 대", ha='center', va='center', fontsize=12, fontweight='bold')

    # 파이 차트 표시
    st.pyplot(fig)

def display_tab(title, df, top_n):

    # 연도와 월 선택
    years = df['연도'].unique()
    months = df['월'].unique()

    with st.container(border=True):
        selected_year = st.selectbox('연도를 선택하세요:', years, key=f'{title}_year')
        selected_month = st.selectbox('월을 선택하세요:', months, key=f'{title}_month')

    # 선택된 연도와 월에 따라 데이터 필터링
    filtered_data = df[(df['연도'] == selected_year) & (df['월'] == selected_month)]

    # 주요 지표 강조
    total_sales = filtered_data['판매량'].str.replace(',', '').astype(int).sum()
    

    # 도넛 모양의 파이 차트 생성
    create_pie_chart(filtered_data, f'{title} 브랜드별 판매 비율', top_n, total_sales)

    # 데이터 카드 형식으로 표시
    st.subheader(f'{title} 순위 데이터')
    create_cards(filtered_data)

# 탭 생성
tab1, tab2 = st.tabs(['국산차', '수입차'])

with tab1:
    display_tab('국산차', domestic_df, 3)

with tab2:
    display_tab('수입차', foreign_df, 5)

--- File: 10 # pages/4_주요_3개_기업_차량_구매_FAQ.py ---
import streamlit as st
import json

st.set_page_config(layout="centered")

# 제목 및 탭 구성
st.title("❓ 주요 3개 기업 차량 구매 FAQ")

tab1, tab2, tab3 = st.tabs(['현대', '기아', '제네시스'])

with tab1:
    st.image("images/hyundai.png")

    file_path = 'data\hyundai_faq.json'  # 경로설정

    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            h_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        h_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(h_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        st.stop()


    # 검색 기능
    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    search_query = st.text_input("", key="hd_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if search_query:
        filtered_data  = [item for item in h_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = h_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="hd_prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="hd_next_page"):
                st.session_state.page = page + 1

with tab2:
    st.image("images/kia.jpg")

    file_path = 'data\kia_faq.json'  # 경로설정
    with open(file_path, 'r', encoding='utf-8') as file:
        k_faq_data = json.load(file)

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    st.text_input("", key="search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if 'search_query' in st.session_state and st.session_state.search_query:
        filtered_data = [item for item in k_faq_data if st.session_state.search_query.lower() in item['question'].lower() or st.session_state.search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = k_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 페이지네이션 설정
    items_per_page = 10
    total_pages = (len(filtered_data) + items_per_page - 1) // items_per_page


    # 페이지 번호 선택
    if 'page' not in st.session_state or st.session_state.page > total_pages:
        st.session_state.page = 1

    def change_page(page):
        st.session_state.page = page

    page = st.session_state.page
    start_idx = (page - 1) * items_per_page
    end_idx = start_idx + items_per_page
    current_page_data = filtered_data[start_idx:end_idx]

    for item in current_page_data:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")

        # 하이퍼링크 처리
        for link in item.get("links", []):
            answer = answer.replace(link["text"], f"[{link['text']}]({link['href']})")

        with st.expander(f"❓ {question}"):
            st.write(answer)

            # 이미지 처리
            for image in item.get("images", []):
                st.image(image["src"], caption=image.get("alt", ""))

    page_numbers = [i for i in range(1, total_pages + 1)]
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()
    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page_tab2"):
                change_page(page - 1)
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page_tab2"):
                change_page(page + 1)


with tab3:
    st.image("images\jenesis.png")

    # JSON 파일 로드
    file_path = 'data\genesis_faq.json'
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            j_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        j_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(j_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        #st.stop()

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    # 검색 기능
    def search():
        st.session_state.search_query = st.session_state.search_input
        st.session_state.page = 1 

    search_query = st.text_input("", key="j_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)
    if search_query:
        filtered_data  = [item for item in j_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = j_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page"):
                st.session_state.page = page + 1

IMPORTANT: Generate the `summary` and relationship `label` fields in **Korean** language. Do NOT use English for these fields.

Please provide:
1. A high-level `summary` of the project's main purpose and functionality in a few beginner-friendly sentences (in Korean). Use markdown formatting with **bold** and *italic* text to highlight important concepts.
2. A list (`relationships`) describing the key interactions between these abstractions. For each relationship, specify:
    - `from_abstraction`: Index of the source abstraction (e.g., `0 # AbstractionName1`)
    - `to_abstraction`: Index of the target abstraction (e.g., `1 # AbstractionName2`)
    - `label`: A brief label for the interaction **in just a few words** (in Korean) (e.g., "Manages", "Inherits", "Uses").
    Ideally the relationship should be backed by one abstraction calling or passing parameters to another.
    Simplify the relationship and exclude those non-important ones.

IMPORTANT: Make sure EVERY abstraction is involved in at least ONE relationship (either as source or target). Each abstraction index must appear at least once across all relationships.

Format the output as YAML:

```yaml
summary: |
  A brief, simple explanation of the project (in Korean).
  Can span multiple lines with **bold** and *italic* for emphasis.
relationships:
  - from_abstraction: 0 # AbstractionName1
    to_abstraction: 1 # AbstractionName2
    label: "Manages" (in Korean)
  - from_abstraction: 2 # AbstractionName3
    to_abstraction: 0 # AbstractionName1
    label: "Provides config" (in Korean)
  # ... other relationships
```

Now, provide the YAML output:

2025-06-29 20:33:26,978 - INFO - RESPONSE (from cache): ```yaml
summary: |
  **SKN10-1st-4Team** 프로젝트는 자동차 등록 및 판매 현황 데이터를 관리하고 *시각화*하는 웹 애플리케이션입니다. **Streamlit**을 사용하여 각종 **연도별, 지역별, 브랜드별** 데이터를 **시각화**하며, **크롤링** 모듈을 통해 주요 브랜드의 **FAQ 데이터를 자동으로 수집**합니다. 또한, 데이터는 **MySQL 데이터베이스**에 저장되고 **검색 및 페이지네이션** 기능을 통해 사용자는 필요한 정보를 쉽게 찾을 수 있습니다.

relationships:
  - from_abstraction: 0 # 데이터베이스 삽입 모듈
    to_abstraction: 7 # 데이터베이스 연결 설정
    label: "사용"
  - from_abstraction: 1 # 연도별 자동차 등록 현황 페이지
    to_abstraction: 0 # 데이터베이스 삽입 모듈
    label: "데이터 읽기"
  - from_abstraction: 2 # 지역별 자동차 등록 현황 페이지
    to_abstraction: 7 # 데이터베이스 연결 설정
    label: "사용"
  - from_abstraction: 3 # 브랜드별 자동차 판매 현황 페이지
    to_abstraction: 6 # 자동차 판매 실적 크롤링 모듈
    label: "데이터 사용"
  - from_abstraction: 4 # 차량 구매 FAQ 페이지
    to_abstraction: 9 # 검색 및 페이지네이션 기능
    label: "활용"
  - from_abstraction: 5 # FAQ 크롤링 모듈
    to_abstraction: 4 # 차량 구매 FAQ 페이지
    label: "데이터 공급"
  - from_abstraction: 6 # 자동차 판매 실적 크롤링 모듈
    to_abstraction: 9 # 검색 및 페이지네이션 기능
    label: "활용"
  - from_abstraction: 8 # 시각화 라이브러리 사용
    to_abstraction: 2 # 지역별 자동차 등록 현황 페이지
    label: "적용"
  - from_abstraction: 9 # 검색 및 페이지네이션 기능
    to_abstraction: 4 # 차량 구매 FAQ 페이지
    label: "지원"
```
2025-06-29 20:33:26,980 - INFO - PROMPT: 
Given the following project abstractions and their relationships for the project ```` SKN10-1st-4Team ````:

Abstractions (Index # Name) (Names might be in Korean):
- 0 # 데이터베이스 삽입 모듈
- 1 # 연도별 자동차 등록 현황 페이지
- 2 # 지역별 자동차 등록 현황 페이지
- 3 # 브랜드별 자동차 판매 현황 페이지
- 4 # 차량 구매 FAQ 페이지
- 5 # FAQ 크롤링 모듈
- 6 # 자동차 판매 실적 크롤링 모듈
- 7 # 데이터베이스 연결 설정
- 8 # 시각화 라이브러리 사용
- 9 # 검색 및 페이지네이션 기능

Context about relationships and project summary:
Project Summary (Note: Project Summary might be in Korean):
**SKN10-1st-4Team** 프로젝트는 자동차 등록 및 판매 현황 데이터를 관리하고 *시각화*하는 웹 애플리케이션입니다. **Streamlit**을 사용하여 각종 **연도별, 지역별, 브랜드별** 데이터를 **시각화**하며, **크롤링** 모듈을 통해 주요 브랜드의 **FAQ 데이터를 자동으로 수집**합니다. 또한, 데이터는 **MySQL 데이터베이스**에 저장되고 **검색 및 페이지네이션** 기능을 통해 사용자는 필요한 정보를 쉽게 찾을 수 있습니다.


Relationships (Indices refer to abstractions above):
- From 0 (데이터베이스 삽입 모듈) to 7 (데이터베이스 연결 설정): 사용
- From 1 (연도별 자동차 등록 현황 페이지) to 0 (데이터베이스 삽입 모듈): 데이터 읽기
- From 2 (지역별 자동차 등록 현황 페이지) to 7 (데이터베이스 연결 설정): 사용
- From 3 (브랜드별 자동차 판매 현황 페이지) to 6 (자동차 판매 실적 크롤링 모듈): 데이터 사용
- From 4 (차량 구매 FAQ 페이지) to 9 (검색 및 페이지네이션 기능): 활용
- From 5 (FAQ 크롤링 모듈) to 4 (차량 구매 FAQ 페이지): 데이터 공급
- From 6 (자동차 판매 실적 크롤링 모듈) to 9 (검색 및 페이지네이션 기능): 활용
- From 8 (시각화 라이브러리 사용) to 2 (지역별 자동차 등록 현황 페이지): 적용
- From 9 (검색 및 페이지네이션 기능) to 4 (차량 구매 FAQ 페이지): 지원


If you are going to make a tutorial for ```` SKN10-1st-4Team ````, what is the best order to explain these abstractions, from first to last?
Ideally, first explain those that are the most important or foundational, perhaps user-facing concepts or entry points. Then move to more detailed, lower-level implementation details or supporting concepts.

Output the ordered list of abstraction indices, including the name in a comment for clarity. Use the format `idx # AbstractionName`.

```yaml
- 2 # FoundationalConcept
- 0 # CoreClassA
- 1 # CoreClassB (uses CoreClassA)
- ...
```

Now, provide the YAML output:

2025-06-29 20:33:26,982 - INFO - RESPONSE (from cache): ```yaml
- 8 # 시각화 라이브러리 사용
- 2 # 지역별 자동차 등록 현황 페이지
- 1 # 연도별 자동차 등록 현황 페이지
- 3 # 브랜드별 자동차 판매 현황 페이지
- 4 # 차량 구매 FAQ 페이지
- 9 # 검색 및 페이지네이션 기능
- 5 # FAQ 크롤링 모듈
- 6 # 자동차 판매 실적 크롤링 모듈
- 0 # 데이터베이스 삽입 모듈
- 7 # 데이터베이스 연결 설정
```
2025-06-29 20:33:26,983 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "시각화 라이브러리 사용". This is Chapter 1.

Concept Details (Note: Provided in Korean):
- Name: 시각화 라이브러리 사용
- Description:
데이터를 차트와 그래프로 시각화하기 위해 Plotly, Matplotlib, Folium 등의 라이브러리를 사용합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
This is the first chapter.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 1: 시각화 라이브러리 사용`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:33:26,986 - INFO - RESPONSE (from cache): # Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
2025-06-29 20:33:26,986 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "지역별 자동차 등록 현황 페이지". This is Chapter 2.

Concept Details (Note: Provided in Korean):
- Name: 지역별 자동차 등록 현황 페이지
- Description:
지역별 자동차 등록 데이터를 차트 및 지도 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 2: 지역별 자동차 등록 현황 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:33:26,989 - INFO - RESPONSE (from cache): # 제 2 장: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
2025-06-29 20:33:26,990 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "연도별 자동차 등록 현황 페이지". This is Chapter 3.

Concept Details (Note: Provided in Korean):
- Name: 연도별 자동차 등록 현황 페이지
- Description:
연도별 자동차 등록 데이터를 시각화하여 사용자에게 제공하는 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 3: 연도별 자동차 등록 현황 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:33:26,992 - INFO - RESPONSE (from cache): # Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
2025-06-29 20:33:26,992 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "브랜드별 자동차 판매 현황 페이지". This is Chapter 4.

Concept Details (Note: Provided in Korean):
- Name: 브랜드별 자동차 판매 현황 페이지
- Description:
브랜드별 자동차 판매 데이터를 카드 및 파이 차트 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 4: 브랜드별 자동차 판매 현황 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:33:26,995 - INFO - RESPONSE (from cache): # 제4장: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
2025-06-29 20:33:26,995 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "차량 구매 FAQ 페이지". This is Chapter 5.

Concept Details (Note: Provided in Korean):
- Name: 차량 구매 FAQ 페이지
- Description:
주요 자동차 브랜드의 차량 구매 관련 FAQ 데이터를 제공하고 검색 기능을 갖춘 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 5: 차량 구매 FAQ 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:33:26,998 - INFO - RESPONSE (from cache): # Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
2025-06-29 20:33:26,998 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "검색 및 페이지네이션 기능". This is Chapter 6.

Concept Details (Note: Provided in Korean):
- Name: 검색 및 페이지네이션 기능
- Description:
FAQ 페이지에서 검색 기능과 페이지네이션을 제공하여 사용자가 원하는 정보를 쉽게 찾아볼 수 있도록 지원합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 6: 검색 및 페이지네이션 기능`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:33:27,001 - INFO - RESPONSE (from cache): # Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
2025-06-29 20:33:27,002 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "FAQ 크롤링 모듈". This is Chapter 7.

Concept Details (Note: Provided in Korean):
- Name: FAQ 크롤링 모듈
- Description:
주요 자동차 브랜드 웹사이트로부터 FAQ 데이터를 크롤링하여 JSON 파일로 저장하는 모듈입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 7: FAQ 크롤링 모듈`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:33:27,005 - INFO - RESPONSE (from cache): # Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.
2025-06-29 20:33:27,005 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "자동차 판매 실적 크롤링 모듈". This is Chapter 8.

Concept Details (Note: Provided in Korean):
- Name: 자동차 판매 실적 크롤링 모듈
- Description:
다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하여 CSV 파일로 저장하는 모듈입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
---
# Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 8: 자동차 판매 실적 크롤링 모듈`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:33:27,009 - INFO - RESPONSE (from cache): # Chapter 8: 자동차 판매 실적 크롤링 모듈

이전 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동차 관련 웹사이트에서 FAQ 데이터를 자동으로 수집하고 저장하는 방법을 배웠습니다. 이번 장에서는 `자동차 판매 실적 크롤링 모듈`을 구축하여 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하고, 이를 CSV 파일로 저장하는 방법을 알아보겠습니다.

## 동기 부여

자동차 판매 실적을 분석하는 것은 시장 동향을 파악하고, 신차 개발 및 판매 전략을 수립하는 데 중요한 역할을 합니다. 만약 특정 브랜드의 판매 실적이 급격히 증가했다면, 그 이유를 파악하여 다른 브랜드에도 적용할 수 있는 영감을 얻을 수 있습니다. 이때 매번 웹사이트를 방문해 수작업으로 데이터를 정리하는 대신, 크롤러를 사용하면 실적 데이터를 자동으로 수집 및 저장할 수 있습니다.

## 주요 개념

### 웹 크롤링

웹 크롤링은 특정 웹사이트의 정보를 자동으로 수집하는 방법입니다. 일반적으로 원하는 페이지의 HTML 코드를 가져와 필요한 데이터를 추출합니다. 다나와의 판매 실적 페이지를 탐색하고 데이터를 추출할 수 있습니다.

### CSV 형식

CSV는 데이터를 쉽고 효율적으로 저장할 수 있는 포맷입니다. 각 행은 하나의 데이터 레코드를 나타내며, 각 값은 쉼표로 구분됩니다. 추출한 판매 실적 데이터를 CSV 파일에 저장하면 데이터를 분석하고 사용할 때 유용합니다.

## 자동차 판매 실적 크롤링 모듈 구현하기

다나와의 자동차 판매 실적 데이터를 수집하기 위한 방법을 살펴보겠습니다.

### 1단계: 기본 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# 판매 실적 페이지 URL
url = 'http://example.com/sales'

# 웹 페이지 요청 및 HTML 파싱
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
```

이 코드는 requests를 사용하여 특정 URL에서 HTML 페이지를 가져오고, BeautifulSoup을 통해 HTML을 파싱하는 기본 크롤러의 구조를 설명합니다. 이 과정은 크롤링의 첫 단계를 나타냅니다.

### 2단계: 판매 실적 데이터 추출

```python
sales_data = []

# 테이블에서 데이터 추출
for row in soup.find_all('tr'):
    cols = row.find_all('td')
    if cols:
        brand = cols[0].get_text()
        sales = cols[1].get_text()
        sales_data.append({'브랜드': brand.strip(), '판매량': sales.strip()})
```

위 코드는 HTML 테이블에서 브랜드와 판매량 데이터를 추출하는 예를 보여줍니다. 여기서는 `find_all`을 통해 테이블 행과 열을 순회하며 데이터를 모읍니다.

### 3단계: 데이터 CSV 파일 저장

```python
import csv

# CSV 파일로 데이터 저장
with open('sales_data.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=['브랜드', '판매량'])
    writer.writeheader()
    writer.writerows(sales_data)
```

크롤링한 데이터를 CSV 파일로 저장합니다. 이를 통해 데이터를 쉽게 접근하고 여러 도구에서 활용할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 전체 과정을 이해하기 위한 단계별 설명입니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant CSV파일

  사용자 ->> 크롤러: URL 설정
  크롤러 ->> 웹사이트: 데이터 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> CSV파일: 가공한 데이터 저장
  사용자 -->> CSV파일: 실적 데이터 분석
```

크롤러가 웹사이트에 HTTP 요청을 보내고, HTML 응답에서 데이터를 추출 및 처리하여 CSV 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 자동차 판매 실적을 다나와 웹사이트에서 자동으로 수집하고 이를 CSV 형식으로 저장하는 방법을 알아보았습니다. 이러한 크롤링 모듈은 데이터 분석 및 비즈니스 전략 수립에 필수적인 요소입니다. 다음은 데이터베이스에 수집한 데이터를 효율적으로 저장하고 관리하는 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md) 입니다. 이를 통해 데이터 관리의 효율성을 더욱 높일 수 있습니다.
2025-06-29 20:33:27,009 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "데이터베이스 삽입 모듈". This is Chapter 9.

Concept Details (Note: Provided in Korean):
- Name: 데이터베이스 삽입 모듈
- Description:
CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 기능을 제공하는 모듈입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
---
# Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.
---
# Chapter 8: 자동차 판매 실적 크롤링 모듈

이전 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동차 관련 웹사이트에서 FAQ 데이터를 자동으로 수집하고 저장하는 방법을 배웠습니다. 이번 장에서는 `자동차 판매 실적 크롤링 모듈`을 구축하여 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하고, 이를 CSV 파일로 저장하는 방법을 알아보겠습니다.

## 동기 부여

자동차 판매 실적을 분석하는 것은 시장 동향을 파악하고, 신차 개발 및 판매 전략을 수립하는 데 중요한 역할을 합니다. 만약 특정 브랜드의 판매 실적이 급격히 증가했다면, 그 이유를 파악하여 다른 브랜드에도 적용할 수 있는 영감을 얻을 수 있습니다. 이때 매번 웹사이트를 방문해 수작업으로 데이터를 정리하는 대신, 크롤러를 사용하면 실적 데이터를 자동으로 수집 및 저장할 수 있습니다.

## 주요 개념

### 웹 크롤링

웹 크롤링은 특정 웹사이트의 정보를 자동으로 수집하는 방법입니다. 일반적으로 원하는 페이지의 HTML 코드를 가져와 필요한 데이터를 추출합니다. 다나와의 판매 실적 페이지를 탐색하고 데이터를 추출할 수 있습니다.

### CSV 형식

CSV는 데이터를 쉽고 효율적으로 저장할 수 있는 포맷입니다. 각 행은 하나의 데이터 레코드를 나타내며, 각 값은 쉼표로 구분됩니다. 추출한 판매 실적 데이터를 CSV 파일에 저장하면 데이터를 분석하고 사용할 때 유용합니다.

## 자동차 판매 실적 크롤링 모듈 구현하기

다나와의 자동차 판매 실적 데이터를 수집하기 위한 방법을 살펴보겠습니다.

### 1단계: 기본 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# 판매 실적 페이지 URL
url = 'http://example.com/sales'

# 웹 페이지 요청 및 HTML 파싱
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
```

이 코드는 requests를 사용하여 특정 URL에서 HTML 페이지를 가져오고, BeautifulSoup을 통해 HTML을 파싱하는 기본 크롤러의 구조를 설명합니다. 이 과정은 크롤링의 첫 단계를 나타냅니다.

### 2단계: 판매 실적 데이터 추출

```python
sales_data = []

# 테이블에서 데이터 추출
for row in soup.find_all('tr'):
    cols = row.find_all('td')
    if cols:
        brand = cols[0].get_text()
        sales = cols[1].get_text()
        sales_data.append({'브랜드': brand.strip(), '판매량': sales.strip()})
```

위 코드는 HTML 테이블에서 브랜드와 판매량 데이터를 추출하는 예를 보여줍니다. 여기서는 `find_all`을 통해 테이블 행과 열을 순회하며 데이터를 모읍니다.

### 3단계: 데이터 CSV 파일 저장

```python
import csv

# CSV 파일로 데이터 저장
with open('sales_data.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=['브랜드', '판매량'])
    writer.writeheader()
    writer.writerows(sales_data)
```

크롤링한 데이터를 CSV 파일로 저장합니다. 이를 통해 데이터를 쉽게 접근하고 여러 도구에서 활용할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 전체 과정을 이해하기 위한 단계별 설명입니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant CSV파일

  사용자 ->> 크롤러: URL 설정
  크롤러 ->> 웹사이트: 데이터 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> CSV파일: 가공한 데이터 저장
  사용자 -->> CSV파일: 실적 데이터 분석
```

크롤러가 웹사이트에 HTTP 요청을 보내고, HTML 응답에서 데이터를 추출 및 처리하여 CSV 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 자동차 판매 실적을 다나와 웹사이트에서 자동으로 수집하고 이를 CSV 형식으로 저장하는 방법을 알아보았습니다. 이러한 크롤링 모듈은 데이터 분석 및 비즈니스 전략 수립에 필수적인 요소입니다. 다음은 데이터베이스에 수집한 데이터를 효율적으로 저장하고 관리하는 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md) 입니다. 이를 통해 데이터 관리의 효율성을 더욱 높일 수 있습니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 9: 데이터베이스 삽입 모듈`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:33:27,012 - INFO - RESPONSE (from cache): # Chapter 9: 데이터베이스 삽입 모듈

이전 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 다나와 웹사이트에서 자동차 판매 실적 데이터를 수집하여 CSV 파일로 저장하는 방법을 배웠습니다. 이번 장에서는 `데이터베이스 삽입 모듈`을 구현하여 CSV 파일의 데이터를 MySQL 데이터베이스에 자동으로 업로드하는 방법을 알아보겠습니다.

## 동기 부여

현대의 많은 애플리케이션은 데이터를 보다 효율적이고 안정적으로 관리하기 위해 데이터베이스를 사용합니다. 특히 대량의 데이터를 처리할 때는 CSV 파일에 저장하는 것보다 데이터베이스에 저장하는 것이 효율적입니다. 이번 데이터베이스 삽입 모듈은 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입함으로써 데이터를 보다 구조적이고 신뢰성 있게 관리할 수 있도록 해줍니다.

## 주요 개념

### CSV 파일 처리

CSV 파일은 간단한 데이터 포맷이며 텍스트 데이터를 쉼표로 구분하여 저장합니다. 파이썬의 `csv` 모듈을 활용하면 CSV 파일의 데이터를 손쉽게 읽어올 수 있습니다.

### MySQL 데이터베이스 연결

MySQL 데이터베이스는 관계형 데이터베이스로, 대량의 데이터를 구조적으로 저장할 수 있게 해줍니다. 파이썬에서는 `MySQL Connector` 라이브러리를 사용하여 데이터베이스에 연결하고 데이터를 삽입할 수 있습니다.

## 데이터베이스 삽입 모듈 사용하기

이제 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 단계별로 살펴보겠습니다.

### 1단계: CSV 파일 읽기

```python
import csv

# CSV 파일 읽기
data = []
with open('sales_data.csv', mode='r', encoding='utf-8') as file:
    reader = csv.DictReader(file)
    for row in reader:
        data.append(row)
```

이 코드에서는 `csv.DictReader`를 사용하여 CSV 파일의 데이터를 읽어 목록에 저장합니다. 각 행은 딕셔너리로 변환되어 `data` 리스트에 추가됩니다.

### 2단계: 데이터베이스 연결 및 데이터 삽입

```python
import mysql.connector

# 데이터베이스 연결 설정
connection = mysql.connector.connect(
    host='localhost',
    user='user',
    password='password',
    database='car_sales_db'
)

cursor = connection.cursor()

# 데이터 삽입
for entry in data:
    sql = "INSERT INTO sales (brand, sales) VALUES (%s, %s)"
    cursor.execute(sql, (entry['브랜드'], entry['판매량']))

# 변경사항 저장
connection.commit()
```

위 코드에서는 `mysql.connector`를 사용하여 MySQL 데이터베이스에 연결한 후, 각 데이터 항목을 반복적으로 삽입합니다. 삽입 문법 `INSERT INTO`를 통해 데이터베이스에 데이터를 추가합니다. 마지막으로, `commit` 메서드로 변경 사항을 저장합니다.

## 내부 구현 이해

데이터베이스 삽입 모듈이 어떻게 작동하는지 이해하기 쉽게 시퀀스 다이어그램으로 설명하겠습니다.

```mermaid
sequenceDiagram
  participant User
  participant CSV파일
  participant Python프로그램
  participant MySQLDB

  User ->> Python프로그램: CSV 파일 읽기 요청
  Python프로그램 ->> CSV파일: 데이터 읽기
  CSV파일 -->> Python프로그램: 데이터 반환
  Python프로그램 ->> MySQLDB: 데이터베이스에 데이터 삽입
  MySQLDB -->> Python프로그램: 삽입 완료
  Python프로그램 -->> User: 완료 메시지 제공
```

이 다이어그램은 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 과정을 확인할 수 있습니다.

## 결론

이번 장에서는 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 배웠습니다. 이를 통해 데이터를 보다 구조적으로 관리하고 활용할 수 있습니다. 다음 [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)에서는 데이터베이스 연결 설정에 대해 더욱 상세히 알아보겠습니다. 데이터베이스와의 원활한 연결은 안정적인 데이터 처리에 필수적입니다. 

---

이번 과정을 통해 데이터베이스 활용 능력이 한 단계 업그레이드될 것입니다. 지속적인 실습을 통해 데이터 관리자 및 개발자로서의 역량을 키워보세요!
2025-06-29 20:33:27,012 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "데이터베이스 연결 설정". This is Chapter 10.

Concept Details (Note: Provided in Korean):
- Name: 데이터베이스 연결 설정
- Description:
MySQL 데이터베이스에 연결하기 위한 설정 및 쿼리를 실행하여 데이터를 가져오는 기능을 제공합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
---
# Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.
---
# Chapter 8: 자동차 판매 실적 크롤링 모듈

이전 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동차 관련 웹사이트에서 FAQ 데이터를 자동으로 수집하고 저장하는 방법을 배웠습니다. 이번 장에서는 `자동차 판매 실적 크롤링 모듈`을 구축하여 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하고, 이를 CSV 파일로 저장하는 방법을 알아보겠습니다.

## 동기 부여

자동차 판매 실적을 분석하는 것은 시장 동향을 파악하고, 신차 개발 및 판매 전략을 수립하는 데 중요한 역할을 합니다. 만약 특정 브랜드의 판매 실적이 급격히 증가했다면, 그 이유를 파악하여 다른 브랜드에도 적용할 수 있는 영감을 얻을 수 있습니다. 이때 매번 웹사이트를 방문해 수작업으로 데이터를 정리하는 대신, 크롤러를 사용하면 실적 데이터를 자동으로 수집 및 저장할 수 있습니다.

## 주요 개념

### 웹 크롤링

웹 크롤링은 특정 웹사이트의 정보를 자동으로 수집하는 방법입니다. 일반적으로 원하는 페이지의 HTML 코드를 가져와 필요한 데이터를 추출합니다. 다나와의 판매 실적 페이지를 탐색하고 데이터를 추출할 수 있습니다.

### CSV 형식

CSV는 데이터를 쉽고 효율적으로 저장할 수 있는 포맷입니다. 각 행은 하나의 데이터 레코드를 나타내며, 각 값은 쉼표로 구분됩니다. 추출한 판매 실적 데이터를 CSV 파일에 저장하면 데이터를 분석하고 사용할 때 유용합니다.

## 자동차 판매 실적 크롤링 모듈 구현하기

다나와의 자동차 판매 실적 데이터를 수집하기 위한 방법을 살펴보겠습니다.

### 1단계: 기본 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# 판매 실적 페이지 URL
url = 'http://example.com/sales'

# 웹 페이지 요청 및 HTML 파싱
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
```

이 코드는 requests를 사용하여 특정 URL에서 HTML 페이지를 가져오고, BeautifulSoup을 통해 HTML을 파싱하는 기본 크롤러의 구조를 설명합니다. 이 과정은 크롤링의 첫 단계를 나타냅니다.

### 2단계: 판매 실적 데이터 추출

```python
sales_data = []

# 테이블에서 데이터 추출
for row in soup.find_all('tr'):
    cols = row.find_all('td')
    if cols:
        brand = cols[0].get_text()
        sales = cols[1].get_text()
        sales_data.append({'브랜드': brand.strip(), '판매량': sales.strip()})
```

위 코드는 HTML 테이블에서 브랜드와 판매량 데이터를 추출하는 예를 보여줍니다. 여기서는 `find_all`을 통해 테이블 행과 열을 순회하며 데이터를 모읍니다.

### 3단계: 데이터 CSV 파일 저장

```python
import csv

# CSV 파일로 데이터 저장
with open('sales_data.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=['브랜드', '판매량'])
    writer.writeheader()
    writer.writerows(sales_data)
```

크롤링한 데이터를 CSV 파일로 저장합니다. 이를 통해 데이터를 쉽게 접근하고 여러 도구에서 활용할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 전체 과정을 이해하기 위한 단계별 설명입니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant CSV파일

  사용자 ->> 크롤러: URL 설정
  크롤러 ->> 웹사이트: 데이터 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> CSV파일: 가공한 데이터 저장
  사용자 -->> CSV파일: 실적 데이터 분석
```

크롤러가 웹사이트에 HTTP 요청을 보내고, HTML 응답에서 데이터를 추출 및 처리하여 CSV 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 자동차 판매 실적을 다나와 웹사이트에서 자동으로 수집하고 이를 CSV 형식으로 저장하는 방법을 알아보았습니다. 이러한 크롤링 모듈은 데이터 분석 및 비즈니스 전략 수립에 필수적인 요소입니다. 다음은 데이터베이스에 수집한 데이터를 효율적으로 저장하고 관리하는 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md) 입니다. 이를 통해 데이터 관리의 효율성을 더욱 높일 수 있습니다.
---
# Chapter 9: 데이터베이스 삽입 모듈

이전 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 다나와 웹사이트에서 자동차 판매 실적 데이터를 수집하여 CSV 파일로 저장하는 방법을 배웠습니다. 이번 장에서는 `데이터베이스 삽입 모듈`을 구현하여 CSV 파일의 데이터를 MySQL 데이터베이스에 자동으로 업로드하는 방법을 알아보겠습니다.

## 동기 부여

현대의 많은 애플리케이션은 데이터를 보다 효율적이고 안정적으로 관리하기 위해 데이터베이스를 사용합니다. 특히 대량의 데이터를 처리할 때는 CSV 파일에 저장하는 것보다 데이터베이스에 저장하는 것이 효율적입니다. 이번 데이터베이스 삽입 모듈은 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입함으로써 데이터를 보다 구조적이고 신뢰성 있게 관리할 수 있도록 해줍니다.

## 주요 개념

### CSV 파일 처리

CSV 파일은 간단한 데이터 포맷이며 텍스트 데이터를 쉼표로 구분하여 저장합니다. 파이썬의 `csv` 모듈을 활용하면 CSV 파일의 데이터를 손쉽게 읽어올 수 있습니다.

### MySQL 데이터베이스 연결

MySQL 데이터베이스는 관계형 데이터베이스로, 대량의 데이터를 구조적으로 저장할 수 있게 해줍니다. 파이썬에서는 `MySQL Connector` 라이브러리를 사용하여 데이터베이스에 연결하고 데이터를 삽입할 수 있습니다.

## 데이터베이스 삽입 모듈 사용하기

이제 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 단계별로 살펴보겠습니다.

### 1단계: CSV 파일 읽기

```python
import csv

# CSV 파일 읽기
data = []
with open('sales_data.csv', mode='r', encoding='utf-8') as file:
    reader = csv.DictReader(file)
    for row in reader:
        data.append(row)
```

이 코드에서는 `csv.DictReader`를 사용하여 CSV 파일의 데이터를 읽어 목록에 저장합니다. 각 행은 딕셔너리로 변환되어 `data` 리스트에 추가됩니다.

### 2단계: 데이터베이스 연결 및 데이터 삽입

```python
import mysql.connector

# 데이터베이스 연결 설정
connection = mysql.connector.connect(
    host='localhost',
    user='user',
    password='password',
    database='car_sales_db'
)

cursor = connection.cursor()

# 데이터 삽입
for entry in data:
    sql = "INSERT INTO sales (brand, sales) VALUES (%s, %s)"
    cursor.execute(sql, (entry['브랜드'], entry['판매량']))

# 변경사항 저장
connection.commit()
```

위 코드에서는 `mysql.connector`를 사용하여 MySQL 데이터베이스에 연결한 후, 각 데이터 항목을 반복적으로 삽입합니다. 삽입 문법 `INSERT INTO`를 통해 데이터베이스에 데이터를 추가합니다. 마지막으로, `commit` 메서드로 변경 사항을 저장합니다.

## 내부 구현 이해

데이터베이스 삽입 모듈이 어떻게 작동하는지 이해하기 쉽게 시퀀스 다이어그램으로 설명하겠습니다.

```mermaid
sequenceDiagram
  participant User
  participant CSV파일
  participant Python프로그램
  participant MySQLDB

  User ->> Python프로그램: CSV 파일 읽기 요청
  Python프로그램 ->> CSV파일: 데이터 읽기
  CSV파일 -->> Python프로그램: 데이터 반환
  Python프로그램 ->> MySQLDB: 데이터베이스에 데이터 삽입
  MySQLDB -->> Python프로그램: 삽입 완료
  Python프로그램 -->> User: 완료 메시지 제공
```

이 다이어그램은 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 과정을 확인할 수 있습니다.

## 결론

이번 장에서는 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 배웠습니다. 이를 통해 데이터를 보다 구조적으로 관리하고 활용할 수 있습니다. 다음 [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)에서는 데이터베이스 연결 설정에 대해 더욱 상세히 알아보겠습니다. 데이터베이스와의 원활한 연결은 안정적인 데이터 처리에 필수적입니다. 

---

이번 과정을 통해 데이터베이스 활용 능력이 한 단계 업그레이드될 것입니다. 지속적인 실습을 통해 데이터 관리자 및 개발자로서의 역량을 키워보세요!

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 10: 데이터베이스 연결 설정`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:33:27,016 - INFO - RESPONSE (from cache): # 제10장: 데이터베이스 연결 설정

이전 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)에서 우리는 CSV 파일로부터 읽은 데이터를 MySQL 데이터베이스에 삽입하는 방법을 배웠습니다. 이번 장에서는 `데이터베이스 연결 설정`에 대해 자세히 알아보겠습니다. 이는 MySQL 데이터베이스와의 안정적인 연결을 위해 반드시 필요한 설정입니다.

## 동기 부여

데이터를 효과적으로 관리하기 위해서는 데이터베이스와의 연결이 매우 중요합니다. 데이터베이스 연결 설정이 제대로 되어 있지 않으면 데이터를 저장하거나 불러올 때 문제가 발생할 수 있습니다. 예를 들어, 자동차 판매 실적 데이터를 분석하고자 할 때 MySQL 데이터베이스에 연결할 수 없거나 연결이 불안정하면 분석에 차질이 생깁니다. 안정적인 데이터베이스 연결을 위해 필요한 주요 설정과 절차를 배워봅시다.

## 주요 개념

### MySQL 데이터베이스 서버

MySQL은 인기 있는 오픈 소스 데이터베이스 관리 시스템으로, 데이터를 효율적으로 저장하고 검색할 수 있습니다. 이를 활용하기 위해서는 데이터베이스 서버와의 연결을 적절히 설정해야 합니다.

### 연결 문자열

연결 문자열은 데이터베이스 서버의 주소, 사용자 이름, 비밀번호 등 연결에 필요한 정보를 포함합니다. Python의 `mysql.connector` 라이브러리를 통해 MySQL에 연결할 수 있습니다. 이를 통해 원하는 데이터를 가져오거나 저장할 수 있습니다.

## 데이터베이스 연결 설정

데이터베이스 연결을 설정하는 방법을 단계적으로 살펴보겠습니다.

### 1단계: MySQL Connector 설치

먼저 MySQL Connector를 설치해야 합니다. 터미널이나 커맨드 라인에서 다음 명령어를 사용하세요.

```bash
pip install mysql-connector-python
```

이 명령어를 실행하면 MySQL 데이터베이스와의 연결을 위한 라이브러리가 설치됩니다.

### 2단계: 데이터베이스 연결 설정 코드

MySQL에 연결하려면 다음과 같이 연결 설정을 할 수 있습니다.

```python
import mysql.connector

# MySQL 데이터베이스에 연결
connection = mysql.connector.connect(
    host='localhost',     # 데이터베이스 서버 주소
    user='user',          # 사용자 이름
    password='password',  # 비밀번호
    database='my_database' # 사용할 데이터베이스 이름
)

# 연결 확인
if connection.is_connected():
    print("연결 성공!")
```

이 코드는 MySQL 데이터베이스와의 연결을 설정하는 가장 기본적인 방법입니다. 데이터베이스 서버 주소, 사용자 이름, 비밀번호, 데이터베이스 이름을 올바르게 입력하면 됩니다.

### 내부 작동 방식 이해

데이터베이스 연결의 내부 작동 방식을 이해하는 것은 중요합니다. 다음은 연결 설정이 이루어지는 과정을 설명합니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant Python프로그램
  participant MySQLDB

  사용자 ->> Python프로그램: 연결 설정 요청
  Python프로그램 ->> MySQLDB: 연결 시도
  MySQLDB -->> Python프로그램: 연결 승인
  Python프로그램 -->> 사용자: 연결 성공 메시지
```

이 다이어그램은 사용자로부터 연결 설정 요청을 받아, Python 프로그램이 MySQL 데이터베이스에 연결을 시도하고, 연결 여부를 사용자에게 알리는 과정을 보여줍니다.

## 결론

이번 장에서는 MySQL 데이터베이스와의 연결을 설정하는 방법에 대해 학습했습니다. MySQL Connector를 설치하고, 필요한 정보를 사용하여 연결을 설정하였습니다. 안정적인 연결 설정을 통해 데이터를 보다 효율적으로 관리할 수 있습니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md) 장에서는 데이터를 효율적으로 탐색할 수 있는 검색 및 페이지네이션 기능을 구현하는 방법을 배워보겠습니다.

데이터베이스 활용의 기초를 다지며 계속해서 발전해 나가시길 바랍니다!
2025-06-29 20:34:41,435 - INFO - PROMPT: 
Analyze the following codebase for the project 'SKN10-1st-4Team'.

Available files (total 11):
- 0 # 1_연도별_자동차_등록_현황.py
- 1 # README.md
- 2 # common/insert_data.py
- 3 # common/insert_data_city.py
- 4 # crawling/danawa.py
- 5 # crawling/genesis_faq.py
- 6 # crawling/hyundai_faq.py
- 7 # crawling/kia_faq.py
- 8 # pages/2_지역별_자동차_등록_현황.py
- 9 # pages/3_브랜드별_자동차_판매_현황.py
- 10 # pages/4_주요_3개_기업_차량_구매_FAQ.py

Full context of all files:
--- File Index 0: 1_연도별_자동차_등록_현황.py ---
#test
import streamlit as st
import pandas as pd
import plotly.express as px
import pymysql
from common.insert_data import insert_data
from common.insert_data_city import insert_data_city

insert_data()
insert_data_city()

st.set_page_config(layout="centered")

st.title("📊 연도별 자동차 등록 현황")
st.divider()

# 데이터베이스 연결 설정
connection = pymysql.connect(
    host="localhost",
    user="SKN10_4team",
    password="skn1234",
    database="SKN10_4team_1st",
    charset="utf8"
)

# SQL 데이터 가져오기
year_data = "select Year FROM Car"
ef = pd.read_sql(year_data, connection)

car_data = """
SELECT Year, SUM(CarCount) YearofCar
FROM SKN10_4team_1st.Car
GROUP BY Year
ORDER BY Year;
"""
cf = pd.read_sql(car_data, connection)

# Streamlit 컨테이너
with st.container():
    # 컬럼 레이아웃 사용
    col1, col2 = st.columns(2)
    # 년도 리스트 생성 및 선택
    years = ef['Year'].unique().tolist()

    # 디폴트 값 설정
    default_start_year_index = 0  # 첫 번째 연도를 디폴트로 설정
    default_end_year_index = len(years) - 1  # 마지막 연도를 디폴트로 설정

    with col1:
        start_year = st.selectbox(
            '첫번째 년도를 선택해주세요.', 
            years, 
            index=default_start_year_index
        )

    with col2:
        end_year = st.selectbox(
            '마지막 년도를 선택해주세요.', 
            years, 
            index=default_end_year_index
        )

# 연도 범위 확인 및 데이터 필터링
if start_year > end_year:
    st.error("Error: The start year cannot be greater than the end year.")
else:
    with st.container():
        # 사용자 입력 값으로 데이터 필터링
        filtered_data = cf[(cf["Year"] >= start_year) & (cf["Year"] <= end_year)]

        # Plotly로 그래프 생성
        fig = px.bar(
            filtered_data, 
            x="Year", 
            y="YearofCar", 
            title="조회결과"
        )

        # axis title 업데이트
        fig.update_xaxes(title_text="연도")
        fig.update_yaxes(title_text="차량 수 (만대)")

        # 그래프 출력
        st.plotly_chart(fig)

}]}

--- File Index 1: README.md ---
# SKN10-1st-4Team
<br/>

![](https://cdn.imweb.me/upload/S20240314bd10436a7991a/41a9769cc44e6.png)
<br/>
<br/>

## ⭐ 프로젝트 팀
<br/>

| 좌민서 | 김민혜 | 박예슬 | 신민주 | 홍승표 | 황인호 |
| :---: | :---: | :---: | :---: | :---: | :---: |
| - 팀장<br/>- 지역별 자동차 등록 현황<br/>(그래프) | - ERD 설계<br/>- DB 구현 | - ERD 설계<br/>- 현대자동차 FAQ | - 화면 설계<br/>- 제네시스 FAQ | - 라이브러리 조사<br/>- 연도별 자동차 등록 현황 | - 화면 설계<br/>- 기아자동차 FAQ<br/>- 지역별 자동차 등록 현황<br/>(지도)<br/>- 브랜드별 자동차 판매 현황
| [@INe](https://github.com/INe904) | [@kkminhye](https://github.com/kkminhye) | [@yeseulnim](https://github.com/yeseulnim) | [@sinminju](https://github.com/sinminju) | [@redwin02](https://github.com/redwin-02) | [@HIHO9999](https://github.com/HIHO999) |
<br/>

## 📌 프로젝트 개요
<br/>

### 프로젝트 주제
<br/>

**전국 자동차 등록 현황 및 기업 FAQ 조회 시스템**
<br/>
<br/>

### 프로젝트 목적
<br/>

1. 전국 자동차 등록 현황을 연도별 및 지역별로 분석하여, **자동차 증가 추세와 지역별 특성을 파악**한다. 이를 통해 **교통 정책 수립 및 지역 발전 전략**에 기여할 수 있는 정보를 제공한다.
<br/>

2. 국내 브랜드별 자동차 구매통계 및 3대 자동차 기업의 차량구매 관련 FAQ 정보를 한 곳에 모아, **자동차 구매 예정 소비자에게 필요한 정보**를 제공한다.
<br/>
<br/>

### 프로젝트 필요성
<br/>

1. 자동차 등록 현황은 도시 교통 문제, 환경 정책, 도로 인프라 계획 등과 밀접하게 연관되어 있다.
<br/>

2. 연도별 및 지역별 자동차 등록 현황 데이터를 시각화하여, 공공 및 민간 부분에서 데이터 기반 정책 결정을 지원한다.
<br/>

3. 자동차 구매를 고려하는 소비자는 브랜드별 차량 등록 현황과 차량 구매 관련 정보를 한눈에 확인하기 어려운 경우가 많다. 국내 브랜드별 자동차 구매 통계와 주요 자동차 기업의 FAQ 정보를 통합 제공함으로써, 소비자들이 보다 신속하고 정확한 의사 결정을 할 수 있도록 돕는다.
<br/>

### 프로젝트 내용
<br/>

 1. **데이터 수집 및 가공**
<br/>

- <b>[지표누리](https://www.index.go.kr/unity/potal/main/EachDtlPageDetail.do?idx_cd=1257)</b>에서 제공하는 연도별 및 지역별 자동차 등록 현황 데이터를 수집하여 목적에 맞게 가공한 후, 데이터베이스에 저장한다.
<br/>

- 국내 판매율이 가장 높은 주요 3개 자동차 회사(<b>[현대](https://www.hyundai.com/kr/ko/e/customer/center/faq)</b>, <b>[기아](https://www.kia.com/kr/customer-service/center/faq)</b>, <b>[제네시스](https://www.genesis.com/kr/ko/support/faq.html)</b>)의 차량 구매 FAQ를 Selenium을 이용하여 크롤링한 뒤 JSON 파일로 저장한다.
<br/>

- 다나와의 <b>[자동차 판매 실적](https://auto.danawa.com/auto/?Work=record&pcUse=y)</b> 페이지에서 제공하는 브랜드별 자동차 판매 실적을 Selenium을 이용하여 크롤링한 뒤 CSV 파일로 저장한다.

<br/>

2. **데이터 시각화**
<br/>

- 수집한 자동차 통계 관련 데이터를 Python의 **Plotly**, **MatPlotLib** 및 **Folium** 라이브러리를 통해 시각화한다.
<br/>

3. **FAQ 제공**
<br/>

- 크롤링한 주요 자동차 브랜드의 FAQ 내용을 한곳에 모아, 검색 기능과 함께 제공한다.
<br/>

### 프로젝트 기대 효과
<br/>

1. **연도별 및 지역별 자동차 등록 현황의 시각적 자료**를 제공하여 데이터를 직관적으로 파악할 수 있다.
<br/>

2. **교통 및 환경 정책 수립**을 위한 기초 데이터를 제공한다.
<br/>

3. **브랜드별 차량 판매량** 및 **기업 FAQ 조회 시스템**을 통해 소비자의 정보 접근성을 높인다.
<br/>
<br/>

## 📌 설치/사용 방법
<br/>

### 1. GitHub에서 Repository Clone
<br/>

```python
    git clone https://github.com/SKNETWORKS-FAMILY-AICAMP/SKN10-1st-4Team.git
```
<br/>

### 2. 라이브러리 설치
<br/>

```python
    pip install -r requirements.txt
```
<br/>

### 3. 데이터베이스 구축
DBeaver 실행 후, 계정생성 권한 있는 계정에서 sql\create_tables.sql 파일의 코드 실행
<br/>

### 4. (생략 가능) 정보 수집 - 웹 크롤링 코드 실행
<br/>

※ 웹 크롤링 결과물은 data 폴더에 json 파일로 저장되어 있으므로, 별도의 크롤링 없이 바로 실행이 가능하다. 다만, 신규 데이터 확인을 위해 웹 크롤링이 필요한 경우 아래 코드를 사용할 수 있다.
<br/>

```python
    python crawling/kia_faq.py
```
```python
    python crawling/hyundai_faq.py
```
```python
    python crawling/genesis_faq.py
```
```python
    python crawling/danawa.py
```
<br/>

### 5. 서비스 실행
<br/>

```python
    streamlit run 1_연도별_자동차_등록_현황.py
```
<br/>
<br/>

## 📌 기술 스택
<br/>

### 화면 설계
<br/>

![](https://img.shields.io/badge/Figma-F24E1E?style=for-the-badge&logo=figma&logoColor=white)
<br/>

### 데이터 가공 및 처리
<br/>

![](https://img.shields.io/badge/MySQL-4479A1?style=for-the-badge&logo=mysql&logoColor=white) &nbsp; ![](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=white)
<br/>

### 화면 구현
<br/>

![](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=white) &nbsp; ![](https://img.shields.io/badge/streamlit-FF0000?style=for-the-badge&logo=streamlit&logoColor=white)
<br/>

### 버전 관리 및 협업
<br/>

![](https://img.shields.io/badge/github-000000?style=for-the-badge&logo=github&logoColor=white)
<br/>
<br/>

## 💻 화면 설계
<br/>

### 0. 메뉴
<br/>

![](/images/menu_design.png)
<br/>

### 1. 연도별 자동차 등록 현황
<br/>

![](/images/year_design.png)
<br/>

### 2. 지역별 자동차 등록 현황
<br/>

![](/images/region_design.png)
<br/>

### 3. 주요 3개 기업 차량 구매 FAQ
<br/>

![](/images/faq_design.png)
<br/>
<br/>

## 💻 데이터 가공 및 처리
<br/>

### ERD
<br/>

![](/images/erd.png)
<br/>
<br/>

### 실제 데이터 가공 및 처리

1. **자동차 등록 현황**
<br/>

- 자료 출처 : <b>[지표누리 자동차 등록 현황](https://www.index.go.kr/unity/potal/main/EachDtlPageDetail.do?idx_cd=1257)</b> (*2012 ~ 2022)
<br/>

- 자료 가공 : 개별 Excel 파일 다운로드 -> CSV로 변경 -> MySQL 데이터베이스 테이블로 저장
<br/>

2. **주요 3개 기업 차량 구매 FAQ**
<br/>

- 자료 출처 : 국내 3대 자동차 기업 (<b>[현대](https://www.hyundai.com/kr/ko/e/customer/center/faq)</b>, <b>[기아](https://www.kia.com/kr/customer-service/center/faq)</b>, <b>[제네시스](https://www.genesis.com/kr/ko/support/faq.html)</b>) 홈페이지 'FAQ' 중 '차량 구매' 항목
<br/>

- 자료 가공 : Selenium으로 웹크롤링 -> JSON으로 저장 
<br/>

3. **브랜드별 자동차 판매 실적**
<br/>

- 자료 출처 : 다나와 <b>[자동차 판매 실적](https://auto.danawa.com/auto/?Work=record&pcUse=y)</b> 페이지 (*2021.01 ~ 2024.12)
<br/>

- 자료 가공 : Selenium으로 웹크롤링 -> CSV로 저장
<br/>
<br/>

## 📌 프로젝트 최종 결과
<br/>

### 1. 연도별 자동차 등록 현황
<br/>

![](/images/final_screen1.png)
<br/>

### 2. 지역별 자동차 등록 현황
<br/>

![](/images/final_screen2.png)
<br/>

![](/images/final_screen3.png)
<br/>

### 3. 주요 3개 기업 차량 구매 FAQ
<br/>

![](/images/final_screen4.png)
<br/>

### 4. 브랜드별 자동차 판매 순위
<br/>

![](/images/final_screen5.png)
<br/>
<br/>

## 🖥️개발과정에서 발생한 이슈 및 해결방법
<br/>

### 1. SQL DB 구축
<br/>

**문제**
<br/>

MySQL DB는 깃헙으로 동기화되지 않고 각 인원이 각자 구축해야 했기에 그 과정에서 시행착오가 있었음.
<br/>

**해결**
<br/>

실수방지를 위해 최종 코드에서는 DB및 테이블 생성 SQL코드를 별도파일로 두고, 테이블 내용 생성은 함수로 만들어 자동 실행되도록 함.
<br/>

### 2. 복잡한 SQL 저장 구조
<br/>

**문제**
<br/>

최초 기획한 ERD 구조에는 FAQ가 포함되어 있었으나, 실제 구현시 FAQ를 별도 JSON 파일에 담고 그를 MySQL 테이블로 만든뒤 이를 불러오는 과정이 비효율적이라 판단되었음. 
<br/>

**해결**
<br/>

ERD구조를 수정하여 FAQ를 ERD에서 빼고, FAQ페이지의 내용은 JSON파일에서 바로 불러오기로 함.
<br/>

### 3. 기능구현 완료후 오류 발생
<br/>

**문제**
<br/>

'현대차 FAQ' 페이지에서 검색기능 이용시, 검색결과가 없을 경우, '기아차 FAQ' 등 다른 탭으로 이동하면 탭의 내용이 나타나지 않는 버그 발생
<br/>

**해결**
<br/>

AI의 디버깅 보조를 이용, 코드를 수정하여 해결함.
<br/>
<br/>

## ✍️팀원별 느낀점
<br/>

### 좌민서
<br/>

지금까지 배운 내용을 바탕으로 응용된 내용을 활용할 수 있었던 좋은 기회가 되었습니다. 어쩌다 보니 이번에 팀장을 맡게 되었는데 많이 부족함에도 불구하고 팀원분들이 잘 따라와 주시고 도와주셔서 이번 프로젝트를 무사히 마칠 수 있었던 것 같습니다.

<br/>

### 신민주
<br/>

체계적인 프로젝트를 처음 진행해봤는데 팀워크의 중요성을 느꼈습니다. 제가 부족한 부분이 많았지만 다들 친절히 알려주셔서 배우면서 프로젝트에 참여할 수 있었습니다. 앞으로의 활동에도 좋은 경험이 될 것 같습니다.

<br/>

### 박예슬
<br/>

다인 프로젝트 깃 관리의 어려움과 중요성을 체감했습니다. 고생하신 팀장님과 팀원들에게 박수를 보냅니다.

<br/>

### 김민혜
<br/>

팀장을 맡으신 민서님이 프로젝트 전반적인 과정을 꼼꼼하게 정리하고 원할하게 진행해주셨다고 생각합니다. 각 팀원이 맡은 역할에 충실할 뿐만 아니라 가진 역량을 빛내고 서로 도와 문제를 해결하는 과정을 경험할 수 있어서 정말 좋았습니다.

<br/>

### 황인호
<br/>

팀프로젝트를  제대로 수행해본적이 처음이었지만 팀장분께서 역할분담 잘해주셔서 맡은바 열심히 그리고 만족스럽게 수행한것같습니다. 앞으로의 협력 업무에 있어서 좋은 경험이 되었습니다.

<br/>

### 홍승표
<br/>

저는 사람이 아닙니다. 몽키입니다. 아닙니다. 코드도 못치니 그냥 몽키입니다. 열심히 배워서 코드몽키라도 될 수 있도록 노력하겠습니다. 그리고 능력자이신 팀원분들을 만나 너무 좋았습니다. 몽키 한 마리 만나서 고생한 팀원들에게 너무 고맙고 다음 프로젝트때는 버스 타기실 기도하겠습니다. 
<br/>


--- File Index 2: common/insert_data.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "Car.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "Car"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (Year, CityID, CarCount) VALUES (%s, %s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[2], row[3])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File Index 3: common/insert_data_city.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data_city():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "City.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "City"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (CityID, CityName) VALUES (%s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[1])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File Index 4: crawling/danawa.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By


import pandas as pd
import time

# 크롬 드라이버 설정

driver = webdriver.Chrome()

# 데이터 저장 리스트
domestic_data = []
foreign_data = []

# 2021년 1월부터 2024년 12월까지의 URL 생성 및 데이터 크롤링
for year in range(2021, 2025):
    for month in range(1, 13):
        if year == 2024 and month > 12:
            break
        month_str = f"{year}-{month:02d}-00"
        url = f"https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month={month_str}&MonthTo="
        driver.get(url)
        time.sleep(0.5)  # 페이지 로딩 대기

        # 국산차 순위 데이터 크롤링
        rank_elements = driver.find_elements(By.CSS_SELECTOR, "ul.sideRankR li")

        for index, rank_element in enumerate(rank_elements):
            rank = rank_element.find_element(By.CSS_SELECTOR, "span.rank").text
            brand = rank_element.find_element(By.CSS_SELECTOR, "span.title").text.strip()
            sales = rank_element.find_element(By.CSS_SELECTOR, "span.sales").text
            rate = rank_element.find_element(By.CSS_SELECTOR, "span.rate").text
            logo_img = rank_element.find_element(By.CSS_SELECTOR, "span.title img").get_attribute("src")
            data = [year, month, rank, brand, sales, rate, logo_img]
            if index < 6:
                domestic_data.append(data)
            else:
                foreign_data.append(data)

# 데이터프레임으로 변환
domestic_df = pd.DataFrame(domestic_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])
foreign_df = pd.DataFrame(foreign_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])

# 데이터프레임 저장
domestic_df.to_csv("data\국산차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')
foreign_df.to_csv("data\해외차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')

# 드라이버 종료
driver.quit()

print("크롤링 완료 및 데이터 저장 완료")
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo=
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo= 에서 2021-01은 21년 1월 데이터를 받아온다는 의미


--- File Index 5: crawling/genesis_faq.py ---

# 제네시스 크롤링
from selenium import webdriver
from bs4 import BeautifulSoup
import json

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.genesis.com/kr/ko/support/faq/vehicle-purchase.html?anchorID=faq_tab"
driver.get(url)

# 페이지 소스 가져오기
html_source = driver.page_source

# HTML 파일로 저장
#with open("genesis_faq.html", "w", encoding="utf-8") as file:
#    file.write(html_source)

# 드라이버 종료
driver.quit()

# BeautifulSoup을 사용하여 페이지 소스 파싱
soup = BeautifulSoup(html_source, 'html.parser')

# FAQ 질문과 답변 추출
faqs = []
faq_items = soup.select('.cp-faq__accordion-item')  # FAQ 항목을 감싸는 클래스 이름을 사용하여 선택

for item in faq_items:
    question = item.select_one('.accordion-title').get_text(strip=True)
    answer = item.select_one('.accordion-panel-inner').get_text(strip=True)
    faqs.append({'question': question, 'answer': answer})

# 추출한 FAQ를 파일로 저장
with open("data\genesis_faq.json", "w", encoding="utf-8") as file:
    json.dump(faqs, file, ensure_ascii=False, indent=4)

--- File Index 6: crawling/hyundai_faq.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from time import sleep

#import pandas as pd
import json


URL = "https://www.hyundai.com/kr/ko/e/customer/center/faq"

driver = webdriver.Chrome()
driver.get(URL)
# 리스트에 딕셔너리로 내용 저장
qna_list = []

for page_id in range(4):
    for question_id in range(1,11):
        try:
            #엘리먼트 찾기
            faq_list = driver.find_element(By.CSS_SELECTOR, "div[data-v-28d34f54].list-wrap")

            try:
                # 플로팅 메뉴 제거
                floating_menu = driver.find_element(By.CSS_SELECTOR, "div[data-v-1ea4ba2d].inner_wrap")
                driver.execute_script("arguments[0].remove();", floating_menu)
            except:
                pass
            faq_title = faq_list.find_elements(By.CSS_SELECTOR,f"div[data-id='{question_id}'] button.list-title")
            driver.execute_script("arguments[0].scrollIntoView({block:'center'});",faq_title[0])
            sleep(0.5)

            #질문타이틀 클릭하기
            faq_title[0].click()
            sleep(0.5)

            #질문타이틀 텍스트 받아오기
            faq_question = faq_title[0].find_element(By.CSS_SELECTOR, "span.list-content[data-v-28d34f54]")
            faq_question_text = faq_question.text
            #print(faq_question_text)

            #질문답변 텍스트 받아오기
            faq_answer = driver.find_element(By.CLASS_NAME, "conts")
            faq_answer_text = faq_answer.text
            #print("전체 답변:", faq_answer_text)

            # 링크 URL 가져오기
            try:
                link_whole = faq_answer.find_elements(By.TAG_NAME, "a")
                link = {
                    "url" : link_whole[0].get_attribute("href"),
                    "text" : link_whole[0].text
                    }
            except:
                link = ""
            #print("링크 URL:", url)
            
            qna_list.append({"question": faq_question_text, "answer": faq_answer_text, "link": link})

        except TimeoutException:
            print("Timed out waiting for page to load")
        except NoSuchElementException:
            print("Could not find the element")
        except IndexError:
            pass

    next_button = driver.find_element(By.CSS_SELECTOR, "button.btn-next")
    next_button.click()
    sleep(1)
 
#qna_df = pd.DataFrame(qna_list, columns = ["page_num","question_num","question","answer","link"])
#qna_df.to_csv(path_or_buf="data/hyundai_qna.csv")

# 결과를 JSON 파일로 저장
with open("data\hyundai_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(qna_list, json_file, ensure_ascii=False, indent=4)

--- File Index 7: crawling/kia_faq.py ---
import json
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.kia.com/kr/customer-service/center/faq"
driver.get(url)

# 페이지가 완전히 로드될 때까지 대기
WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, "body")))

# "TOP 10" 버튼 클릭
top_10_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//button[contains(text(), 'TOP 10')]"))
)
top_10_button.click()

# "차량 구매" 버튼 클릭
car_purchase_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//li[button/span[text()='차량 구매']]"))
)
car_purchase_button.click()

# 3초 텀을 둠
time.sleep(3)

# 각 질문 클릭하여 답변 가져오기
faq_data = []

def get_faq_data():
    # FAQ 항목이 로드될 때까지 대기
    WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

    # FAQ 항목들 찾기
    faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")

    for i in range(len(faq_items)):
        # 각 질문을 클릭하기 전에 요소를 다시 찾음
        faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")
        item = faq_items[i]
        question = item.find_element(By.CSS_SELECTOR, ".cmp-accordion__title").text
        item.click()  # 질문 클릭하여 답변 표시

        # 답변이 로드될 때까지 대기
        panel_id = item.get_attribute("aria-controls")
        WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.ID, panel_id)))
        answer_element = driver.find_element(By.ID, panel_id)
        answer = answer_element.text

        # 하이퍼링크 정보 가져오기
        links = []
        link_elements = answer_element.find_elements(By.TAG_NAME, "a")
        for link in link_elements:
            links.append({
                "href": link.get_attribute("href"),
                "text": link.text
            })

        # 이미지 링크 정보 가져오기
        images = []
        image_elements = answer_element.find_elements(By.TAG_NAME, "img")
        for img in image_elements:
            images.append({
                "src": img.get_attribute("src"),
                "alt": img.get_attribute("alt")
            })

        faq_data.append({
            "question": question,
            "answer": answer,
            "links": links,
            "images": images
        })

    # 스크롤을 맨 위로 올리기
    driver.execute_script("window.scrollTo(0, 0);")

# 첫 페이지의 FAQ 데이터 가져오기
get_faq_data()

# 페이지 넘기기
current_page = 1
while current_page < 4:
    try:
        next_page = str(current_page + 1)

        # 다음 페이지 번호 클릭
        next_page_element = driver.find_element(By.XPATH, f"//ul[@class='paging-list']//a[text()='{next_page}']")
        next_page_element.click()

        # 3초 텀을 둠
        time.sleep(3)

        # 다음 페이지가 로드될 때까지 대기
        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

        # 각 페이지의 FAQ 데이터를 가져오기 전에 요소를 다시 찾음
        get_faq_data()

        current_page += 1
    except Exception as e:
        print(f"Error: {e}")
        break

# 드라이버 종료
driver.quit()

# 결과를 JSON 파일로 저장
with open("/data/kia_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(faq_data, json_file, ensure_ascii=False, indent=4)

# 결과 출력
'''
for faq in faq_data:
    print(f"Question: {faq['question']}")
    print(f"Answer: {faq['answer']}")
    print(f"Links: {faq['links']}")
    print(f"Images: {faq['images']}\n")
'''

--- File Index 8: pages/2_지역별_자동차_등록_현황.py ---
import streamlit as st
import pymysql
import pandas as pd
import plotly.express as px
import folium
import random
from streamlit_folium import folium_static

st.set_page_config(layout="wide")

st.title("📊 지역별 자동차 등록 현황")

tab1, tab2 = st.tabs(['차트', '지도'])

with tab1:
    # Database 연결
    connection = pymysql.connect(
        host = "localhost",
        user = "SKN10_4team",
        password = "skn1234",
        database = "SKN10_4team_1st",
        charset = "utf8"
    )

    cursor = connection.cursor(pymysql.cursors.DictCursor)

    year_data = """
    SELECT DISTINCT year
    FROM Car
    ;
    """
    cursor.execute(year_data)
    years = cursor.fetchall()
    year_list = [year['year'] for year in years]

    with st.container(border=True):
        selected_year = st.selectbox("연도를 선택하세요:", year_list, index=year_list.index('2022'))

    car_data = f"""
    SELECT City.CityName, Car.CarCount, Car.CityID
    FROM Car
    JOIN City ON Car.CityID = City.CityID
    WHERE Car.Year = {selected_year}
    ;
    """
    cursor.execute(car_data)
    result = cursor.fetchall()

    df = pd.DataFrame(result)

    df['CityID_Number'] = df['CityID'].str.extract(r'(\d+)').astype(int)
    df = df.sort_values(by='CityID_Number')

    fig = px.pie(df, names = "CityName", values="CarCount",
                hover_data={'CarCount': True}, labels={'CarCount': 'CarCount'})
    fig.update_traces(textposition='outside', textinfo='label+value+percent', textfont_color="black", hole=.4,
                    direction='counterclockwise')
    fig.add_annotation(dict(text=f"{selected_year}", x=0.5, y=0.5, font_color="black", font_size=25, showarrow=False))
    fig.add_annotation(dict(text="단위: 만 대", x=0.5, y=0.45, font_color="gray", font_size=13, showarrow=False))

    fig.update_layout(width=1600, height=850, legend=dict(
        yanchor="top",
        y=1.05
    ))
    st.plotly_chart(fig)

with tab2:
    # CSV 파일 경로
    car_file_path = 'data/Car.csv'
    city_file_path = 'data/City_m.csv'

    # CSV 파일 읽기
    car_df = pd.read_csv(car_file_path)
    city_df = pd.read_csv(city_file_path)

    # 연도 선택
    years = car_df['연도'].unique()
    selected_year = st.selectbox('연도를 선택하세요:', years)

    # 선택된 연도에 따라 데이터 필터링
    filtered_car_df = car_df[car_df['연도'] == selected_year]

    # 지도 생성
    m = folium.Map(location=[36.5, 127.5], zoom_start=7)

    # 색상 팔레트 생성
    colors = ['#%06X' % random.randint(0, 0xFFFFFF) for _ in range(len(city_df))]

    # 각 도시의 좌표에 등록대수를 반영한 원 추가
    for i, (_, row) in enumerate(filtered_car_df.iterrows()):
        city_id = row['지역ID']
        city_data = city_df[city_df['CityID'] == city_id].iloc[0]
        folium.Circle(
            location=[city_data['Latitude'], city_data['Longitude']],
            radius=row['등록대수'] * 100,  # 등록대수에 비례한 반경
            color=colors[i],
            fill=True,
            fill_color=colors[i],
            fill_opacity=0.6,
            popup=f"{city_data['CityName']} ({row['등록대수']} 만대)"
        ).add_to(m)

    # 지도 표시
    folium_static(m)

    # 색상 레이블 표시

    legend_html = """
    <div style="border:1px solid black; padding:5px; width: 200px;">
        <b>지역별 색상 레이블</b><br>
    """
    for i, city in city_df.iterrows():
        legend_html += f"<div style='display: flex; align-items: center; margin-bottom: 5px;'><div style='width: 15px; height: 15px; background-color: {colors[i]}; margin-right: 5px;'></div>{city['CityName']}</div>"
    legend_html += "</div>"
    st.markdown(legend_html, unsafe_allow_html=True)

--- File Index 9: pages/3_브랜드별_자동차_판매_현황.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc

st.set_page_config(layout="centered")

st.title("📊 브랜드별 자동차 판매 현황")

# 한글 폰트 설정
font_path = 'C:/Windows/Fonts/malgun.ttf'  # Windows의 경우
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)

# CSV 파일 경로
domestic_file_path = 'data/국산차_순위_2021_2024.csv'
foreign_file_path = 'data/해외차_순위_2021_2024.csv'

# CSV 파일 읽기
domestic_df = pd.read_csv(domestic_file_path)
foreign_df = pd.read_csv(foreign_file_path)

def create_cards(data):
    for index, row in data.iterrows():
        st.markdown(f"""
        <div style="border: 1px solid #ddd; border-radius: 10px; padding: 10px; margin: 10px 0;">
            <h3 style="margin: 0;">{row['순위']}위 - {row['브랜드']}</h3>
            <img src="{row['로고 이미지 링크']}" width="50" style="float: right; margin-left: 10px;">
            <p>판매량: {row['판매량']}</p>
            <p>비율: {row['비율']}</p>
        </div>
        """, unsafe_allow_html=True)

def create_pie_chart(data, title, top_n, total_sales):
    st.subheader(title)
    fig, ax = plt.subplots()
    top_brands = data.iloc[:top_n]
    others = data.iloc[top_n:]
    labels = top_brands['브랜드'].tolist() + ['기타 브랜드']
    sizes = top_brands['판매량'].str.replace(',', '').astype(int).tolist() + [others['판매량'].str.replace(',', '').astype(int).sum()]
    colors = plt.get_cmap('tab20').colors  # 다양한 색상 사용
    ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3))
    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

    # 도넛 차트의 가운데에 총 판매량 표시
    ax.text(0, 0, f"{total_sales:,} 대", ha='center', va='center', fontsize=12, fontweight='bold')

    # 파이 차트 표시
    st.pyplot(fig)

def display_tab(title, df, top_n):

    # 연도와 월 선택
    years = df['연도'].unique()
    months = df['월'].unique()

    with st.container(border=True):
        selected_year = st.selectbox('연도를 선택하세요:', years, key=f'{title}_year')
        selected_month = st.selectbox('월을 선택하세요:', months, key=f'{title}_month')

    # 선택된 연도와 월에 따라 데이터 필터링
    filtered_data = df[(df['연도'] == selected_year) & (df['월'] == selected_month)]

    # 주요 지표 강조
    total_sales = filtered_data['판매량'].str.replace(',', '').astype(int).sum()
    

    # 도넛 모양의 파이 차트 생성
    create_pie_chart(filtered_data, f'{title} 브랜드별 판매 비율', top_n, total_sales)

    # 데이터 카드 형식으로 표시
    st.subheader(f'{title} 순위 데이터')
    create_cards(filtered_data)

# 탭 생성
tab1, tab2 = st.tabs(['국산차', '수입차'])

with tab1:
    display_tab('국산차', domestic_df, 3)

with tab2:
    display_tab('수입차', foreign_df, 5)

--- File Index 10: pages/4_주요_3개_기업_차량_구매_FAQ.py ---
import streamlit as st
import json

st.set_page_config(layout="centered")

# 제목 및 탭 구성
st.title("❓ 주요 3개 기업 차량 구매 FAQ")

tab1, tab2, tab3 = st.tabs(['현대', '기아', '제네시스'])

with tab1:
    st.image("images/hyundai.png")

    file_path = 'data\hyundai_faq.json'  # 경로설정

    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            h_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        h_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(h_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        st.stop()


    # 검색 기능
    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    search_query = st.text_input("", key="hd_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if search_query:
        filtered_data  = [item for item in h_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = h_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="hd_prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="hd_next_page"):
                st.session_state.page = page + 1

with tab2:
    st.image("images/kia.jpg")

    file_path = 'data\kia_faq.json'  # 경로설정
    with open(file_path, 'r', encoding='utf-8') as file:
        k_faq_data = json.load(file)

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    st.text_input("", key="search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if 'search_query' in st.session_state and st.session_state.search_query:
        filtered_data = [item for item in k_faq_data if st.session_state.search_query.lower() in item['question'].lower() or st.session_state.search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = k_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 페이지네이션 설정
    items_per_page = 10
    total_pages = (len(filtered_data) + items_per_page - 1) // items_per_page


    # 페이지 번호 선택
    if 'page' not in st.session_state or st.session_state.page > total_pages:
        st.session_state.page = 1

    def change_page(page):
        st.session_state.page = page

    page = st.session_state.page
    start_idx = (page - 1) * items_per_page
    end_idx = start_idx + items_per_page
    current_page_data = filtered_data[start_idx:end_idx]

    for item in current_page_data:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")

        # 하이퍼링크 처리
        for link in item.get("links", []):
            answer = answer.replace(link["text"], f"[{link['text']}]({link['href']})")

        with st.expander(f"❓ {question}"):
            st.write(answer)

            # 이미지 처리
            for image in item.get("images", []):
                st.image(image["src"], caption=image.get("alt", ""))

    page_numbers = [i for i in range(1, total_pages + 1)]
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()
    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page_tab2"):
                change_page(page - 1)
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page_tab2"):
                change_page(page + 1)


with tab3:
    st.image("images\jenesis.png")

    # JSON 파일 로드
    file_path = 'data\genesis_faq.json'
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            j_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        j_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(j_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        #st.stop()

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    # 검색 기능
    def search():
        st.session_state.search_query = st.session_state.search_input
        st.session_state.page = 1 

    search_query = st.text_input("", key="j_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)
    if search_query:
        filtered_data  = [item for item in j_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = j_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page"):
                st.session_state.page = page + 1



Based on the provided codebase, identify the key abstractions that are central to understanding this project. 
These abstractions should represent the core components, modules, or concepts.

Desired output format is a YAML list of objects, where each object has:
- 'name': A concise name for the abstraction (in korean).
- 'description': A brief explanation of what this abstraction represents and its role (in korean).
- 'file_indices': A list of integer file indices that are most relevant to this abstraction. Choose from the file list above.

Return at most 10 key abstractions.

Example for a different project (simple web server):
```yaml
- name: "HTTP 요청 핸들러 (HTTP Request Handler)"
  description: "수신 HTTP 요청을 처리하고 적절한 응답을 생성하는 구성 요소입니다. (Component that processes incoming HTTP requests and generates appropriate responses.)"
  file_indices: [0, 2]
- name: "라우팅 설정 (Routing Configuration)"
  description: "URL 경로를 특정 요청 핸들러 함수에 매핑하는 규칙을 정의합니다. (Defines rules for mapping URL paths to specific request handler functions.)"
  file_indices: [1]
```

Your response should be only the YAML list, enclosed in triple backticks (```yaml ... ```).
Ensure the output is valid YAML.

2025-06-29 20:34:41,438 - INFO - RESPONSE (from cache): ```yaml
- name: "데이터베이스 삽입 모듈"
  description: "CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 기능을 제공하는 모듈입니다."
  file_indices: [2, 3]
- name: "연도별 자동차 등록 현황 페이지"
  description: "연도별 자동차 등록 데이터를 시각화하여 사용자에게 제공하는 스트림릿 웹 페이지입니다."
  file_indices: [0]
- name: "지역별 자동차 등록 현황 페이지"
  description: "지역별 자동차 등록 데이터를 차트 및 지도 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다."
  file_indices: [8]
- name: "브랜드별 자동차 판매 현황 페이지"
  description: "브랜드별 자동차 판매 데이터를 카드 및 파이 차트 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다."
  file_indices: [9]
- name: "차량 구매 FAQ 페이지"
  description: "주요 자동차 브랜드의 차량 구매 관련 FAQ 데이터를 제공하고 검색 기능을 갖춘 스트림릿 웹 페이지입니다."
  file_indices: [10]
- name: "FAQ 크롤링 모듈"
  description: "주요 자동차 브랜드 웹사이트로부터 FAQ 데이터를 크롤링하여 JSON 파일로 저장하는 모듈입니다."
  file_indices: [5, 6, 7]
- name: "자동차 판매 실적 크롤링 모듈"
  description: "다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하여 CSV 파일로 저장하는 모듈입니다."
  file_indices: [4]
- name: "데이터베이스 연결 설정"
  description: "MySQL 데이터베이스에 연결하기 위한 설정 및 쿼리를 실행하여 데이터를 가져오는 기능을 제공합니다."
  file_indices: [0, 8]
- name: "시각화 라이브러리 사용"
  description: "데이터를 차트와 그래프로 시각화하기 위해 Plotly, Matplotlib, Folium 등의 라이브러리를 사용합니다."
  file_indices: [0, 8, 9]
- name: "검색 및 페이지네이션 기능"
  description: "FAQ 페이지에서 검색 기능과 페이지네이션을 제공하여 사용자가 원하는 정보를 쉽게 찾아볼 수 있도록 지원합니다."
  file_indices: [10]
```
2025-06-29 20:34:41,442 - INFO - PROMPT: 
Based on the following abstractions and relevant code snippets from the project `SKN10-1st-4Team`:

List of Abstraction Indices and Names (Names might be in Korean):
0 # 데이터베이스 삽입 모듈
1 # 연도별 자동차 등록 현황 페이지
2 # 지역별 자동차 등록 현황 페이지
3 # 브랜드별 자동차 판매 현황 페이지
4 # 차량 구매 FAQ 페이지
5 # FAQ 크롤링 모듈
6 # 자동차 판매 실적 크롤링 모듈
7 # 데이터베이스 연결 설정
8 # 시각화 라이브러리 사용
9 # 검색 및 페이지네이션 기능

Context (Abstractions, Descriptions, Code):
Identified Abstractions:
- Index 0: 데이터베이스 삽입 모듈 (Relevant file indices: [2, 3])
  Description: CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 기능을 제공하는 모듈입니다.
- Index 1: 연도별 자동차 등록 현황 페이지 (Relevant file indices: [0])
  Description: 연도별 자동차 등록 데이터를 시각화하여 사용자에게 제공하는 스트림릿 웹 페이지입니다.
- Index 2: 지역별 자동차 등록 현황 페이지 (Relevant file indices: [8])
  Description: 지역별 자동차 등록 데이터를 차트 및 지도 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.
- Index 3: 브랜드별 자동차 판매 현황 페이지 (Relevant file indices: [9])
  Description: 브랜드별 자동차 판매 데이터를 카드 및 파이 차트 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.
- Index 4: 차량 구매 FAQ 페이지 (Relevant file indices: [10])
  Description: 주요 자동차 브랜드의 차량 구매 관련 FAQ 데이터를 제공하고 검색 기능을 갖춘 스트림릿 웹 페이지입니다.
- Index 5: FAQ 크롤링 모듈 (Relevant file indices: [5, 6, 7])
  Description: 주요 자동차 브랜드 웹사이트로부터 FAQ 데이터를 크롤링하여 JSON 파일로 저장하는 모듈입니다.
- Index 6: 자동차 판매 실적 크롤링 모듈 (Relevant file indices: [4])
  Description: 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하여 CSV 파일로 저장하는 모듈입니다.
- Index 7: 데이터베이스 연결 설정 (Relevant file indices: [0, 8])
  Description: MySQL 데이터베이스에 연결하기 위한 설정 및 쿼리를 실행하여 데이터를 가져오는 기능을 제공합니다.
- Index 8: 시각화 라이브러리 사용 (Relevant file indices: [0, 8, 9])
  Description: 데이터를 차트와 그래프로 시각화하기 위해 Plotly, Matplotlib, Folium 등의 라이브러리를 사용합니다.
- Index 9: 검색 및 페이지네이션 기능 (Relevant file indices: [10])
  Description: FAQ 페이지에서 검색 기능과 페이지네이션을 제공하여 사용자가 원하는 정보를 쉽게 찾아볼 수 있도록 지원합니다.

Relevant File Snippets (Referenced by Index and Path):
--- File: 0 # 1_연도별_자동차_등록_현황.py ---
#test
import streamlit as st
import pandas as pd
import plotly.express as px
import pymysql
from common.insert_data import insert_data
from common.insert_data_city import insert_data_city

insert_data()
insert_data_city()

st.set_page_config(layout="centered")

st.title("📊 연도별 자동차 등록 현황")
st.divider()

# 데이터베이스 연결 설정
connection = pymysql.connect(
    host="localhost",
    user="SKN10_4team",
    password="skn1234",
    database="SKN10_4team_1st",
    charset="utf8"
)

# SQL 데이터 가져오기
year_data = "select Year FROM Car"
ef = pd.read_sql(year_data, connection)

car_data = """
SELECT Year, SUM(CarCount) YearofCar
FROM SKN10_4team_1st.Car
GROUP BY Year
ORDER BY Year;
"""
cf = pd.read_sql(car_data, connection)

# Streamlit 컨테이너
with st.container():
    # 컬럼 레이아웃 사용
    col1, col2 = st.columns(2)
    # 년도 리스트 생성 및 선택
    years = ef['Year'].unique().tolist()

    # 디폴트 값 설정
    default_start_year_index = 0  # 첫 번째 연도를 디폴트로 설정
    default_end_year_index = len(years) - 1  # 마지막 연도를 디폴트로 설정

    with col1:
        start_year = st.selectbox(
            '첫번째 년도를 선택해주세요.', 
            years, 
            index=default_start_year_index
        )

    with col2:
        end_year = st.selectbox(
            '마지막 년도를 선택해주세요.', 
            years, 
            index=default_end_year_index
        )

# 연도 범위 확인 및 데이터 필터링
if start_year > end_year:
    st.error("Error: The start year cannot be greater than the end year.")
else:
    with st.container():
        # 사용자 입력 값으로 데이터 필터링
        filtered_data = cf[(cf["Year"] >= start_year) & (cf["Year"] <= end_year)]

        # Plotly로 그래프 생성
        fig = px.bar(
            filtered_data, 
            x="Year", 
            y="YearofCar", 
            title="조회결과"
        )

        # axis title 업데이트
        fig.update_xaxes(title_text="연도")
        fig.update_yaxes(title_text="차량 수 (만대)")

        # 그래프 출력
        st.plotly_chart(fig)

}]}

--- File: 2 # common/insert_data.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "Car.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "Car"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (Year, CityID, CarCount) VALUES (%s, %s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[2], row[3])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File: 3 # common/insert_data_city.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data_city():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "City.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "City"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (CityID, CityName) VALUES (%s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[1])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File: 4 # crawling/danawa.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By


import pandas as pd
import time

# 크롬 드라이버 설정

driver = webdriver.Chrome()

# 데이터 저장 리스트
domestic_data = []
foreign_data = []

# 2021년 1월부터 2024년 12월까지의 URL 생성 및 데이터 크롤링
for year in range(2021, 2025):
    for month in range(1, 13):
        if year == 2024 and month > 12:
            break
        month_str = f"{year}-{month:02d}-00"
        url = f"https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month={month_str}&MonthTo="
        driver.get(url)
        time.sleep(0.5)  # 페이지 로딩 대기

        # 국산차 순위 데이터 크롤링
        rank_elements = driver.find_elements(By.CSS_SELECTOR, "ul.sideRankR li")

        for index, rank_element in enumerate(rank_elements):
            rank = rank_element.find_element(By.CSS_SELECTOR, "span.rank").text
            brand = rank_element.find_element(By.CSS_SELECTOR, "span.title").text.strip()
            sales = rank_element.find_element(By.CSS_SELECTOR, "span.sales").text
            rate = rank_element.find_element(By.CSS_SELECTOR, "span.rate").text
            logo_img = rank_element.find_element(By.CSS_SELECTOR, "span.title img").get_attribute("src")
            data = [year, month, rank, brand, sales, rate, logo_img]
            if index < 6:
                domestic_data.append(data)
            else:
                foreign_data.append(data)

# 데이터프레임으로 변환
domestic_df = pd.DataFrame(domestic_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])
foreign_df = pd.DataFrame(foreign_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])

# 데이터프레임 저장
domestic_df.to_csv("data\국산차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')
foreign_df.to_csv("data\해외차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')

# 드라이버 종료
driver.quit()

print("크롤링 완료 및 데이터 저장 완료")
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo=
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo= 에서 2021-01은 21년 1월 데이터를 받아온다는 의미


--- File: 5 # crawling/genesis_faq.py ---

# 제네시스 크롤링
from selenium import webdriver
from bs4 import BeautifulSoup
import json

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.genesis.com/kr/ko/support/faq/vehicle-purchase.html?anchorID=faq_tab"
driver.get(url)

# 페이지 소스 가져오기
html_source = driver.page_source

# HTML 파일로 저장
#with open("genesis_faq.html", "w", encoding="utf-8") as file:
#    file.write(html_source)

# 드라이버 종료
driver.quit()

# BeautifulSoup을 사용하여 페이지 소스 파싱
soup = BeautifulSoup(html_source, 'html.parser')

# FAQ 질문과 답변 추출
faqs = []
faq_items = soup.select('.cp-faq__accordion-item')  # FAQ 항목을 감싸는 클래스 이름을 사용하여 선택

for item in faq_items:
    question = item.select_one('.accordion-title').get_text(strip=True)
    answer = item.select_one('.accordion-panel-inner').get_text(strip=True)
    faqs.append({'question': question, 'answer': answer})

# 추출한 FAQ를 파일로 저장
with open("data\genesis_faq.json", "w", encoding="utf-8") as file:
    json.dump(faqs, file, ensure_ascii=False, indent=4)

--- File: 6 # crawling/hyundai_faq.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from time import sleep

#import pandas as pd
import json


URL = "https://www.hyundai.com/kr/ko/e/customer/center/faq"

driver = webdriver.Chrome()
driver.get(URL)
# 리스트에 딕셔너리로 내용 저장
qna_list = []

for page_id in range(4):
    for question_id in range(1,11):
        try:
            #엘리먼트 찾기
            faq_list = driver.find_element(By.CSS_SELECTOR, "div[data-v-28d34f54].list-wrap")

            try:
                # 플로팅 메뉴 제거
                floating_menu = driver.find_element(By.CSS_SELECTOR, "div[data-v-1ea4ba2d].inner_wrap")
                driver.execute_script("arguments[0].remove();", floating_menu)
            except:
                pass
            faq_title = faq_list.find_elements(By.CSS_SELECTOR,f"div[data-id='{question_id}'] button.list-title")
            driver.execute_script("arguments[0].scrollIntoView({block:'center'});",faq_title[0])
            sleep(0.5)

            #질문타이틀 클릭하기
            faq_title[0].click()
            sleep(0.5)

            #질문타이틀 텍스트 받아오기
            faq_question = faq_title[0].find_element(By.CSS_SELECTOR, "span.list-content[data-v-28d34f54]")
            faq_question_text = faq_question.text
            #print(faq_question_text)

            #질문답변 텍스트 받아오기
            faq_answer = driver.find_element(By.CLASS_NAME, "conts")
            faq_answer_text = faq_answer.text
            #print("전체 답변:", faq_answer_text)

            # 링크 URL 가져오기
            try:
                link_whole = faq_answer.find_elements(By.TAG_NAME, "a")
                link = {
                    "url" : link_whole[0].get_attribute("href"),
                    "text" : link_whole[0].text
                    }
            except:
                link = ""
            #print("링크 URL:", url)
            
            qna_list.append({"question": faq_question_text, "answer": faq_answer_text, "link": link})

        except TimeoutException:
            print("Timed out waiting for page to load")
        except NoSuchElementException:
            print("Could not find the element")
        except IndexError:
            pass

    next_button = driver.find_element(By.CSS_SELECTOR, "button.btn-next")
    next_button.click()
    sleep(1)
 
#qna_df = pd.DataFrame(qna_list, columns = ["page_num","question_num","question","answer","link"])
#qna_df.to_csv(path_or_buf="data/hyundai_qna.csv")

# 결과를 JSON 파일로 저장
with open("data\hyundai_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(qna_list, json_file, ensure_ascii=False, indent=4)

--- File: 7 # crawling/kia_faq.py ---
import json
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.kia.com/kr/customer-service/center/faq"
driver.get(url)

# 페이지가 완전히 로드될 때까지 대기
WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, "body")))

# "TOP 10" 버튼 클릭
top_10_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//button[contains(text(), 'TOP 10')]"))
)
top_10_button.click()

# "차량 구매" 버튼 클릭
car_purchase_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//li[button/span[text()='차량 구매']]"))
)
car_purchase_button.click()

# 3초 텀을 둠
time.sleep(3)

# 각 질문 클릭하여 답변 가져오기
faq_data = []

def get_faq_data():
    # FAQ 항목이 로드될 때까지 대기
    WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

    # FAQ 항목들 찾기
    faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")

    for i in range(len(faq_items)):
        # 각 질문을 클릭하기 전에 요소를 다시 찾음
        faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")
        item = faq_items[i]
        question = item.find_element(By.CSS_SELECTOR, ".cmp-accordion__title").text
        item.click()  # 질문 클릭하여 답변 표시

        # 답변이 로드될 때까지 대기
        panel_id = item.get_attribute("aria-controls")
        WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.ID, panel_id)))
        answer_element = driver.find_element(By.ID, panel_id)
        answer = answer_element.text

        # 하이퍼링크 정보 가져오기
        links = []
        link_elements = answer_element.find_elements(By.TAG_NAME, "a")
        for link in link_elements:
            links.append({
                "href": link.get_attribute("href"),
                "text": link.text
            })

        # 이미지 링크 정보 가져오기
        images = []
        image_elements = answer_element.find_elements(By.TAG_NAME, "img")
        for img in image_elements:
            images.append({
                "src": img.get_attribute("src"),
                "alt": img.get_attribute("alt")
            })

        faq_data.append({
            "question": question,
            "answer": answer,
            "links": links,
            "images": images
        })

    # 스크롤을 맨 위로 올리기
    driver.execute_script("window.scrollTo(0, 0);")

# 첫 페이지의 FAQ 데이터 가져오기
get_faq_data()

# 페이지 넘기기
current_page = 1
while current_page < 4:
    try:
        next_page = str(current_page + 1)

        # 다음 페이지 번호 클릭
        next_page_element = driver.find_element(By.XPATH, f"//ul[@class='paging-list']//a[text()='{next_page}']")
        next_page_element.click()

        # 3초 텀을 둠
        time.sleep(3)

        # 다음 페이지가 로드될 때까지 대기
        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

        # 각 페이지의 FAQ 데이터를 가져오기 전에 요소를 다시 찾음
        get_faq_data()

        current_page += 1
    except Exception as e:
        print(f"Error: {e}")
        break

# 드라이버 종료
driver.quit()

# 결과를 JSON 파일로 저장
with open("/data/kia_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(faq_data, json_file, ensure_ascii=False, indent=4)

# 결과 출력
'''
for faq in faq_data:
    print(f"Question: {faq['question']}")
    print(f"Answer: {faq['answer']}")
    print(f"Links: {faq['links']}")
    print(f"Images: {faq['images']}\n")
'''

--- File: 8 # pages/2_지역별_자동차_등록_현황.py ---
import streamlit as st
import pymysql
import pandas as pd
import plotly.express as px
import folium
import random
from streamlit_folium import folium_static

st.set_page_config(layout="wide")

st.title("📊 지역별 자동차 등록 현황")

tab1, tab2 = st.tabs(['차트', '지도'])

with tab1:
    # Database 연결
    connection = pymysql.connect(
        host = "localhost",
        user = "SKN10_4team",
        password = "skn1234",
        database = "SKN10_4team_1st",
        charset = "utf8"
    )

    cursor = connection.cursor(pymysql.cursors.DictCursor)

    year_data = """
    SELECT DISTINCT year
    FROM Car
    ;
    """
    cursor.execute(year_data)
    years = cursor.fetchall()
    year_list = [year['year'] for year in years]

    with st.container(border=True):
        selected_year = st.selectbox("연도를 선택하세요:", year_list, index=year_list.index('2022'))

    car_data = f"""
    SELECT City.CityName, Car.CarCount, Car.CityID
    FROM Car
    JOIN City ON Car.CityID = City.CityID
    WHERE Car.Year = {selected_year}
    ;
    """
    cursor.execute(car_data)
    result = cursor.fetchall()

    df = pd.DataFrame(result)

    df['CityID_Number'] = df['CityID'].str.extract(r'(\d+)').astype(int)
    df = df.sort_values(by='CityID_Number')

    fig = px.pie(df, names = "CityName", values="CarCount",
                hover_data={'CarCount': True}, labels={'CarCount': 'CarCount'})
    fig.update_traces(textposition='outside', textinfo='label+value+percent', textfont_color="black", hole=.4,
                    direction='counterclockwise')
    fig.add_annotation(dict(text=f"{selected_year}", x=0.5, y=0.5, font_color="black", font_size=25, showarrow=False))
    fig.add_annotation(dict(text="단위: 만 대", x=0.5, y=0.45, font_color="gray", font_size=13, showarrow=False))

    fig.update_layout(width=1600, height=850, legend=dict(
        yanchor="top",
        y=1.05
    ))
    st.plotly_chart(fig)

with tab2:
    # CSV 파일 경로
    car_file_path = 'data/Car.csv'
    city_file_path = 'data/City_m.csv'

    # CSV 파일 읽기
    car_df = pd.read_csv(car_file_path)
    city_df = pd.read_csv(city_file_path)

    # 연도 선택
    years = car_df['연도'].unique()
    selected_year = st.selectbox('연도를 선택하세요:', years)

    # 선택된 연도에 따라 데이터 필터링
    filtered_car_df = car_df[car_df['연도'] == selected_year]

    # 지도 생성
    m = folium.Map(location=[36.5, 127.5], zoom_start=7)

    # 색상 팔레트 생성
    colors = ['#%06X' % random.randint(0, 0xFFFFFF) for _ in range(len(city_df))]

    # 각 도시의 좌표에 등록대수를 반영한 원 추가
    for i, (_, row) in enumerate(filtered_car_df.iterrows()):
        city_id = row['지역ID']
        city_data = city_df[city_df['CityID'] == city_id].iloc[0]
        folium.Circle(
            location=[city_data['Latitude'], city_data['Longitude']],
            radius=row['등록대수'] * 100,  # 등록대수에 비례한 반경
            color=colors[i],
            fill=True,
            fill_color=colors[i],
            fill_opacity=0.6,
            popup=f"{city_data['CityName']} ({row['등록대수']} 만대)"
        ).add_to(m)

    # 지도 표시
    folium_static(m)

    # 색상 레이블 표시

    legend_html = """
    <div style="border:1px solid black; padding:5px; width: 200px;">
        <b>지역별 색상 레이블</b><br>
    """
    for i, city in city_df.iterrows():
        legend_html += f"<div style='display: flex; align-items: center; margin-bottom: 5px;'><div style='width: 15px; height: 15px; background-color: {colors[i]}; margin-right: 5px;'></div>{city['CityName']}</div>"
    legend_html += "</div>"
    st.markdown(legend_html, unsafe_allow_html=True)

--- File: 9 # pages/3_브랜드별_자동차_판매_현황.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc

st.set_page_config(layout="centered")

st.title("📊 브랜드별 자동차 판매 현황")

# 한글 폰트 설정
font_path = 'C:/Windows/Fonts/malgun.ttf'  # Windows의 경우
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)

# CSV 파일 경로
domestic_file_path = 'data/국산차_순위_2021_2024.csv'
foreign_file_path = 'data/해외차_순위_2021_2024.csv'

# CSV 파일 읽기
domestic_df = pd.read_csv(domestic_file_path)
foreign_df = pd.read_csv(foreign_file_path)

def create_cards(data):
    for index, row in data.iterrows():
        st.markdown(f"""
        <div style="border: 1px solid #ddd; border-radius: 10px; padding: 10px; margin: 10px 0;">
            <h3 style="margin: 0;">{row['순위']}위 - {row['브랜드']}</h3>
            <img src="{row['로고 이미지 링크']}" width="50" style="float: right; margin-left: 10px;">
            <p>판매량: {row['판매량']}</p>
            <p>비율: {row['비율']}</p>
        </div>
        """, unsafe_allow_html=True)

def create_pie_chart(data, title, top_n, total_sales):
    st.subheader(title)
    fig, ax = plt.subplots()
    top_brands = data.iloc[:top_n]
    others = data.iloc[top_n:]
    labels = top_brands['브랜드'].tolist() + ['기타 브랜드']
    sizes = top_brands['판매량'].str.replace(',', '').astype(int).tolist() + [others['판매량'].str.replace(',', '').astype(int).sum()]
    colors = plt.get_cmap('tab20').colors  # 다양한 색상 사용
    ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3))
    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

    # 도넛 차트의 가운데에 총 판매량 표시
    ax.text(0, 0, f"{total_sales:,} 대", ha='center', va='center', fontsize=12, fontweight='bold')

    # 파이 차트 표시
    st.pyplot(fig)

def display_tab(title, df, top_n):

    # 연도와 월 선택
    years = df['연도'].unique()
    months = df['월'].unique()

    with st.container(border=True):
        selected_year = st.selectbox('연도를 선택하세요:', years, key=f'{title}_year')
        selected_month = st.selectbox('월을 선택하세요:', months, key=f'{title}_month')

    # 선택된 연도와 월에 따라 데이터 필터링
    filtered_data = df[(df['연도'] == selected_year) & (df['월'] == selected_month)]

    # 주요 지표 강조
    total_sales = filtered_data['판매량'].str.replace(',', '').astype(int).sum()
    

    # 도넛 모양의 파이 차트 생성
    create_pie_chart(filtered_data, f'{title} 브랜드별 판매 비율', top_n, total_sales)

    # 데이터 카드 형식으로 표시
    st.subheader(f'{title} 순위 데이터')
    create_cards(filtered_data)

# 탭 생성
tab1, tab2 = st.tabs(['국산차', '수입차'])

with tab1:
    display_tab('국산차', domestic_df, 3)

with tab2:
    display_tab('수입차', foreign_df, 5)

--- File: 10 # pages/4_주요_3개_기업_차량_구매_FAQ.py ---
import streamlit as st
import json

st.set_page_config(layout="centered")

# 제목 및 탭 구성
st.title("❓ 주요 3개 기업 차량 구매 FAQ")

tab1, tab2, tab3 = st.tabs(['현대', '기아', '제네시스'])

with tab1:
    st.image("images/hyundai.png")

    file_path = 'data\hyundai_faq.json'  # 경로설정

    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            h_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        h_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(h_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        st.stop()


    # 검색 기능
    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    search_query = st.text_input("", key="hd_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if search_query:
        filtered_data  = [item for item in h_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = h_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="hd_prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="hd_next_page"):
                st.session_state.page = page + 1

with tab2:
    st.image("images/kia.jpg")

    file_path = 'data\kia_faq.json'  # 경로설정
    with open(file_path, 'r', encoding='utf-8') as file:
        k_faq_data = json.load(file)

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    st.text_input("", key="search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if 'search_query' in st.session_state and st.session_state.search_query:
        filtered_data = [item for item in k_faq_data if st.session_state.search_query.lower() in item['question'].lower() or st.session_state.search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = k_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 페이지네이션 설정
    items_per_page = 10
    total_pages = (len(filtered_data) + items_per_page - 1) // items_per_page


    # 페이지 번호 선택
    if 'page' not in st.session_state or st.session_state.page > total_pages:
        st.session_state.page = 1

    def change_page(page):
        st.session_state.page = page

    page = st.session_state.page
    start_idx = (page - 1) * items_per_page
    end_idx = start_idx + items_per_page
    current_page_data = filtered_data[start_idx:end_idx]

    for item in current_page_data:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")

        # 하이퍼링크 처리
        for link in item.get("links", []):
            answer = answer.replace(link["text"], f"[{link['text']}]({link['href']})")

        with st.expander(f"❓ {question}"):
            st.write(answer)

            # 이미지 처리
            for image in item.get("images", []):
                st.image(image["src"], caption=image.get("alt", ""))

    page_numbers = [i for i in range(1, total_pages + 1)]
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()
    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page_tab2"):
                change_page(page - 1)
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page_tab2"):
                change_page(page + 1)


with tab3:
    st.image("images\jenesis.png")

    # JSON 파일 로드
    file_path = 'data\genesis_faq.json'
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            j_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        j_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(j_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        #st.stop()

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    # 검색 기능
    def search():
        st.session_state.search_query = st.session_state.search_input
        st.session_state.page = 1 

    search_query = st.text_input("", key="j_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)
    if search_query:
        filtered_data  = [item for item in j_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = j_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page"):
                st.session_state.page = page + 1

IMPORTANT: Generate the `summary` and relationship `label` fields in **Korean** language. Do NOT use English for these fields.

Please provide:
1. A high-level `summary` of the project's main purpose and functionality in a few beginner-friendly sentences (in Korean). Use markdown formatting with **bold** and *italic* text to highlight important concepts.
2. A list (`relationships`) describing the key interactions between these abstractions. For each relationship, specify:
    - `from_abstraction`: Index of the source abstraction (e.g., `0 # AbstractionName1`)
    - `to_abstraction`: Index of the target abstraction (e.g., `1 # AbstractionName2`)
    - `label`: A brief label for the interaction **in just a few words** (in Korean) (e.g., "Manages", "Inherits", "Uses").
    Ideally the relationship should be backed by one abstraction calling or passing parameters to another.
    Simplify the relationship and exclude those non-important ones.

IMPORTANT: Make sure EVERY abstraction is involved in at least ONE relationship (either as source or target). Each abstraction index must appear at least once across all relationships.

Format the output as YAML:

```yaml
summary: |
  A brief, simple explanation of the project (in Korean).
  Can span multiple lines with **bold** and *italic* for emphasis.
relationships:
  - from_abstraction: 0 # AbstractionName1
    to_abstraction: 1 # AbstractionName2
    label: "Manages" (in Korean)
  - from_abstraction: 2 # AbstractionName3
    to_abstraction: 0 # AbstractionName1
    label: "Provides config" (in Korean)
  # ... other relationships
```

Now, provide the YAML output:

2025-06-29 20:34:41,445 - INFO - RESPONSE (from cache): ```yaml
summary: |
  **SKN10-1st-4Team** 프로젝트는 자동차 등록 및 판매 현황 데이터를 관리하고 *시각화*하는 웹 애플리케이션입니다. **Streamlit**을 사용하여 각종 **연도별, 지역별, 브랜드별** 데이터를 **시각화**하며, **크롤링** 모듈을 통해 주요 브랜드의 **FAQ 데이터를 자동으로 수집**합니다. 또한, 데이터는 **MySQL 데이터베이스**에 저장되고 **검색 및 페이지네이션** 기능을 통해 사용자는 필요한 정보를 쉽게 찾을 수 있습니다.

relationships:
  - from_abstraction: 0 # 데이터베이스 삽입 모듈
    to_abstraction: 7 # 데이터베이스 연결 설정
    label: "사용"
  - from_abstraction: 1 # 연도별 자동차 등록 현황 페이지
    to_abstraction: 0 # 데이터베이스 삽입 모듈
    label: "데이터 읽기"
  - from_abstraction: 2 # 지역별 자동차 등록 현황 페이지
    to_abstraction: 7 # 데이터베이스 연결 설정
    label: "사용"
  - from_abstraction: 3 # 브랜드별 자동차 판매 현황 페이지
    to_abstraction: 6 # 자동차 판매 실적 크롤링 모듈
    label: "데이터 사용"
  - from_abstraction: 4 # 차량 구매 FAQ 페이지
    to_abstraction: 9 # 검색 및 페이지네이션 기능
    label: "활용"
  - from_abstraction: 5 # FAQ 크롤링 모듈
    to_abstraction: 4 # 차량 구매 FAQ 페이지
    label: "데이터 공급"
  - from_abstraction: 6 # 자동차 판매 실적 크롤링 모듈
    to_abstraction: 9 # 검색 및 페이지네이션 기능
    label: "활용"
  - from_abstraction: 8 # 시각화 라이브러리 사용
    to_abstraction: 2 # 지역별 자동차 등록 현황 페이지
    label: "적용"
  - from_abstraction: 9 # 검색 및 페이지네이션 기능
    to_abstraction: 4 # 차량 구매 FAQ 페이지
    label: "지원"
```
2025-06-29 20:34:41,447 - INFO - PROMPT: 
Given the following project abstractions and their relationships for the project ```` SKN10-1st-4Team ````:

Abstractions (Index # Name) (Names might be in Korean):
- 0 # 데이터베이스 삽입 모듈
- 1 # 연도별 자동차 등록 현황 페이지
- 2 # 지역별 자동차 등록 현황 페이지
- 3 # 브랜드별 자동차 판매 현황 페이지
- 4 # 차량 구매 FAQ 페이지
- 5 # FAQ 크롤링 모듈
- 6 # 자동차 판매 실적 크롤링 모듈
- 7 # 데이터베이스 연결 설정
- 8 # 시각화 라이브러리 사용
- 9 # 검색 및 페이지네이션 기능

Context about relationships and project summary:
Project Summary (Note: Project Summary might be in Korean):
**SKN10-1st-4Team** 프로젝트는 자동차 등록 및 판매 현황 데이터를 관리하고 *시각화*하는 웹 애플리케이션입니다. **Streamlit**을 사용하여 각종 **연도별, 지역별, 브랜드별** 데이터를 **시각화**하며, **크롤링** 모듈을 통해 주요 브랜드의 **FAQ 데이터를 자동으로 수집**합니다. 또한, 데이터는 **MySQL 데이터베이스**에 저장되고 **검색 및 페이지네이션** 기능을 통해 사용자는 필요한 정보를 쉽게 찾을 수 있습니다.


Relationships (Indices refer to abstractions above):
- From 0 (데이터베이스 삽입 모듈) to 7 (데이터베이스 연결 설정): 사용
- From 1 (연도별 자동차 등록 현황 페이지) to 0 (데이터베이스 삽입 모듈): 데이터 읽기
- From 2 (지역별 자동차 등록 현황 페이지) to 7 (데이터베이스 연결 설정): 사용
- From 3 (브랜드별 자동차 판매 현황 페이지) to 6 (자동차 판매 실적 크롤링 모듈): 데이터 사용
- From 4 (차량 구매 FAQ 페이지) to 9 (검색 및 페이지네이션 기능): 활용
- From 5 (FAQ 크롤링 모듈) to 4 (차량 구매 FAQ 페이지): 데이터 공급
- From 6 (자동차 판매 실적 크롤링 모듈) to 9 (검색 및 페이지네이션 기능): 활용
- From 8 (시각화 라이브러리 사용) to 2 (지역별 자동차 등록 현황 페이지): 적용
- From 9 (검색 및 페이지네이션 기능) to 4 (차량 구매 FAQ 페이지): 지원


If you are going to make a tutorial for ```` SKN10-1st-4Team ````, what is the best order to explain these abstractions, from first to last?
Ideally, first explain those that are the most important or foundational, perhaps user-facing concepts or entry points. Then move to more detailed, lower-level implementation details or supporting concepts.

Output the ordered list of abstraction indices, including the name in a comment for clarity. Use the format `idx # AbstractionName`.

```yaml
- 2 # FoundationalConcept
- 0 # CoreClassA
- 1 # CoreClassB (uses CoreClassA)
- ...
```

Now, provide the YAML output:

2025-06-29 20:34:41,449 - INFO - RESPONSE (from cache): ```yaml
- 8 # 시각화 라이브러리 사용
- 2 # 지역별 자동차 등록 현황 페이지
- 1 # 연도별 자동차 등록 현황 페이지
- 3 # 브랜드별 자동차 판매 현황 페이지
- 4 # 차량 구매 FAQ 페이지
- 9 # 검색 및 페이지네이션 기능
- 5 # FAQ 크롤링 모듈
- 6 # 자동차 판매 실적 크롤링 모듈
- 0 # 데이터베이스 삽입 모듈
- 7 # 데이터베이스 연결 설정
```
2025-06-29 20:34:41,450 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "시각화 라이브러리 사용". This is Chapter 1.

Concept Details (Note: Provided in Korean):
- Name: 시각화 라이브러리 사용
- Description:
데이터를 차트와 그래프로 시각화하기 위해 Plotly, Matplotlib, Folium 등의 라이브러리를 사용합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
This is the first chapter.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 1: 시각화 라이브러리 사용`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:34:41,452 - INFO - RESPONSE (from cache): # Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
2025-06-29 20:34:41,452 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "지역별 자동차 등록 현황 페이지". This is Chapter 2.

Concept Details (Note: Provided in Korean):
- Name: 지역별 자동차 등록 현황 페이지
- Description:
지역별 자동차 등록 데이터를 차트 및 지도 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 2: 지역별 자동차 등록 현황 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:34:41,455 - INFO - RESPONSE (from cache): # 제 2 장: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
2025-06-29 20:34:41,455 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "연도별 자동차 등록 현황 페이지". This is Chapter 3.

Concept Details (Note: Provided in Korean):
- Name: 연도별 자동차 등록 현황 페이지
- Description:
연도별 자동차 등록 데이터를 시각화하여 사용자에게 제공하는 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 3: 연도별 자동차 등록 현황 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:34:41,458 - INFO - RESPONSE (from cache): # Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
2025-06-29 20:34:41,458 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "브랜드별 자동차 판매 현황 페이지". This is Chapter 4.

Concept Details (Note: Provided in Korean):
- Name: 브랜드별 자동차 판매 현황 페이지
- Description:
브랜드별 자동차 판매 데이터를 카드 및 파이 차트 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 4: 브랜드별 자동차 판매 현황 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:34:41,461 - INFO - RESPONSE (from cache): # 제4장: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
2025-06-29 20:34:41,461 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "차량 구매 FAQ 페이지". This is Chapter 5.

Concept Details (Note: Provided in Korean):
- Name: 차량 구매 FAQ 페이지
- Description:
주요 자동차 브랜드의 차량 구매 관련 FAQ 데이터를 제공하고 검색 기능을 갖춘 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 5: 차량 구매 FAQ 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:34:41,464 - INFO - RESPONSE (from cache): # Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
2025-06-29 20:34:41,464 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "검색 및 페이지네이션 기능". This is Chapter 6.

Concept Details (Note: Provided in Korean):
- Name: 검색 및 페이지네이션 기능
- Description:
FAQ 페이지에서 검색 기능과 페이지네이션을 제공하여 사용자가 원하는 정보를 쉽게 찾아볼 수 있도록 지원합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 6: 검색 및 페이지네이션 기능`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:34:41,466 - INFO - RESPONSE (from cache): # Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
2025-06-29 20:34:41,466 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "FAQ 크롤링 모듈". This is Chapter 7.

Concept Details (Note: Provided in Korean):
- Name: FAQ 크롤링 모듈
- Description:
주요 자동차 브랜드 웹사이트로부터 FAQ 데이터를 크롤링하여 JSON 파일로 저장하는 모듈입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 7: FAQ 크롤링 모듈`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:34:41,469 - INFO - RESPONSE (from cache): # Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.
2025-06-29 20:34:41,469 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "자동차 판매 실적 크롤링 모듈". This is Chapter 8.

Concept Details (Note: Provided in Korean):
- Name: 자동차 판매 실적 크롤링 모듈
- Description:
다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하여 CSV 파일로 저장하는 모듈입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
---
# Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 8: 자동차 판매 실적 크롤링 모듈`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:34:41,471 - INFO - RESPONSE (from cache): # Chapter 8: 자동차 판매 실적 크롤링 모듈

이전 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동차 관련 웹사이트에서 FAQ 데이터를 자동으로 수집하고 저장하는 방법을 배웠습니다. 이번 장에서는 `자동차 판매 실적 크롤링 모듈`을 구축하여 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하고, 이를 CSV 파일로 저장하는 방법을 알아보겠습니다.

## 동기 부여

자동차 판매 실적을 분석하는 것은 시장 동향을 파악하고, 신차 개발 및 판매 전략을 수립하는 데 중요한 역할을 합니다. 만약 특정 브랜드의 판매 실적이 급격히 증가했다면, 그 이유를 파악하여 다른 브랜드에도 적용할 수 있는 영감을 얻을 수 있습니다. 이때 매번 웹사이트를 방문해 수작업으로 데이터를 정리하는 대신, 크롤러를 사용하면 실적 데이터를 자동으로 수집 및 저장할 수 있습니다.

## 주요 개념

### 웹 크롤링

웹 크롤링은 특정 웹사이트의 정보를 자동으로 수집하는 방법입니다. 일반적으로 원하는 페이지의 HTML 코드를 가져와 필요한 데이터를 추출합니다. 다나와의 판매 실적 페이지를 탐색하고 데이터를 추출할 수 있습니다.

### CSV 형식

CSV는 데이터를 쉽고 효율적으로 저장할 수 있는 포맷입니다. 각 행은 하나의 데이터 레코드를 나타내며, 각 값은 쉼표로 구분됩니다. 추출한 판매 실적 데이터를 CSV 파일에 저장하면 데이터를 분석하고 사용할 때 유용합니다.

## 자동차 판매 실적 크롤링 모듈 구현하기

다나와의 자동차 판매 실적 데이터를 수집하기 위한 방법을 살펴보겠습니다.

### 1단계: 기본 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# 판매 실적 페이지 URL
url = 'http://example.com/sales'

# 웹 페이지 요청 및 HTML 파싱
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
```

이 코드는 requests를 사용하여 특정 URL에서 HTML 페이지를 가져오고, BeautifulSoup을 통해 HTML을 파싱하는 기본 크롤러의 구조를 설명합니다. 이 과정은 크롤링의 첫 단계를 나타냅니다.

### 2단계: 판매 실적 데이터 추출

```python
sales_data = []

# 테이블에서 데이터 추출
for row in soup.find_all('tr'):
    cols = row.find_all('td')
    if cols:
        brand = cols[0].get_text()
        sales = cols[1].get_text()
        sales_data.append({'브랜드': brand.strip(), '판매량': sales.strip()})
```

위 코드는 HTML 테이블에서 브랜드와 판매량 데이터를 추출하는 예를 보여줍니다. 여기서는 `find_all`을 통해 테이블 행과 열을 순회하며 데이터를 모읍니다.

### 3단계: 데이터 CSV 파일 저장

```python
import csv

# CSV 파일로 데이터 저장
with open('sales_data.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=['브랜드', '판매량'])
    writer.writeheader()
    writer.writerows(sales_data)
```

크롤링한 데이터를 CSV 파일로 저장합니다. 이를 통해 데이터를 쉽게 접근하고 여러 도구에서 활용할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 전체 과정을 이해하기 위한 단계별 설명입니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant CSV파일

  사용자 ->> 크롤러: URL 설정
  크롤러 ->> 웹사이트: 데이터 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> CSV파일: 가공한 데이터 저장
  사용자 -->> CSV파일: 실적 데이터 분석
```

크롤러가 웹사이트에 HTTP 요청을 보내고, HTML 응답에서 데이터를 추출 및 처리하여 CSV 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 자동차 판매 실적을 다나와 웹사이트에서 자동으로 수집하고 이를 CSV 형식으로 저장하는 방법을 알아보았습니다. 이러한 크롤링 모듈은 데이터 분석 및 비즈니스 전략 수립에 필수적인 요소입니다. 다음은 데이터베이스에 수집한 데이터를 효율적으로 저장하고 관리하는 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md) 입니다. 이를 통해 데이터 관리의 효율성을 더욱 높일 수 있습니다.
2025-06-29 20:34:41,471 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "데이터베이스 삽입 모듈". This is Chapter 9.

Concept Details (Note: Provided in Korean):
- Name: 데이터베이스 삽입 모듈
- Description:
CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 기능을 제공하는 모듈입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
---
# Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.
---
# Chapter 8: 자동차 판매 실적 크롤링 모듈

이전 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동차 관련 웹사이트에서 FAQ 데이터를 자동으로 수집하고 저장하는 방법을 배웠습니다. 이번 장에서는 `자동차 판매 실적 크롤링 모듈`을 구축하여 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하고, 이를 CSV 파일로 저장하는 방법을 알아보겠습니다.

## 동기 부여

자동차 판매 실적을 분석하는 것은 시장 동향을 파악하고, 신차 개발 및 판매 전략을 수립하는 데 중요한 역할을 합니다. 만약 특정 브랜드의 판매 실적이 급격히 증가했다면, 그 이유를 파악하여 다른 브랜드에도 적용할 수 있는 영감을 얻을 수 있습니다. 이때 매번 웹사이트를 방문해 수작업으로 데이터를 정리하는 대신, 크롤러를 사용하면 실적 데이터를 자동으로 수집 및 저장할 수 있습니다.

## 주요 개념

### 웹 크롤링

웹 크롤링은 특정 웹사이트의 정보를 자동으로 수집하는 방법입니다. 일반적으로 원하는 페이지의 HTML 코드를 가져와 필요한 데이터를 추출합니다. 다나와의 판매 실적 페이지를 탐색하고 데이터를 추출할 수 있습니다.

### CSV 형식

CSV는 데이터를 쉽고 효율적으로 저장할 수 있는 포맷입니다. 각 행은 하나의 데이터 레코드를 나타내며, 각 값은 쉼표로 구분됩니다. 추출한 판매 실적 데이터를 CSV 파일에 저장하면 데이터를 분석하고 사용할 때 유용합니다.

## 자동차 판매 실적 크롤링 모듈 구현하기

다나와의 자동차 판매 실적 데이터를 수집하기 위한 방법을 살펴보겠습니다.

### 1단계: 기본 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# 판매 실적 페이지 URL
url = 'http://example.com/sales'

# 웹 페이지 요청 및 HTML 파싱
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
```

이 코드는 requests를 사용하여 특정 URL에서 HTML 페이지를 가져오고, BeautifulSoup을 통해 HTML을 파싱하는 기본 크롤러의 구조를 설명합니다. 이 과정은 크롤링의 첫 단계를 나타냅니다.

### 2단계: 판매 실적 데이터 추출

```python
sales_data = []

# 테이블에서 데이터 추출
for row in soup.find_all('tr'):
    cols = row.find_all('td')
    if cols:
        brand = cols[0].get_text()
        sales = cols[1].get_text()
        sales_data.append({'브랜드': brand.strip(), '판매량': sales.strip()})
```

위 코드는 HTML 테이블에서 브랜드와 판매량 데이터를 추출하는 예를 보여줍니다. 여기서는 `find_all`을 통해 테이블 행과 열을 순회하며 데이터를 모읍니다.

### 3단계: 데이터 CSV 파일 저장

```python
import csv

# CSV 파일로 데이터 저장
with open('sales_data.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=['브랜드', '판매량'])
    writer.writeheader()
    writer.writerows(sales_data)
```

크롤링한 데이터를 CSV 파일로 저장합니다. 이를 통해 데이터를 쉽게 접근하고 여러 도구에서 활용할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 전체 과정을 이해하기 위한 단계별 설명입니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant CSV파일

  사용자 ->> 크롤러: URL 설정
  크롤러 ->> 웹사이트: 데이터 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> CSV파일: 가공한 데이터 저장
  사용자 -->> CSV파일: 실적 데이터 분석
```

크롤러가 웹사이트에 HTTP 요청을 보내고, HTML 응답에서 데이터를 추출 및 처리하여 CSV 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 자동차 판매 실적을 다나와 웹사이트에서 자동으로 수집하고 이를 CSV 형식으로 저장하는 방법을 알아보았습니다. 이러한 크롤링 모듈은 데이터 분석 및 비즈니스 전략 수립에 필수적인 요소입니다. 다음은 데이터베이스에 수집한 데이터를 효율적으로 저장하고 관리하는 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md) 입니다. 이를 통해 데이터 관리의 효율성을 더욱 높일 수 있습니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 9: 데이터베이스 삽입 모듈`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:34:41,474 - INFO - RESPONSE (from cache): # Chapter 9: 데이터베이스 삽입 모듈

이전 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 다나와 웹사이트에서 자동차 판매 실적 데이터를 수집하여 CSV 파일로 저장하는 방법을 배웠습니다. 이번 장에서는 `데이터베이스 삽입 모듈`을 구현하여 CSV 파일의 데이터를 MySQL 데이터베이스에 자동으로 업로드하는 방법을 알아보겠습니다.

## 동기 부여

현대의 많은 애플리케이션은 데이터를 보다 효율적이고 안정적으로 관리하기 위해 데이터베이스를 사용합니다. 특히 대량의 데이터를 처리할 때는 CSV 파일에 저장하는 것보다 데이터베이스에 저장하는 것이 효율적입니다. 이번 데이터베이스 삽입 모듈은 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입함으로써 데이터를 보다 구조적이고 신뢰성 있게 관리할 수 있도록 해줍니다.

## 주요 개념

### CSV 파일 처리

CSV 파일은 간단한 데이터 포맷이며 텍스트 데이터를 쉼표로 구분하여 저장합니다. 파이썬의 `csv` 모듈을 활용하면 CSV 파일의 데이터를 손쉽게 읽어올 수 있습니다.

### MySQL 데이터베이스 연결

MySQL 데이터베이스는 관계형 데이터베이스로, 대량의 데이터를 구조적으로 저장할 수 있게 해줍니다. 파이썬에서는 `MySQL Connector` 라이브러리를 사용하여 데이터베이스에 연결하고 데이터를 삽입할 수 있습니다.

## 데이터베이스 삽입 모듈 사용하기

이제 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 단계별로 살펴보겠습니다.

### 1단계: CSV 파일 읽기

```python
import csv

# CSV 파일 읽기
data = []
with open('sales_data.csv', mode='r', encoding='utf-8') as file:
    reader = csv.DictReader(file)
    for row in reader:
        data.append(row)
```

이 코드에서는 `csv.DictReader`를 사용하여 CSV 파일의 데이터를 읽어 목록에 저장합니다. 각 행은 딕셔너리로 변환되어 `data` 리스트에 추가됩니다.

### 2단계: 데이터베이스 연결 및 데이터 삽입

```python
import mysql.connector

# 데이터베이스 연결 설정
connection = mysql.connector.connect(
    host='localhost',
    user='user',
    password='password',
    database='car_sales_db'
)

cursor = connection.cursor()

# 데이터 삽입
for entry in data:
    sql = "INSERT INTO sales (brand, sales) VALUES (%s, %s)"
    cursor.execute(sql, (entry['브랜드'], entry['판매량']))

# 변경사항 저장
connection.commit()
```

위 코드에서는 `mysql.connector`를 사용하여 MySQL 데이터베이스에 연결한 후, 각 데이터 항목을 반복적으로 삽입합니다. 삽입 문법 `INSERT INTO`를 통해 데이터베이스에 데이터를 추가합니다. 마지막으로, `commit` 메서드로 변경 사항을 저장합니다.

## 내부 구현 이해

데이터베이스 삽입 모듈이 어떻게 작동하는지 이해하기 쉽게 시퀀스 다이어그램으로 설명하겠습니다.

```mermaid
sequenceDiagram
  participant User
  participant CSV파일
  participant Python프로그램
  participant MySQLDB

  User ->> Python프로그램: CSV 파일 읽기 요청
  Python프로그램 ->> CSV파일: 데이터 읽기
  CSV파일 -->> Python프로그램: 데이터 반환
  Python프로그램 ->> MySQLDB: 데이터베이스에 데이터 삽입
  MySQLDB -->> Python프로그램: 삽입 완료
  Python프로그램 -->> User: 완료 메시지 제공
```

이 다이어그램은 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 과정을 확인할 수 있습니다.

## 결론

이번 장에서는 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 배웠습니다. 이를 통해 데이터를 보다 구조적으로 관리하고 활용할 수 있습니다. 다음 [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)에서는 데이터베이스 연결 설정에 대해 더욱 상세히 알아보겠습니다. 데이터베이스와의 원활한 연결은 안정적인 데이터 처리에 필수적입니다. 

---

이번 과정을 통해 데이터베이스 활용 능력이 한 단계 업그레이드될 것입니다. 지속적인 실습을 통해 데이터 관리자 및 개발자로서의 역량을 키워보세요!
2025-06-29 20:34:41,474 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "데이터베이스 연결 설정". This is Chapter 10.

Concept Details (Note: Provided in Korean):
- Name: 데이터베이스 연결 설정
- Description:
MySQL 데이터베이스에 연결하기 위한 설정 및 쿼리를 실행하여 데이터를 가져오는 기능을 제공합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
---
# Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.
---
# Chapter 8: 자동차 판매 실적 크롤링 모듈

이전 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동차 관련 웹사이트에서 FAQ 데이터를 자동으로 수집하고 저장하는 방법을 배웠습니다. 이번 장에서는 `자동차 판매 실적 크롤링 모듈`을 구축하여 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하고, 이를 CSV 파일로 저장하는 방법을 알아보겠습니다.

## 동기 부여

자동차 판매 실적을 분석하는 것은 시장 동향을 파악하고, 신차 개발 및 판매 전략을 수립하는 데 중요한 역할을 합니다. 만약 특정 브랜드의 판매 실적이 급격히 증가했다면, 그 이유를 파악하여 다른 브랜드에도 적용할 수 있는 영감을 얻을 수 있습니다. 이때 매번 웹사이트를 방문해 수작업으로 데이터를 정리하는 대신, 크롤러를 사용하면 실적 데이터를 자동으로 수집 및 저장할 수 있습니다.

## 주요 개념

### 웹 크롤링

웹 크롤링은 특정 웹사이트의 정보를 자동으로 수집하는 방법입니다. 일반적으로 원하는 페이지의 HTML 코드를 가져와 필요한 데이터를 추출합니다. 다나와의 판매 실적 페이지를 탐색하고 데이터를 추출할 수 있습니다.

### CSV 형식

CSV는 데이터를 쉽고 효율적으로 저장할 수 있는 포맷입니다. 각 행은 하나의 데이터 레코드를 나타내며, 각 값은 쉼표로 구분됩니다. 추출한 판매 실적 데이터를 CSV 파일에 저장하면 데이터를 분석하고 사용할 때 유용합니다.

## 자동차 판매 실적 크롤링 모듈 구현하기

다나와의 자동차 판매 실적 데이터를 수집하기 위한 방법을 살펴보겠습니다.

### 1단계: 기본 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# 판매 실적 페이지 URL
url = 'http://example.com/sales'

# 웹 페이지 요청 및 HTML 파싱
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
```

이 코드는 requests를 사용하여 특정 URL에서 HTML 페이지를 가져오고, BeautifulSoup을 통해 HTML을 파싱하는 기본 크롤러의 구조를 설명합니다. 이 과정은 크롤링의 첫 단계를 나타냅니다.

### 2단계: 판매 실적 데이터 추출

```python
sales_data = []

# 테이블에서 데이터 추출
for row in soup.find_all('tr'):
    cols = row.find_all('td')
    if cols:
        brand = cols[0].get_text()
        sales = cols[1].get_text()
        sales_data.append({'브랜드': brand.strip(), '판매량': sales.strip()})
```

위 코드는 HTML 테이블에서 브랜드와 판매량 데이터를 추출하는 예를 보여줍니다. 여기서는 `find_all`을 통해 테이블 행과 열을 순회하며 데이터를 모읍니다.

### 3단계: 데이터 CSV 파일 저장

```python
import csv

# CSV 파일로 데이터 저장
with open('sales_data.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=['브랜드', '판매량'])
    writer.writeheader()
    writer.writerows(sales_data)
```

크롤링한 데이터를 CSV 파일로 저장합니다. 이를 통해 데이터를 쉽게 접근하고 여러 도구에서 활용할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 전체 과정을 이해하기 위한 단계별 설명입니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant CSV파일

  사용자 ->> 크롤러: URL 설정
  크롤러 ->> 웹사이트: 데이터 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> CSV파일: 가공한 데이터 저장
  사용자 -->> CSV파일: 실적 데이터 분석
```

크롤러가 웹사이트에 HTTP 요청을 보내고, HTML 응답에서 데이터를 추출 및 처리하여 CSV 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 자동차 판매 실적을 다나와 웹사이트에서 자동으로 수집하고 이를 CSV 형식으로 저장하는 방법을 알아보았습니다. 이러한 크롤링 모듈은 데이터 분석 및 비즈니스 전략 수립에 필수적인 요소입니다. 다음은 데이터베이스에 수집한 데이터를 효율적으로 저장하고 관리하는 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md) 입니다. 이를 통해 데이터 관리의 효율성을 더욱 높일 수 있습니다.
---
# Chapter 9: 데이터베이스 삽입 모듈

이전 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 다나와 웹사이트에서 자동차 판매 실적 데이터를 수집하여 CSV 파일로 저장하는 방법을 배웠습니다. 이번 장에서는 `데이터베이스 삽입 모듈`을 구현하여 CSV 파일의 데이터를 MySQL 데이터베이스에 자동으로 업로드하는 방법을 알아보겠습니다.

## 동기 부여

현대의 많은 애플리케이션은 데이터를 보다 효율적이고 안정적으로 관리하기 위해 데이터베이스를 사용합니다. 특히 대량의 데이터를 처리할 때는 CSV 파일에 저장하는 것보다 데이터베이스에 저장하는 것이 효율적입니다. 이번 데이터베이스 삽입 모듈은 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입함으로써 데이터를 보다 구조적이고 신뢰성 있게 관리할 수 있도록 해줍니다.

## 주요 개념

### CSV 파일 처리

CSV 파일은 간단한 데이터 포맷이며 텍스트 데이터를 쉼표로 구분하여 저장합니다. 파이썬의 `csv` 모듈을 활용하면 CSV 파일의 데이터를 손쉽게 읽어올 수 있습니다.

### MySQL 데이터베이스 연결

MySQL 데이터베이스는 관계형 데이터베이스로, 대량의 데이터를 구조적으로 저장할 수 있게 해줍니다. 파이썬에서는 `MySQL Connector` 라이브러리를 사용하여 데이터베이스에 연결하고 데이터를 삽입할 수 있습니다.

## 데이터베이스 삽입 모듈 사용하기

이제 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 단계별로 살펴보겠습니다.

### 1단계: CSV 파일 읽기

```python
import csv

# CSV 파일 읽기
data = []
with open('sales_data.csv', mode='r', encoding='utf-8') as file:
    reader = csv.DictReader(file)
    for row in reader:
        data.append(row)
```

이 코드에서는 `csv.DictReader`를 사용하여 CSV 파일의 데이터를 읽어 목록에 저장합니다. 각 행은 딕셔너리로 변환되어 `data` 리스트에 추가됩니다.

### 2단계: 데이터베이스 연결 및 데이터 삽입

```python
import mysql.connector

# 데이터베이스 연결 설정
connection = mysql.connector.connect(
    host='localhost',
    user='user',
    password='password',
    database='car_sales_db'
)

cursor = connection.cursor()

# 데이터 삽입
for entry in data:
    sql = "INSERT INTO sales (brand, sales) VALUES (%s, %s)"
    cursor.execute(sql, (entry['브랜드'], entry['판매량']))

# 변경사항 저장
connection.commit()
```

위 코드에서는 `mysql.connector`를 사용하여 MySQL 데이터베이스에 연결한 후, 각 데이터 항목을 반복적으로 삽입합니다. 삽입 문법 `INSERT INTO`를 통해 데이터베이스에 데이터를 추가합니다. 마지막으로, `commit` 메서드로 변경 사항을 저장합니다.

## 내부 구현 이해

데이터베이스 삽입 모듈이 어떻게 작동하는지 이해하기 쉽게 시퀀스 다이어그램으로 설명하겠습니다.

```mermaid
sequenceDiagram
  participant User
  participant CSV파일
  participant Python프로그램
  participant MySQLDB

  User ->> Python프로그램: CSV 파일 읽기 요청
  Python프로그램 ->> CSV파일: 데이터 읽기
  CSV파일 -->> Python프로그램: 데이터 반환
  Python프로그램 ->> MySQLDB: 데이터베이스에 데이터 삽입
  MySQLDB -->> Python프로그램: 삽입 완료
  Python프로그램 -->> User: 완료 메시지 제공
```

이 다이어그램은 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 과정을 확인할 수 있습니다.

## 결론

이번 장에서는 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 배웠습니다. 이를 통해 데이터를 보다 구조적으로 관리하고 활용할 수 있습니다. 다음 [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)에서는 데이터베이스 연결 설정에 대해 더욱 상세히 알아보겠습니다. 데이터베이스와의 원활한 연결은 안정적인 데이터 처리에 필수적입니다. 

---

이번 과정을 통해 데이터베이스 활용 능력이 한 단계 업그레이드될 것입니다. 지속적인 실습을 통해 데이터 관리자 및 개발자로서의 역량을 키워보세요!

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 10: 데이터베이스 연결 설정`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:34:41,477 - INFO - RESPONSE (from cache): # 제10장: 데이터베이스 연결 설정

이전 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)에서 우리는 CSV 파일로부터 읽은 데이터를 MySQL 데이터베이스에 삽입하는 방법을 배웠습니다. 이번 장에서는 `데이터베이스 연결 설정`에 대해 자세히 알아보겠습니다. 이는 MySQL 데이터베이스와의 안정적인 연결을 위해 반드시 필요한 설정입니다.

## 동기 부여

데이터를 효과적으로 관리하기 위해서는 데이터베이스와의 연결이 매우 중요합니다. 데이터베이스 연결 설정이 제대로 되어 있지 않으면 데이터를 저장하거나 불러올 때 문제가 발생할 수 있습니다. 예를 들어, 자동차 판매 실적 데이터를 분석하고자 할 때 MySQL 데이터베이스에 연결할 수 없거나 연결이 불안정하면 분석에 차질이 생깁니다. 안정적인 데이터베이스 연결을 위해 필요한 주요 설정과 절차를 배워봅시다.

## 주요 개념

### MySQL 데이터베이스 서버

MySQL은 인기 있는 오픈 소스 데이터베이스 관리 시스템으로, 데이터를 효율적으로 저장하고 검색할 수 있습니다. 이를 활용하기 위해서는 데이터베이스 서버와의 연결을 적절히 설정해야 합니다.

### 연결 문자열

연결 문자열은 데이터베이스 서버의 주소, 사용자 이름, 비밀번호 등 연결에 필요한 정보를 포함합니다. Python의 `mysql.connector` 라이브러리를 통해 MySQL에 연결할 수 있습니다. 이를 통해 원하는 데이터를 가져오거나 저장할 수 있습니다.

## 데이터베이스 연결 설정

데이터베이스 연결을 설정하는 방법을 단계적으로 살펴보겠습니다.

### 1단계: MySQL Connector 설치

먼저 MySQL Connector를 설치해야 합니다. 터미널이나 커맨드 라인에서 다음 명령어를 사용하세요.

```bash
pip install mysql-connector-python
```

이 명령어를 실행하면 MySQL 데이터베이스와의 연결을 위한 라이브러리가 설치됩니다.

### 2단계: 데이터베이스 연결 설정 코드

MySQL에 연결하려면 다음과 같이 연결 설정을 할 수 있습니다.

```python
import mysql.connector

# MySQL 데이터베이스에 연결
connection = mysql.connector.connect(
    host='localhost',     # 데이터베이스 서버 주소
    user='user',          # 사용자 이름
    password='password',  # 비밀번호
    database='my_database' # 사용할 데이터베이스 이름
)

# 연결 확인
if connection.is_connected():
    print("연결 성공!")
```

이 코드는 MySQL 데이터베이스와의 연결을 설정하는 가장 기본적인 방법입니다. 데이터베이스 서버 주소, 사용자 이름, 비밀번호, 데이터베이스 이름을 올바르게 입력하면 됩니다.

### 내부 작동 방식 이해

데이터베이스 연결의 내부 작동 방식을 이해하는 것은 중요합니다. 다음은 연결 설정이 이루어지는 과정을 설명합니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant Python프로그램
  participant MySQLDB

  사용자 ->> Python프로그램: 연결 설정 요청
  Python프로그램 ->> MySQLDB: 연결 시도
  MySQLDB -->> Python프로그램: 연결 승인
  Python프로그램 -->> 사용자: 연결 성공 메시지
```

이 다이어그램은 사용자로부터 연결 설정 요청을 받아, Python 프로그램이 MySQL 데이터베이스에 연결을 시도하고, 연결 여부를 사용자에게 알리는 과정을 보여줍니다.

## 결론

이번 장에서는 MySQL 데이터베이스와의 연결을 설정하는 방법에 대해 학습했습니다. MySQL Connector를 설치하고, 필요한 정보를 사용하여 연결을 설정하였습니다. 안정적인 연결 설정을 통해 데이터를 보다 효율적으로 관리할 수 있습니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md) 장에서는 데이터를 효율적으로 탐색할 수 있는 검색 및 페이지네이션 기능을 구현하는 방법을 배워보겠습니다.

데이터베이스 활용의 기초를 다지며 계속해서 발전해 나가시길 바랍니다!
2025-06-29 20:35:32,768 - INFO - PROMPT: 
Analyze the following codebase for the project 'SKN10-1st-4Team'.

Available files (total 11):
- 0 # 1_연도별_자동차_등록_현황.py
- 1 # README.md
- 2 # common/insert_data.py
- 3 # common/insert_data_city.py
- 4 # crawling/danawa.py
- 5 # crawling/genesis_faq.py
- 6 # crawling/hyundai_faq.py
- 7 # crawling/kia_faq.py
- 8 # pages/2_지역별_자동차_등록_현황.py
- 9 # pages/3_브랜드별_자동차_판매_현황.py
- 10 # pages/4_주요_3개_기업_차량_구매_FAQ.py

Full context of all files:
--- File Index 0: 1_연도별_자동차_등록_현황.py ---
#test
import streamlit as st
import pandas as pd
import plotly.express as px
import pymysql
from common.insert_data import insert_data
from common.insert_data_city import insert_data_city

insert_data()
insert_data_city()

st.set_page_config(layout="centered")

st.title("📊 연도별 자동차 등록 현황")
st.divider()

# 데이터베이스 연결 설정
connection = pymysql.connect(
    host="localhost",
    user="SKN10_4team",
    password="skn1234",
    database="SKN10_4team_1st",
    charset="utf8"
)

# SQL 데이터 가져오기
year_data = "select Year FROM Car"
ef = pd.read_sql(year_data, connection)

car_data = """
SELECT Year, SUM(CarCount) YearofCar
FROM SKN10_4team_1st.Car
GROUP BY Year
ORDER BY Year;
"""
cf = pd.read_sql(car_data, connection)

# Streamlit 컨테이너
with st.container():
    # 컬럼 레이아웃 사용
    col1, col2 = st.columns(2)
    # 년도 리스트 생성 및 선택
    years = ef['Year'].unique().tolist()

    # 디폴트 값 설정
    default_start_year_index = 0  # 첫 번째 연도를 디폴트로 설정
    default_end_year_index = len(years) - 1  # 마지막 연도를 디폴트로 설정

    with col1:
        start_year = st.selectbox(
            '첫번째 년도를 선택해주세요.', 
            years, 
            index=default_start_year_index
        )

    with col2:
        end_year = st.selectbox(
            '마지막 년도를 선택해주세요.', 
            years, 
            index=default_end_year_index
        )

# 연도 범위 확인 및 데이터 필터링
if start_year > end_year:
    st.error("Error: The start year cannot be greater than the end year.")
else:
    with st.container():
        # 사용자 입력 값으로 데이터 필터링
        filtered_data = cf[(cf["Year"] >= start_year) & (cf["Year"] <= end_year)]

        # Plotly로 그래프 생성
        fig = px.bar(
            filtered_data, 
            x="Year", 
            y="YearofCar", 
            title="조회결과"
        )

        # axis title 업데이트
        fig.update_xaxes(title_text="연도")
        fig.update_yaxes(title_text="차량 수 (만대)")

        # 그래프 출력
        st.plotly_chart(fig)

}]}

--- File Index 1: README.md ---
# SKN10-1st-4Team
<br/>

![](https://cdn.imweb.me/upload/S20240314bd10436a7991a/41a9769cc44e6.png)
<br/>
<br/>

## ⭐ 프로젝트 팀
<br/>

| 좌민서 | 김민혜 | 박예슬 | 신민주 | 홍승표 | 황인호 |
| :---: | :---: | :---: | :---: | :---: | :---: |
| - 팀장<br/>- 지역별 자동차 등록 현황<br/>(그래프) | - ERD 설계<br/>- DB 구현 | - ERD 설계<br/>- 현대자동차 FAQ | - 화면 설계<br/>- 제네시스 FAQ | - 라이브러리 조사<br/>- 연도별 자동차 등록 현황 | - 화면 설계<br/>- 기아자동차 FAQ<br/>- 지역별 자동차 등록 현황<br/>(지도)<br/>- 브랜드별 자동차 판매 현황
| [@INe](https://github.com/INe904) | [@kkminhye](https://github.com/kkminhye) | [@yeseulnim](https://github.com/yeseulnim) | [@sinminju](https://github.com/sinminju) | [@redwin02](https://github.com/redwin-02) | [@HIHO9999](https://github.com/HIHO999) |
<br/>

## 📌 프로젝트 개요
<br/>

### 프로젝트 주제
<br/>

**전국 자동차 등록 현황 및 기업 FAQ 조회 시스템**
<br/>
<br/>

### 프로젝트 목적
<br/>

1. 전국 자동차 등록 현황을 연도별 및 지역별로 분석하여, **자동차 증가 추세와 지역별 특성을 파악**한다. 이를 통해 **교통 정책 수립 및 지역 발전 전략**에 기여할 수 있는 정보를 제공한다.
<br/>

2. 국내 브랜드별 자동차 구매통계 및 3대 자동차 기업의 차량구매 관련 FAQ 정보를 한 곳에 모아, **자동차 구매 예정 소비자에게 필요한 정보**를 제공한다.
<br/>
<br/>

### 프로젝트 필요성
<br/>

1. 자동차 등록 현황은 도시 교통 문제, 환경 정책, 도로 인프라 계획 등과 밀접하게 연관되어 있다.
<br/>

2. 연도별 및 지역별 자동차 등록 현황 데이터를 시각화하여, 공공 및 민간 부분에서 데이터 기반 정책 결정을 지원한다.
<br/>

3. 자동차 구매를 고려하는 소비자는 브랜드별 차량 등록 현황과 차량 구매 관련 정보를 한눈에 확인하기 어려운 경우가 많다. 국내 브랜드별 자동차 구매 통계와 주요 자동차 기업의 FAQ 정보를 통합 제공함으로써, 소비자들이 보다 신속하고 정확한 의사 결정을 할 수 있도록 돕는다.
<br/>

### 프로젝트 내용
<br/>

 1. **데이터 수집 및 가공**
<br/>

- <b>[지표누리](https://www.index.go.kr/unity/potal/main/EachDtlPageDetail.do?idx_cd=1257)</b>에서 제공하는 연도별 및 지역별 자동차 등록 현황 데이터를 수집하여 목적에 맞게 가공한 후, 데이터베이스에 저장한다.
<br/>

- 국내 판매율이 가장 높은 주요 3개 자동차 회사(<b>[현대](https://www.hyundai.com/kr/ko/e/customer/center/faq)</b>, <b>[기아](https://www.kia.com/kr/customer-service/center/faq)</b>, <b>[제네시스](https://www.genesis.com/kr/ko/support/faq.html)</b>)의 차량 구매 FAQ를 Selenium을 이용하여 크롤링한 뒤 JSON 파일로 저장한다.
<br/>

- 다나와의 <b>[자동차 판매 실적](https://auto.danawa.com/auto/?Work=record&pcUse=y)</b> 페이지에서 제공하는 브랜드별 자동차 판매 실적을 Selenium을 이용하여 크롤링한 뒤 CSV 파일로 저장한다.

<br/>

2. **데이터 시각화**
<br/>

- 수집한 자동차 통계 관련 데이터를 Python의 **Plotly**, **MatPlotLib** 및 **Folium** 라이브러리를 통해 시각화한다.
<br/>

3. **FAQ 제공**
<br/>

- 크롤링한 주요 자동차 브랜드의 FAQ 내용을 한곳에 모아, 검색 기능과 함께 제공한다.
<br/>

### 프로젝트 기대 효과
<br/>

1. **연도별 및 지역별 자동차 등록 현황의 시각적 자료**를 제공하여 데이터를 직관적으로 파악할 수 있다.
<br/>

2. **교통 및 환경 정책 수립**을 위한 기초 데이터를 제공한다.
<br/>

3. **브랜드별 차량 판매량** 및 **기업 FAQ 조회 시스템**을 통해 소비자의 정보 접근성을 높인다.
<br/>
<br/>

## 📌 설치/사용 방법
<br/>

### 1. GitHub에서 Repository Clone
<br/>

```python
    git clone https://github.com/SKNETWORKS-FAMILY-AICAMP/SKN10-1st-4Team.git
```
<br/>

### 2. 라이브러리 설치
<br/>

```python
    pip install -r requirements.txt
```
<br/>

### 3. 데이터베이스 구축
DBeaver 실행 후, 계정생성 권한 있는 계정에서 sql\create_tables.sql 파일의 코드 실행
<br/>

### 4. (생략 가능) 정보 수집 - 웹 크롤링 코드 실행
<br/>

※ 웹 크롤링 결과물은 data 폴더에 json 파일로 저장되어 있으므로, 별도의 크롤링 없이 바로 실행이 가능하다. 다만, 신규 데이터 확인을 위해 웹 크롤링이 필요한 경우 아래 코드를 사용할 수 있다.
<br/>

```python
    python crawling/kia_faq.py
```
```python
    python crawling/hyundai_faq.py
```
```python
    python crawling/genesis_faq.py
```
```python
    python crawling/danawa.py
```
<br/>

### 5. 서비스 실행
<br/>

```python
    streamlit run 1_연도별_자동차_등록_현황.py
```
<br/>
<br/>

## 📌 기술 스택
<br/>

### 화면 설계
<br/>

![](https://img.shields.io/badge/Figma-F24E1E?style=for-the-badge&logo=figma&logoColor=white)
<br/>

### 데이터 가공 및 처리
<br/>

![](https://img.shields.io/badge/MySQL-4479A1?style=for-the-badge&logo=mysql&logoColor=white) &nbsp; ![](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=white)
<br/>

### 화면 구현
<br/>

![](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=white) &nbsp; ![](https://img.shields.io/badge/streamlit-FF0000?style=for-the-badge&logo=streamlit&logoColor=white)
<br/>

### 버전 관리 및 협업
<br/>

![](https://img.shields.io/badge/github-000000?style=for-the-badge&logo=github&logoColor=white)
<br/>
<br/>

## 💻 화면 설계
<br/>

### 0. 메뉴
<br/>

![](/images/menu_design.png)
<br/>

### 1. 연도별 자동차 등록 현황
<br/>

![](/images/year_design.png)
<br/>

### 2. 지역별 자동차 등록 현황
<br/>

![](/images/region_design.png)
<br/>

### 3. 주요 3개 기업 차량 구매 FAQ
<br/>

![](/images/faq_design.png)
<br/>
<br/>

## 💻 데이터 가공 및 처리
<br/>

### ERD
<br/>

![](/images/erd.png)
<br/>
<br/>

### 실제 데이터 가공 및 처리

1. **자동차 등록 현황**
<br/>

- 자료 출처 : <b>[지표누리 자동차 등록 현황](https://www.index.go.kr/unity/potal/main/EachDtlPageDetail.do?idx_cd=1257)</b> (*2012 ~ 2022)
<br/>

- 자료 가공 : 개별 Excel 파일 다운로드 -> CSV로 변경 -> MySQL 데이터베이스 테이블로 저장
<br/>

2. **주요 3개 기업 차량 구매 FAQ**
<br/>

- 자료 출처 : 국내 3대 자동차 기업 (<b>[현대](https://www.hyundai.com/kr/ko/e/customer/center/faq)</b>, <b>[기아](https://www.kia.com/kr/customer-service/center/faq)</b>, <b>[제네시스](https://www.genesis.com/kr/ko/support/faq.html)</b>) 홈페이지 'FAQ' 중 '차량 구매' 항목
<br/>

- 자료 가공 : Selenium으로 웹크롤링 -> JSON으로 저장 
<br/>

3. **브랜드별 자동차 판매 실적**
<br/>

- 자료 출처 : 다나와 <b>[자동차 판매 실적](https://auto.danawa.com/auto/?Work=record&pcUse=y)</b> 페이지 (*2021.01 ~ 2024.12)
<br/>

- 자료 가공 : Selenium으로 웹크롤링 -> CSV로 저장
<br/>
<br/>

## 📌 프로젝트 최종 결과
<br/>

### 1. 연도별 자동차 등록 현황
<br/>

![](/images/final_screen1.png)
<br/>

### 2. 지역별 자동차 등록 현황
<br/>

![](/images/final_screen2.png)
<br/>

![](/images/final_screen3.png)
<br/>

### 3. 주요 3개 기업 차량 구매 FAQ
<br/>

![](/images/final_screen4.png)
<br/>

### 4. 브랜드별 자동차 판매 순위
<br/>

![](/images/final_screen5.png)
<br/>
<br/>

## 🖥️개발과정에서 발생한 이슈 및 해결방법
<br/>

### 1. SQL DB 구축
<br/>

**문제**
<br/>

MySQL DB는 깃헙으로 동기화되지 않고 각 인원이 각자 구축해야 했기에 그 과정에서 시행착오가 있었음.
<br/>

**해결**
<br/>

실수방지를 위해 최종 코드에서는 DB및 테이블 생성 SQL코드를 별도파일로 두고, 테이블 내용 생성은 함수로 만들어 자동 실행되도록 함.
<br/>

### 2. 복잡한 SQL 저장 구조
<br/>

**문제**
<br/>

최초 기획한 ERD 구조에는 FAQ가 포함되어 있었으나, 실제 구현시 FAQ를 별도 JSON 파일에 담고 그를 MySQL 테이블로 만든뒤 이를 불러오는 과정이 비효율적이라 판단되었음. 
<br/>

**해결**
<br/>

ERD구조를 수정하여 FAQ를 ERD에서 빼고, FAQ페이지의 내용은 JSON파일에서 바로 불러오기로 함.
<br/>

### 3. 기능구현 완료후 오류 발생
<br/>

**문제**
<br/>

'현대차 FAQ' 페이지에서 검색기능 이용시, 검색결과가 없을 경우, '기아차 FAQ' 등 다른 탭으로 이동하면 탭의 내용이 나타나지 않는 버그 발생
<br/>

**해결**
<br/>

AI의 디버깅 보조를 이용, 코드를 수정하여 해결함.
<br/>
<br/>

## ✍️팀원별 느낀점
<br/>

### 좌민서
<br/>

지금까지 배운 내용을 바탕으로 응용된 내용을 활용할 수 있었던 좋은 기회가 되었습니다. 어쩌다 보니 이번에 팀장을 맡게 되었는데 많이 부족함에도 불구하고 팀원분들이 잘 따라와 주시고 도와주셔서 이번 프로젝트를 무사히 마칠 수 있었던 것 같습니다.

<br/>

### 신민주
<br/>

체계적인 프로젝트를 처음 진행해봤는데 팀워크의 중요성을 느꼈습니다. 제가 부족한 부분이 많았지만 다들 친절히 알려주셔서 배우면서 프로젝트에 참여할 수 있었습니다. 앞으로의 활동에도 좋은 경험이 될 것 같습니다.

<br/>

### 박예슬
<br/>

다인 프로젝트 깃 관리의 어려움과 중요성을 체감했습니다. 고생하신 팀장님과 팀원들에게 박수를 보냅니다.

<br/>

### 김민혜
<br/>

팀장을 맡으신 민서님이 프로젝트 전반적인 과정을 꼼꼼하게 정리하고 원할하게 진행해주셨다고 생각합니다. 각 팀원이 맡은 역할에 충실할 뿐만 아니라 가진 역량을 빛내고 서로 도와 문제를 해결하는 과정을 경험할 수 있어서 정말 좋았습니다.

<br/>

### 황인호
<br/>

팀프로젝트를  제대로 수행해본적이 처음이었지만 팀장분께서 역할분담 잘해주셔서 맡은바 열심히 그리고 만족스럽게 수행한것같습니다. 앞으로의 협력 업무에 있어서 좋은 경험이 되었습니다.

<br/>

### 홍승표
<br/>

저는 사람이 아닙니다. 몽키입니다. 아닙니다. 코드도 못치니 그냥 몽키입니다. 열심히 배워서 코드몽키라도 될 수 있도록 노력하겠습니다. 그리고 능력자이신 팀원분들을 만나 너무 좋았습니다. 몽키 한 마리 만나서 고생한 팀원들에게 너무 고맙고 다음 프로젝트때는 버스 타기실 기도하겠습니다. 
<br/>


--- File Index 2: common/insert_data.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "Car.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "Car"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (Year, CityID, CarCount) VALUES (%s, %s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[2], row[3])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File Index 3: common/insert_data_city.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data_city():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "City.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "City"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (CityID, CityName) VALUES (%s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[1])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File Index 4: crawling/danawa.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By


import pandas as pd
import time

# 크롬 드라이버 설정

driver = webdriver.Chrome()

# 데이터 저장 리스트
domestic_data = []
foreign_data = []

# 2021년 1월부터 2024년 12월까지의 URL 생성 및 데이터 크롤링
for year in range(2021, 2025):
    for month in range(1, 13):
        if year == 2024 and month > 12:
            break
        month_str = f"{year}-{month:02d}-00"
        url = f"https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month={month_str}&MonthTo="
        driver.get(url)
        time.sleep(0.5)  # 페이지 로딩 대기

        # 국산차 순위 데이터 크롤링
        rank_elements = driver.find_elements(By.CSS_SELECTOR, "ul.sideRankR li")

        for index, rank_element in enumerate(rank_elements):
            rank = rank_element.find_element(By.CSS_SELECTOR, "span.rank").text
            brand = rank_element.find_element(By.CSS_SELECTOR, "span.title").text.strip()
            sales = rank_element.find_element(By.CSS_SELECTOR, "span.sales").text
            rate = rank_element.find_element(By.CSS_SELECTOR, "span.rate").text
            logo_img = rank_element.find_element(By.CSS_SELECTOR, "span.title img").get_attribute("src")
            data = [year, month, rank, brand, sales, rate, logo_img]
            if index < 6:
                domestic_data.append(data)
            else:
                foreign_data.append(data)

# 데이터프레임으로 변환
domestic_df = pd.DataFrame(domestic_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])
foreign_df = pd.DataFrame(foreign_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])

# 데이터프레임 저장
domestic_df.to_csv("data\국산차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')
foreign_df.to_csv("data\해외차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')

# 드라이버 종료
driver.quit()

print("크롤링 완료 및 데이터 저장 완료")
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo=
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo= 에서 2021-01은 21년 1월 데이터를 받아온다는 의미


--- File Index 5: crawling/genesis_faq.py ---

# 제네시스 크롤링
from selenium import webdriver
from bs4 import BeautifulSoup
import json

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.genesis.com/kr/ko/support/faq/vehicle-purchase.html?anchorID=faq_tab"
driver.get(url)

# 페이지 소스 가져오기
html_source = driver.page_source

# HTML 파일로 저장
#with open("genesis_faq.html", "w", encoding="utf-8") as file:
#    file.write(html_source)

# 드라이버 종료
driver.quit()

# BeautifulSoup을 사용하여 페이지 소스 파싱
soup = BeautifulSoup(html_source, 'html.parser')

# FAQ 질문과 답변 추출
faqs = []
faq_items = soup.select('.cp-faq__accordion-item')  # FAQ 항목을 감싸는 클래스 이름을 사용하여 선택

for item in faq_items:
    question = item.select_one('.accordion-title').get_text(strip=True)
    answer = item.select_one('.accordion-panel-inner').get_text(strip=True)
    faqs.append({'question': question, 'answer': answer})

# 추출한 FAQ를 파일로 저장
with open("data\genesis_faq.json", "w", encoding="utf-8") as file:
    json.dump(faqs, file, ensure_ascii=False, indent=4)

--- File Index 6: crawling/hyundai_faq.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from time import sleep

#import pandas as pd
import json


URL = "https://www.hyundai.com/kr/ko/e/customer/center/faq"

driver = webdriver.Chrome()
driver.get(URL)
# 리스트에 딕셔너리로 내용 저장
qna_list = []

for page_id in range(4):
    for question_id in range(1,11):
        try:
            #엘리먼트 찾기
            faq_list = driver.find_element(By.CSS_SELECTOR, "div[data-v-28d34f54].list-wrap")

            try:
                # 플로팅 메뉴 제거
                floating_menu = driver.find_element(By.CSS_SELECTOR, "div[data-v-1ea4ba2d].inner_wrap")
                driver.execute_script("arguments[0].remove();", floating_menu)
            except:
                pass
            faq_title = faq_list.find_elements(By.CSS_SELECTOR,f"div[data-id='{question_id}'] button.list-title")
            driver.execute_script("arguments[0].scrollIntoView({block:'center'});",faq_title[0])
            sleep(0.5)

            #질문타이틀 클릭하기
            faq_title[0].click()
            sleep(0.5)

            #질문타이틀 텍스트 받아오기
            faq_question = faq_title[0].find_element(By.CSS_SELECTOR, "span.list-content[data-v-28d34f54]")
            faq_question_text = faq_question.text
            #print(faq_question_text)

            #질문답변 텍스트 받아오기
            faq_answer = driver.find_element(By.CLASS_NAME, "conts")
            faq_answer_text = faq_answer.text
            #print("전체 답변:", faq_answer_text)

            # 링크 URL 가져오기
            try:
                link_whole = faq_answer.find_elements(By.TAG_NAME, "a")
                link = {
                    "url" : link_whole[0].get_attribute("href"),
                    "text" : link_whole[0].text
                    }
            except:
                link = ""
            #print("링크 URL:", url)
            
            qna_list.append({"question": faq_question_text, "answer": faq_answer_text, "link": link})

        except TimeoutException:
            print("Timed out waiting for page to load")
        except NoSuchElementException:
            print("Could not find the element")
        except IndexError:
            pass

    next_button = driver.find_element(By.CSS_SELECTOR, "button.btn-next")
    next_button.click()
    sleep(1)
 
#qna_df = pd.DataFrame(qna_list, columns = ["page_num","question_num","question","answer","link"])
#qna_df.to_csv(path_or_buf="data/hyundai_qna.csv")

# 결과를 JSON 파일로 저장
with open("data\hyundai_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(qna_list, json_file, ensure_ascii=False, indent=4)

--- File Index 7: crawling/kia_faq.py ---
import json
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.kia.com/kr/customer-service/center/faq"
driver.get(url)

# 페이지가 완전히 로드될 때까지 대기
WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, "body")))

# "TOP 10" 버튼 클릭
top_10_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//button[contains(text(), 'TOP 10')]"))
)
top_10_button.click()

# "차량 구매" 버튼 클릭
car_purchase_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//li[button/span[text()='차량 구매']]"))
)
car_purchase_button.click()

# 3초 텀을 둠
time.sleep(3)

# 각 질문 클릭하여 답변 가져오기
faq_data = []

def get_faq_data():
    # FAQ 항목이 로드될 때까지 대기
    WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

    # FAQ 항목들 찾기
    faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")

    for i in range(len(faq_items)):
        # 각 질문을 클릭하기 전에 요소를 다시 찾음
        faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")
        item = faq_items[i]
        question = item.find_element(By.CSS_SELECTOR, ".cmp-accordion__title").text
        item.click()  # 질문 클릭하여 답변 표시

        # 답변이 로드될 때까지 대기
        panel_id = item.get_attribute("aria-controls")
        WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.ID, panel_id)))
        answer_element = driver.find_element(By.ID, panel_id)
        answer = answer_element.text

        # 하이퍼링크 정보 가져오기
        links = []
        link_elements = answer_element.find_elements(By.TAG_NAME, "a")
        for link in link_elements:
            links.append({
                "href": link.get_attribute("href"),
                "text": link.text
            })

        # 이미지 링크 정보 가져오기
        images = []
        image_elements = answer_element.find_elements(By.TAG_NAME, "img")
        for img in image_elements:
            images.append({
                "src": img.get_attribute("src"),
                "alt": img.get_attribute("alt")
            })

        faq_data.append({
            "question": question,
            "answer": answer,
            "links": links,
            "images": images
        })

    # 스크롤을 맨 위로 올리기
    driver.execute_script("window.scrollTo(0, 0);")

# 첫 페이지의 FAQ 데이터 가져오기
get_faq_data()

# 페이지 넘기기
current_page = 1
while current_page < 4:
    try:
        next_page = str(current_page + 1)

        # 다음 페이지 번호 클릭
        next_page_element = driver.find_element(By.XPATH, f"//ul[@class='paging-list']//a[text()='{next_page}']")
        next_page_element.click()

        # 3초 텀을 둠
        time.sleep(3)

        # 다음 페이지가 로드될 때까지 대기
        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

        # 각 페이지의 FAQ 데이터를 가져오기 전에 요소를 다시 찾음
        get_faq_data()

        current_page += 1
    except Exception as e:
        print(f"Error: {e}")
        break

# 드라이버 종료
driver.quit()

# 결과를 JSON 파일로 저장
with open("/data/kia_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(faq_data, json_file, ensure_ascii=False, indent=4)

# 결과 출력
'''
for faq in faq_data:
    print(f"Question: {faq['question']}")
    print(f"Answer: {faq['answer']}")
    print(f"Links: {faq['links']}")
    print(f"Images: {faq['images']}\n")
'''

--- File Index 8: pages/2_지역별_자동차_등록_현황.py ---
import streamlit as st
import pymysql
import pandas as pd
import plotly.express as px
import folium
import random
from streamlit_folium import folium_static

st.set_page_config(layout="wide")

st.title("📊 지역별 자동차 등록 현황")

tab1, tab2 = st.tabs(['차트', '지도'])

with tab1:
    # Database 연결
    connection = pymysql.connect(
        host = "localhost",
        user = "SKN10_4team",
        password = "skn1234",
        database = "SKN10_4team_1st",
        charset = "utf8"
    )

    cursor = connection.cursor(pymysql.cursors.DictCursor)

    year_data = """
    SELECT DISTINCT year
    FROM Car
    ;
    """
    cursor.execute(year_data)
    years = cursor.fetchall()
    year_list = [year['year'] for year in years]

    with st.container(border=True):
        selected_year = st.selectbox("연도를 선택하세요:", year_list, index=year_list.index('2022'))

    car_data = f"""
    SELECT City.CityName, Car.CarCount, Car.CityID
    FROM Car
    JOIN City ON Car.CityID = City.CityID
    WHERE Car.Year = {selected_year}
    ;
    """
    cursor.execute(car_data)
    result = cursor.fetchall()

    df = pd.DataFrame(result)

    df['CityID_Number'] = df['CityID'].str.extract(r'(\d+)').astype(int)
    df = df.sort_values(by='CityID_Number')

    fig = px.pie(df, names = "CityName", values="CarCount",
                hover_data={'CarCount': True}, labels={'CarCount': 'CarCount'})
    fig.update_traces(textposition='outside', textinfo='label+value+percent', textfont_color="black", hole=.4,
                    direction='counterclockwise')
    fig.add_annotation(dict(text=f"{selected_year}", x=0.5, y=0.5, font_color="black", font_size=25, showarrow=False))
    fig.add_annotation(dict(text="단위: 만 대", x=0.5, y=0.45, font_color="gray", font_size=13, showarrow=False))

    fig.update_layout(width=1600, height=850, legend=dict(
        yanchor="top",
        y=1.05
    ))
    st.plotly_chart(fig)

with tab2:
    # CSV 파일 경로
    car_file_path = 'data/Car.csv'
    city_file_path = 'data/City_m.csv'

    # CSV 파일 읽기
    car_df = pd.read_csv(car_file_path)
    city_df = pd.read_csv(city_file_path)

    # 연도 선택
    years = car_df['연도'].unique()
    selected_year = st.selectbox('연도를 선택하세요:', years)

    # 선택된 연도에 따라 데이터 필터링
    filtered_car_df = car_df[car_df['연도'] == selected_year]

    # 지도 생성
    m = folium.Map(location=[36.5, 127.5], zoom_start=7)

    # 색상 팔레트 생성
    colors = ['#%06X' % random.randint(0, 0xFFFFFF) for _ in range(len(city_df))]

    # 각 도시의 좌표에 등록대수를 반영한 원 추가
    for i, (_, row) in enumerate(filtered_car_df.iterrows()):
        city_id = row['지역ID']
        city_data = city_df[city_df['CityID'] == city_id].iloc[0]
        folium.Circle(
            location=[city_data['Latitude'], city_data['Longitude']],
            radius=row['등록대수'] * 100,  # 등록대수에 비례한 반경
            color=colors[i],
            fill=True,
            fill_color=colors[i],
            fill_opacity=0.6,
            popup=f"{city_data['CityName']} ({row['등록대수']} 만대)"
        ).add_to(m)

    # 지도 표시
    folium_static(m)

    # 색상 레이블 표시

    legend_html = """
    <div style="border:1px solid black; padding:5px; width: 200px;">
        <b>지역별 색상 레이블</b><br>
    """
    for i, city in city_df.iterrows():
        legend_html += f"<div style='display: flex; align-items: center; margin-bottom: 5px;'><div style='width: 15px; height: 15px; background-color: {colors[i]}; margin-right: 5px;'></div>{city['CityName']}</div>"
    legend_html += "</div>"
    st.markdown(legend_html, unsafe_allow_html=True)

--- File Index 9: pages/3_브랜드별_자동차_판매_현황.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc

st.set_page_config(layout="centered")

st.title("📊 브랜드별 자동차 판매 현황")

# 한글 폰트 설정
font_path = 'C:/Windows/Fonts/malgun.ttf'  # Windows의 경우
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)

# CSV 파일 경로
domestic_file_path = 'data/국산차_순위_2021_2024.csv'
foreign_file_path = 'data/해외차_순위_2021_2024.csv'

# CSV 파일 읽기
domestic_df = pd.read_csv(domestic_file_path)
foreign_df = pd.read_csv(foreign_file_path)

def create_cards(data):
    for index, row in data.iterrows():
        st.markdown(f"""
        <div style="border: 1px solid #ddd; border-radius: 10px; padding: 10px; margin: 10px 0;">
            <h3 style="margin: 0;">{row['순위']}위 - {row['브랜드']}</h3>
            <img src="{row['로고 이미지 링크']}" width="50" style="float: right; margin-left: 10px;">
            <p>판매량: {row['판매량']}</p>
            <p>비율: {row['비율']}</p>
        </div>
        """, unsafe_allow_html=True)

def create_pie_chart(data, title, top_n, total_sales):
    st.subheader(title)
    fig, ax = plt.subplots()
    top_brands = data.iloc[:top_n]
    others = data.iloc[top_n:]
    labels = top_brands['브랜드'].tolist() + ['기타 브랜드']
    sizes = top_brands['판매량'].str.replace(',', '').astype(int).tolist() + [others['판매량'].str.replace(',', '').astype(int).sum()]
    colors = plt.get_cmap('tab20').colors  # 다양한 색상 사용
    ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3))
    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

    # 도넛 차트의 가운데에 총 판매량 표시
    ax.text(0, 0, f"{total_sales:,} 대", ha='center', va='center', fontsize=12, fontweight='bold')

    # 파이 차트 표시
    st.pyplot(fig)

def display_tab(title, df, top_n):

    # 연도와 월 선택
    years = df['연도'].unique()
    months = df['월'].unique()

    with st.container(border=True):
        selected_year = st.selectbox('연도를 선택하세요:', years, key=f'{title}_year')
        selected_month = st.selectbox('월을 선택하세요:', months, key=f'{title}_month')

    # 선택된 연도와 월에 따라 데이터 필터링
    filtered_data = df[(df['연도'] == selected_year) & (df['월'] == selected_month)]

    # 주요 지표 강조
    total_sales = filtered_data['판매량'].str.replace(',', '').astype(int).sum()
    

    # 도넛 모양의 파이 차트 생성
    create_pie_chart(filtered_data, f'{title} 브랜드별 판매 비율', top_n, total_sales)

    # 데이터 카드 형식으로 표시
    st.subheader(f'{title} 순위 데이터')
    create_cards(filtered_data)

# 탭 생성
tab1, tab2 = st.tabs(['국산차', '수입차'])

with tab1:
    display_tab('국산차', domestic_df, 3)

with tab2:
    display_tab('수입차', foreign_df, 5)

--- File Index 10: pages/4_주요_3개_기업_차량_구매_FAQ.py ---
import streamlit as st
import json

st.set_page_config(layout="centered")

# 제목 및 탭 구성
st.title("❓ 주요 3개 기업 차량 구매 FAQ")

tab1, tab2, tab3 = st.tabs(['현대', '기아', '제네시스'])

with tab1:
    st.image("images/hyundai.png")

    file_path = 'data\hyundai_faq.json'  # 경로설정

    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            h_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        h_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(h_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        st.stop()


    # 검색 기능
    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    search_query = st.text_input("", key="hd_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if search_query:
        filtered_data  = [item for item in h_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = h_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="hd_prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="hd_next_page"):
                st.session_state.page = page + 1

with tab2:
    st.image("images/kia.jpg")

    file_path = 'data\kia_faq.json'  # 경로설정
    with open(file_path, 'r', encoding='utf-8') as file:
        k_faq_data = json.load(file)

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    st.text_input("", key="search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if 'search_query' in st.session_state and st.session_state.search_query:
        filtered_data = [item for item in k_faq_data if st.session_state.search_query.lower() in item['question'].lower() or st.session_state.search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = k_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 페이지네이션 설정
    items_per_page = 10
    total_pages = (len(filtered_data) + items_per_page - 1) // items_per_page


    # 페이지 번호 선택
    if 'page' not in st.session_state or st.session_state.page > total_pages:
        st.session_state.page = 1

    def change_page(page):
        st.session_state.page = page

    page = st.session_state.page
    start_idx = (page - 1) * items_per_page
    end_idx = start_idx + items_per_page
    current_page_data = filtered_data[start_idx:end_idx]

    for item in current_page_data:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")

        # 하이퍼링크 처리
        for link in item.get("links", []):
            answer = answer.replace(link["text"], f"[{link['text']}]({link['href']})")

        with st.expander(f"❓ {question}"):
            st.write(answer)

            # 이미지 처리
            for image in item.get("images", []):
                st.image(image["src"], caption=image.get("alt", ""))

    page_numbers = [i for i in range(1, total_pages + 1)]
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()
    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page_tab2"):
                change_page(page - 1)
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page_tab2"):
                change_page(page + 1)


with tab3:
    st.image("images\jenesis.png")

    # JSON 파일 로드
    file_path = 'data\genesis_faq.json'
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            j_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        j_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(j_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        #st.stop()

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    # 검색 기능
    def search():
        st.session_state.search_query = st.session_state.search_input
        st.session_state.page = 1 

    search_query = st.text_input("", key="j_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)
    if search_query:
        filtered_data  = [item for item in j_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = j_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page"):
                st.session_state.page = page + 1



Based on the provided codebase, identify the key abstractions that are central to understanding this project. 
These abstractions should represent the core components, modules, or concepts.

Desired output format is a YAML list of objects, where each object has:
- 'name': A concise name for the abstraction (in korean).
- 'description': A brief explanation of what this abstraction represents and its role (in korean).
- 'file_indices': A list of integer file indices that are most relevant to this abstraction. Choose from the file list above.

Return at most 10 key abstractions.

Example for a different project (simple web server):
```yaml
- name: "HTTP 요청 핸들러 (HTTP Request Handler)"
  description: "수신 HTTP 요청을 처리하고 적절한 응답을 생성하는 구성 요소입니다. (Component that processes incoming HTTP requests and generates appropriate responses.)"
  file_indices: [0, 2]
- name: "라우팅 설정 (Routing Configuration)"
  description: "URL 경로를 특정 요청 핸들러 함수에 매핑하는 규칙을 정의합니다. (Defines rules for mapping URL paths to specific request handler functions.)"
  file_indices: [1]
```

Your response should be only the YAML list, enclosed in triple backticks (```yaml ... ```).
Ensure the output is valid YAML.

2025-06-29 20:35:32,771 - INFO - RESPONSE (from cache): ```yaml
- name: "데이터베이스 삽입 모듈"
  description: "CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 기능을 제공하는 모듈입니다."
  file_indices: [2, 3]
- name: "연도별 자동차 등록 현황 페이지"
  description: "연도별 자동차 등록 데이터를 시각화하여 사용자에게 제공하는 스트림릿 웹 페이지입니다."
  file_indices: [0]
- name: "지역별 자동차 등록 현황 페이지"
  description: "지역별 자동차 등록 데이터를 차트 및 지도 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다."
  file_indices: [8]
- name: "브랜드별 자동차 판매 현황 페이지"
  description: "브랜드별 자동차 판매 데이터를 카드 및 파이 차트 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다."
  file_indices: [9]
- name: "차량 구매 FAQ 페이지"
  description: "주요 자동차 브랜드의 차량 구매 관련 FAQ 데이터를 제공하고 검색 기능을 갖춘 스트림릿 웹 페이지입니다."
  file_indices: [10]
- name: "FAQ 크롤링 모듈"
  description: "주요 자동차 브랜드 웹사이트로부터 FAQ 데이터를 크롤링하여 JSON 파일로 저장하는 모듈입니다."
  file_indices: [5, 6, 7]
- name: "자동차 판매 실적 크롤링 모듈"
  description: "다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하여 CSV 파일로 저장하는 모듈입니다."
  file_indices: [4]
- name: "데이터베이스 연결 설정"
  description: "MySQL 데이터베이스에 연결하기 위한 설정 및 쿼리를 실행하여 데이터를 가져오는 기능을 제공합니다."
  file_indices: [0, 8]
- name: "시각화 라이브러리 사용"
  description: "데이터를 차트와 그래프로 시각화하기 위해 Plotly, Matplotlib, Folium 등의 라이브러리를 사용합니다."
  file_indices: [0, 8, 9]
- name: "검색 및 페이지네이션 기능"
  description: "FAQ 페이지에서 검색 기능과 페이지네이션을 제공하여 사용자가 원하는 정보를 쉽게 찾아볼 수 있도록 지원합니다."
  file_indices: [10]
```
2025-06-29 20:35:32,775 - INFO - PROMPT: 
Based on the following abstractions and relevant code snippets from the project `SKN10-1st-4Team`:

List of Abstraction Indices and Names (Names might be in Korean):
0 # 데이터베이스 삽입 모듈
1 # 연도별 자동차 등록 현황 페이지
2 # 지역별 자동차 등록 현황 페이지
3 # 브랜드별 자동차 판매 현황 페이지
4 # 차량 구매 FAQ 페이지
5 # FAQ 크롤링 모듈
6 # 자동차 판매 실적 크롤링 모듈
7 # 데이터베이스 연결 설정
8 # 시각화 라이브러리 사용
9 # 검색 및 페이지네이션 기능

Context (Abstractions, Descriptions, Code):
Identified Abstractions:
- Index 0: 데이터베이스 삽입 모듈 (Relevant file indices: [2, 3])
  Description: CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 기능을 제공하는 모듈입니다.
- Index 1: 연도별 자동차 등록 현황 페이지 (Relevant file indices: [0])
  Description: 연도별 자동차 등록 데이터를 시각화하여 사용자에게 제공하는 스트림릿 웹 페이지입니다.
- Index 2: 지역별 자동차 등록 현황 페이지 (Relevant file indices: [8])
  Description: 지역별 자동차 등록 데이터를 차트 및 지도 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.
- Index 3: 브랜드별 자동차 판매 현황 페이지 (Relevant file indices: [9])
  Description: 브랜드별 자동차 판매 데이터를 카드 및 파이 차트 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.
- Index 4: 차량 구매 FAQ 페이지 (Relevant file indices: [10])
  Description: 주요 자동차 브랜드의 차량 구매 관련 FAQ 데이터를 제공하고 검색 기능을 갖춘 스트림릿 웹 페이지입니다.
- Index 5: FAQ 크롤링 모듈 (Relevant file indices: [5, 6, 7])
  Description: 주요 자동차 브랜드 웹사이트로부터 FAQ 데이터를 크롤링하여 JSON 파일로 저장하는 모듈입니다.
- Index 6: 자동차 판매 실적 크롤링 모듈 (Relevant file indices: [4])
  Description: 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하여 CSV 파일로 저장하는 모듈입니다.
- Index 7: 데이터베이스 연결 설정 (Relevant file indices: [0, 8])
  Description: MySQL 데이터베이스에 연결하기 위한 설정 및 쿼리를 실행하여 데이터를 가져오는 기능을 제공합니다.
- Index 8: 시각화 라이브러리 사용 (Relevant file indices: [0, 8, 9])
  Description: 데이터를 차트와 그래프로 시각화하기 위해 Plotly, Matplotlib, Folium 등의 라이브러리를 사용합니다.
- Index 9: 검색 및 페이지네이션 기능 (Relevant file indices: [10])
  Description: FAQ 페이지에서 검색 기능과 페이지네이션을 제공하여 사용자가 원하는 정보를 쉽게 찾아볼 수 있도록 지원합니다.

Relevant File Snippets (Referenced by Index and Path):
--- File: 0 # 1_연도별_자동차_등록_현황.py ---
#test
import streamlit as st
import pandas as pd
import plotly.express as px
import pymysql
from common.insert_data import insert_data
from common.insert_data_city import insert_data_city

insert_data()
insert_data_city()

st.set_page_config(layout="centered")

st.title("📊 연도별 자동차 등록 현황")
st.divider()

# 데이터베이스 연결 설정
connection = pymysql.connect(
    host="localhost",
    user="SKN10_4team",
    password="skn1234",
    database="SKN10_4team_1st",
    charset="utf8"
)

# SQL 데이터 가져오기
year_data = "select Year FROM Car"
ef = pd.read_sql(year_data, connection)

car_data = """
SELECT Year, SUM(CarCount) YearofCar
FROM SKN10_4team_1st.Car
GROUP BY Year
ORDER BY Year;
"""
cf = pd.read_sql(car_data, connection)

# Streamlit 컨테이너
with st.container():
    # 컬럼 레이아웃 사용
    col1, col2 = st.columns(2)
    # 년도 리스트 생성 및 선택
    years = ef['Year'].unique().tolist()

    # 디폴트 값 설정
    default_start_year_index = 0  # 첫 번째 연도를 디폴트로 설정
    default_end_year_index = len(years) - 1  # 마지막 연도를 디폴트로 설정

    with col1:
        start_year = st.selectbox(
            '첫번째 년도를 선택해주세요.', 
            years, 
            index=default_start_year_index
        )

    with col2:
        end_year = st.selectbox(
            '마지막 년도를 선택해주세요.', 
            years, 
            index=default_end_year_index
        )

# 연도 범위 확인 및 데이터 필터링
if start_year > end_year:
    st.error("Error: The start year cannot be greater than the end year.")
else:
    with st.container():
        # 사용자 입력 값으로 데이터 필터링
        filtered_data = cf[(cf["Year"] >= start_year) & (cf["Year"] <= end_year)]

        # Plotly로 그래프 생성
        fig = px.bar(
            filtered_data, 
            x="Year", 
            y="YearofCar", 
            title="조회결과"
        )

        # axis title 업데이트
        fig.update_xaxes(title_text="연도")
        fig.update_yaxes(title_text="차량 수 (만대)")

        # 그래프 출력
        st.plotly_chart(fig)

}]}

--- File: 2 # common/insert_data.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "Car.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "Car"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (Year, CityID, CarCount) VALUES (%s, %s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[2], row[3])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File: 3 # common/insert_data_city.py ---
import os
import pymysql
import csv

# MySQL 연결 설정
db_config = {
    "host": "127.0.0.1",       # MySQL 서버 호스트
    "user": "SKN10_4team",   # MySQL 사용자 이름
    "password": "skn1234", # MySQL 비밀번호
    "database": "SKN10_4team_1st"  # 대상 데이터베이스 이름
}

def insert_data_city():
    # CSV 파일 경로 설정
    csv_file_path = os.path.join("data", "City.csv")

    # MySQL 연결
    connection = pymysql.connect(**db_config)
    cursor = connection.cursor()

    # 테이블 이름
    table_name = "City"

    # CSV 파일 읽고 데이터 삽입
    try:
        with open(csv_file_path, mode="r", encoding="utf-8") as file:
            csv_reader = csv.reader(file)
            headers = next(csv_reader)  # 헤더 스킵
            
            # INSERT 쿼리 생성
            query = f"INSERT INTO {table_name} (CityID, CityName) VALUES (%s, %s)"
            
            # 데이터 삽입
            for row in csv_reader:
                mapped_row = (row[0], row[1])  # 순서 매핑
                cursor.execute(query, mapped_row)
        
        # 변경사항 커밋
        connection.commit()
        print("Data successfully inserted into MySQL table.")

    except Exception as e:
        print(f"An error occurred: {e}")
        connection.rollback()

    finally:
        # 연결 종료
        cursor.close()
        connection.close()

--- File: 4 # crawling/danawa.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By


import pandas as pd
import time

# 크롬 드라이버 설정

driver = webdriver.Chrome()

# 데이터 저장 리스트
domestic_data = []
foreign_data = []

# 2021년 1월부터 2024년 12월까지의 URL 생성 및 데이터 크롤링
for year in range(2021, 2025):
    for month in range(1, 13):
        if year == 2024 and month > 12:
            break
        month_str = f"{year}-{month:02d}-00"
        url = f"https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month={month_str}&MonthTo="
        driver.get(url)
        time.sleep(0.5)  # 페이지 로딩 대기

        # 국산차 순위 데이터 크롤링
        rank_elements = driver.find_elements(By.CSS_SELECTOR, "ul.sideRankR li")

        for index, rank_element in enumerate(rank_elements):
            rank = rank_element.find_element(By.CSS_SELECTOR, "span.rank").text
            brand = rank_element.find_element(By.CSS_SELECTOR, "span.title").text.strip()
            sales = rank_element.find_element(By.CSS_SELECTOR, "span.sales").text
            rate = rank_element.find_element(By.CSS_SELECTOR, "span.rate").text
            logo_img = rank_element.find_element(By.CSS_SELECTOR, "span.title img").get_attribute("src")
            data = [year, month, rank, brand, sales, rate, logo_img]
            if index < 6:
                domestic_data.append(data)
            else:
                foreign_data.append(data)

# 데이터프레임으로 변환
domestic_df = pd.DataFrame(domestic_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])
foreign_df = pd.DataFrame(foreign_data, columns=["연도", "월", "순위", "브랜드", "판매량", "비율", "로고 이미지 링크"])

# 데이터프레임 저장
domestic_df.to_csv("data\국산차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')
foreign_df.to_csv("data\해외차_순위_2021_2024.csv", index=False, encoding='utf-8-sig')

# 드라이버 종료
driver.quit()

print("크롤링 완료 및 데이터 저장 완료")
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo=
#https://mauto.danawa.com/auto/?Work=record&Tab=Grand&Month=2021-01-00&MonthTo= 에서 2021-01은 21년 1월 데이터를 받아온다는 의미


--- File: 5 # crawling/genesis_faq.py ---

# 제네시스 크롤링
from selenium import webdriver
from bs4 import BeautifulSoup
import json

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.genesis.com/kr/ko/support/faq/vehicle-purchase.html?anchorID=faq_tab"
driver.get(url)

# 페이지 소스 가져오기
html_source = driver.page_source

# HTML 파일로 저장
#with open("genesis_faq.html", "w", encoding="utf-8") as file:
#    file.write(html_source)

# 드라이버 종료
driver.quit()

# BeautifulSoup을 사용하여 페이지 소스 파싱
soup = BeautifulSoup(html_source, 'html.parser')

# FAQ 질문과 답변 추출
faqs = []
faq_items = soup.select('.cp-faq__accordion-item')  # FAQ 항목을 감싸는 클래스 이름을 사용하여 선택

for item in faq_items:
    question = item.select_one('.accordion-title').get_text(strip=True)
    answer = item.select_one('.accordion-panel-inner').get_text(strip=True)
    faqs.append({'question': question, 'answer': answer})

# 추출한 FAQ를 파일로 저장
with open("data\genesis_faq.json", "w", encoding="utf-8") as file:
    json.dump(faqs, file, ensure_ascii=False, indent=4)

--- File: 6 # crawling/hyundai_faq.py ---
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from time import sleep

#import pandas as pd
import json


URL = "https://www.hyundai.com/kr/ko/e/customer/center/faq"

driver = webdriver.Chrome()
driver.get(URL)
# 리스트에 딕셔너리로 내용 저장
qna_list = []

for page_id in range(4):
    for question_id in range(1,11):
        try:
            #엘리먼트 찾기
            faq_list = driver.find_element(By.CSS_SELECTOR, "div[data-v-28d34f54].list-wrap")

            try:
                # 플로팅 메뉴 제거
                floating_menu = driver.find_element(By.CSS_SELECTOR, "div[data-v-1ea4ba2d].inner_wrap")
                driver.execute_script("arguments[0].remove();", floating_menu)
            except:
                pass
            faq_title = faq_list.find_elements(By.CSS_SELECTOR,f"div[data-id='{question_id}'] button.list-title")
            driver.execute_script("arguments[0].scrollIntoView({block:'center'});",faq_title[0])
            sleep(0.5)

            #질문타이틀 클릭하기
            faq_title[0].click()
            sleep(0.5)

            #질문타이틀 텍스트 받아오기
            faq_question = faq_title[0].find_element(By.CSS_SELECTOR, "span.list-content[data-v-28d34f54]")
            faq_question_text = faq_question.text
            #print(faq_question_text)

            #질문답변 텍스트 받아오기
            faq_answer = driver.find_element(By.CLASS_NAME, "conts")
            faq_answer_text = faq_answer.text
            #print("전체 답변:", faq_answer_text)

            # 링크 URL 가져오기
            try:
                link_whole = faq_answer.find_elements(By.TAG_NAME, "a")
                link = {
                    "url" : link_whole[0].get_attribute("href"),
                    "text" : link_whole[0].text
                    }
            except:
                link = ""
            #print("링크 URL:", url)
            
            qna_list.append({"question": faq_question_text, "answer": faq_answer_text, "link": link})

        except TimeoutException:
            print("Timed out waiting for page to load")
        except NoSuchElementException:
            print("Could not find the element")
        except IndexError:
            pass

    next_button = driver.find_element(By.CSS_SELECTOR, "button.btn-next")
    next_button.click()
    sleep(1)
 
#qna_df = pd.DataFrame(qna_list, columns = ["page_num","question_num","question","answer","link"])
#qna_df.to_csv(path_or_buf="data/hyundai_qna.csv")

# 결과를 JSON 파일로 저장
with open("data\hyundai_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(qna_list, json_file, ensure_ascii=False, indent=4)

--- File: 7 # crawling/kia_faq.py ---
import json
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# 웹 드라이버 설정 (Chrome 드라이버 사용)
driver = webdriver.Chrome()

# 웹 페이지 열기
url = "https://www.kia.com/kr/customer-service/center/faq"
driver.get(url)

# 페이지가 완전히 로드될 때까지 대기
WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, "body")))

# "TOP 10" 버튼 클릭
top_10_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//button[contains(text(), 'TOP 10')]"))
)
top_10_button.click()

# "차량 구매" 버튼 클릭
car_purchase_button = WebDriverWait(driver, 20).until(
    EC.element_to_be_clickable((By.XPATH, "//li[button/span[text()='차량 구매']]"))
)
car_purchase_button.click()

# 3초 텀을 둠
time.sleep(3)

# 각 질문 클릭하여 답변 가져오기
faq_data = []

def get_faq_data():
    # FAQ 항목이 로드될 때까지 대기
    WebDriverWait(driver, 20).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

    # FAQ 항목들 찾기
    faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")

    for i in range(len(faq_items)):
        # 각 질문을 클릭하기 전에 요소를 다시 찾음
        faq_items = driver.find_elements(By.CSS_SELECTOR, ".cmp-accordion__button")
        item = faq_items[i]
        question = item.find_element(By.CSS_SELECTOR, ".cmp-accordion__title").text
        item.click()  # 질문 클릭하여 답변 표시

        # 답변이 로드될 때까지 대기
        panel_id = item.get_attribute("aria-controls")
        WebDriverWait(driver, 20).until(EC.visibility_of_element_located((By.ID, panel_id)))
        answer_element = driver.find_element(By.ID, panel_id)
        answer = answer_element.text

        # 하이퍼링크 정보 가져오기
        links = []
        link_elements = answer_element.find_elements(By.TAG_NAME, "a")
        for link in link_elements:
            links.append({
                "href": link.get_attribute("href"),
                "text": link.text
            })

        # 이미지 링크 정보 가져오기
        images = []
        image_elements = answer_element.find_elements(By.TAG_NAME, "img")
        for img in image_elements:
            images.append({
                "src": img.get_attribute("src"),
                "alt": img.get_attribute("alt")
            })

        faq_data.append({
            "question": question,
            "answer": answer,
            "links": links,
            "images": images
        })

    # 스크롤을 맨 위로 올리기
    driver.execute_script("window.scrollTo(0, 0);")

# 첫 페이지의 FAQ 데이터 가져오기
get_faq_data()

# 페이지 넘기기
current_page = 1
while current_page < 4:
    try:
        next_page = str(current_page + 1)

        # 다음 페이지 번호 클릭
        next_page_element = driver.find_element(By.XPATH, f"//ul[@class='paging-list']//a[text()='{next_page}']")
        next_page_element.click()

        # 3초 텀을 둠
        time.sleep(3)

        # 다음 페이지가 로드될 때까지 대기
        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, ".cmp-accordion__button")))

        # 각 페이지의 FAQ 데이터를 가져오기 전에 요소를 다시 찾음
        get_faq_data()

        current_page += 1
    except Exception as e:
        print(f"Error: {e}")
        break

# 드라이버 종료
driver.quit()

# 결과를 JSON 파일로 저장
with open("/data/kia_faq.json", "w", encoding="utf-8") as json_file:
    json.dump(faq_data, json_file, ensure_ascii=False, indent=4)

# 결과 출력
'''
for faq in faq_data:
    print(f"Question: {faq['question']}")
    print(f"Answer: {faq['answer']}")
    print(f"Links: {faq['links']}")
    print(f"Images: {faq['images']}\n")
'''

--- File: 8 # pages/2_지역별_자동차_등록_현황.py ---
import streamlit as st
import pymysql
import pandas as pd
import plotly.express as px
import folium
import random
from streamlit_folium import folium_static

st.set_page_config(layout="wide")

st.title("📊 지역별 자동차 등록 현황")

tab1, tab2 = st.tabs(['차트', '지도'])

with tab1:
    # Database 연결
    connection = pymysql.connect(
        host = "localhost",
        user = "SKN10_4team",
        password = "skn1234",
        database = "SKN10_4team_1st",
        charset = "utf8"
    )

    cursor = connection.cursor(pymysql.cursors.DictCursor)

    year_data = """
    SELECT DISTINCT year
    FROM Car
    ;
    """
    cursor.execute(year_data)
    years = cursor.fetchall()
    year_list = [year['year'] for year in years]

    with st.container(border=True):
        selected_year = st.selectbox("연도를 선택하세요:", year_list, index=year_list.index('2022'))

    car_data = f"""
    SELECT City.CityName, Car.CarCount, Car.CityID
    FROM Car
    JOIN City ON Car.CityID = City.CityID
    WHERE Car.Year = {selected_year}
    ;
    """
    cursor.execute(car_data)
    result = cursor.fetchall()

    df = pd.DataFrame(result)

    df['CityID_Number'] = df['CityID'].str.extract(r'(\d+)').astype(int)
    df = df.sort_values(by='CityID_Number')

    fig = px.pie(df, names = "CityName", values="CarCount",
                hover_data={'CarCount': True}, labels={'CarCount': 'CarCount'})
    fig.update_traces(textposition='outside', textinfo='label+value+percent', textfont_color="black", hole=.4,
                    direction='counterclockwise')
    fig.add_annotation(dict(text=f"{selected_year}", x=0.5, y=0.5, font_color="black", font_size=25, showarrow=False))
    fig.add_annotation(dict(text="단위: 만 대", x=0.5, y=0.45, font_color="gray", font_size=13, showarrow=False))

    fig.update_layout(width=1600, height=850, legend=dict(
        yanchor="top",
        y=1.05
    ))
    st.plotly_chart(fig)

with tab2:
    # CSV 파일 경로
    car_file_path = 'data/Car.csv'
    city_file_path = 'data/City_m.csv'

    # CSV 파일 읽기
    car_df = pd.read_csv(car_file_path)
    city_df = pd.read_csv(city_file_path)

    # 연도 선택
    years = car_df['연도'].unique()
    selected_year = st.selectbox('연도를 선택하세요:', years)

    # 선택된 연도에 따라 데이터 필터링
    filtered_car_df = car_df[car_df['연도'] == selected_year]

    # 지도 생성
    m = folium.Map(location=[36.5, 127.5], zoom_start=7)

    # 색상 팔레트 생성
    colors = ['#%06X' % random.randint(0, 0xFFFFFF) for _ in range(len(city_df))]

    # 각 도시의 좌표에 등록대수를 반영한 원 추가
    for i, (_, row) in enumerate(filtered_car_df.iterrows()):
        city_id = row['지역ID']
        city_data = city_df[city_df['CityID'] == city_id].iloc[0]
        folium.Circle(
            location=[city_data['Latitude'], city_data['Longitude']],
            radius=row['등록대수'] * 100,  # 등록대수에 비례한 반경
            color=colors[i],
            fill=True,
            fill_color=colors[i],
            fill_opacity=0.6,
            popup=f"{city_data['CityName']} ({row['등록대수']} 만대)"
        ).add_to(m)

    # 지도 표시
    folium_static(m)

    # 색상 레이블 표시

    legend_html = """
    <div style="border:1px solid black; padding:5px; width: 200px;">
        <b>지역별 색상 레이블</b><br>
    """
    for i, city in city_df.iterrows():
        legend_html += f"<div style='display: flex; align-items: center; margin-bottom: 5px;'><div style='width: 15px; height: 15px; background-color: {colors[i]}; margin-right: 5px;'></div>{city['CityName']}</div>"
    legend_html += "</div>"
    st.markdown(legend_html, unsafe_allow_html=True)

--- File: 9 # pages/3_브랜드별_자동차_판매_현황.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc

st.set_page_config(layout="centered")

st.title("📊 브랜드별 자동차 판매 현황")

# 한글 폰트 설정
font_path = 'C:/Windows/Fonts/malgun.ttf'  # Windows의 경우
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)

# CSV 파일 경로
domestic_file_path = 'data/국산차_순위_2021_2024.csv'
foreign_file_path = 'data/해외차_순위_2021_2024.csv'

# CSV 파일 읽기
domestic_df = pd.read_csv(domestic_file_path)
foreign_df = pd.read_csv(foreign_file_path)

def create_cards(data):
    for index, row in data.iterrows():
        st.markdown(f"""
        <div style="border: 1px solid #ddd; border-radius: 10px; padding: 10px; margin: 10px 0;">
            <h3 style="margin: 0;">{row['순위']}위 - {row['브랜드']}</h3>
            <img src="{row['로고 이미지 링크']}" width="50" style="float: right; margin-left: 10px;">
            <p>판매량: {row['판매량']}</p>
            <p>비율: {row['비율']}</p>
        </div>
        """, unsafe_allow_html=True)

def create_pie_chart(data, title, top_n, total_sales):
    st.subheader(title)
    fig, ax = plt.subplots()
    top_brands = data.iloc[:top_n]
    others = data.iloc[top_n:]
    labels = top_brands['브랜드'].tolist() + ['기타 브랜드']
    sizes = top_brands['판매량'].str.replace(',', '').astype(int).tolist() + [others['판매량'].str.replace(',', '').astype(int).sum()]
    colors = plt.get_cmap('tab20').colors  # 다양한 색상 사용
    ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3))
    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

    # 도넛 차트의 가운데에 총 판매량 표시
    ax.text(0, 0, f"{total_sales:,} 대", ha='center', va='center', fontsize=12, fontweight='bold')

    # 파이 차트 표시
    st.pyplot(fig)

def display_tab(title, df, top_n):

    # 연도와 월 선택
    years = df['연도'].unique()
    months = df['월'].unique()

    with st.container(border=True):
        selected_year = st.selectbox('연도를 선택하세요:', years, key=f'{title}_year')
        selected_month = st.selectbox('월을 선택하세요:', months, key=f'{title}_month')

    # 선택된 연도와 월에 따라 데이터 필터링
    filtered_data = df[(df['연도'] == selected_year) & (df['월'] == selected_month)]

    # 주요 지표 강조
    total_sales = filtered_data['판매량'].str.replace(',', '').astype(int).sum()
    

    # 도넛 모양의 파이 차트 생성
    create_pie_chart(filtered_data, f'{title} 브랜드별 판매 비율', top_n, total_sales)

    # 데이터 카드 형식으로 표시
    st.subheader(f'{title} 순위 데이터')
    create_cards(filtered_data)

# 탭 생성
tab1, tab2 = st.tabs(['국산차', '수입차'])

with tab1:
    display_tab('국산차', domestic_df, 3)

with tab2:
    display_tab('수입차', foreign_df, 5)

--- File: 10 # pages/4_주요_3개_기업_차량_구매_FAQ.py ---
import streamlit as st
import json

st.set_page_config(layout="centered")

# 제목 및 탭 구성
st.title("❓ 주요 3개 기업 차량 구매 FAQ")

tab1, tab2, tab3 = st.tabs(['현대', '기아', '제네시스'])

with tab1:
    st.image("images/hyundai.png")

    file_path = 'data\hyundai_faq.json'  # 경로설정

    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            h_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        h_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(h_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        st.stop()


    # 검색 기능
    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    search_query = st.text_input("", key="hd_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if search_query:
        filtered_data  = [item for item in h_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = h_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="hd_prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="hd_next_page"):
                st.session_state.page = page + 1

with tab2:
    st.image("images/kia.jpg")

    file_path = 'data\kia_faq.json'  # 경로설정
    with open(file_path, 'r', encoding='utf-8') as file:
        k_faq_data = json.load(file)

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    def search():
        st.session_state.search_query = st.session_state.search_input

    st.text_input("", key="search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)

    if 'search_query' in st.session_state and st.session_state.search_query:
        filtered_data = [item for item in k_faq_data if st.session_state.search_query.lower() in item['question'].lower() or st.session_state.search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = k_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        #st.stop()

    # 페이지네이션 설정
    items_per_page = 10
    total_pages = (len(filtered_data) + items_per_page - 1) // items_per_page


    # 페이지 번호 선택
    if 'page' not in st.session_state or st.session_state.page > total_pages:
        st.session_state.page = 1

    def change_page(page):
        st.session_state.page = page

    page = st.session_state.page
    start_idx = (page - 1) * items_per_page
    end_idx = start_idx + items_per_page
    current_page_data = filtered_data[start_idx:end_idx]

    for item in current_page_data:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")

        # 하이퍼링크 처리
        for link in item.get("links", []):
            answer = answer.replace(link["text"], f"[{link['text']}]({link['href']})")

        with st.expander(f"❓ {question}"):
            st.write(answer)

            # 이미지 처리
            for image in item.get("images", []):
                st.image(image["src"], caption=image.get("alt", ""))

    page_numbers = [i for i in range(1, total_pages + 1)]
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()
    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page_tab2"):
                change_page(page - 1)
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page_tab2"):
                change_page(page + 1)


with tab3:
    st.image("images\jenesis.png")

    # JSON 파일 로드
    file_path = 'data\genesis_faq.json'
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            j_faq_data = json.load(file)
    except Exception as e:
        st.error(f"FAQ 데이터를 로드하는 중 오류 발생: {e}")
        j_faq_data = []

    # 세션 상태 초기화
    if 'page' not in st.session_state:
        st.session_state.page = 1

    # FAQ 데이터 확인 및 예외 처리
    if len(j_faq_data) == 0:
        st.write("FAQ 데이터가 없습니다.")
        #st.stop()

    # 검색 기능 스타일링
    search_style = """
        <style>
        .search-container {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }
        .search-input {
            width: 300px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 16px;
        }
        </style>
    """
    st.markdown(search_style, unsafe_allow_html=True)

    # 검색 기능
    def search():
        st.session_state.search_query = st.session_state.search_input
        st.session_state.page = 1 

    search_query = st.text_input("", key="j_search_input", placeholder="검색어를 입력하세요...", label_visibility="collapsed", on_change=search)
    if search_query:
        filtered_data  = [item for item in j_faq_data if search_query.lower() in item['question'].lower() or search_query.lower() in item['answer'].lower()]
    else:
        filtered_data = j_faq_data

    # 검색 결과가 없을 경우 메시지 출력
    if len(filtered_data) == 0:
        st.write("검색 결과가 없습니다.")
        st.stop()

    # 한 페이지에 표시할 FAQ 수와 페이지 계산
    faq_per_page = 10
    total_pages = (len(filtered_data) - 1) // faq_per_page + 1

    # 현재 페이지에 해당하는 FAQ 가져오기
    page = st.session_state.page
    start_index = (page - 1) * faq_per_page
    end_index = start_index + faq_per_page
    current_faqs = filtered_data[start_index:end_index]

    # 현재 페이지의 FAQ 출력
    for item in current_faqs:
        question = item.get("question", "질문 없음")
        answer = item.get("answer", "답변 없음")
        with st.expander(f"❓ {question}"):
            st.write(answer)
    
    # 이전, 다음 버튼을 양쪽 끝에 배치하고 가운데에 현재 페이지 표시
    button_container = st.container()

    with button_container:
        col1, col2, col3 = st.columns([1, 6, 1])
        with col1:
            if page > 1 and st.button("이전", key="prev_page"):
                st.session_state.page = page - 1
        with col2:
            st.markdown(f"<div style='text-align: center;'>페이지 {page} / {total_pages}</div>", unsafe_allow_html=True)
        with col3:
            if page < total_pages and st.button("다음", key="next_page"):
                st.session_state.page = page + 1

IMPORTANT: Generate the `summary` and relationship `label` fields in **Korean** language. Do NOT use English for these fields.

Please provide:
1. A high-level `summary` of the project's main purpose and functionality in a few beginner-friendly sentences (in Korean). Use markdown formatting with **bold** and *italic* text to highlight important concepts.
2. A list (`relationships`) describing the key interactions between these abstractions. For each relationship, specify:
    - `from_abstraction`: Index of the source abstraction (e.g., `0 # AbstractionName1`)
    - `to_abstraction`: Index of the target abstraction (e.g., `1 # AbstractionName2`)
    - `label`: A brief label for the interaction **in just a few words** (in Korean) (e.g., "Manages", "Inherits", "Uses").
    Ideally the relationship should be backed by one abstraction calling or passing parameters to another.
    Simplify the relationship and exclude those non-important ones.

IMPORTANT: Make sure EVERY abstraction is involved in at least ONE relationship (either as source or target). Each abstraction index must appear at least once across all relationships.

Format the output as YAML:

```yaml
summary: |
  A brief, simple explanation of the project (in Korean).
  Can span multiple lines with **bold** and *italic* for emphasis.
relationships:
  - from_abstraction: 0 # AbstractionName1
    to_abstraction: 1 # AbstractionName2
    label: "Manages" (in Korean)
  - from_abstraction: 2 # AbstractionName3
    to_abstraction: 0 # AbstractionName1
    label: "Provides config" (in Korean)
  # ... other relationships
```

Now, provide the YAML output:

2025-06-29 20:35:32,778 - INFO - RESPONSE (from cache): ```yaml
summary: |
  **SKN10-1st-4Team** 프로젝트는 자동차 등록 및 판매 현황 데이터를 관리하고 *시각화*하는 웹 애플리케이션입니다. **Streamlit**을 사용하여 각종 **연도별, 지역별, 브랜드별** 데이터를 **시각화**하며, **크롤링** 모듈을 통해 주요 브랜드의 **FAQ 데이터를 자동으로 수집**합니다. 또한, 데이터는 **MySQL 데이터베이스**에 저장되고 **검색 및 페이지네이션** 기능을 통해 사용자는 필요한 정보를 쉽게 찾을 수 있습니다.

relationships:
  - from_abstraction: 0 # 데이터베이스 삽입 모듈
    to_abstraction: 7 # 데이터베이스 연결 설정
    label: "사용"
  - from_abstraction: 1 # 연도별 자동차 등록 현황 페이지
    to_abstraction: 0 # 데이터베이스 삽입 모듈
    label: "데이터 읽기"
  - from_abstraction: 2 # 지역별 자동차 등록 현황 페이지
    to_abstraction: 7 # 데이터베이스 연결 설정
    label: "사용"
  - from_abstraction: 3 # 브랜드별 자동차 판매 현황 페이지
    to_abstraction: 6 # 자동차 판매 실적 크롤링 모듈
    label: "데이터 사용"
  - from_abstraction: 4 # 차량 구매 FAQ 페이지
    to_abstraction: 9 # 검색 및 페이지네이션 기능
    label: "활용"
  - from_abstraction: 5 # FAQ 크롤링 모듈
    to_abstraction: 4 # 차량 구매 FAQ 페이지
    label: "데이터 공급"
  - from_abstraction: 6 # 자동차 판매 실적 크롤링 모듈
    to_abstraction: 9 # 검색 및 페이지네이션 기능
    label: "활용"
  - from_abstraction: 8 # 시각화 라이브러리 사용
    to_abstraction: 2 # 지역별 자동차 등록 현황 페이지
    label: "적용"
  - from_abstraction: 9 # 검색 및 페이지네이션 기능
    to_abstraction: 4 # 차량 구매 FAQ 페이지
    label: "지원"
```
2025-06-29 20:35:32,780 - INFO - PROMPT: 
Given the following project abstractions and their relationships for the project ```` SKN10-1st-4Team ````:

Abstractions (Index # Name) (Names might be in Korean):
- 0 # 데이터베이스 삽입 모듈
- 1 # 연도별 자동차 등록 현황 페이지
- 2 # 지역별 자동차 등록 현황 페이지
- 3 # 브랜드별 자동차 판매 현황 페이지
- 4 # 차량 구매 FAQ 페이지
- 5 # FAQ 크롤링 모듈
- 6 # 자동차 판매 실적 크롤링 모듈
- 7 # 데이터베이스 연결 설정
- 8 # 시각화 라이브러리 사용
- 9 # 검색 및 페이지네이션 기능

Context about relationships and project summary:
Project Summary (Note: Project Summary might be in Korean):
**SKN10-1st-4Team** 프로젝트는 자동차 등록 및 판매 현황 데이터를 관리하고 *시각화*하는 웹 애플리케이션입니다. **Streamlit**을 사용하여 각종 **연도별, 지역별, 브랜드별** 데이터를 **시각화**하며, **크롤링** 모듈을 통해 주요 브랜드의 **FAQ 데이터를 자동으로 수집**합니다. 또한, 데이터는 **MySQL 데이터베이스**에 저장되고 **검색 및 페이지네이션** 기능을 통해 사용자는 필요한 정보를 쉽게 찾을 수 있습니다.


Relationships (Indices refer to abstractions above):
- From 0 (데이터베이스 삽입 모듈) to 7 (데이터베이스 연결 설정): 사용
- From 1 (연도별 자동차 등록 현황 페이지) to 0 (데이터베이스 삽입 모듈): 데이터 읽기
- From 2 (지역별 자동차 등록 현황 페이지) to 7 (데이터베이스 연결 설정): 사용
- From 3 (브랜드별 자동차 판매 현황 페이지) to 6 (자동차 판매 실적 크롤링 모듈): 데이터 사용
- From 4 (차량 구매 FAQ 페이지) to 9 (검색 및 페이지네이션 기능): 활용
- From 5 (FAQ 크롤링 모듈) to 4 (차량 구매 FAQ 페이지): 데이터 공급
- From 6 (자동차 판매 실적 크롤링 모듈) to 9 (검색 및 페이지네이션 기능): 활용
- From 8 (시각화 라이브러리 사용) to 2 (지역별 자동차 등록 현황 페이지): 적용
- From 9 (검색 및 페이지네이션 기능) to 4 (차량 구매 FAQ 페이지): 지원


If you are going to make a tutorial for ```` SKN10-1st-4Team ````, what is the best order to explain these abstractions, from first to last?
Ideally, first explain those that are the most important or foundational, perhaps user-facing concepts or entry points. Then move to more detailed, lower-level implementation details or supporting concepts.

Output the ordered list of abstraction indices, including the name in a comment for clarity. Use the format `idx # AbstractionName`.

```yaml
- 2 # FoundationalConcept
- 0 # CoreClassA
- 1 # CoreClassB (uses CoreClassA)
- ...
```

Now, provide the YAML output:

2025-06-29 20:35:32,783 - INFO - RESPONSE (from cache): ```yaml
- 8 # 시각화 라이브러리 사용
- 2 # 지역별 자동차 등록 현황 페이지
- 1 # 연도별 자동차 등록 현황 페이지
- 3 # 브랜드별 자동차 판매 현황 페이지
- 4 # 차량 구매 FAQ 페이지
- 9 # 검색 및 페이지네이션 기능
- 5 # FAQ 크롤링 모듈
- 6 # 자동차 판매 실적 크롤링 모듈
- 0 # 데이터베이스 삽입 모듈
- 7 # 데이터베이스 연결 설정
```
2025-06-29 20:35:32,783 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "시각화 라이브러리 사용". This is Chapter 1.

Concept Details (Note: Provided in Korean):
- Name: 시각화 라이브러리 사용
- Description:
데이터를 차트와 그래프로 시각화하기 위해 Plotly, Matplotlib, Folium 등의 라이브러리를 사용합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
This is the first chapter.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 1: 시각화 라이브러리 사용`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:35:32,786 - INFO - RESPONSE (from cache): # Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
2025-06-29 20:35:32,786 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "지역별 자동차 등록 현황 페이지". This is Chapter 2.

Concept Details (Note: Provided in Korean):
- Name: 지역별 자동차 등록 현황 페이지
- Description:
지역별 자동차 등록 데이터를 차트 및 지도 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 2: 지역별 자동차 등록 현황 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:35:32,788 - INFO - RESPONSE (from cache): # 제 2 장: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
2025-06-29 20:35:32,789 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "연도별 자동차 등록 현황 페이지". This is Chapter 3.

Concept Details (Note: Provided in Korean):
- Name: 연도별 자동차 등록 현황 페이지
- Description:
연도별 자동차 등록 데이터를 시각화하여 사용자에게 제공하는 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 3: 연도별 자동차 등록 현황 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:35:32,791 - INFO - RESPONSE (from cache): # Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
2025-06-29 20:35:32,792 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "브랜드별 자동차 판매 현황 페이지". This is Chapter 4.

Concept Details (Note: Provided in Korean):
- Name: 브랜드별 자동차 판매 현황 페이지
- Description:
브랜드별 자동차 판매 데이터를 카드 및 파이 차트 형태로 시각화하여 제공하는 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 4: 브랜드별 자동차 판매 현황 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:35:32,795 - INFO - RESPONSE (from cache): # 제4장: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
2025-06-29 20:35:32,795 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "차량 구매 FAQ 페이지". This is Chapter 5.

Concept Details (Note: Provided in Korean):
- Name: 차량 구매 FAQ 페이지
- Description:
주요 자동차 브랜드의 차량 구매 관련 FAQ 데이터를 제공하고 검색 기능을 갖춘 스트림릿 웹 페이지입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 5: 차량 구매 FAQ 페이지`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:35:32,798 - INFO - RESPONSE (from cache): # Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
2025-06-29 20:35:32,798 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "검색 및 페이지네이션 기능". This is Chapter 6.

Concept Details (Note: Provided in Korean):
- Name: 검색 및 페이지네이션 기능
- Description:
FAQ 페이지에서 검색 기능과 페이지네이션을 제공하여 사용자가 원하는 정보를 쉽게 찾아볼 수 있도록 지원합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 6: 검색 및 페이지네이션 기능`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:35:32,800 - INFO - RESPONSE (from cache): # Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
2025-06-29 20:35:32,801 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "FAQ 크롤링 모듈". This is Chapter 7.

Concept Details (Note: Provided in Korean):
- Name: FAQ 크롤링 모듈
- Description:
주요 자동차 브랜드 웹사이트로부터 FAQ 데이터를 크롤링하여 JSON 파일로 저장하는 모듈입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 7: FAQ 크롤링 모듈`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:35:32,803 - INFO - RESPONSE (from cache): # Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.
2025-06-29 20:35:32,804 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "자동차 판매 실적 크롤링 모듈". This is Chapter 8.

Concept Details (Note: Provided in Korean):
- Name: 자동차 판매 실적 크롤링 모듈
- Description:
다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하여 CSV 파일로 저장하는 모듈입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
---
# Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 8: 자동차 판매 실적 크롤링 모듈`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:35:32,806 - INFO - RESPONSE (from cache): # Chapter 8: 자동차 판매 실적 크롤링 모듈

이전 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동차 관련 웹사이트에서 FAQ 데이터를 자동으로 수집하고 저장하는 방법을 배웠습니다. 이번 장에서는 `자동차 판매 실적 크롤링 모듈`을 구축하여 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하고, 이를 CSV 파일로 저장하는 방법을 알아보겠습니다.

## 동기 부여

자동차 판매 실적을 분석하는 것은 시장 동향을 파악하고, 신차 개발 및 판매 전략을 수립하는 데 중요한 역할을 합니다. 만약 특정 브랜드의 판매 실적이 급격히 증가했다면, 그 이유를 파악하여 다른 브랜드에도 적용할 수 있는 영감을 얻을 수 있습니다. 이때 매번 웹사이트를 방문해 수작업으로 데이터를 정리하는 대신, 크롤러를 사용하면 실적 데이터를 자동으로 수집 및 저장할 수 있습니다.

## 주요 개념

### 웹 크롤링

웹 크롤링은 특정 웹사이트의 정보를 자동으로 수집하는 방법입니다. 일반적으로 원하는 페이지의 HTML 코드를 가져와 필요한 데이터를 추출합니다. 다나와의 판매 실적 페이지를 탐색하고 데이터를 추출할 수 있습니다.

### CSV 형식

CSV는 데이터를 쉽고 효율적으로 저장할 수 있는 포맷입니다. 각 행은 하나의 데이터 레코드를 나타내며, 각 값은 쉼표로 구분됩니다. 추출한 판매 실적 데이터를 CSV 파일에 저장하면 데이터를 분석하고 사용할 때 유용합니다.

## 자동차 판매 실적 크롤링 모듈 구현하기

다나와의 자동차 판매 실적 데이터를 수집하기 위한 방법을 살펴보겠습니다.

### 1단계: 기본 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# 판매 실적 페이지 URL
url = 'http://example.com/sales'

# 웹 페이지 요청 및 HTML 파싱
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
```

이 코드는 requests를 사용하여 특정 URL에서 HTML 페이지를 가져오고, BeautifulSoup을 통해 HTML을 파싱하는 기본 크롤러의 구조를 설명합니다. 이 과정은 크롤링의 첫 단계를 나타냅니다.

### 2단계: 판매 실적 데이터 추출

```python
sales_data = []

# 테이블에서 데이터 추출
for row in soup.find_all('tr'):
    cols = row.find_all('td')
    if cols:
        brand = cols[0].get_text()
        sales = cols[1].get_text()
        sales_data.append({'브랜드': brand.strip(), '판매량': sales.strip()})
```

위 코드는 HTML 테이블에서 브랜드와 판매량 데이터를 추출하는 예를 보여줍니다. 여기서는 `find_all`을 통해 테이블 행과 열을 순회하며 데이터를 모읍니다.

### 3단계: 데이터 CSV 파일 저장

```python
import csv

# CSV 파일로 데이터 저장
with open('sales_data.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=['브랜드', '판매량'])
    writer.writeheader()
    writer.writerows(sales_data)
```

크롤링한 데이터를 CSV 파일로 저장합니다. 이를 통해 데이터를 쉽게 접근하고 여러 도구에서 활용할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 전체 과정을 이해하기 위한 단계별 설명입니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant CSV파일

  사용자 ->> 크롤러: URL 설정
  크롤러 ->> 웹사이트: 데이터 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> CSV파일: 가공한 데이터 저장
  사용자 -->> CSV파일: 실적 데이터 분석
```

크롤러가 웹사이트에 HTTP 요청을 보내고, HTML 응답에서 데이터를 추출 및 처리하여 CSV 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 자동차 판매 실적을 다나와 웹사이트에서 자동으로 수집하고 이를 CSV 형식으로 저장하는 방법을 알아보았습니다. 이러한 크롤링 모듈은 데이터 분석 및 비즈니스 전략 수립에 필수적인 요소입니다. 다음은 데이터베이스에 수집한 데이터를 효율적으로 저장하고 관리하는 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md) 입니다. 이를 통해 데이터 관리의 효율성을 더욱 높일 수 있습니다.
2025-06-29 20:35:32,807 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "데이터베이스 삽입 모듈". This is Chapter 9.

Concept Details (Note: Provided in Korean):
- Name: 데이터베이스 삽입 모듈
- Description:
CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 기능을 제공하는 모듈입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
---
# Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.
---
# Chapter 8: 자동차 판매 실적 크롤링 모듈

이전 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동차 관련 웹사이트에서 FAQ 데이터를 자동으로 수집하고 저장하는 방법을 배웠습니다. 이번 장에서는 `자동차 판매 실적 크롤링 모듈`을 구축하여 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하고, 이를 CSV 파일로 저장하는 방법을 알아보겠습니다.

## 동기 부여

자동차 판매 실적을 분석하는 것은 시장 동향을 파악하고, 신차 개발 및 판매 전략을 수립하는 데 중요한 역할을 합니다. 만약 특정 브랜드의 판매 실적이 급격히 증가했다면, 그 이유를 파악하여 다른 브랜드에도 적용할 수 있는 영감을 얻을 수 있습니다. 이때 매번 웹사이트를 방문해 수작업으로 데이터를 정리하는 대신, 크롤러를 사용하면 실적 데이터를 자동으로 수집 및 저장할 수 있습니다.

## 주요 개념

### 웹 크롤링

웹 크롤링은 특정 웹사이트의 정보를 자동으로 수집하는 방법입니다. 일반적으로 원하는 페이지의 HTML 코드를 가져와 필요한 데이터를 추출합니다. 다나와의 판매 실적 페이지를 탐색하고 데이터를 추출할 수 있습니다.

### CSV 형식

CSV는 데이터를 쉽고 효율적으로 저장할 수 있는 포맷입니다. 각 행은 하나의 데이터 레코드를 나타내며, 각 값은 쉼표로 구분됩니다. 추출한 판매 실적 데이터를 CSV 파일에 저장하면 데이터를 분석하고 사용할 때 유용합니다.

## 자동차 판매 실적 크롤링 모듈 구현하기

다나와의 자동차 판매 실적 데이터를 수집하기 위한 방법을 살펴보겠습니다.

### 1단계: 기본 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# 판매 실적 페이지 URL
url = 'http://example.com/sales'

# 웹 페이지 요청 및 HTML 파싱
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
```

이 코드는 requests를 사용하여 특정 URL에서 HTML 페이지를 가져오고, BeautifulSoup을 통해 HTML을 파싱하는 기본 크롤러의 구조를 설명합니다. 이 과정은 크롤링의 첫 단계를 나타냅니다.

### 2단계: 판매 실적 데이터 추출

```python
sales_data = []

# 테이블에서 데이터 추출
for row in soup.find_all('tr'):
    cols = row.find_all('td')
    if cols:
        brand = cols[0].get_text()
        sales = cols[1].get_text()
        sales_data.append({'브랜드': brand.strip(), '판매량': sales.strip()})
```

위 코드는 HTML 테이블에서 브랜드와 판매량 데이터를 추출하는 예를 보여줍니다. 여기서는 `find_all`을 통해 테이블 행과 열을 순회하며 데이터를 모읍니다.

### 3단계: 데이터 CSV 파일 저장

```python
import csv

# CSV 파일로 데이터 저장
with open('sales_data.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=['브랜드', '판매량'])
    writer.writeheader()
    writer.writerows(sales_data)
```

크롤링한 데이터를 CSV 파일로 저장합니다. 이를 통해 데이터를 쉽게 접근하고 여러 도구에서 활용할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 전체 과정을 이해하기 위한 단계별 설명입니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant CSV파일

  사용자 ->> 크롤러: URL 설정
  크롤러 ->> 웹사이트: 데이터 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> CSV파일: 가공한 데이터 저장
  사용자 -->> CSV파일: 실적 데이터 분석
```

크롤러가 웹사이트에 HTTP 요청을 보내고, HTML 응답에서 데이터를 추출 및 처리하여 CSV 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 자동차 판매 실적을 다나와 웹사이트에서 자동으로 수집하고 이를 CSV 형식으로 저장하는 방법을 알아보았습니다. 이러한 크롤링 모듈은 데이터 분석 및 비즈니스 전략 수립에 필수적인 요소입니다. 다음은 데이터베이스에 수집한 데이터를 효율적으로 저장하고 관리하는 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md) 입니다. 이를 통해 데이터 관리의 효율성을 더욱 높일 수 있습니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 9: 데이터베이스 삽입 모듈`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:35:32,809 - INFO - RESPONSE (from cache): # Chapter 9: 데이터베이스 삽입 모듈

이전 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 다나와 웹사이트에서 자동차 판매 실적 데이터를 수집하여 CSV 파일로 저장하는 방법을 배웠습니다. 이번 장에서는 `데이터베이스 삽입 모듈`을 구현하여 CSV 파일의 데이터를 MySQL 데이터베이스에 자동으로 업로드하는 방법을 알아보겠습니다.

## 동기 부여

현대의 많은 애플리케이션은 데이터를 보다 효율적이고 안정적으로 관리하기 위해 데이터베이스를 사용합니다. 특히 대량의 데이터를 처리할 때는 CSV 파일에 저장하는 것보다 데이터베이스에 저장하는 것이 효율적입니다. 이번 데이터베이스 삽입 모듈은 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입함으로써 데이터를 보다 구조적이고 신뢰성 있게 관리할 수 있도록 해줍니다.

## 주요 개념

### CSV 파일 처리

CSV 파일은 간단한 데이터 포맷이며 텍스트 데이터를 쉼표로 구분하여 저장합니다. 파이썬의 `csv` 모듈을 활용하면 CSV 파일의 데이터를 손쉽게 읽어올 수 있습니다.

### MySQL 데이터베이스 연결

MySQL 데이터베이스는 관계형 데이터베이스로, 대량의 데이터를 구조적으로 저장할 수 있게 해줍니다. 파이썬에서는 `MySQL Connector` 라이브러리를 사용하여 데이터베이스에 연결하고 데이터를 삽입할 수 있습니다.

## 데이터베이스 삽입 모듈 사용하기

이제 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 단계별로 살펴보겠습니다.

### 1단계: CSV 파일 읽기

```python
import csv

# CSV 파일 읽기
data = []
with open('sales_data.csv', mode='r', encoding='utf-8') as file:
    reader = csv.DictReader(file)
    for row in reader:
        data.append(row)
```

이 코드에서는 `csv.DictReader`를 사용하여 CSV 파일의 데이터를 읽어 목록에 저장합니다. 각 행은 딕셔너리로 변환되어 `data` 리스트에 추가됩니다.

### 2단계: 데이터베이스 연결 및 데이터 삽입

```python
import mysql.connector

# 데이터베이스 연결 설정
connection = mysql.connector.connect(
    host='localhost',
    user='user',
    password='password',
    database='car_sales_db'
)

cursor = connection.cursor()

# 데이터 삽입
for entry in data:
    sql = "INSERT INTO sales (brand, sales) VALUES (%s, %s)"
    cursor.execute(sql, (entry['브랜드'], entry['판매량']))

# 변경사항 저장
connection.commit()
```

위 코드에서는 `mysql.connector`를 사용하여 MySQL 데이터베이스에 연결한 후, 각 데이터 항목을 반복적으로 삽입합니다. 삽입 문법 `INSERT INTO`를 통해 데이터베이스에 데이터를 추가합니다. 마지막으로, `commit` 메서드로 변경 사항을 저장합니다.

## 내부 구현 이해

데이터베이스 삽입 모듈이 어떻게 작동하는지 이해하기 쉽게 시퀀스 다이어그램으로 설명하겠습니다.

```mermaid
sequenceDiagram
  participant User
  participant CSV파일
  participant Python프로그램
  participant MySQLDB

  User ->> Python프로그램: CSV 파일 읽기 요청
  Python프로그램 ->> CSV파일: 데이터 읽기
  CSV파일 -->> Python프로그램: 데이터 반환
  Python프로그램 ->> MySQLDB: 데이터베이스에 데이터 삽입
  MySQLDB -->> Python프로그램: 삽입 완료
  Python프로그램 -->> User: 완료 메시지 제공
```

이 다이어그램은 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 과정을 확인할 수 있습니다.

## 결론

이번 장에서는 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 배웠습니다. 이를 통해 데이터를 보다 구조적으로 관리하고 활용할 수 있습니다. 다음 [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)에서는 데이터베이스 연결 설정에 대해 더욱 상세히 알아보겠습니다. 데이터베이스와의 원활한 연결은 안정적인 데이터 처리에 필수적입니다. 

---

이번 과정을 통해 데이터베이스 활용 능력이 한 단계 업그레이드될 것입니다. 지속적인 실습을 통해 데이터 관리자 및 개발자로서의 역량을 키워보세요!
2025-06-29 20:35:32,810 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-1st-4Team` about the concept: "데이터베이스 연결 설정". This is Chapter 10.

Concept Details (Note: Provided in Korean):
- Name: 데이터베이스 연결 설정
- Description:
MySQL 데이터베이스에 연결하기 위한 설정 및 쿼리를 실행하여 데이터를 가져오는 기능을 제공합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)
2. [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)
3. [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)
4. [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)
5. [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)
6. [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)
7. [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)
8. [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)
9. [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)
10. [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 시각화 라이브러리 사용

## 소개

데이터를 효과적으로 전달하는 가장 좋은 방법 중 하나는 시각화를 사용하는 것입니다. 특히, 많은 양의 데이터를 다룰 때 시각화는 패턴을 쉽게 파악하고 인사이트를 얻을 수 있게 해줍니다. 예를 들어, 특정 지역의 자동차 등록 현황을 여러 해에 걸쳐 분석하려고 한다고 가정해봅시다. 수치 데이터만 사용한다면 분석이 어렵고 시간이 오래 걸립니다. 그러나 그래프와 차트를 사용하면 데이터 간의 연결과 트렌드를 빠르게 볼 수 있습니다.

## 사용 가능한 시각화 라이브러리

### Plotly
Plotly는 웹 기반의 대화형 그래프와 차트를 만드는 데 도움을 주는 강력한 도구입니다. 사용이 비교적 간단하며, 데이터 분석 및 프레젠테이션에 아주 유용합니다.

### Matplotlib
Matplotlib는 가장 오래되고 많이 사용되는 파이썬 시각화 라이브러리 중 하나입니다. 2D 그래프를 그리는 데 아주 효과적이며, 폭넓은 커스터마이징 옵션을 제공합니다.

### Folium
Folium은 지리적 데이터를 시각화하는 데 특화된 라이브러리입니다. 특히 지도 위에 데이터를 표현하고자 할 때 유용합니다.

## 간단한 예제: 차트 만들기

### 예제 1: 간단한 라인 그래프 그리기 (Matplotlib)

아래는 Matplotlib를 사용하여 간단한 라인 차트를 생성하는 예제입니다. 이 예제의 목적은 몇 년간의 자동차 등록 데이터를 시각화하는 것입니다.

```python
import matplotlib.pyplot as plt

years = [2018, 2019, 2020, 2021, 2022]
registrations = [120, 150, 180, 210, 250]

plt.plot(years, registrations)
plt.title('연도별 자동차 등록 현황')
plt.xlabel('연도')
plt.ylabel('등록 수')
plt.show()
```

이 코드에서는 `years`와 `registrations`라는 두 가지 리스트를 생성했습니다. 그런 다음 `plt.plot()` 함수를 사용하여 데이터를 시각화했습니다. 제목과 레이블을 추가하여 이해를 도왔습니다.

### 내부 구현 방법 이해

Matplotlib를 호출하면 다음과 같은 프로세스가 진행됩니다:

```mermaid
sequenceDiagram
  participant 유저
  participant Matplotlib
  participant 차트
  유저 ->> Matplotlib: 데이터 전달 (연도, 등록 수)
  Matplotlib ->> 차트: 차트 생성 요청
  차트 -->> Matplotlib: 차트 생성 완료
  Matplotlib -->> 유저: 차트 시각화
```

이 시퀀스 다이어그램은 데이터가 Matplotlib로 전달되어 최종적으로 차트를 생성하는 단계를 보여줍니다.

## Folium을 사용한 지도 생성

Folium을 사용하면 지도를 통해 데이터를 시각화할 수 있습니다. 다음은 간단한 지도를 만드는 예제입니다.

```python
import folium

# 지도 중심 좌표 설정 (예: 서울)
m = folium.Map(location=[37.5665, 126.9780], zoom_start=10)

# 지도에 마커 추가
folium.Marker([37.5665, 126.9780], popup='서울').add_to(m)

# 지도 보여주기
m.save('map.html')
```

이 코드에서는 서울을 중심으로 하는 지도를 만들었습니다. `folium.Marker()` 함수를 사용하여 서울에 마커를 추가했습니다.

## 결론

이번 챕터에서는 다양한 시각화 도구를 통해 데이터를 시각화하는 방법을 살펴보았습니다. 이를 통해 데이터의 인사이트를 쉽게 얻을 수 있으며, 효과적인 커뮤니케이션 수단으로 사용할 수 있습니다. 다음 챕터에서는 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)를 만들어 보겠습니다. 이 과정에서 시각화 라이브러리의 실질적인 사용법을 더 깊이 있게 알아볼 것입니다.
---
# Chapter 2: 지역별 자동차 등록 현황 페이지

이전 [제 1 장: 시각화 라이브러리 사용](01_시각화_라이브러리_사용.md)에서 다양한 시각화 도구를 사용하는 방법을 살펴보았습니다. 이번 장에서는 이 도구들을 활용하여 `지역별 자동차 등록 현황 페이지`를 만들어 보겠습니다.

## 동기 부여

지역별 자동차 등록 현황을 파악하는 것은 지역별 자동차 시장의 수요와 공급을 이해하는 데 중요한 역할을 합니다. 예를 들어, 서울과 같은 대도시에서 최근 몇 년간의 자동차 등록 데이터를 통해 이를 분석하고자 할 때, 지도와 차트를 사용하면 시각적으로 이해하기 쉬워집니다. 이를 통해 특정 지역의 트렌드를 분석하거나 사업 전략을 세우는 데 유용하게 활용할 수 있습니다.

## 주요 개념

### 스트림릿(Web 차트 시각화 도구)

스트림릿(Streamlit)은 데이터 앱을 손쉽게 만들 수 있는 파이썬 기반의 오픈 소스 프레임워크입니다. 특히 시각화 라이브러리와 함께 사용하면 웹 페이지 형태로 데이터를 효과적으로 전달할 수 있습니다.

### Plotly 및 Folium

- **Plotly**: 대화형 차트를 생성할 수 있는 라이브러리로, 다양한 차트 종류를 제공합니다.
- **Folium**: 지도 데이터를 기반으로 시각화할 때 유용한 라이브러리입니다.

## 사용 예제

스트림릿과 시각화 라이브러리를 사용하여 지역별 자동차 등록 현황 페이지를 만드는 방법을 살펴보겠습니다.

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '지역': ['서울', '부산', '대구', '인천'],
    '등록 수': [12000, 8500, 6400, 7700]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('지역별 자동차 등록 현황')
```

여기서는 pandas를 사용하여 간단한 예시 데이터를 준비하고 스트림릿을 사용하여 제목을 설정하였습니다. 

#### 2단계: Plotly 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 바 차트 생성
fig = px.bar(df, x='지역', y='등록 수', title='지역별 자동차 등록 수')

# 스트림릿을 사용하여 차트 앱에 표시
st.plotly_chart(fig)
```

이 단계에서는 Plotly의 `plotly.express` 모듈을 사용해 간단한 바 차트를 생성하고 스트림릿을 통해 웹 페이지에 표시합니다.

#### 3단계: Folium 지도 생성

```python
import folium
from streamlit_folium import st_folium

# 서울을 중심으로 지도 생성
m = folium.Map(location=[37.5665, 126.9780], zoom_start=7)

# 각 도시 위치에 마커 추가
for index, row in df.iterrows():
    folium.Marker(location=[37.5665 + index*0.1, 126.9780], 
                  popup=f"{row['지역']} ({row['등록 수']}대)").add_to(m)

# 스트림릿을 사용하여 지도 앱에 표시
st_folium(m)
```

여기서는 Folium을 이용해 서울을 중심으로 하는 지도를 생성하고 각 지역에 마커를 표시했습니다. 마커는 지역의 이름과 등록된 차량 수를 팝업으로 보여줍니다.

## 내부 구현 이해

스트림릿 특성과 Plotly 및 Folium의 해당 기능들을 사용하여 웹 페이지가 어떻게 작동하는지 이해해 봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly
  participant Folium
  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 차트 반환
  스트림릿 ->> Folium: 지도 생성 요청
  Folium -->> 스트림릿: 지도 반환
  스트림릿 -->> 사용자: 웹 페이지 출력
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 최종적으로 Plotly와 Folium을 통해 차트와 지도가 생성되는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿, Plotly 및 Folium을 활용하여 지역별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 익혔습니다. 이러한 시각적 도구들을 사용하여 데이터를 효율적으로 전달할 수 있는 방법을 이해했겠지만, 익숙하지 않다면 지도를 잘 보지 않거나 UX를 개선할 수도 있습니다.

다음 장에서는 [연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)를 만들어보겠습니다. 여기서는 시간에 따른 데이터를 시각화하는 방법을 더 자세히 알아볼 것입니다.
---
# Chapter 3: 연도별 자동차 등록 현황 페이지

이전 [지역별 자동차 등록 현황 페이지](02_지역별_자동차_등록_현황_페이지.md)에서는 특정 지역을 기준으로 자동차 등록 데이터를 시각화하는 방법을 알아보았습니다. 이번 장에서는 연도를 기준으로 데이터를 시각화하는 `연도별 자동차 등록 현황 페이지`를 만들어보겠습니다.

## 동기 부여

연도별 자동차 등록 현황을 분석하는 것은 시장의 성장 추세를 파악하거나 정책 효과를 평가하는 데 중요합니다. 예를 들어, 한 나라의 전체적인 자동차 등록 수가 매년 얼마나 증가했는지를 보고 싶다면, 향후 자동차 시장의 변화를 예측하는 데 큰 도움이 됩니다. 이러한 데이터는 그래프 등을 이용해 시각화하면 더욱 쉽게 이해할 수 있습니다.

## 주요 개념

### 스트림릿과 연도별 데이터

스트림릿(Streamlit)은 웹 기반 대화형 데이터 시각화를 쉽게 만들 수 있도록 지원합니다. 이를 통해 연도별 데이터를 손쉽게 확인할 수 있습니다.

### Plotly 라이브러리

Plotly는 대화형 시각화를 제공하는 강력한 도구로, 바 차트, 라인 차트 등을 쉽게 생성할 수 있습니다.

## 예제: 스트림릿과 Plotly로 연도별 데이터 시각화

### 예제 코드

#### 1단계: 데이터 준비 및 스트림릿 초기 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터 준비
data = {
    '연도': [2018, 2019, 2020, 2021, 2022],
    '자동차 등록 수': [120000, 150000, 180000, 210000, 250000]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('연도별 자동차 등록 현황')
```

위 코드는 pandas를 사용하여 연도별 자동차 등록 수에 대한 간단한 데이터를 준비하고, 스트림릿으로 웹 페이지 제목을 설정합니다.

#### 2단계: Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용하여 라인 차트 생성
fig = px.line(df, x='연도', y='자동차 등록 수', title='연도별 자동차 등록 차트')

# 스트림릿을 사용해 차트를 표시
st.plotly_chart(fig)
```

이 예제는 `plotly.express` 모듈을 사용하여 시간에 따른 자동차 등록 수를 라인 차트로 시각화한 것입니다. 그런 다음, 스트림릿을 사용하여 웹 페이지에 차트가 표시되도록 합니다.

## 내부 구현 방법 이해

스트림릿과 Plotly가 어떻게 상호작용하여 데이터를 시각화하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 입력
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 대화형 차트 반환
  스트림릿 -->> 사용자: 차트 표시
```

이 시퀀스 다이어그램은 데이터가 스트림릿으로 입력되어 Plotly의 차트 생성을 요청하고, 생성된 차트를 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 활용하여 연도별 자동차 등록 현황을 시각화하는 웹 페이지를 만드는 방법을 배웠습니다. 이를 통해 연도별 데이터의 변화를 쉽게 파악할 수 있게 되었으며, 이제 [브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)로 넘어가 상세히 학습해보겠습니다.
---
# Chapter 4: 브랜드별 자동차 판매 현황 페이지

이전 [제3장: 연도별 자동차 등록 현황 페이지](03_연도별_자동차_등록_현황_페이지.md)에서는 연도를 기준으로 자동차 등록 데이터를 시각화하는 방법을 배웠습니다. 이제 특정 브랜드 별로 자동차 판매 데이터를 시각화하여 제공하는 '브랜드별 자동차 판매 현황 페이지'를 만들어보겠습니다.

## 동기 부여

브랜드별 자동차 판매 현황을 파악하는 것은 각 브랜드의 시장 점유율을 이해하고 소비자 선호도를 분석하는 데 중요합니다. 예를 들어, 특정 브랜드의 자동차가 꾸준히 판매 증가세를 보인다면, 그 요인을 분석하여 마케팅 전략을 세울 수 있습니다. 스트림릿 웹 페이지를 활용하면 이러한 데이터를 효과적으로 시각화하고 전달할 수 있습니다.

## 주요 개념

### 스트림릿

스트림릿은 파이썬 기반의 애플리케이션을 손쉽게 만들 수 있는 오픈 소스 프레임워크로, 대화형 데이터 시각화에 특히 유용합니다.

### Plotly 라이브러리

Plotly는 대화형 그래프와 차트를 생성할 수 있는 강력한 도구로, 다양한 형태의 차트를 쉽게 만들 수 있습니다.

## 브랜드별 자동차 판매 현황 시각화하기

이제 스트림릿과 Plotly를 이용해 브랜드별 자동차 판매 현황을 시각화하는 방법을 알아보겠습니다.

### 데이터 준비 및 스트림릿 설정

```python
import streamlit as st
import pandas as pd

# 예시 데이터
data = {
    '브랜드': ['브랜드A', '브랜드B', '브랜드C'],
    '판매량': [1500, 2300, 1200]
}

df = pd.DataFrame(data)

# 웹 페이지 제목 설정
st.title('브랜드별 자동차 판매 현황')
```

위 코드는 브랜드별 판매량 데이터를 준비하고 스트림릿으로 웹 페이지 제목을 설정합니다. 각각의 브랜드에 대한 판매량을 간단한 데이터프레임으로 나타냈습니다.

### Plotly를 사용한 차트 생성

```python
import plotly.express as px

# Plotly를 사용한 파이 차트 생성
fig = px.pie(df, names='브랜드', values='판매량', title='브랜드별 판매 비율')

# 스트림릿으로 차트 출력
st.plotly_chart(fig)
```

위 코드에서는 Plotly의 `px.pie` 함수를 사용하여 브랜드별 판매 비율을 파이 차트로 시각화했습니다. 스트림릿에서는 이 차트를 웹 페이지에 직접 표시합니다.

## 내부 구현 이해

브랜드별 자동차 판매 데이터를 스트림릿 및 Plotly를 통해 어떻게 처리하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant Plotly

  사용자 ->> 스트림릿: 데이터 (브랜드 및 판매량)
  스트림릿 ->> Plotly: 차트 생성 요청
  Plotly -->> 스트림릿: 생성된 차트 반환
  스트림릿 -->> 사용자: 차트 출력
```

이 시퀀스 다이어그램은 사용자가 입력한 브랜드별 판매량 데이터를 스트림릿이 받아 Plotly를 통해 차트를 생성하여 웹 페이지에 표시하는 과정을 보여줍니다.

## 결론

이번 장에서는 스트림릿과 Plotly를 통해 브랜드별 자동차 판매 현황을 시각화하는 방법을 배웠습니다. 이를 통해 시장 분석 및 전략 수립에 보다 직관적으로 접근할 수 있습니다. 다음 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md) 장에서는 차량 구매와 관련된 FAQ를 다루는 페이지를 만들어보겠습니다. 여러분의 웹 서비스에 도움이 될 수 있도록 다양한 질문과 답변을 효과적으로 제공하는 방법을 배워보세요.
---
# Chapter 5: 차량 구매 FAQ 페이지

이전 [제 4 장: 브랜드별 자동차 판매 현황 페이지](04_브랜드별_자동차_판매_현황_페이지.md)에서는 특정 브랜드의 자동차 판매 데이터를 시각화하는 방법을 배웠습니다. 이번 장에서는 차량 구매와 관련된 중요한 질문 및 답변들을 다루는 `차량 구매 FAQ 페이지`를 만들어보겠습니다.

## 동기 부여

차량 구매 과정은 복잡할 수 있으며, 여러 궁금증과 과제를 유발할 수 있습니다. 다양한 브랜드와 모델, 금융 옵션, 서비스 및 유지관리 등 고려할 요소가 많습니다. 이때, 구매자들이 자주 질문하는 FAQ를 정리하여 제공하면 사용자가 보다 쉽게 필요한 정보를 찾고 중요한 결정을 내리는 데 큰 도움이 될 것입니다.

## 주요 개념

### 스트림릿을 활용한 FAQ 페이지

스트림릿(Streamlit)은 간편하게 웹 애플리케이션을 구축할 수 있는 도구입니다. 사용자는 이를 통해 인터랙티브한 데이터를 빠르게 시각화하고 배포할 수 있습니다.

### 정리된 FAQ 데이터를 통한 검색

사용자가 자주 묻는 질문들을 데이터베이스로 정리하여, 스트림릿을 통해 쉽게 검색할 수 있도록 만든 FAQ 페이지를 구축하려고 합니다.

## 예제: 스트림릿을 활용한 FAQ 페이지 만들기

### 예제 코드

#### 1단계: FAQ 데이터 준비 및 스트림릿 설정

```python
import streamlit as st

# 예시 FAQ 데이터 설정
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다."
}

# 웹 페이지 제목 설정
st.title('차량 구매 FAQ 페이지')
```

위 코드에서는 자주 묻는 질문과 답변을 딕셔너리 형태로 준비하고 스트림릿으로 웹 페이지 제목을 설정하였습니다.

#### 2단계: FAQ 데이터 검색 기능 구현

```python
# 질문 입력란 생성
question = st.text_input('궁금한 내용을 입력하세요')

# 질문에 대한 답변 출력
if question in faq_data:
    st.write(faq_data[question])
else:
    st.write('해당 질문에 대한 정보가 없습니다.')
```

사용자가 질문을 입력하면, 해당 질문에 대한 답변을 검색하여 화면에 보여줍니다. 질문이 데이터에 없는 경우, 정보가 없다는 메시지를 표시합니다.

## 내부 구현 이해

FAQ 페이지의 내부 작동 방식을 이해하기 위해 단계를 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 스트림릿
  participant FAQ데이터

  사용자 ->> 스트림릿: 질문 입력
  스트림릿 ->> FAQ데이터: 질문 검색 요청
  FAQ데이터 -->> 스트림릿: 답변 반환
  스트림릿 -->> 사용자: 답변 표시
```

이 시퀀스 다이어그램에서는 사용자가 입력한 질문을 스트림릿이 받아서 FAQ 데이터베이스를 검색한 후, 해당 질문에 대한 답변을 사용자에게 반환하는 과정을 보여줍니다.

## 결론

이 장에서는 스트림릿을 활용하여 차량 구매에 관련한 FAQ 페이지를 만드는 방법을 배웠습니다. 이를 통해 사용자는 차량 구매와 관련된 정보를 빠르고 편리하게 확인할 수 있을 것입니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서는 검색 및 페이지네이션 기능을 통해 사용자가 더 효율적으로 정보를 찾을 수 있도록 하는 기능을 구현해보겠습니다. 

이렇게 간단한 FAQ 페이지를 만들면서 웹 애플리케이션의 기본 개념을 이해하는 데 도움이 되길 바랍니다.
---
# Chapter 6: 검색 및 페이지네이션 기능

이전 [차량 구매 FAQ 페이지](05_차량_구매_faq_페이지.md)에서는 사용자가 자주 묻는 질문과 답변을 제공하는 방법을 배워보았습니다. 이번 장에서는 검색 및 페이지네이션 기능을 추가하여 사용자가 원하는 정보를 쉽게 찾을 수 있는 기능을 구현해보겠습니다.

## 동기 부여

검색 기능은 웹 페이지에서 사용자가 필요한 정보를 빠르게 찾을 수 있도록 도와줍니다. 예를 들어, 방대한 FAQ 데이터베이스가 있다면 사용자는 특정 키워드를 검색하여 관련 정보를 쉽고 빠르게 얻을 수 있습니다. 페이지네이션은 긴 목록을 여러 페이지에 나누어보여주는 기능으로, 사용자가 보다 편리하게 정보를 탐색할 수 있습니다. 이 두 기능을 결합하여 사용자가 FAQ 페이지를 효율적으로 이용할 수 있도록 해봅시다.

## 주요 개념

### 검색 기능

검색 기능은 사용자가 입력한 키워드를 기준으로 관련 데이터를 빠르게 찾아 제공합니다. 간단한 문자열 검색 방법을 사용하여 구현할 수 있습니다.

### 페이지네이션 기능

페이지네이션은 데이터를 한 번에 다 보여주지 않고, 여러 페이지로 나누어 보여주는 기능입니다. 이는 사용성이 매우 좋아지며, 특히 모바일 환경에서 유용합니다.

## 검색 및 페이지네이션 기능 구현하기

검색과 페이지네이션 기능을 구현하는 방법을 살펴보겠습니다.

### 1단계: 검색 기능 구현

```python
import streamlit as st

# 예시 FAQ 데이터 준비
faq_data = {
    "어떤 차를 선택해야 하나요?": "용도에 맞는 차량을 선택하는 것이 중요합니다.",
    "리스를 하는 것이 좋은 선택인가요?": "리스를 하면 초기 비용이 줄어드는 장점이 있습니다.",
    "자동차 보험은 어떻게 가입하나요?": "보험 회사에 직접 문의하시거나 온라인에서 가입할 수 있습니다."
}

# 검색 입력란 생성
search_query = st.text_input('검색어를 입력하세요')

# 검색 결과 출력
if search_query:
    results = {q: a for q, a in faq_data.items() if search_query in q}
    for q, a in results.items():
        st.write(f"질문: {q}")
        st.write(f"답변: {a}")
else:
    st.write('검색 결과가 없습니다.')
```

위 코드에서는 사용자가 입력한 검색어에 대해 FAQ 데이터에서 관련 결과를 찾아 반환합니다. `search_query` 안에 검색어가 포함된 질문을 필터링하여 해당되는 질문과 답변을 출력합니다.

### 2단계: 페이지네이션 기능 구현

```python
# 데이터 세트를 페이지 단위로 나누기
faq_list = list(faq_data.items())
items_per_page = 1  # 페이지당 항목 수
page_number = st.number_input('페이지 번호', min_value=1, max_value=(len(faq_list) // items_per_page) + 1)

# 해당 페이지의 데이터 출력
start = (page_number - 1) * items_per_page
end = start + items_per_page
for q, a in faq_list[start:end]:
    st.write(f"질문: {q}")
    st.write(f"답변: {a}")
```

페이지네이션 코드는 FAQ 데이터 항목을 정해진 수만큼 페이지 단위로 나누어서 보여줍니다. 사용자는 `페이지 번호` 입력란을 통해 다른 페이지를 선택할 수 있습니다.

## 내부 구현 이해

검색과 페이지네이션 기능이 실제로 어떻게 작동하는지 살펴보겠습니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 인터페이스
  participant 검색기능
  participant 페이지네이션

  사용자 ->> 인터페이스: 검색어 입력
  인터페이스 ->> 검색기능: 검색 요청
  검색기능 -->> 인터페이스: 검색 결과 반환
  사용자 ->> 인터페이스: 페이지 번호 선택
  인터페이스 ->> 페이지네이션: 데이터 요청
  페이지네이션 -->> 인터페이스: 해당 페이지 데이터 반환
  인터페이스 -->> 사용자: 데이터 표시
```

사용자가 인터페이스에서 검색어를 입력하면, 검색 기능이 해당 키워드를 기반으로 결과를 찾아 반환합니다. 페이지 번호 선택 시 페이지네이션 기능이 데이터베이스에서 해당 페이지의 데이터를 로드하여 사용자에게 표시합니다.

## 결론

이번 장에서는 검색 및 페이지네이션 기능을 통해 사용자가 FAQ 페이지에서 정보를 더욱 빠르고 효율적으로 찾을 수 있도록 하는 방법을 배웠습니다. 앞으로의 웹 애플리케이션 개발에 있어 정보 탐색의 편리함을 제공하는 데 큰 도움이 될 것입니다. 다음 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동으로 FAQ 데이터를 수집하는 모듈을 구현해보도록 하겠습니다. 이 기능을 통해 신규 정보를 계속적으로 업데이트할 수 있습니다.
---
# Chapter 7: FAQ 크롤링 모듈

이전 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md)에서 우리는 사용자가 정보를 효과적으로 찾아볼 수 있도록 검색 기능과 페이지네이션 기능을 구현했습니다. 이번 장에서는 자동차 관련 주요 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 파일로 저장하는 'FAQ 크롤링 모듈'을 만들어 보겠습니다.

## 동기 부여

최근 차량 구매를 고려 중인 사용자들은 여러 브랜드의 웹사이트를 방문하여 FAQ를 읽어보곤 합니다. 이때, 모든 사이트를 직접 방문하지 않고도 관련 정보를 한 곳에서 모아볼 수 있으면 시간과 노력을 절약할 수 있습니다. FAQ 크롤링 모듈을 사용하면 다양한 자동차 브랜드의 웹사이트로부터 FAQ 데이터를 자동으로 수집하여 업데이트된 정보를 제공할 수 있습니다.

## 주요 개념

### 크롤링

크롤링이란 웹 페이지를 자동으로 탐색하고 원하는 데이터를 추출하는 과정입니다. 웹 크롤러는 이 작업을 수행하는 프로그램으로, URL을 순차적으로 방문하여 데이터를 수집합니다.

### JSON 저장

수집된 FAQ 데이터를 JSON 형식으로 저장하면, 데이터 구조를 효율적으로 관리할 수 있습니다. JSON은 읽고 쓰기 쉬운 형식의 경량 데이터 교환 포맷입니다.

## FAQ 크롤링 모듈 사용하기

자동차 브랜드의 웹사이트에서 FAQ 데이터를 크롤링하는 방법을 단계별로 살펴보겠습니다.

### 1단계: 간단한 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# URL 지정
url = 'http://example.com/faq'

# 웹 페이지 요청
response = requests.get(url)

# HTML 파싱
soup = BeautifulSoup(response.text, 'html.parser')
```

위 코드는 크롤러의 기초를 나타냅니다. `requests`를 사용하여 지정한 URL의 데이터를 요청하고, `BeautifulSoup`으로 HTML을 파싱합니다. 이 과정이 크롤링의 시작입니다.

### 2단계: FAQ 데이터 추출

```python
faqs = []

# FAQ 항목 추출 예시
for item in soup.find_all('div', class_='faq-item'):
    question = item.find('h2').get_text()
    answer = item.find('p').get_text()
    faqs.append({'question': question, 'answer': answer})
```

이 코드에서는 `soup.find_all()`을 사용하여 FAQ 항목을 추출합니다. `find` 함수는 HTML 구조를 탐색하여 질문과 답변을 얻는 데 사용됩니다.

### 3단계: 데이터 저장

```python
import json

# JSON 파일로 저장
with open('faqs.json', 'w', encoding='utf-8') as f:
    json.dump(faqs, f, ensure_ascii=False, indent=4)
```

추출된 FAQ 데이터를 JSON 파일로 저장합니다. 이를 통해 데이터를 효율적으로 관리하고 접근할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 과정을 시퀀스 다이어그램으로 간단히 이해해봅시다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant JSON파일

  사용자 ->> 크롤러: URL 제공
  크롤러 ->> 웹사이트: 페이지 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> JSON파일: 데이터 저장
  사용자 -->> JSON파일: FAQ 데이터 접근
```

크롤러가 사용자가 제공한 URL로 웹사이트에 요청을 보내고, FAQ 데이터를 추출하여 JSON 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 인터넷 상의 다양한 자동차 브랜드 웹사이트로부터 FAQ 데이터를 자동으로 수집하고 이를 JSON 형식으로 저장하는 FAQ 크롤링 모듈을 구현하는 방법을 살펴보았습니다. 이제 다음 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 자동차 판매 실적 데이터를 수집하는 방법을 알아보겠습니다. 이 모든 과정은 데이터를 효율적으로 수집하고 사용자에게 중요한 정보를 제공하는 기반을 마련합니다.
---
# Chapter 8: 자동차 판매 실적 크롤링 모듈

이전 [FAQ 크롤링 모듈](07_faq_크롤링_모듈.md)에서는 자동차 관련 웹사이트에서 FAQ 데이터를 자동으로 수집하고 저장하는 방법을 배웠습니다. 이번 장에서는 `자동차 판매 실적 크롤링 모듈`을 구축하여 다나와 자동차 판매 실적 페이지로부터 데이터를 크롤링하고, 이를 CSV 파일로 저장하는 방법을 알아보겠습니다.

## 동기 부여

자동차 판매 실적을 분석하는 것은 시장 동향을 파악하고, 신차 개발 및 판매 전략을 수립하는 데 중요한 역할을 합니다. 만약 특정 브랜드의 판매 실적이 급격히 증가했다면, 그 이유를 파악하여 다른 브랜드에도 적용할 수 있는 영감을 얻을 수 있습니다. 이때 매번 웹사이트를 방문해 수작업으로 데이터를 정리하는 대신, 크롤러를 사용하면 실적 데이터를 자동으로 수집 및 저장할 수 있습니다.

## 주요 개념

### 웹 크롤링

웹 크롤링은 특정 웹사이트의 정보를 자동으로 수집하는 방법입니다. 일반적으로 원하는 페이지의 HTML 코드를 가져와 필요한 데이터를 추출합니다. 다나와의 판매 실적 페이지를 탐색하고 데이터를 추출할 수 있습니다.

### CSV 형식

CSV는 데이터를 쉽고 효율적으로 저장할 수 있는 포맷입니다. 각 행은 하나의 데이터 레코드를 나타내며, 각 값은 쉼표로 구분됩니다. 추출한 판매 실적 데이터를 CSV 파일에 저장하면 데이터를 분석하고 사용할 때 유용합니다.

## 자동차 판매 실적 크롤링 모듈 구현하기

다나와의 자동차 판매 실적 데이터를 수집하기 위한 방법을 살펴보겠습니다.

### 1단계: 기본 크롤러 설계

```python
import requests
from bs4 import BeautifulSoup

# 판매 실적 페이지 URL
url = 'http://example.com/sales'

# 웹 페이지 요청 및 HTML 파싱
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')
```

이 코드는 requests를 사용하여 특정 URL에서 HTML 페이지를 가져오고, BeautifulSoup을 통해 HTML을 파싱하는 기본 크롤러의 구조를 설명합니다. 이 과정은 크롤링의 첫 단계를 나타냅니다.

### 2단계: 판매 실적 데이터 추출

```python
sales_data = []

# 테이블에서 데이터 추출
for row in soup.find_all('tr'):
    cols = row.find_all('td')
    if cols:
        brand = cols[0].get_text()
        sales = cols[1].get_text()
        sales_data.append({'브랜드': brand.strip(), '판매량': sales.strip()})
```

위 코드는 HTML 테이블에서 브랜드와 판매량 데이터를 추출하는 예를 보여줍니다. 여기서는 `find_all`을 통해 테이블 행과 열을 순회하며 데이터를 모읍니다.

### 3단계: 데이터 CSV 파일 저장

```python
import csv

# CSV 파일로 데이터 저장
with open('sales_data.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames=['브랜드', '판매량'])
    writer.writeheader()
    writer.writerows(sales_data)
```

크롤링한 데이터를 CSV 파일로 저장합니다. 이를 통해 데이터를 쉽게 접근하고 여러 도구에서 활용할 수 있습니다.

## 내부 구현 이해

크롤러가 작동하는 전체 과정을 이해하기 위한 단계별 설명입니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant 크롤러
  participant 웹사이트
  participant CSV파일

  사용자 ->> 크롤러: URL 설정
  크롤러 ->> 웹사이트: 데이터 요청
  웹사이트 -->> 크롤러: HTML 반환
  크롤러 ->> CSV파일: 가공한 데이터 저장
  사용자 -->> CSV파일: 실적 데이터 분석
```

크롤러가 웹사이트에 HTTP 요청을 보내고, HTML 응답에서 데이터를 추출 및 처리하여 CSV 파일에 저장하는 과정을 보여줍니다.

## 결론

이번 장에서는 자동차 판매 실적을 다나와 웹사이트에서 자동으로 수집하고 이를 CSV 형식으로 저장하는 방법을 알아보았습니다. 이러한 크롤링 모듈은 데이터 분석 및 비즈니스 전략 수립에 필수적인 요소입니다. 다음은 데이터베이스에 수집한 데이터를 효율적으로 저장하고 관리하는 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md) 입니다. 이를 통해 데이터 관리의 효율성을 더욱 높일 수 있습니다.
---
# Chapter 9: 데이터베이스 삽입 모듈

이전 [자동차 판매 실적 크롤링 모듈](08_자동차_판매_실적_크롤링_모듈.md)에서는 다나와 웹사이트에서 자동차 판매 실적 데이터를 수집하여 CSV 파일로 저장하는 방법을 배웠습니다. 이번 장에서는 `데이터베이스 삽입 모듈`을 구현하여 CSV 파일의 데이터를 MySQL 데이터베이스에 자동으로 업로드하는 방법을 알아보겠습니다.

## 동기 부여

현대의 많은 애플리케이션은 데이터를 보다 효율적이고 안정적으로 관리하기 위해 데이터베이스를 사용합니다. 특히 대량의 데이터를 처리할 때는 CSV 파일에 저장하는 것보다 데이터베이스에 저장하는 것이 효율적입니다. 이번 데이터베이스 삽입 모듈은 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입함으로써 데이터를 보다 구조적이고 신뢰성 있게 관리할 수 있도록 해줍니다.

## 주요 개념

### CSV 파일 처리

CSV 파일은 간단한 데이터 포맷이며 텍스트 데이터를 쉼표로 구분하여 저장합니다. 파이썬의 `csv` 모듈을 활용하면 CSV 파일의 데이터를 손쉽게 읽어올 수 있습니다.

### MySQL 데이터베이스 연결

MySQL 데이터베이스는 관계형 데이터베이스로, 대량의 데이터를 구조적으로 저장할 수 있게 해줍니다. 파이썬에서는 `MySQL Connector` 라이브러리를 사용하여 데이터베이스에 연결하고 데이터를 삽입할 수 있습니다.

## 데이터베이스 삽입 모듈 사용하기

이제 CSV 파일에서 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 단계별로 살펴보겠습니다.

### 1단계: CSV 파일 읽기

```python
import csv

# CSV 파일 읽기
data = []
with open('sales_data.csv', mode='r', encoding='utf-8') as file:
    reader = csv.DictReader(file)
    for row in reader:
        data.append(row)
```

이 코드에서는 `csv.DictReader`를 사용하여 CSV 파일의 데이터를 읽어 목록에 저장합니다. 각 행은 딕셔너리로 변환되어 `data` 리스트에 추가됩니다.

### 2단계: 데이터베이스 연결 및 데이터 삽입

```python
import mysql.connector

# 데이터베이스 연결 설정
connection = mysql.connector.connect(
    host='localhost',
    user='user',
    password='password',
    database='car_sales_db'
)

cursor = connection.cursor()

# 데이터 삽입
for entry in data:
    sql = "INSERT INTO sales (brand, sales) VALUES (%s, %s)"
    cursor.execute(sql, (entry['브랜드'], entry['판매량']))

# 변경사항 저장
connection.commit()
```

위 코드에서는 `mysql.connector`를 사용하여 MySQL 데이터베이스에 연결한 후, 각 데이터 항목을 반복적으로 삽입합니다. 삽입 문법 `INSERT INTO`를 통해 데이터베이스에 데이터를 추가합니다. 마지막으로, `commit` 메서드로 변경 사항을 저장합니다.

## 내부 구현 이해

데이터베이스 삽입 모듈이 어떻게 작동하는지 이해하기 쉽게 시퀀스 다이어그램으로 설명하겠습니다.

```mermaid
sequenceDiagram
  participant User
  participant CSV파일
  participant Python프로그램
  participant MySQLDB

  User ->> Python프로그램: CSV 파일 읽기 요청
  Python프로그램 ->> CSV파일: 데이터 읽기
  CSV파일 -->> Python프로그램: 데이터 반환
  Python프로그램 ->> MySQLDB: 데이터베이스에 데이터 삽입
  MySQLDB -->> Python프로그램: 삽입 완료
  Python프로그램 -->> User: 완료 메시지 제공
```

이 다이어그램은 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 과정을 확인할 수 있습니다.

## 결론

이번 장에서는 CSV 파일로부터 데이터를 읽어와 MySQL 데이터베이스에 삽입하는 방법을 배웠습니다. 이를 통해 데이터를 보다 구조적으로 관리하고 활용할 수 있습니다. 다음 [데이터베이스 연결 설정](10_데이터베이스_연결_설정.md)에서는 데이터베이스 연결 설정에 대해 더욱 상세히 알아보겠습니다. 데이터베이스와의 원활한 연결은 안정적인 데이터 처리에 필수적입니다. 

---

이번 과정을 통해 데이터베이스 활용 능력이 한 단계 업그레이드될 것입니다. 지속적인 실습을 통해 데이터 관리자 및 개발자로서의 역량을 키워보세요!

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 10: 데이터베이스 연결 설정`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:35:32,813 - INFO - RESPONSE (from cache): # 제10장: 데이터베이스 연결 설정

이전 [데이터베이스 삽입 모듈](09_데이터베이스_삽입_모듈.md)에서 우리는 CSV 파일로부터 읽은 데이터를 MySQL 데이터베이스에 삽입하는 방법을 배웠습니다. 이번 장에서는 `데이터베이스 연결 설정`에 대해 자세히 알아보겠습니다. 이는 MySQL 데이터베이스와의 안정적인 연결을 위해 반드시 필요한 설정입니다.

## 동기 부여

데이터를 효과적으로 관리하기 위해서는 데이터베이스와의 연결이 매우 중요합니다. 데이터베이스 연결 설정이 제대로 되어 있지 않으면 데이터를 저장하거나 불러올 때 문제가 발생할 수 있습니다. 예를 들어, 자동차 판매 실적 데이터를 분석하고자 할 때 MySQL 데이터베이스에 연결할 수 없거나 연결이 불안정하면 분석에 차질이 생깁니다. 안정적인 데이터베이스 연결을 위해 필요한 주요 설정과 절차를 배워봅시다.

## 주요 개념

### MySQL 데이터베이스 서버

MySQL은 인기 있는 오픈 소스 데이터베이스 관리 시스템으로, 데이터를 효율적으로 저장하고 검색할 수 있습니다. 이를 활용하기 위해서는 데이터베이스 서버와의 연결을 적절히 설정해야 합니다.

### 연결 문자열

연결 문자열은 데이터베이스 서버의 주소, 사용자 이름, 비밀번호 등 연결에 필요한 정보를 포함합니다. Python의 `mysql.connector` 라이브러리를 통해 MySQL에 연결할 수 있습니다. 이를 통해 원하는 데이터를 가져오거나 저장할 수 있습니다.

## 데이터베이스 연결 설정

데이터베이스 연결을 설정하는 방법을 단계적으로 살펴보겠습니다.

### 1단계: MySQL Connector 설치

먼저 MySQL Connector를 설치해야 합니다. 터미널이나 커맨드 라인에서 다음 명령어를 사용하세요.

```bash
pip install mysql-connector-python
```

이 명령어를 실행하면 MySQL 데이터베이스와의 연결을 위한 라이브러리가 설치됩니다.

### 2단계: 데이터베이스 연결 설정 코드

MySQL에 연결하려면 다음과 같이 연결 설정을 할 수 있습니다.

```python
import mysql.connector

# MySQL 데이터베이스에 연결
connection = mysql.connector.connect(
    host='localhost',     # 데이터베이스 서버 주소
    user='user',          # 사용자 이름
    password='password',  # 비밀번호
    database='my_database' # 사용할 데이터베이스 이름
)

# 연결 확인
if connection.is_connected():
    print("연결 성공!")
```

이 코드는 MySQL 데이터베이스와의 연결을 설정하는 가장 기본적인 방법입니다. 데이터베이스 서버 주소, 사용자 이름, 비밀번호, 데이터베이스 이름을 올바르게 입력하면 됩니다.

### 내부 작동 방식 이해

데이터베이스 연결의 내부 작동 방식을 이해하는 것은 중요합니다. 다음은 연결 설정이 이루어지는 과정을 설명합니다.

```mermaid
sequenceDiagram
  participant 사용자
  participant Python프로그램
  participant MySQLDB

  사용자 ->> Python프로그램: 연결 설정 요청
  Python프로그램 ->> MySQLDB: 연결 시도
  MySQLDB -->> Python프로그램: 연결 승인
  Python프로그램 -->> 사용자: 연결 성공 메시지
```

이 다이어그램은 사용자로부터 연결 설정 요청을 받아, Python 프로그램이 MySQL 데이터베이스에 연결을 시도하고, 연결 여부를 사용자에게 알리는 과정을 보여줍니다.

## 결론

이번 장에서는 MySQL 데이터베이스와의 연결을 설정하는 방법에 대해 학습했습니다. MySQL Connector를 설치하고, 필요한 정보를 사용하여 연결을 설정하였습니다. 안정적인 연결 설정을 통해 데이터를 보다 효율적으로 관리할 수 있습니다. 다음 [검색 및 페이지네이션 기능](06_검색_및_페이지네이션_기능.md) 장에서는 데이터를 효율적으로 탐색할 수 있는 검색 및 페이지네이션 기능을 구현하는 방법을 배워보겠습니다.

데이터베이스 활용의 기초를 다지며 계속해서 발전해 나가시길 바랍니다!
2025-06-29 20:52:38,808 - INFO - PROMPT: 
Analyze the following codebase for the project 'SKN10-FINAL-1Team'.

Available files (total 51):
- 0 # README.md
- 1 # backend/accounts/__init__.py
- 2 # backend/accounts/admin.py
- 3 # backend/accounts/apps.py
- 4 # backend/accounts/migrations/0001_initial.py
- 5 # backend/accounts/migrations/__init__.py
- 6 # backend/accounts/models.py
- 7 # backend/accounts/serializers.py
- 8 # backend/accounts/urls.py
- 9 # backend/accounts/views.py
- 10 # backend/config/__init__.py
- 11 # backend/config/asgi.py
- 12 # backend/config/settings.py
- 13 # backend/config/urls.py
- 14 # backend/config/wsgi.py
- 15 # backend/conversations/__init__.py
- 16 # backend/conversations/admin.py
- 17 # backend/conversations/apps.py
- 18 # backend/conversations/migrations/0001_initial.py
- 19 # backend/conversations/migrations/0002_checkpoint_checkpointblob_checkpointmigration_and_more.py
- 20 # backend/conversations/migrations/0003_delete_checkpoint_delete_checkpointblob_and_more.py
- 21 # backend/conversations/migrations/__init__.py
- 22 # backend/conversations/models.py
- 23 # backend/conversations/serializers.py
- 24 # backend/conversations/urls.py
- 25 # backend/conversations/views.py
- 26 # backend/knowledge/__init__.py
- 27 # backend/knowledge/admin.py
- 28 # backend/knowledge/apps.py
- 29 # backend/knowledge/migrations/0001_initial.py
- 30 # backend/knowledge/migrations/0002_alter_summarynewskeywords_options_and_more.py
- 31 # backend/knowledge/migrations/__init__.py
- 32 # backend/knowledge/models.py
- 33 # backend/knowledge/views.py
- 34 # backend/manage.py
- 35 # backend/mlops/__init__.py
- 36 # backend/mlops/admin.py
- 37 # backend/mlops/apps.py
- 38 # backend/mlops/migrations/0001_initial.py
- 39 # backend/mlops/migrations/__init__.py
- 40 # backend/mlops/models.py
- 41 # backend/mlops/modules/nodes/__init__.py
- 42 # backend/mlops/views.py
- 43 # backend/path/to/your/app/Makefile
- 44 # backend/path/to/your/app/README.md
- 45 # backend/path/to/your/app/src/agent/__init__.py
- 46 # backend/path/to/your/app/src/agent/graph.py
- 47 # fastapi_server/README.md
- 48 # fastapi_server/__init__.py
- 49 # fastapi_server/agent/__init__.py
- 50 # fastapi_server/agent/agent2.py

Full context of all files:
--- File Index 0: README.md ---
## TSKN10-FINAL-1Team

## 프로젝트 개요
이 프로젝트는 사용자가 채팅으로 업무를 요청할 수 있는 **지능형 사내 업무 보조 챗봇 시스템**입니다. 사용자의 질문 의도를 **AI 에이전트 총괄 시스템 LangGraph Supervisor**이 파악하여 적절한 전문 에이전트에게 작업을 분배합니다. 마치 오케스트라의 지휘자처럼, 슈퍼바이저는 전체적인 요청을 보고 적임자(에이전트)를 찾아 지시를 내립니다. 예를 들어, 회사 규정 관련 질문은 **문서 검색 전문 에이전트 RAG Agent**에게, 데이터 분석 요청은 **데이터 분석 전문 에이전트 Analytics Agent**에게 전달됩니다. 코드 관련 질문은 **코드 분석 에이전트**가 담당할 수 있습니다. 모든 데이터는 **애플리케이션 데이터 설계도 Django 모델**에 따라 체계적으로 저장되며, 프론트엔드는 **실시간 AI 통신 게이트웨이 FastAPI & WebSocket**를 통해 AI 시스템과 매끄럽게 연결되어 AI 답변 생성 과정을 실시간으로 보여줍니다 (스트리밍). 이 시스템은 복잡한 내부 구조를 몰라도 사용자가 AI를 사람과 대화하듯 편안하게 사용할 수 있도록 설계되었습니다.

## 핵심 기능
*   **AI 에이전트 총괄 시스템 LangGraph Supervisor**: 사용자의 자연어 요청을 분석하여 가장 적합한 전문 에이전트 노드에게 작업을 라우팅하는 역할을 합니다. 슈퍼바이저는 특정 '업무 지침서'(Prompt)를 바탕으로 다음 에이전트를 결정합니다.
*   **문서 검색 전문 에이전트 RAG Agent**: 회사 내부 문서(정책, 매뉴얼, 회의록 등)에 대한 사용자의 질문에 답변합니다. Retrieval-Augmented Generation (RAG) 기술을 사용하며, 질문과 관련 있는 문서 조각을 **임베딩**과 **벡터 데이터베이스 Pinecone**를 통해 먼저 검색한 뒤(Retrieval), 그 내용을 바탕으로 답변을 생성합니다(Generation).
*   **데이터 분석 전문 에이전트 Analytics Agent**: 데이터베이스에 저장된 데이터를 분석하고 통찰력을 제공합니다. 사용자의 자연어 질문을 컴퓨터가 이해하는 SQL 쿼리로 변환하고 데이터베이스에서 실행하여 결과를 가져옵니다. 결과는 텍스트로 요약되거나 **Mermaid 차트** 코드로 시각화됩니다. (논의를 통해 시계열 예측보다는 이상치 모델링 방향으로 고려되었습니다).
*   **코드 분석 에이전트 Code Agent** (논의 중): GitHub 저장소나 사내 코드 베이스의 내용을 분석하고 질의응답하는 것을 목표로 합니다. 코드의 오류 부분을 파악하거나, 특정 함수의 사용 위치나 상호작용하는 파일을 알려주고, 도큐멘테이션을 참고하여 질문에 답변할 수 있습니다. 필요에 따라 코드 변환 기능도 포함될 수 있습니다. 사용자의 코드 언어 버전 탐지 및 해당 버전에 맞는 답변 제공이 중요하게 고려됩니다.
*   **실시간 AI 통신 게이트웨이 FastAPI & WebSocket**: 사용자의 브라우저과 AI 시스템을 연결하는 통신 다리 역할을 합니다. **WebSocket**을 통해 한 번 연결되면 끊기지 않는 '전화 통화'처럼 실시간으로 데이터를 주고받으며, **FastAPI**가 이 통신을 효율적으로 처리합니다. 이를 통해 AI 답변 생성 과정을 실시간 스트리밍으로 사용자에게 보여줍니다.
*   **외부 데이터 수집 및 처리 ETL**: AI 에이전트가 사용할 데이터(고객 정보, 뉴스, 문서 등)를 외부에서 가져와(Extract) 시스템이 사용하기 좋은 형태로 가공한 뒤(Transform), 데이터베이스나 벡터 저장소에 저장하는(Load) 자동화된 스크립트(파이프라인)를 의미합니다. tools 및 lambda 폴더의 파이썬 스크립트가 이 역할을 수행합니다. (CSV 파일의 고객 데이터, 최신 뉴스, 문서 파일(PDF, HTML) 텍스트 및 벡터 변환 등을 처리합니다).
*   **프론트엔드 채팅 UI**: 사용자가 AI와 직접 소통하고 눈으로 볼 수 있는 '얼굴'입니다. 메시지 입력창, 대화 내용이 보이는 말풍선(메시지 목록), 과거 대화 목록을 보여주는 사이드바 등으로 구성됩니다. React(Next.js)의 useState 기능을 사용하여 UI 상태를 관리하고, 서버로부터 받은 메시지를 화면에 그려줍니다.

## 기술 스택
*   **백엔드/AI**:
    *   웹 프레임워크: ![Django](https://img.shields.io/badge/Django-092E20?style=flat-square&logo=django&logoColor=white) (애플리케이션 데이터 설계 및 전통적인 API 연동)
    *   AI 통신 게이트웨이: ![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=flat-square&logo=fastapi&logoColor=white) (실시간 통신 처리 및 에이전트 시스템 연동)
    *   실시간 통신: ![WebSocket](https://img.shields.io/badge/WebSocket-4353FF?style=flat-square&logo=socketdotio&logoColor=white)
    *   AI 오케스트레이션: ![LangGraph](https://img.shields.io/badge/LangGraph-FF5A5F?style=flat-square&logo=langchain&logoColor=white) (다양한 에이전트들의 작업 흐름 및 협업 설계)
    *   LLM: ![GPT](https://img.shields.io/badge/GPT-74aa9c?style=flat-square&logo=openai&logoColor=white) (주요 모델), 필요에 따라 ![Local LLM](https://img.shields.io/badge/Local_LLM-4B32C3?style=flat-square&logo=artificial-intelligence&logoColor=white) (Qwen3 32B 등) 서빙 (Runpod 활용), 다른 오픈소스 모델 (Mistral 등) 및 상용 모델 (Claude, Gemini) 고려.
    *   임베딩 모델: ![OpenAI Embeddings](https://img.shields.io/badge/OpenAI_Embeddings-74aa9c?style=flat-square&logo=openai&logoColor=white) (문서 및 쿼리 벡터 생성)
    *   벡터 데이터베이스: ![Pinecone](https://img.shields.io/badge/Pinecone-000000?style=flat-square&logo=pinecone&logoColor=white) (문서 임베딩 저장 및 검색), ![PostgreSQL](https://img.shields.io/badge/PostgreSQL_pgvector-4169E1?style=flat-square&logo=postgresql&logoColor=white) (논의됨). 하이브리드 서치 및 리랭킹 기능 고려.
    *   관계형 데이터베이스: ![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?style=flat-square&logo=postgresql&logoColor=white) (사용자 정보, 채팅 내용, 분석 결과, 정형 데이터셋 등 저장).
    *   객체 스토리지: ![AWS S3](https://img.shields.io/badge/AWS_S3-569A31?style=flat-square&logo=amazons3&logoColor=white) (업로드 파일, 원본 문서, 모델 저장 등).
    *   ETL 스크립트: ![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=white) ![AWS Lambda](https://img.shields.io/badge/AWS_Lambda-FF9900?style=flat-square&logo=awslambda&logoColor=white) (requests, psycopg2, tqdm, pdfplumber, beautifulsoup, OpenAI API 등 활용).
    *   배포: ![AWS EC2](https://img.shields.io/badge/AWS_EC2-FF9900?style=flat-square&logo=amazonec2&logoColor=white), ![Runpod](https://img.shields.io/badge/Runpod-6C47FF?style=flat-square&logo=runpod&logoColor=white) (VLLM 서빙).
    *   툴 호출 표준: ![MCP](https://img.shields.io/badge/MCP-007ACC?style=flat-square&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAqFBMVEX///8AAP8AgP8AgIAAgIBVVaoAYIBAgIBAYGBAYIBJbYBJbXFJbW1Nc21NbnZNbnFNbm1QcXFQcXZQcW1SdG1SdHFSdG1VVXFVVXZVVXFVVWpVVW1VVW1VVW1VVW1VVW1VVW1VVW1VVW1VVW1VVW1VVW1VVW1VVW1VVW1)

## 팀원 및 역할 (Roles and Responsibilities)
| 이름 | 이미지 | 역할 |
| ------ | ------ | ------ |
| **신정우** (PM) | <img src="./img/신정우.png" width="150"> | 데이터 분석 에이전트 개발 및 머신러닝 모델링 (프로젝트 기획 및 일정/이슈 관리 포함) |
| **경규휘** | <img src="./img/경규희.png" width="150"> | 문서 검색 전문 에이전트 (RAG) 개발 및 데이터 검색 (Product 문서 데이터 수집 및 RAG 테스트 포함) |
| **남궁승원** | <img src="./img/남궁승원.png" width="150"> | 데이터 분석 에이전트 개발 및 머신러닝 모델링 (ML 부분 포함) (기술 문서 및 사내 정책 문서 데이터 수집 포함) |
| **이태수** | <img src="./img/이태수.png" width="150"> | 시장 조사 및 문서 검색 전문 에이전트 (RAG) 개발 (뉴스 수집 API 개발 및 이슈/동향 수집 포함) |
| **황인호** | <img src="./img/인호.jpeg" width="150"> | AI 에이전트 총괄 시스템 (LangGraph Supervisor), 코드 에이전트, 프론트엔드 개발 (ERD, 배포, 데이터 조회 프로그램 개발 포함) |

## 문서 구조 (Chapters)
프로젝트의 핵심 구성 요소 및 개발 과정에 대한 자세한 내용은 다음 장에서 확인할 수 있습니다.
1.  [애플리케이션 데이터 설계도 (Django 모델)](docs/01_애플리케이션_데이터_설계도__django_모델__.md)
2.  [프론트엔드 채팅 UI](docs/02_프론트엔드_채팅_ui_.md)
3.  [실시간 AI 통신 게이트웨이 (FastAPI & WebSocket)](docs/03_실시간_ai_통신_게이트웨이__fastapi___websocket__.md)
4.  [AI 에이전트 총괄 시스템 (LangGraph Supervisor)](docs/04_ai_에이전트_총괄_시스템__langgraph_supervisor__.md)
5.  [데이터 분석 전문 에이전트 (Analytics Agent)](docs/05_데이터_분석_전문_에이전트__analytics_agent__.md)
6.  [문서 검색 전문 에이전트 (RAG Agent)](docs/06_문서_검색_전문_에이전트__rag_agent__.md)
7.  [외부 데이터 수집 및 처리 (ETL)](docs/07_외부_데이터_수집_및_처리__etl__.md)
8.  [프론트엔드-데이터베이스 연동](docs/08_프론트엔드_데이터베이스_연동_.md)

## 협업 및 일정 관리
*   **회의**: 정기적인 팀 회의를 통해 프로젝트 진행 상황 공유 및 다음 업무 논의.
*   **회의록**: Notion, ClovaNote 등을 활용하여 회의 내용, 결정 사항, 개별 업무 내용 기록 및 공유.
*   **코드 관리**: Git Repository를 사용하여 코드 버전 관리 및 협업.
*   **일정/이슈 관리**: GitHub Project를 활용하여 업무 이슈 등록, 담당자 배정, 진행 상황 추적.
*   **커뮤니케이션**: Discord, KakaoTalk 등을 활용하여 실시간 소통.
*   **기술 스터디**: LangGraph, LangSmith, Pinecone 사용법 등 핵심 기술에 대한 팀원 간 스터디 진행.


--- File Index 1: backend/accounts/__init__.py ---


--- File Index 2: backend/accounts/admin.py ---
from django.contrib import admin
from django.contrib.auth.admin import UserAdmin as BaseUserAdmin
from django.utils.translation import gettext_lazy as _

from .models import Organization, User


@admin.register(Organization)
class OrganizationAdmin(admin.ModelAdmin):
    list_display = ('name', 'created_at')
    search_fields = ('name',)
    ordering = ('name',)


@admin.register(User)
class UserAdmin(BaseUserAdmin):
    list_display = ('email', 'name', 'org', 'role', 'is_staff', 'is_active')
    list_filter = ('is_staff', 'is_superuser', 'is_active', 'role', 'org')
    search_fields = ('email', 'name')
    ordering = ('email',)
    
    fieldsets = (
        (None, {'fields': ('email', 'password')}),
        (_('Personal info'), {'fields': ('name', 'org', 'role')}),
        (_('Permissions'), {
            'fields': ('is_active', 'is_staff', 'is_superuser', 'groups', 'user_permissions'),
        }),
        (_('Important dates'), {'fields': ('last_login', 'created_at')}),
    )
    add_fieldsets = (
        (None, {
            'classes': ('wide',),
            'fields': ('email', 'password1', 'password2', 'org', 'role'),
        }),
    )
    readonly_fields = ('created_at',)


--- File Index 3: backend/accounts/apps.py ---
from django.apps import AppConfig


class AccountsConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'accounts'


--- File Index 4: backend/accounts/migrations/0001_initial.py ---
# Generated by Django 5.2.1 on 2025-05-29 05:36

import django.db.models.deletion
import uuid
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('auth', '0012_alter_user_first_name_max_length'),
    ]

    operations = [
        migrations.CreateModel(
            name='Organization',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('name', models.CharField(max_length=255, unique=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
            ],
            options={
                'db_table': 'organizations',
                'ordering': ['name'],
            },
        ),
        migrations.CreateModel(
            name='User',
            fields=[
                ('password', models.CharField(max_length=128, verbose_name='password')),
                ('is_superuser', models.BooleanField(default=False, help_text='Designates that this user has all permissions without explicitly assigning them.', verbose_name='superuser status')),
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('email', models.EmailField(max_length=254, unique=True)),
                ('name', models.CharField(blank=True, max_length=100)),
                ('role', models.CharField(choices=[('admin', 'Admin'), ('engineer', 'Engineer'), ('analyst', 'Analyst'), ('guest', 'Guest')], default='guest', max_length=20)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('last_login', models.DateTimeField(blank=True, null=True)),
                ('is_active', models.BooleanField(default=True)),
                ('is_staff', models.BooleanField(default=False)),
                ('groups', models.ManyToManyField(blank=True, help_text='The groups this user belongs to. A user will get all permissions granted to each of their groups.', related_name='user_set', related_query_name='user', to='auth.group', verbose_name='groups')),
                ('user_permissions', models.ManyToManyField(blank=True, help_text='Specific permissions for this user.', related_name='user_set', related_query_name='user', to='auth.permission', verbose_name='user permissions')),
                ('org', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='users', to='accounts.organization')),
            ],
            options={
                'db_table': 'users',
                'ordering': ['email'],
            },
        ),
    ]


--- File Index 5: backend/accounts/migrations/__init__.py ---


--- File Index 6: backend/accounts/models.py ---
"""accounts/models.py  –  조직·사용자"""

import uuid
from django.db import models
from django.contrib.auth.models import AbstractBaseUser, PermissionsMixin, BaseUserManager


class UserRole(models.TextChoices):
    ADMIN = "admin", "Admin"
    ENGINEER = "engineer", "Engineer"
    ANALYST = "analyst", "Analyst"
    GUEST = "guest", "Guest"


class Organization(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    name = models.CharField(max_length=255, unique=True)
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = "organizations"
        ordering = ["name"]

    def __str__(self):
        return self.name


class UserManager(BaseUserManager):
    def create_user(self, email: str, password: str | None = None, **extra):
        if not email:
            raise ValueError("Email is required")
        user = self.model(email=self.normalize_email(email), **extra)
        user.set_password(password)
        user.save()
        return user

    def create_superuser(self, email: str, password: str | None = None, **extra):
        extra.setdefault("role", UserRole.ADMIN)
        extra.setdefault("is_staff", True)
        extra.setdefault("is_superuser", True)
        
        # Organization이 제공되지 않은 경우 기본 Organization 생성 또는 사용
        if 'org' not in extra:
            # 기본 조직이 있는지 확인
            default_org, created = Organization.objects.get_or_create(
                name="Default Organization"
            )
            extra["org"] = default_org
            
        return self.create_user(email, password, **extra)


class User(AbstractBaseUser, PermissionsMixin):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    org = models.ForeignKey(Organization, on_delete=models.CASCADE, related_name="users")
    email = models.EmailField(unique=True)
    name = models.CharField(max_length=100, blank=True)
    role = models.CharField(max_length=20, choices=UserRole.choices, default=UserRole.GUEST)
    created_at = models.DateTimeField(auto_now_add=True)
    last_login = models.DateTimeField(null=True, blank=True)

    is_active = models.BooleanField(default=True)
    is_staff = models.BooleanField(default=False)

    objects = UserManager()
    USERNAME_FIELD = "email"

    class Meta:
        db_table = "users"
        ordering = ["email"]

    def __str__(self):
        return self.email


--- File Index 7: backend/accounts/serializers.py ---
from rest_framework import serializers
from .models import User, Organization

class OrganizationSerializer(serializers.ModelSerializer):
    class Meta:
        model = Organization
        fields = ['id', 'name']

class UserSerializer(serializers.ModelSerializer):
    org = OrganizationSerializer(read_only=True)
    
    class Meta:
        model = User
        fields = ['id', 'email', 'name', 'org', 'role', 'created_at', 'last_login', 'is_active', 'is_staff']
        read_only_fields = ['id', 'email', 'created_at', 'last_login', 'is_active', 'is_staff']


--- File Index 8: backend/accounts/urls.py ---
from django.urls import path, re_path
from rest_framework_simplejwt.views import TokenRefreshView
from . import views

urlpatterns = [
    # 유연한 URL 패턴 사용 - 슬래시 유무 상관없이 처리
    re_path(r'^login/?$', views.login_view, name='login'),
    re_path(r'^logout/?$', views.logout_view, name='logout'),
    re_path(r'^me/?$', views.user_detail, name='user-detail'),
    re_path(r'^profile/?$', views.update_profile, name='update-profile'),
    re_path(r'^token/refresh/?$', TokenRefreshView.as_view(), name='token-refresh'),
]


--- File Index 9: backend/accounts/views.py ---
from django.contrib.auth import authenticate
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated, AllowAny
from rest_framework.response import Response
from rest_framework_simplejwt.tokens import RefreshToken
from rest_framework_simplejwt.views import TokenRefreshView
from .serializers import UserSerializer

@api_view(['POST'])
@permission_classes([AllowAny])
def login_view(request):
    email = request.data.get('email')
    password = request.data.get('password')
    
    if not email or not password:
        return Response({'detail': 'Email and password are required'}, status=status.HTTP_400_BAD_REQUEST)
    
    # Debugging info - remove in production
    print(f"Login attempt with email: {email}")
    
    # Check if the user exists in the database
    from django.contrib.auth import get_user_model
    User = get_user_model()
    
    try:
        user_exists = User.objects.filter(email=email).exists()
        print(f"User exists in database: {user_exists}")
        
        if not user_exists:
            # Create a test user for debugging if it doesn't exist
            print("Creating test user for debugging...")
            from django.contrib.auth.hashers import make_password
            from .models import Organization
            
            # Get or create default organization
            default_org, _ = Organization.objects.get_or_create(name="Default Organization")
            
            # Create test user
            User.objects.create(
                email=email,
                password=make_password(password),  # Properly hash the password
                name="Test User",
                org=default_org,
                role="admin",
                is_active=True,
                is_staff=True
            )
            print(f"Test user created with email: {email}")
    except Exception as e:
        print(f"Error checking/creating user: {e}")
    
    # Django's authenticate expects the USERNAME_FIELD value in the 'username' parameter
    # Since our User model has USERNAME_FIELD = 'email', we pass email to username parameter
    user = authenticate(username=email, password=password)
    print(f"Authentication result: {'Success' if user else 'Failed'}")
    
    if user:
        refresh = RefreshToken.for_user(user)
        return Response({
            'refresh': str(refresh),
            'access': str(refresh.access_token),
            'user': UserSerializer(user).data
        })
    
    # More detailed error for debugging
    return Response({'detail': 'Invalid credentials. Please check your email and password.'}, 
                    status=status.HTTP_401_UNAUTHORIZED)

@api_view(['POST'])
@permission_classes([AllowAny])
def logout_view(request):
    # JWT doesn't really need server-side logout, but we keep the endpoint for API consistency
    return Response({"detail": "Successfully logged out."})

@api_view(['GET'])
@permission_classes([IsAuthenticated])
def user_detail(request):
    serializer = UserSerializer(request.user)
    return Response(serializer.data)

@api_view(['PATCH'])
@permission_classes([IsAuthenticated])
def update_profile(request):
    user = request.user
    serializer = UserSerializer(user, data=request.data, partial=True)
    
    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data)
    
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


--- File Index 10: backend/config/__init__.py ---


--- File Index 11: backend/config/asgi.py ---
"""
ASGI config for config project.

It exposes the ASGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/howto/deployment/asgi/
"""

import os

from django.core.asgi import get_asgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')

application = get_asgi_application()


--- File Index 12: backend/config/settings.py ---
"""
Django settings for config project.

Generated by 'django-admin startproject' using Django 5.2.1.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/5.2/ref/settings/
"""
import os
from dotenv import load_dotenv
from pathlib import Path

load_dotenv()

# Build paths inside the project like this: BASE_DIR / 'subdir'.
BASE_DIR = Path(__file__).resolve().parent.parent


# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/5.2/howto/deployment/checklist/

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = os.getenv('SECRET_KEY')

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = True

ALLOWED_HOSTS = []


# Application definition

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    'rest_framework', 'rest_framework_simplejwt', 'corsheaders',
    'accounts', 'knowledge', 'conversations', 'mlops',
    'pgvector.django'
]

# Custom user model
AUTH_USER_MODEL = 'accounts.User'

MIDDLEWARE = [
    'corsheaders.middleware.CorsMiddleware',  # CORS 미들웨어는 가장 앞에 위치해야 함
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'config.urls'

# URL configuration
APPEND_SLASH = False  # Do not force appending slashes to URLs

# CORS settings
CORS_ALLOWED_ORIGINS = [
    "http://localhost:3000",  # Next.js 개발 서버
]
CORS_ALLOW_CREDENTIALS = True

# Add CORS_ALLOWED_METHODS
CORS_ALLOWED_METHODS = [
    'DELETE',
    'GET',
    'OPTIONS',
    'PATCH',
    'POST',
    'PUT',
]

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'config.wsgi.application'


# Database
# https://docs.djangoproject.com/en/5.2/ref/settings/#databases

# DATABASES = {
#     'default': {
#         'ENGINE': 'django.db.backends.sqlite3',
#         'NAME': BASE_DIR / 'db.sqlite3',
#     }
# }

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.getenv('DB_NAME'),
        'USER': os.getenv('DB_USER'),
        'PASSWORD': os.getenv('DB_PASSWORD'),
        'HOST': os.getenv('DB_HOST'),
        'PORT': os.getenv('DB_PORT', '5432'),
    }
}
#print(DATABASES)


# Password validation
# https://docs.djangoproject.com/en/5.2/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]


# Internationalization
# https://docs.djangoproject.com/en/5.2/topics/i18n/

LANGUAGE_CODE = 'en-us'

TIME_ZONE = 'UTC'

USE_I18N = True

USE_TZ = True


# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/5.2/howto/static-files/

STATIC_URL = 'static/'

# Default primary key field type
# https://docs.djangoproject.com/en/5.2/ref/settings/#default-auto-field

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'

# REST Framework settings
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': (
        'rest_framework_simplejwt.authentication.JWTAuthentication',
    ),
    'DEFAULT_PERMISSION_CLASSES': [
        'rest_framework.permissions.IsAuthenticated',
    ],
}

# JWT settings
from datetime import timedelta
SIMPLE_JWT = {
    'ACCESS_TOKEN_LIFETIME': timedelta(hours=1),
    'REFRESH_TOKEN_LIFETIME': timedelta(days=7),
    'ROTATE_REFRESH_TOKENS': False,
    'BLACKLIST_AFTER_ROTATION': True,
    'ALGORITHM': 'HS256',
    'SIGNING_KEY': SECRET_KEY,
    'VERIFYING_KEY': None,
    'AUTH_HEADER_TYPES': ('Bearer',),
    'USER_ID_FIELD': 'id',
    'USER_ID_CLAIM': 'user_id',
    'AUTH_TOKEN_CLASSES': ('rest_framework_simplejwt.tokens.AccessToken',),
    'TOKEN_TYPE_CLAIM': 'token_type',
}

# CORS settings
CORS_ALLOWED_ORIGINS = [
    'http://localhost:3000',  # Next.js frontend
]
CORS_ALLOW_CREDENTIALS = True


--- File Index 13: backend/config/urls.py ---
"""
URL configuration for config project.

The `urlpatterns` list routes URLs to views. For more information please see:
    https://docs.djangoproject.com/en/5.2/topics/http/urls/
Examples:
Function views
    1. Add an import:  from my_app import views
    2. Add a URL to urlpatterns:  path('', views.home, name='home')
Class-based views
    1. Add an import:  from other_app.views import Home
    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
Including another URLconf
    1. Import the include() function: from django.urls import include, path
    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
"""
from django.contrib import admin
from django.urls import path, include, re_path
from django.http import JsonResponse

def health_check(request):
    return JsonResponse({'status': 'ok'})

urlpatterns = [
    path('admin/', admin.site.urls),
    # 유연한 URL 패턴 사용 - 슬래시 유무 상관없이 처리
    re_path(r'^api/auth/?', include('accounts.urls')),
    re_path(r'^api/chat/?', include('conversations.urls')),
    re_path(r'^api/health-check/?$', health_check, name='health-check'),
]


--- File Index 14: backend/config/wsgi.py ---
"""
WSGI config for config project.

It exposes the WSGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/howto/deployment/wsgi/
"""

import os

from django.core.wsgi import get_wsgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')

application = get_wsgi_application()


--- File Index 15: backend/conversations/__init__.py ---


--- File Index 16: backend/conversations/admin.py ---
from django.contrib import admin

from django.utils.html import format_html
from .models import ChatSession, ChatMessage, LlmCall
import json # JSONField 내용을 파싱하거나 요약할 때 사용 가능


class ChatMessageInline(admin.TabularInline):
    model = ChatMessage
    extra = 0
    readonly_fields = ('created_at',)
    fields = ('role', 'content', 'created_at')
    ordering = ('created_at',)


class LlmCallInline(admin.TabularInline):
    model = LlmCall
    extra = 0
    readonly_fields = ('called_at',)
    fields = ('provider', 'model', 'prompt_tokens', 'completion_tokens', 'cost_usd', 'latency_ms', 'called_at')
    ordering = ('-called_at',)


@admin.register(ChatSession)
class ChatSessionAdmin(admin.ModelAdmin):
    list_display = ('id', 'user', 'agent_type', 'started_at', 'ended_at', 'duration', 'message_count')
    list_filter = ('agent_type', 'started_at')
    search_fields = ('user__email', 'user__name')
    readonly_fields = ('started_at', 'ended_at')
    list_select_related = ('user',)
    inlines = [ChatMessageInline, LlmCallInline]
    
    def duration(self, obj):
        if obj.ended_at:
            duration = obj.ended_at - obj.started_at
            return f"{duration.seconds // 60}m {duration.seconds % 60}s"
        return "Ongoing"
    duration.short_description = 'Duration'
    
    def message_count(self, obj):
        return obj.messages.count()
    message_count.short_description = 'Messages'


@admin.register(ChatMessage)
class ChatMessageAdmin(admin.ModelAdmin):
    list_display = ('truncated_content', 'role', 'session', 'created_at')
    list_filter = ('role', 'created_at')
    search_fields = ('content', 'session__user__email')
    readonly_fields = ('created_at',)
    list_select_related = ('session__user',)
    
    def truncated_content(self, obj):
        return obj.content[:100] + '...' if len(obj.content) > 100 else obj.content
    truncated_content.short_description = 'Content'


@admin.register(LlmCall)
class LlmCallAdmin(admin.ModelAdmin):
    list_display = ('id', 'session', 'model', 'cost_usd', 'latency_ms', 'called_at')
    list_filter = ('provider', 'model', 'called_at')
    search_fields = ('session__user__email', 'model')
    readonly_fields = ('called_at',)
    list_select_related = ('session__user',)
    
    def has_add_permission(self, request):
        return False  # Prevent manual addition of LLM calls


# 모든 LangGraph 테이블에 적용할 읽기 전용 Admin 클래스
class ReadOnlyAdmin(admin.ModelAdmin):
    def has_add_permission(self, request):
        # 추가 기능 비활성화
        return False
    def has_change_permission(self, request, obj=None):
        # 변경 기능 비활성화
        return False
    def has_delete_permission(self, request, obj=None):
        # 삭제 기능 비활성화
        return False
    
    # list_display의 항목들이 변경 페이지로 연결되는 링크가 되지 않도록 설정
    # 이렇게 하면 list_display의 각 항목이 링크로 표시되지 않습니다.
    def get_list_display_links(self, request, list_display):
        return None





--- File Index 17: backend/conversations/apps.py ---
from django.apps import AppConfig


class ConversationsConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'conversations'


--- File Index 18: backend/conversations/migrations/0001_initial.py ---
# Generated by Django 5.2.1 on 2025-05-29 05:36

import django.db.models.deletion
import uuid
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.CreateModel(
            name='ChatSession',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('agent_type', models.CharField(choices=[('code', 'Code'), ('rag', 'RAG'), ('analytics', 'Analytics')], max_length=20)),
                ('started_at', models.DateTimeField(auto_now_add=True)),
                ('ended_at', models.DateTimeField(blank=True, null=True)),
                ('user', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='chat_sessions', to=settings.AUTH_USER_MODEL)),
            ],
            options={
                'db_table': 'chat_sessions',
            },
        ),
        migrations.CreateModel(
            name='ChatMessage',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('role', models.CharField(max_length=20)),
                ('content', models.TextField()),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('session', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='messages', to='conversations.chatsession')),
            ],
            options={
                'db_table': 'chat_messages',
                'ordering': ['created_at'],
            },
        ),
        migrations.CreateModel(
            name='LlmCall',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('provider', models.CharField(max_length=50)),
                ('model', models.CharField(max_length=100)),
                ('prompt_tokens', models.PositiveIntegerField()),
                ('completion_tokens', models.PositiveIntegerField()),
                ('cost_usd', models.DecimalField(decimal_places=4, max_digits=10)),
                ('latency_ms', models.PositiveIntegerField(blank=True, null=True)),
                ('called_at', models.DateTimeField(auto_now_add=True)),
                ('session', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='llm_calls', to='conversations.chatsession')),
            ],
            options={
                'db_table': 'llm_calls',
                'indexes': [models.Index(fields=['called_at'], name='idx_llm_called_at')],
            },
        ),
    ]


--- File Index 19: backend/conversations/migrations/0002_checkpoint_checkpointblob_checkpointmigration_and_more.py ---
# Generated by Django 5.2.1 on 2025-06-02 17:18

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('conversations', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='Checkpoint',
            fields=[
                ('thread_id', models.TextField(primary_key=True, serialize=False)),
                ('checkpoint_ns', models.TextField(default='')),
                ('checkpoint_id', models.TextField()),
                ('parent_checkpoint_id', models.TextField(blank=True, null=True)),
                ('type', models.TextField(blank=True, null=True)),
                ('checkpoint', models.JSONField()),
                ('metadata', models.JSONField(default=dict)),
            ],
            options={
                'db_table': 'checkpoints',
                'managed': False,
            },
        ),
        migrations.CreateModel(
            name='CheckpointBlob',
            fields=[
                ('thread_id', models.TextField(primary_key=True, serialize=False)),
                ('checkpoint_ns', models.TextField(default='')),
                ('channel', models.TextField()),
                ('version', models.TextField()),
                ('type', models.TextField()),
                ('blob', models.BinaryField(blank=True, null=True)),
            ],
            options={
                'db_table': 'checkpoint_blobs',
                'managed': False,
            },
        ),
        migrations.CreateModel(
            name='CheckpointMigration',
            fields=[
                ('v', models.IntegerField(primary_key=True, serialize=False)),
            ],
            options={
                'db_table': 'checkpoint_migrations',
                'managed': False,
            },
        ),
        migrations.CreateModel(
            name='CheckpointWrite',
            fields=[
                ('thread_id', models.TextField(primary_key=True, serialize=False)),
                ('checkpoint_ns', models.TextField(default='')),
                ('checkpoint_id', models.TextField()),
                ('task_id', models.TextField()),
                ('idx', models.IntegerField()),
                ('channel', models.TextField()),
                ('type', models.TextField(blank=True, null=True)),
                ('blob', models.BinaryField()),
            ],
            options={
                'db_table': 'checkpoint_writes',
                'managed': False,
            },
        ),
        migrations.AddField(
            model_name='chatsession',
            name='title',
            field=models.CharField(default='새 세션', max_length=60),
        ),
    ]


--- File Index 20: backend/conversations/migrations/0003_delete_checkpoint_delete_checkpointblob_and_more.py ---
# Generated by Django 5.2.1 on 2025-06-04 00:45

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('conversations', '0002_checkpoint_checkpointblob_checkpointmigration_and_more'),
    ]

    operations = [
        migrations.DeleteModel(
            name='Checkpoint',
        ),
        migrations.DeleteModel(
            name='CheckpointBlob',
        ),
        migrations.DeleteModel(
            name='CheckpointMigration',
        ),
        migrations.DeleteModel(
            name='CheckpointWrite',
        ),
        migrations.AlterField(
            model_name='chatsession',
            name='agent_type',
            field=models.CharField(choices=[('code', 'Code'), ('rag', 'RAG'), ('analytics', 'Analytics'), ('auto', 'Auto')], max_length=20),
        ),
    ]


--- File Index 21: backend/conversations/migrations/__init__.py ---


--- File Index 22: backend/conversations/models.py ---
"""conversations/models.py  –  채팅·LLM 호출"""

import uuid
from django.db import models
from accounts.models import User


class AgentType(models.TextChoices):
    CODE = "code", "Code"
    RAG = "rag", "RAG"
    ANALYTICS = "analytics", "Analytics"
    AUTO = "auto", "Auto"


class ChatSession(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    user = models.ForeignKey(User, on_delete=models.CASCADE, related_name="chat_sessions")
    agent_type = models.CharField(max_length=20, choices=AgentType.choices)
    started_at = models.DateTimeField(auto_now_add=True)
    ended_at = models.DateTimeField(null=True, blank=True)
    title = models.CharField(max_length=60, default="새 세션")

    class Meta:
        db_table = "chat_sessions"


class ChatMessage(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    session = models.ForeignKey(ChatSession, on_delete=models.CASCADE, related_name="messages")
    role = models.CharField(max_length=20)  # user | assistant | system
    content = models.TextField()
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = "chat_messages"
        ordering = ["created_at"]


class LlmCall(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    session = models.ForeignKey(ChatSession, on_delete=models.CASCADE, related_name="llm_calls")
    provider = models.CharField(max_length=50)
    model = models.CharField(max_length=100)
    prompt_tokens = models.PositiveIntegerField()
    completion_tokens = models.PositiveIntegerField()
    cost_usd = models.DecimalField(max_digits=10, decimal_places=4)
    latency_ms = models.PositiveIntegerField(null=True, blank=True)
    called_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = "llm_calls"
        indexes = [models.Index(fields=["called_at"], name="idx_llm_called_at")]



--- File Index 23: backend/conversations/serializers.py ---
from rest_framework import serializers
from .models import ChatSession, ChatMessage, LlmCall, AgentType


class ChatMessageSerializer(serializers.ModelSerializer):
    """ChatMessage 모델 직렬화를 위한 serializer"""
    
    class Meta:
        model = ChatMessage
        fields = ['id', 'session', 'role', 'content', 'created_at']
        read_only_fields = ['id', 'created_at']


class LlmCallSerializer(serializers.ModelSerializer):
    """LlmCall 모델 직렬화를 위한 serializer"""
    
    class Meta:
        model = LlmCall
        fields = ['id', 'session', 'provider', 'model', 'prompt_tokens', 
                 'completion_tokens', 'cost_usd', 'latency_ms', 'called_at']
        read_only_fields = ['id', 'called_at']


class ChatSessionSerializer(serializers.ModelSerializer):
    """ChatSession 모델 직렬화를 위한 serializer"""
    messages = ChatMessageSerializer(many=True, read_only=True)
    
    class Meta:
        model = ChatSession
        fields = ['id', 'user', 'agent_type', 'started_at', 'ended_at', 'title', 'messages']
        read_only_fields = ['id', 'started_at']

    def validate_agent_type(self, value):
        """agent_type 필드 유효성 검사"""
        if value not in [choice[0] for choice in AgentType.choices]:
            raise serializers.ValidationError(f"유효하지 않은 에이전트 유형입니다. 유효한 값: {AgentType.choices}")
        return value


--- File Index 24: backend/conversations/urls.py ---
from django.urls import path, re_path
from . import views

urlpatterns = [
    # 채팅 세션 관련 URL
    re_path(r'^sessions/?$', views.ChatSessionViewSet.as_view(), name='chat_sessions'),
    re_path(r'^sessions/(?P<pk>[0-9a-f-]+)/?$', views.ChatSessionDetailView.as_view(), name='chat_session_detail'),
    
    # 채팅 메시지 관련 URL
    re_path(r'^sessions/(?P<session_pk>[0-9a-f-]+)/messages/?$', views.ChatMessageView.as_view(), name='chat_messages'),
]


--- File Index 25: backend/conversations/views.py ---
from django.utils import timezone
from django.shortcuts import get_object_or_404
from rest_framework import status, viewsets
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated
from rest_framework.response import Response
from rest_framework.views import APIView

from .models import ChatSession, ChatMessage
from .serializers import ChatSessionSerializer, ChatMessageSerializer


class ChatSessionViewSet(APIView):
    """채팅 세션을 관리하는 API 뷰셋"""
    permission_classes = [IsAuthenticated]

    def get(self, request):
        """현재 사용자의 모든 채팅 세션 조회"""
        sessions = ChatSession.objects.filter(user=request.user).order_by('-started_at')
        serializer = ChatSessionSerializer(sessions, many=True)
        return Response(serializer.data)

    def post(self, request):
        """새 채팅 세션 생성"""
        # 요청 데이터에 사용자 ID 추가
        data = request.data.copy()
        data['user'] = request.user.id
        
        serializer = ChatSessionSerializer(data=data)
        if serializer.is_valid():
            session = serializer.save()
            
            # 시스템 메시지 생성 (선택적)
            welcome_message = f"Welcome to your new {session.agent_type} session. How can I help you today?"
            ChatMessage.objects.create(
                session=session,
                role="system",
                content=welcome_message
            )
            
            return Response(serializer.data, status=status.HTTP_201_CREATED)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class ChatSessionDetailView(APIView):
    """특정 채팅 세션을 관리하는 API 뷰"""
    permission_classes = [IsAuthenticated]

    def get(self, request, pk):
        """특정 채팅 세션 조회"""
        session = get_object_or_404(ChatSession, pk=pk, user=request.user)
        serializer = ChatSessionSerializer(session)
        return Response(serializer.data)

    def patch(self, request, pk):
        """채팅 세션 업데이트 (주로 종료 시간)"""
        session = get_object_or_404(ChatSession, pk=pk, user=request.user)
        serializer = ChatSessionSerializer(session, data=request.data, partial=True)
        
        if serializer.is_valid():
            serializer.save()
            return Response(serializer.data)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class ChatMessageView(APIView):
    """채팅 메시지를 관리하는 API 뷰"""
    permission_classes = [IsAuthenticated]

    def get(self, request, session_pk):
        """특정 세션의 모든 메시지 조회"""
        # 해당 세션이 현재 사용자의 것인지 확인
        session = get_object_or_404(ChatSession, pk=session_pk, user=request.user)
        messages = ChatMessage.objects.filter(session=session).order_by('created_at')
        serializer = ChatMessageSerializer(messages, many=True)
        return Response(serializer.data)

    def post(self, request, session_pk):
        """새 메시지 생성 및 AI 응답 생성"""
        # 해당 세션이 현재 사용자의 것인지 확인
        session = get_object_or_404(ChatSession, pk=session_pk, user=request.user)
        
        # 사용자 메시지 생성
        data = request.data.copy()
        data['session'] = session.pk
        data['role'] = 'user'
        
        serializer = ChatMessageSerializer(data=data)
        if serializer.is_valid():
            user_message = serializer.save()
            
            # 여기서 AI 응답을 생성하는 로직을 추가할 수 있습니다
            # 지금은 간단한 예시 응답을 생성합니다
            ai_response_content = f"This is a mock response to your message: {user_message.content}"
            
            # AI 응답 메시지 생성
            ai_message = ChatMessage.objects.create(
                session=session,
                role="assistant",
                content=ai_response_content
            )
            
            # 사용자 메시지와 AI 응답을 모두 포함하여 반환
            both_messages = ChatMessage.objects.filter(id__in=[user_message.id, ai_message.id])
            messages_serializer = ChatMessageSerializer(both_messages, many=True)
            return Response(messages_serializer.data, status=status.HTTP_201_CREATED)
        
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


--- File Index 26: backend/knowledge/__init__.py ---


--- File Index 27: backend/knowledge/admin.py ---
from django.contrib import admin
from django.utils.html import format_html
from .models import Document, GitRepository, CodeFile, EmbedChunk, TelecomCustomers, SummaryNewsKeywords


@admin.register(Document)
class DocumentAdmin(admin.ModelAdmin):
    list_display = ('title', 'doc_type', 'org', 'version', 'created_at')
    list_filter = ('doc_type', 'org')
    search_fields = ('title', 's3_key')
    list_select_related = ('org', 'uploaded_by')
    readonly_fields = ('created_at',)
    date_hierarchy = 'created_at'


@admin.register(GitRepository)
class GitRepositoryAdmin(admin.ModelAdmin):
    list_display = ('repo_url', 'org', 'default_branch', 'fetched_at')
    list_filter = ('org',)
    search_fields = ('repo_url',)
    readonly_fields = ('fetched_at',)


@admin.register(CodeFile)
class CodeFileAdmin(admin.ModelAdmin):
    list_display = ('file_path', 'repo', 'language', 'loc')
    list_filter = ('repo', 'language')
    search_fields = ('file_path', 'latest_commit')
    list_select_related = ('repo',)
    readonly_fields = ('id',)


@admin.register(EmbedChunk)
class EmbedChunkAdmin(admin.ModelAdmin):
    list_display = ('id', 'chunk_index', 'document', 'file', 'hash_short')
    list_filter = ('document', 'file')
    search_fields = ('hash', 'pinecone_id')
    readonly_fields = ('id',)
    list_select_related = ('document', 'file')
    
    def hash_short(self, obj):
        return f"{obj.hash[:10]}..." if obj.hash else ""
    hash_short.short_description = 'Hash'





@admin.register(TelecomCustomers)
class TelecomCustomersAdmin(admin.ModelAdmin) :
    list_display = ('id', 'customer_id', 'gender', 'partner', 'dependents' ,'churn')
    list_filter = ('dependents','churn', 'gender')
    search_fields = ('id','customer_id')
    readonly_fields = ('id', 'customer_id')


@admin.register(SummaryNewsKeywords)
class SummaryNewsKeywordsAdmin(admin.ModelAdmin):
    list_display = ('date', 'keyword_display', 'title_short', 'url_short')
    list_filter = ('date', 'keyword')
    search_fields = ('title', 'summary', 'keyword')
    list_select_related = ()
    date_hierarchy = 'date'
    ordering = ('-date', 'keyword')
    
    def keyword_display(self, obj):
        return obj.keyword
    keyword_display.short_description = 'Keyword'
    
    def title_short(self, obj):
        return f"{obj.title[:50]}..." if len(obj.title) > 50 else obj.title
    title_short.short_description = 'Title'
    
    def url_short(self, obj):
        return format_html('<a href="{}" target="_blank">Link</a>', obj.url)
    url_short.short_description = 'URL'


--- File Index 28: backend/knowledge/apps.py ---
from django.apps import AppConfig


class KnowledgeConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'knowledge'


--- File Index 29: backend/knowledge/migrations/0001_initial.py ---
# Generated by Django 5.2.1 on 2025-05-29 05:36

import django.db.models.deletion
import uuid
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('accounts', '0001_initial'),
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.CreateModel(
            name='CodeFile',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('file_path', models.TextField()),
                ('language', models.CharField(blank=True, max_length=50)),
                ('latest_commit', models.CharField(blank=True, max_length=40)),
                ('loc', models.PositiveIntegerField(blank=True, null=True)),
            ],
            options={
                'db_table': 'code_files',
            },
        ),
        migrations.CreateModel(
            name='TelecomCustomers',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('customer_id', models.CharField(max_length=20)),
                ('gender', models.CharField(max_length=6)),
                ('senior_citizen', models.BooleanField()),
                ('partner', models.BooleanField()),
                ('dependents', models.BooleanField()),
                ('tenure', models.IntegerField()),
                ('phone_service', models.BooleanField()),
                ('multiple_lines', models.CharField(max_length=20)),
                ('internet_serivce', models.CharField(max_length=20)),
                ('online_security', models.CharField(max_length=20)),
                ('online_backup', models.CharField(max_length=20)),
                ('device_protection', models.CharField(max_length=20)),
                ('tech_support', models.CharField(max_length=20)),
                ('streaming_tv', models.CharField(max_length=20)),
                ('streaming_movies', models.CharField(max_length=20)),
                ('contract', models.CharField(max_length=20)),
                ('paperless_billing', models.BooleanField()),
                ('payment_method', models.CharField(max_length=30)),
                ('monthly_charges', models.DecimalField(decimal_places=2, max_digits=10)),
                ('total_charges', models.DecimalField(decimal_places=2, max_digits=14)),
                ('churn', models.BooleanField()),
            ],
            options={
                'db_table': 'telecom_customers',
            },
        ),
        migrations.CreateModel(
            name='Document',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('title', models.CharField(max_length=255)),
                ('doc_type', models.CharField(choices=[('policy', 'Policy'), ('product', 'Product'), ('tech_manual', 'Tech Manual')], max_length=20)),
                ('s3_key', models.TextField(unique=True)),
                ('version', models.CharField(default='v1', max_length=50)),
                ('pinecone_ns', models.CharField(max_length=100)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('org', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='documents', to='accounts.organization')),
                ('uploaded_by', models.ForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='uploaded_documents', to=settings.AUTH_USER_MODEL)),
            ],
            options={
                'db_table': 'documents',
            },
        ),
        migrations.CreateModel(
            name='EmbedChunk',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('chunk_index', models.PositiveIntegerField()),
                ('pinecone_id', models.CharField(max_length=100)),
                ('hash', models.CharField(max_length=64, unique=True)),
                ('document', models.ForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.CASCADE, related_name='chunks', to='knowledge.document')),
                ('file', models.ForeignKey(blank=True, null=True, on_delete=django.db.models.deletion.CASCADE, related_name='chunks', to='knowledge.codefile')),
            ],
            options={
                'db_table': 'embed_chunks',
            },
        ),
        migrations.CreateModel(
            name='GitRepository',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('repo_url', models.TextField(unique=True)),
                ('default_branch', models.CharField(default='main', max_length=100)),
                ('fetched_at', models.DateTimeField(blank=True, null=True)),
                ('org', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='repositories', to='accounts.organization')),
            ],
            options={
                'db_table': 'git_repositories',
            },
        ),
        migrations.AddField(
            model_name='codefile',
            name='repo',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='code_files', to='knowledge.gitrepository'),
        ),
        migrations.CreateModel(
            name='SummaryNewsKeywords',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('date', models.DateField()),
                ('keyword', models.TextField()),
                ('title', models.TextField()),
                ('summary', models.TextField()),
                ('url', models.URLField(max_length=500)),
            ],
            options={
                'db_table': 'summary_news_keywords',
                'ordering': ['-date'],
                'indexes': [models.Index(fields=['date'], name='idx_news_date'), models.Index(fields=['keyword'], name='idx_news_keyword')],
            },
        ),
        migrations.AddIndex(
            model_name='document',
            index=models.Index(fields=['org', 'doc_type'], name='idx_docs_org_type'),
        ),
        migrations.AddIndex(
            model_name='embedchunk',
            index=models.Index(fields=['document', 'file'], name='idx_chunks_source'),
        ),
        migrations.AddConstraint(
            model_name='embedchunk',
            constraint=models.CheckConstraint(condition=models.Q(models.Q(('document__isnull', False), ('file__isnull', True)), models.Q(('document__isnull', True), ('file__isnull', False)), _connector='OR'), name='embed_chunks_one_fk'),
        ),
        migrations.AddIndex(
            model_name='codefile',
            index=models.Index(fields=['repo'], name='idx_files_repo'),
        ),
        migrations.AlterUniqueTogether(
            name='codefile',
            unique_together={('repo', 'file_path')},
        ),
    ]


--- File Index 30: backend/knowledge/migrations/0002_alter_summarynewskeywords_options_and_more.py ---
# Generated by Django 5.2.1 on 2025-05-29 06:30

from django.db import migrations


class Migration(migrations.Migration):

    dependencies = [
        ('knowledge', '0001_initial'),
    ]

    operations = [
        migrations.AlterModelOptions(
            name='summarynewskeywords',
            options={'verbose_name_plural': 'Summary news keywords'},
        ),
        migrations.AlterModelOptions(
            name='telecomcustomers',
            options={'verbose_name_plural': 'Telecom customers'},
        ),
        migrations.RemoveIndex(
            model_name='summarynewskeywords',
            name='idx_news_date',
        ),
        migrations.RemoveIndex(
            model_name='summarynewskeywords',
            name='idx_news_keyword',
        ),
    ]


--- File Index 31: backend/knowledge/migrations/__init__.py ---


--- File Index 32: backend/knowledge/models.py ---
"""knowledge/models.py  –  문서·레포·임베딩"""

import uuid
from django.db import models
from django.db.models import Q, CheckConstraint
from accounts.models import Organization, User
from pgvector.django import VectorField

class DocType(models.TextChoices):
    POLICY = "policy", "Policy"
    PRODUCT = "product", "Product"
    TECH_MANUAL = "tech_manual", "Tech Manual"


class Document(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    org = models.ForeignKey(Organization, on_delete=models.CASCADE, related_name="documents")
    title = models.CharField(max_length=255)
    doc_type = models.CharField(max_length=20, choices=DocType.choices)
    s3_key = models.TextField(unique=True)
    version = models.CharField(max_length=50, default="v1")
    pinecone_ns = models.CharField(max_length=100)
    uploaded_by = models.ForeignKey(
        User, null=True, blank=True, on_delete=models.SET_NULL, related_name="uploaded_documents"
    )
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = "documents"
        indexes = [models.Index(fields=["org", "doc_type"], name="idx_docs_org_type")]

    def __str__(self):
        return self.title


class GitRepository(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    org = models.ForeignKey(Organization, on_delete=models.CASCADE, related_name="repositories")
    repo_url = models.TextField(unique=True)
    default_branch = models.CharField(max_length=100, default="main")
    fetched_at = models.DateTimeField(null=True, blank=True)

    class Meta:
        db_table = "git_repositories"

    def __str__(self):
        return self.repo_url


class CodeFile(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    repo = models.ForeignKey(GitRepository, on_delete=models.CASCADE, related_name="code_files")
    file_path = models.TextField()
    language = models.CharField(max_length=50, blank=True)
    latest_commit = models.CharField(max_length=40, blank=True)
    loc = models.PositiveIntegerField(null=True, blank=True)

    class Meta:
        db_table = "code_files"
        unique_together = ("repo", "file_path")
        indexes = [models.Index(fields=["repo"], name="idx_files_repo")]

    def __str__(self):
        return self.file_path


class EmbedChunk(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    document = models.ForeignKey(
        Document, null=True, blank=True, on_delete=models.CASCADE, related_name="chunks"
    )
    file = models.ForeignKey(
        CodeFile, null=True, blank=True, on_delete=models.CASCADE, related_name="chunks"
    )
    chunk_index = models.PositiveIntegerField()
    pinecone_id = models.CharField(max_length=100)
    hash = models.CharField(max_length=64, unique=True)

    class Meta:
        db_table = "embed_chunks"
        constraints = [
            CheckConstraint(
                name="embed_chunks_one_fk",
                check=Q(document__isnull=False, file__isnull=True)
                | Q(document__isnull=True, file__isnull=False),
            )
        ]
        indexes = [models.Index(fields=["document", "file"], name="idx_chunks_source")]

    def __str__(self):
        return self.hash
    



class TelecomCustomers(models.Model) :
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    customer_id = models.CharField(max_length=20, null=False)
    gender = models.CharField(max_length=6)
    senior_citizen = models.BooleanField()
    partner = models.BooleanField()
    dependents = models.BooleanField()
    tenure = models.IntegerField()
    phone_service = models.BooleanField()
    multiple_lines = models.CharField(max_length=20)
    internet_serivce = models.CharField(max_length=20)
    online_security = models.CharField(max_length=20)
    online_backup = models.CharField(max_length=20)
    device_protection = models.CharField(max_length=20)
    tech_support = models.CharField(max_length=20)
    streaming_tv = models.CharField(max_length=20)
    streaming_movies = models.CharField(max_length=20)
    contract = models.CharField(max_length=20)
    paperless_billing = models.BooleanField()
    payment_method = models.CharField(max_length=30)
    monthly_charges = models.DecimalField(max_digits=10, decimal_places=2)
    total_charges = models.DecimalField(max_digits=14, decimal_places=2)
    churn = models.BooleanField()

    class Meta:
        verbose_name_plural = "Telecom customers"  # 복수형 이름 지정
        db_table = 'telecom_customers'  # 테이블 이름도 명시적으로 지정


class SummaryNewsKeywords(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    date = models.DateField()
    keyword = models.TextField()
    title = models.TextField()
    summary = models.TextField()
    url = models.URLField(max_length=500)

    class Meta:
        verbose_name_plural = "Summary news keywords"  # 복수형 이름 지정
        db_table = 'summary_news_keywords'  # 테이블 이름도 명시적으로 지정



    def __str__(self):
        return f"{self.date} - {self.keyword} - {self.title[:50]}..."




--- File Index 33: backend/knowledge/views.py ---
from django.shortcuts import render

# Create your views here.


--- File Index 34: backend/manage.py ---
#!/usr/bin/env python
"""Django's command-line utility for administrative tasks."""
import os
import sys


def main():
    """Run administrative tasks."""
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')
    try:
        from django.core.management import execute_from_command_line
    except ImportError as exc:
        raise ImportError(
            "Couldn't import Django. Are you sure it's installed and "
            "available on your PYTHONPATH environment variable? Did you "
            "forget to activate a virtual environment?"
        ) from exc
    execute_from_command_line(sys.argv)


if __name__ == '__main__':
    main()


--- File Index 35: backend/mlops/__init__.py ---


--- File Index 36: backend/mlops/admin.py ---
from django.contrib import admin
from django.utils.html import format_html
from .models import AnalyticsResult, ModelArtifact


@admin.register(AnalyticsResult)
class AnalyticsResultAdmin(admin.ModelAdmin):
    list_display = ('id', 'user', 'result_type', 'created_at', 's3_key_preview')
    list_filter = ('result_type', 'created_at')
    search_fields = ('user__email', 's3_key', 'meta')
    readonly_fields = ('created_at', 'meta_prettified')
    list_select_related = ('user',)
    
    def s3_key_preview(self, obj):
        return obj.s3_key[:50] + '...' if len(obj.s3_key) > 50 else obj.s3_key
    s3_key_preview.short_description = 'S3 Key'
    
    def meta_prettified(self, obj):
        import json
        from pygments import highlight
        from pygments.lexers import JsonLexer
        from pygments.formatters import HtmlFormatter
        from django.utils.safestring import mark_safe
        
        if not obj.meta:
            return ""
            
        response = json.dumps(obj.meta, indent=2, ensure_ascii=False)
        response = response[:5000]  # Limit the size to prevent performance issues
        
        # Truncate and add ellipsis if necessary
        if len(response) > 5000:
            response = response[:5000] + '... (truncated)'
            
        # Format the JSON
        formatter = HtmlFormatter(style='colorful')
        response = highlight(response, JsonLexer(), formatter)
        style = "<style>" + formatter.get_style_defs() + "</style><br>"
        return mark_safe(style + response)
    
    meta_prettified.short_description = 'Metadata'


@admin.register(ModelArtifact)
class ModelArtifactAdmin(admin.ModelAdmin):
    list_display = ('name', 'version', 'stage', 'created_by', 'created_at', 's3_key_preview')
    list_filter = ('stage', 'created_at')
    search_fields = ('name', 'version', 's3_key')
    readonly_fields = ('created_at', 'metrics_prettified')
    list_select_related = ('created_by',)
    
    def s3_key_preview(self, obj):
        return obj.s3_key[:50] + '...' if len(obj.s3_key) > 50 else obj.s3_key
    s3_key_preview.short_description = 'S3 Key'
    
    def metrics_prettified(self, obj):
        if not obj.metrics:
            return ""
            
        import json
        from pygments import highlight
        from pygments.lexers import JsonLexer
        from pygments.formatters import HtmlFormatter
        from django.utils.safestring import mark_safe
        
        response = json.dumps(obj.metrics, indent=2, ensure_ascii=False)
        response = response[:5000]  # Limit the size to prevent performance issues
        
        # Truncate and add ellipsis if necessary
        if len(response) > 5000:
            response = response[:5000] + '... (truncated)'
            
        # Format the JSON
        formatter = HtmlFormatter(style='colorful')
        response = highlight(response, JsonLexer(), formatter)
        style = "<style>" + formatter.get_style_defs() + "</style><br>"
        return mark_safe(style + response)
    
    metrics_prettified.short_description = 'Metrics'


--- File Index 37: backend/mlops/apps.py ---
from django.apps import AppConfig


class MlopsConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'mlops'


--- File Index 38: backend/mlops/migrations/0001_initial.py ---
# Generated by Django 5.2.1 on 2025-05-29 05:36

import django.db.models.deletion
import uuid
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.CreateModel(
            name='AnalyticsResult',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('result_type', models.CharField(choices=[('churn_pred', 'Churn Prediction'), ('viz_image', 'Visualization Image'), ('timeseries_forecast', 'Time-series Forecast')], max_length=30)),
                ('s3_key', models.TextField()),
                ('meta', models.JSONField(blank=True, null=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('user', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='analytics_results', to=settings.AUTH_USER_MODEL)),
            ],
            options={
                'db_table': 'analytics_results',
                'indexes': [models.Index(fields=['user', 'result_type'], name='idx_analytics_user_type')],
            },
        ),
        migrations.CreateModel(
            name='ModelArtifact',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('name', models.CharField(max_length=120)),
                ('version', models.CharField(default='v1', max_length=50)),
                ('s3_key', models.TextField()),
                ('stage', models.CharField(choices=[('staging', 'Staging'), ('production', 'Production'), ('archived', 'Archived')], default='staging', max_length=20)),
                ('metrics', models.JSONField(blank=True, null=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('created_by', models.ForeignKey(null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='model_artifacts', to=settings.AUTH_USER_MODEL)),
            ],
            options={
                'db_table': 'model_artifacts',
                'ordering': ['-created_at'],
                'indexes': [models.Index(fields=['name', 'stage'], name='idx_model_stage'), models.Index(fields=['created_at'], name='idx_model_created')],
                'unique_together': {('name', 'version')},
            },
        ),
    ]


--- File Index 39: backend/mlops/migrations/__init__.py ---


--- File Index 40: backend/mlops/models.py ---
"""mlops/models.py  –  분석 결과 & 모델 레지스트리"""

import uuid
from django.db import models
from accounts.models import User


class ResultType(models.TextChoices):
    CHURN_PRED = "churn_pred", "Churn Prediction"
    VIZ_IMAGE = "viz_image", "Visualization Image"
    TS_FORECAST = "timeseries_forecast", "Time-series Forecast"


class AnalyticsResult(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    user = models.ForeignKey(User, on_delete=models.CASCADE, related_name="analytics_results")
    result_type = models.CharField(max_length=30, choices=ResultType.choices)
    s3_key = models.TextField()
    meta = models.JSONField(null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = "analytics_results"
        indexes = [models.Index(fields=["user", "result_type"], name="idx_analytics_user_type")]

    def __str__(self):
        return f"{self.result_type} - {self.id}"


class ModelStage(models.TextChoices):
    STAGING = "staging", "Staging"
    PRODUCTION = "production", "Production"
    ARCHIVED = "archived", "Archived"


class ModelArtifact(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    name = models.CharField(max_length=120)
    version = models.CharField(max_length=50, default="v1")
    s3_key = models.TextField()
    stage = models.CharField(max_length=20, choices=ModelStage.choices, default=ModelStage.STAGING)
    metrics = models.JSONField(null=True, blank=True)
    created_by = models.ForeignKey(
        User, null=True, on_delete=models.SET_NULL, related_name="model_artifacts"
    )
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = "model_artifacts"
        unique_together = ("name", "version")
        indexes = [
            models.Index(fields=["name", "stage"], name="idx_model_stage"),
            models.Index(fields=["created_at"], name="idx_model_created"),
        ]
        ordering = ["-created_at"]

    def __str__(self):
        return f"{self.name} ({self.version}) - {self.stage}"


--- File Index 41: backend/mlops/modules/nodes/__init__.py ---


--- File Index 42: backend/mlops/views.py ---
from django.shortcuts import render

# Create your views here.


--- File Index 43: backend/path/to/your/app/Makefile ---
.PHONY: all format lint test tests test_watch integration_tests docker_tests help extended_tests

# Default target executed when no arguments are given to make.
all: help

# Define a variable for the test file path.
TEST_FILE ?= tests/unit_tests/

test:
	python -m pytest $(TEST_FILE)

integration_tests:
	python -m pytest tests/integration_tests 

test_watch:
	python -m ptw --snapshot-update --now . -- -vv tests/unit_tests

test_profile:
	python -m pytest -vv tests/unit_tests/ --profile-svg

extended_tests:
	python -m pytest --only-extended $(TEST_FILE)


######################
# LINTING AND FORMATTING
######################

# Define a variable for Python and notebook files.
PYTHON_FILES=src/
MYPY_CACHE=.mypy_cache
lint format: PYTHON_FILES=.
lint_diff format_diff: PYTHON_FILES=$(shell git diff --name-only --diff-filter=d main | grep -E '\.py$$|\.ipynb$$')
lint_package: PYTHON_FILES=src
lint_tests: PYTHON_FILES=tests
lint_tests: MYPY_CACHE=.mypy_cache_test

lint lint_diff lint_package lint_tests:
	python -m ruff check .
	[ "$(PYTHON_FILES)" = "" ] || python -m ruff format $(PYTHON_FILES) --diff
	[ "$(PYTHON_FILES)" = "" ] || python -m ruff check --select I $(PYTHON_FILES)
	[ "$(PYTHON_FILES)" = "" ] || python -m mypy --strict $(PYTHON_FILES)
	[ "$(PYTHON_FILES)" = "" ] || mkdir -p $(MYPY_CACHE) && python -m mypy --strict $(PYTHON_FILES) --cache-dir $(MYPY_CACHE)

format format_diff:
	ruff format $(PYTHON_FILES)
	ruff check --select I --fix $(PYTHON_FILES)

spell_check:
	codespell --toml pyproject.toml

spell_fix:
	codespell --toml pyproject.toml -w

######################
# HELP
######################

help:
	@echo '----'
	@echo 'format                       - run code formatters'
	@echo 'lint                         - run linters'
	@echo 'test                         - run unit tests'
	@echo 'tests                        - run unit tests'
	@echo 'test TEST_FILE=<test_file>   - run all tests in file'
	@echo 'test_watch                   - run unit tests in watch mode'



--- File Index 44: backend/path/to/your/app/README.md ---
# New LangGraph Project

[![CI](https://github.com/langchain-ai/new-langgraph-project/actions/workflows/unit-tests.yml/badge.svg)](https://github.com/langchain-ai/new-langgraph-project/actions/workflows/unit-tests.yml)
[![Integration Tests](https://github.com/langchain-ai/new-langgraph-project/actions/workflows/integration-tests.yml/badge.svg)](https://github.com/langchain-ai/new-langgraph-project/actions/workflows/integration-tests.yml)

This template demonstrates a simple application implemented using [LangGraph](https://github.com/langchain-ai/langgraph), designed for showing how to get started with [LangGraph Server](https://langchain-ai.github.io/langgraph/concepts/langgraph_server/#langgraph-server) and using [LangGraph Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/), a visual debugging IDE.

<div align="center">
  <img src="./static/studio_ui.png" alt="Graph view in LangGraph studio UI" width="75%" />
</div>

The core logic defined in `src/agent/graph.py`, showcases an single-step application that responds with a fixed string and the configuration provided.

You can extend this graph to orchestrate more complex agentic workflows that can be visualized and debugged in LangGraph Studio.

## Getting Started

<!--
Setup instruction auto-generated by `langgraph template lock`. DO NOT EDIT MANUALLY.
-->

<!--
End setup instructions
-->

1. Install dependencies, along with the [LangGraph CLI](https://langchain-ai.github.io/langgraph/concepts/langgraph_cli/), which will be used to run the server.

```bash
cd path/to/your/app
pip install -e . "langgraph-cli[inmem]"
```

2. (Optional) Customize the code and project as needed. Create a `.env` file if you need to use secrets.

```bash
cp .env.example .env
```

If you want to enable LangSmith tracing, add your LangSmith API key to the `.env` file.

```text
# .env
LANGSMITH_API_KEY=lsv2...
```

3. Start the LangGraph Server.

```shell
langgraph dev
```

For more information on getting started with LangGraph Server, [see here](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/).

## How to customize

1. **Define configurable parameters**: Modify the `Configuration` class in the `graph.py` file to expose the arguments you want to configure. For example, in a chatbot application you may want to define a dynamic system prompt or LLM to use. For more information on configurations in LangGraph, [see here](https://langchain-ai.github.io/langgraph/concepts/low_level/?h=configuration#configuration).

2. **Extend the graph**: The core logic of the application is defined in [graph.py](./src/agent/graph.py). You can modify this file to add new nodes, edges, or change the flow of information.

## Development

While iterating on your graph in LangGraph Studio, you can edit past state and rerun your app from previous states to debug specific nodes. Local changes will be automatically applied via hot reload.

Follow-up requests extend the same thread. You can create an entirely new thread, clearing previous history, using the `+` button in the top right.

For more advanced features and examples, refer to the [LangGraph documentation](https://langchain-ai.github.io/langgraph/). These resources can help you adapt this template for your specific use case and build more sophisticated conversational agents.

LangGraph Studio also integrates with [LangSmith](https://smith.langchain.com/) for more in-depth tracing and collaboration with teammates, allowing you to analyze and optimize your chatbot's performance.

<!--
Configuration auto-generated by `langgraph template lock`. DO NOT EDIT MANUALLY.
{
  "config_schemas": {
    "agent": {
      "type": "object",
      "properties": {}
    }
  }
}
-->


--- File Index 45: backend/path/to/your/app/src/agent/__init__.py ---
"""New LangGraph Agent.

This module defines a custom graph.
"""

from agent.graph import graph

__all__ = ["graph"]


--- File Index 46: backend/path/to/your/app/src/agent/graph.py ---
"""LangGraph single-node graph template.

Returns a predefined response. Replace logic and configuration as needed.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, TypedDict

from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph


class Configuration(TypedDict):
    """Configurable parameters for the agent.

    Set these when creating assistants OR when invoking the graph.
    See: https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/
    """

    my_configurable_param: str


@dataclass
class State:
    """Input state for the agent.

    Defines the initial structure of incoming data.
    See: https://langchain-ai.github.io/langgraph/concepts/low_level/#state
    """

    changeme: str = "example"


async def call_model(state: State, config: RunnableConfig) -> Dict[str, Any]:
    """Process input and returns output.

    Can use runtime configuration to alter behavior.
    """
    configuration = config["configurable"]
    return {
        "changeme": "output from call_model. "
        f'Configured with {configuration.get("my_configurable_param")}'
    }


# Define the graph
graph = (
    StateGraph(State, config_schema=Configuration)
    .add_node(call_model)
    .add_edge("__start__", "call_model")
    .compile(name="New Graph")
)


--- File Index 47: fastapi_server/README.md ---
# LangGraph Agent FastAPI Server

이 프로젝트는 LangGraph 기반 멀티 에이전트 시스템을 FastAPI 웹 서버로 서빙하는 어플리케이션입니다.

## 프로젝트 구조

```
fastapi_server/
├── __init__.py          # 패키지 초기화 파일
├── main.py              # FastAPI 애플리케이션 메인 파일
├── agent_service.py     # LangGraph 에이전트와의 인터페이스
├── models.py            # API 요청/응답 모델
├── requirements.txt     # 필요한 의존성
├── start_server.py      # 서버 실행 스크립트
└── README.md            # 이 문서
```

## 설치 및 실행 방법

### 1. 가상 환경 설정

항상 가상 환경을 사용하는 것이 좋습니다. 가상 환경을 생성하고 활성화하세요:

```bash
# 가상 환경 생성
python -m venv venv

# 가상 환경 활성화 (Windows)
venv\Scripts\activate

# 가상 환경 활성화 (Linux/Mac)
source venv/bin/activate
```

### 2. 의존성 설치

필요한 패키지를 설치합니다:

```bash
pip install -r requirements.txt
```

### 3. 환경 변수 설정

프로젝트 루트 디렉토리에 `.env` 파일이 있는지 확인하세요. 다음과 같은 환경 변수가 필요합니다:

```
OPENAI_API_KEY=your_openai_api_key_here
```

### 4. 서버 실행

다음 명령을 사용하여 서버를 시작합니다:

```bash
# 방법 1: start_server.py 스크립트 사용
python start_server.py

# 방법 2: uvicorn 직접 사용
uvicorn fastapi_server.main:app --host 0.0.0.0 --port 8001 --reload
```

서버가 성공적으로 시작되면 http://localhost:8001 에서 접근할 수 있습니다.

## API 엔드포인트

### 1. 상태 확인

- **URL**: GET /
- **응답**: 서버 상태 정보

### 2. 채팅 메시지 전송

- **URL**: POST /api/chat
- **요청 본문**:
  ```json
  {
    "message": "사용자 메시지",
    "thread_id": "선택적_대화_ID"
  }
  ```
- **응답**: 에이전트 응답

### 3. WebSocket 스트리밍 채팅

- **URL**: WebSocket /api/chat/ws/{thread_id}
- **사용법**: 
  - 연결 후, JSON 형식의 메시지 전송: `{"message": "사용자 메시지"}`
  - 서버는 다양한 이벤트 타입을 포함한 JSON 응답을 스트리밍합니다.
  - 이벤트 타입: `token`, `agent_change`, `tool_start`, `tool_end`, `done`, `error`

## 예제 사용 코드

### HTTP API 사용 예제 (Python)

```python
import requests

response = requests.post(
    "http://localhost:8001/api/chat",
    json={"message": "지역별 매출을 분석해줘"}
)
print(response.json())
```

### WebSocket 스트리밍 예제 (JavaScript)

```javascript
const ws = new WebSocket('ws://localhost:8001/api/chat/ws/my-thread-1');

ws.onopen = () => {
  console.log('Connected to server');
  ws.send(JSON.stringify({
    message: '데이터 시각화를 도와줘'
  }));
};

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log(data);
  
  if (data.type === 'token') {
    // 토큰 처리 (점진적으로 UI에 텍스트 추가)
    process.stdout.write(data.content);
  } else if (data.type === 'agent_change') {
    console.log(`Agent changed to: ${data.agent}`);
  } else if (data.type === 'done') {
    console.log('\nResponse complete!');
  }
};
```

## 문제 해결

1. **ImportError**: 필요한 모듈을 찾지 못하는 경우, 가상 환경이 활성화되어 있고 모든 의존성이 설치되어 있는지 확인하세요.

2. **API 키 오류**: OPENAI_API_KEY가 올바르게 설정되어 있는지 확인하세요.

3. **포트 충돌**: 8001 포트가 이미 사용 중인 경우, `main.py`에서 포트 번호를 변경하세요.


--- File Index 48: fastapi_server/__init__.py ---
# FastAPI server package for LangGraph Agent


--- File Index 49: fastapi_server/agent/__init__.py ---
# fastapi_server/agent package


--- File Index 50: fastapi_server/agent/agent2.py ---
from __future__ import annotations

import os
from dataclasses import dataclass
from typing import TypedDict, Dict, Sequence, Union, Optional, Any
import asyncio

from asgiref.sync import sync_to_async
from langchain_core.prompts import PromptTemplate, SystemMessagePromptTemplate,HumanMessagePromptTemplate,ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langgraph.graph import END, START, StateGraph
from dotenv import load_dotenv
from openai import OpenAI
from pinecone import Pinecone, ServerlessSpec
from langchain.chat_models import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langgraph.graph.message import add_messages
from fastapi_server.agent.prompt import (
    document_type_system_prompt_agent2,
    proceedings_summary_prompt_agent2,
    internal_policy_summary_prompt_template_agent2,
    product_document_summary_prompt_template_agent2,
    technical_document_summary_prompt_template_agent2,
    unknown_document_type_prompt_agent2,
    rag_answer_generation_prompt_agent2,
    rag_system_message_agent2
)
load_dotenv()

def init_clients():
    # 1-1) OpenAI 클라이언트 생성
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        raise ValueError("⚠️ 환경변수 OPENAI_API_KEY가 설정되지 않았습니다.")
    # OpenAI 인스턴스를 만듭니다.
    openai_client = OpenAI(api_key=openai_api_key)
    print("✅ OpenAI 클라이언트 생성 완료")

    # 1-2) Pinecone 인스턴스 생성
    pinecone_api_key = os.getenv("PINECONE_API_KEY")
    pinecone_env     = os.getenv("PINECONE_ENVIRONMENT")   # 예: "us-east1-gcp" 또는 "us-west1-gcp" 등
    if not pinecone_api_key or not pinecone_env:
        raise ValueError("⚠️ 환경변수 PINECONE_API_KEY 또는 PINECONE_ENVIRONMENT가 누락되었습니다.")

    pc = Pinecone(api_key=pinecone_api_key, environment=pinecone_env)
    print("✅ Pinecone 클라이언트 생성 완료")

    # 1-3) 인덱스 존재 여부 확인
    index_name = "dense-index"  # 실제 사용 중인 인덱스 이름으로 교체하세요
    existing_indexes = pc.list_indexes().names()
    if index_name not in existing_indexes:
        raise ValueError(f"⚠️ 인덱스 '{index_name}'가 Pinecone에 존재하지 않습니다. 현재 인덱스 목록: {existing_indexes}")

    # 1-4) 해당 인덱스 객체 가져오기
    index = pc.Index(index_name)
    print(f"✅ Pinecone 인덱스 '{index_name}' 연결 완료 (Namespaces: {len(index.describe_index_stats().namespaces)})")

    return openai_client, index


# --------------------------------------------------
# 2) 질문 문장을 임베딩 벡터로 변환
# --------------------------------------------------
def embed_query(openai_client: OpenAI, text: str) -> list:
    """
    최신 OpenAI 클라이언트에서는 resp.data[0].embedding 으로 벡터에 접근해야 합니다.
    """
    resp = openai_client.embeddings.create(
        model="text-embedding-3-large",
        input=text
    )
    return resp.data[0].embedding


# --------------------------------------------------
# 3) 여러 네임스페이스 중 “가장 높은 유사도”를 준 네임스페이스와 매칭 결과 반환
# --------------------------------------------------
def retrieve_best_namespace(index, query_vector: list, top_k: int = 5):
    """
    1) index.describe_index_stats()를 통해 모든 네임스페이스 목록을 얻는다.
    2) 각 네임스페이스별로 query_vector를 index.query()로 검색하고,
       matches[0].score 를 비교해서 “최고 유사도”를 찾는다.
    3) 가장 높은 유사도를 준 네임스페이스(best_ns)와 해당 네임스페이스의 전체 매칭 결과(best_matches)를 반환.
    """
    stats = index.describe_index_stats()
    available_namespaces = list(stats.namespaces.keys())
    if not available_namespaces:
        raise ValueError("⚠️ 인덱스에 네임스페이스가 없습니다.")

    best_ns = None
    best_score = -1.0
    best_matches = None

    for ns in available_namespaces:
        count = stats.namespaces[ns]["vector_count"]
        if count == 0:
            # 비어 있는 네임스페이스 건너뛰기
            continue

        res = index.query(
            vector=query_vector,
            namespace=ns,
            top_k=top_k,
            include_metadata=True
        )
        if not res.matches:
            continue

        top_score = res.matches[0].score
        if top_score > best_score:
            best_score = top_score
            best_ns = ns
            best_matches = res.matches

    if best_ns is None:
        raise ValueError("⚠️ 어떤 네임스페이스에서도 매칭 결과를 찾을 수 없습니다.")
    
    print(f"🔍 선택된 네임스페이스: '{best_ns}' (최고 유사도: {best_score:.4f})")
    return best_ns, best_matches


# --------------------------------------------------
# 4) 검색된 매칭 결과에서 실제 텍스트(메타데이터)를 꺼내 Context 로 결합
# --------------------------------------------------
def build_context_from_matches(matches):
    """
    res.matches 리스트 안의 각 item.metadata 에 들어 있는 텍스트 필드를 추출합니다.
    업로드 시 metadata 키가 "text"였다고 가정했습니다.
    """
    contexts = []
    for m in matches:
        chunk_text = m.metadata.get("text", "")
        if chunk_text:
            contexts.append(chunk_text)

    return "\n---\n".join(contexts)


# --------------------------------------------------
# 5) LLM ChatCompletion 호출하여 답변 생성
# --------------------------------------------------
def generate_answer_with_context(openai_client: OpenAI, question: str, context: str) -> str:
    """
    최신 OpenAI 클라이언트에서는 client.chat.completions.create(...) 형태를 씁니다.
    """
    formatted_prompt = rag_answer_generation_prompt_agent2.format(context=context, question=question)
    resp = openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": rag_system_message_agent2},
            {"role": "user", "content": formatted_prompt}
        ],
        temperature=0.0,
        max_tokens=1024
    )
    # resp.choices[0].message.content 으로 답변 추출
    return resp.choices[0].message.content.strip()



@dataclass
class State:
    # Compatible with both direct user_input and messages-based interface
    user_input: str = ""
    document_type: str = ""
    result: str = ""
    messages: Sequence[BaseMessage] = None
    
    def __post_init__(self):
        # If initialized from supervisor with messages but no user_input, extract user_input
        if not self.user_input and self.messages:
            # Extract user input from the last human message
            user_messages = [msg for msg in self.messages if isinstance(msg, HumanMessage)]
            if user_messages:
                self.user_input = user_messages[-1].content
    
    def dict(self):
        """Return dict representation with messages if present"""
        result = {
            "result": self.result,
            "document_type": self.document_type,
            "user_input": self.user_input
        }
        # If this was called with messages, return updated messages too
        if self.messages is not None:
            result["messages"] = self.messages + [AIMessage(content=self.result)] if self.result else self.messages
        return result  # 챗봇 결과


def choose_document_type(message):
    """
    OpenAI 클라이언트를 사용하여 문서 타입을 분류합니다. 리턴 데이터 형식은 기존과 동일하게 유지합니다.
    """
    client = OpenAI()
    formatted_prompt = document_type_system_prompt_agent2.format(user_input=message)
    
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": formatted_prompt}
        ],
        temperature=0,
        max_tokens=100
    )
    
    classified_type = resp.choices[0].message.content.strip()
    print(f"문서 타입 분류 결과: {classified_type}")
    return classified_type

def choose_node(state: State):
    # Extract the user input from the state
    user_input = state.user_input

    # Choose document type
    document_type = choose_document_type(user_input)
    
    # Update state with document type
    state.document_type = document_type
    
    # Print document type for debugging
    # print(f"Document Type: {document_type}")
    
    return state.dict()

def choose_one(state: State) -> str:
    choice = state.document_type
    # Use logging instead of print to avoid output being captured in response
    # print(f"(choice_one) Choice: {choice}")
    # This must return the string key for conditional edge routing
    if choice in ["internal_policy", "product_document", "technical_document", "proceedings"]:
        return choice
    else:
        return "product_document"  # Default fallback

def execute_rag(state: State):
    # print(f"\n📄 RAG 노드 실행: 문서 타입 = '{state.document_type}', 질문 = '{state.user_input}'")
    openai_client, pinecone_index = init_clients()
    # print("   - 클라이언트 초기화 완료")

    query_vector = embed_query(openai_client, state.user_input)
    # print(f"   - 질문 임베딩 완료 (벡터 크기: {len(query_vector)})")

    namespace_to_search = state.document_type
    if not namespace_to_search or namespace_to_search == "unknown":
        message = f"문서 타입이 '{namespace_to_search}'(으)로 분류되어 Pinecone 검색을 수행하지 않습니다."
        # print(f"   - 정보: {message}")
        # 'unknown'일 경우, unknown_handler_node에서 이미 메시지를 설정했을 수 있으므로, 여기서는 덮어쓰지 않거나
        # 혹은 여기서 다른 메시지를 설정할 수 있습니다. 여기서는 검색 불가 메시지만 남깁니다.
        # 실제로는 'unknown' 타입은 이 노드로 오지 않고 unknown_handler_node로 가야 합니다.
        # 이 코드는 execute_rag_node가 'unknown' 타입으로 호출될 경우를 대비한 방어 코드입니다.
        state.result = "적절한 문서 저장소를 찾을 수 없어 검색을 수행할 수 없습니다."
        return state.dict()

    # print(f"   - Pinecone 네임스페이스 '{namespace_to_search}'에서 검색 시작...")
    index_stats = pinecone_index.describe_index_stats()
    if namespace_to_search not in index_stats.namespaces or \
        index_stats.namespaces[namespace_to_search].vector_count == 0:
        message = f"'{namespace_to_search}' 네임스페이스를 Pinecone에서 찾을 수 없거나, 해당 네임스페이스에 데이터가 없습니다. Pinecone 대시보드에서 네임스페이스 이름과 데이터 존재 여부를 확인해주세요."
        # print(f"   - 경고: {message}")
        state.result = message
        return state.dict()

    res = pinecone_index.query(
        vector=query_vector,
        namespace=namespace_to_search,
        top_k=5, # 검색할 문서 수
        include_metadata=True
    )
    matches = res.matches
    # print(f"   - Pinecone 검색 완료: {len(matches)}개 결과 수신")

    if not matches:
        message = f"'{namespace_to_search}' 네임스페이스에서 '{state.user_input}' 질문과 관련된 정보를 찾지 못했습니다."
        # print(f"   - 정보 없음: {message}")
        state.result = message
        return state.dict()
    
    context = build_context_from_matches(matches)
    if not context:
        message = "검색된 정보에서 답변을 생성할 컨텍스트를 추출하지 못했습니다."
        print(f"   - 컨텍스트 구축 실패: {message}")
        state.result = message
        return state.dict()
    print(f"   - 컨텍스트 구축 완료 (길이: {len(context)})")

    state.result = context
    return state.dict()
    

def summarize_node(state: State):
    text = state.result
    document_type = state.document_type
    user_input = state.user_input

    if state.document_type == "proceedings":
        system_message = proceedings_summary_prompt_agent2
    elif state.document_type == "internal_policy":
        system_message = internal_policy_summary_prompt_template_agent2.format(user_input=user_input)
    elif state.document_type == "product_document":
        system_message = product_document_summary_prompt_template_agent2.format(user_input=user_input)
    elif state.document_type == "technical_document":
        system_message = technical_document_summary_prompt_template_agent2.format(user_input=user_input)
    else: # unknown or fallback
        system_message = unknown_document_type_prompt_agent2
    
    system_message = SystemMessagePromptTemplate.from_template(system_message)
    human_message = HumanMessagePromptTemplate.from_template("{text}")

    chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])

    # 2. LLM 생성
    llm = ChatOpenAI(model="gpt-4o")

    # 3. Prompt와 LLM 결합
    chatbot = chat_prompt | llm

    # 4. 실행
    response = chatbot.invoke({"text": text})
    result = response.content
    # print(result)  # 디버깅용 출력 제거
    state.result = result
    
    # 문서 타입이 최종 결과에 포함되지 않도록, document_type을 제외한 상태만 반환
    result_state = state.dict()
    if "document_type" in result_state:
        # document_type 값이 최종 출력에 포함되지 않도록 제거
        del result_state["document_type"]
    
    return result_state

# 비동기 노드 래퍼 함수들 정의
async def async_choose_node(state: State):
    return await sync_to_async(choose_node)(state)

async def async_execute_rag(state: State):
    return await sync_to_async(execute_rag)(state)

async def async_summarize_node(state: State):
    return await sync_to_async(summarize_node)(state)

async def async_choose_one(state: State):
    return await sync_to_async(choose_one)(state)

# Define the graph with async nodes
graph = (
    StateGraph(State)
    # (1) choose_node 분기 노드 등록 (outputs에 리턴 키 명시)
    .add_node("choose_node", async_choose_node)
    # (2) RAG 실행 노드들 등록
    .add_node("product_node", async_execute_rag)
    .add_node("proceedings_node", async_execute_rag)
    .add_node("hr_policy_node", async_execute_rag)
    .add_node("technical_document_node", async_execute_rag)
    # (3) summarize_node 등록 (최종 노드)
    .add_node("summarize_node", async_summarize_node)
    # (4) START → 분기 노드(choose_node) → (next_node 값에 따라) 분기
    .add_edge(START,"choose_node")
    .add_conditional_edges(
        "choose_node",
        async_choose_one,
        {
            "product_document": "product_node",
            "proceedings": "proceedings_node",
            "internal_policy": "hr_policy_node",
            "technical_document": "technical_document_node"
        }
    )
    # (5) 각 RAG 노드 → summarize_node 연결
    .add_edge("product_node", "summarize_node")
    .add_edge("proceedings_node", "summarize_node")
    .add_edge("hr_policy_node", "summarize_node")
    .add_edge("technical_document_node", "summarize_node")
    .add_edge("summarize_node", END)
    # (6) 최종 컴파일
    .compile(name="New Graph")
)



Based on the provided codebase, identify the key abstractions that are central to understanding this project. 
These abstractions should represent the core components, modules, or concepts.

Desired output format is a YAML list of objects, where each object has:
- 'name': A concise name for the abstraction (in korean).
- 'description': A brief explanation of what this abstraction represents and its role (in korean).
- 'file_indices': A list of integer file indices that are most relevant to this abstraction. Choose from the file list above.

Return at most 10 key abstractions.

Example for a different project (simple web server):
```yaml
- name: "HTTP 요청 핸들러 (HTTP Request Handler)"
  description: "수신 HTTP 요청을 처리하고 적절한 응답을 생성하는 구성 요소입니다. (Component that processes incoming HTTP requests and generates appropriate responses.)"
  file_indices: [0, 2]
- name: "라우팅 설정 (Routing Configuration)"
  description: "URL 경로를 특정 요청 핸들러 함수에 매핑하는 규칙을 정의합니다. (Defines rules for mapping URL paths to specific request handler functions.)"
  file_indices: [1]
```

Your response should be only the YAML list, enclosed in triple backticks (```yaml ... ```).
Ensure the output is valid YAML.

2025-06-29 20:52:38,989 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:52:49,878 - INFO - RESPONSE: ```yaml
- name: "AI 에이전트 총괄 시스템 (LangGraph Supervisor)"
  description: "사용자의 자연어 요청을 분석하여 적합한 전문 에이전트에 작업을 분배하는 시스템입니다. (System that analyzes user natural language requests and routes tasks to appropriate specialized agents.)"
  file_indices: [0, 44, 46, 50]

- name: "문서 검색 전문 에이전트 (RAG Agent)"
  description: "사용자의 질문에 대해 회사 내부 문서를 검색하고 답변을 생성하는 에이전트입니다. (Agent that retrieves and generates answers based on company internal documents in response to user queries.)"
  file_indices: [46, 50]

- name: "데이터 분석 전문 에이전트 (Analytics Agent)"
  description: "사용자의 질문을 바탕으로 데이터베이스를 검색, 분석하여 정보를 제공하는 에이전트입니다. (Agent that analyzes and provides insights from the database based on user queries.)"
  file_indices: [0, 40, 46]

- name: "FastAPI 서버"
  description: "실시간 AI 통신을 처리하며, 사용자와 AI 시스템 간의 데이터 교환을 담당하는 서버입니다. (Server that handles real-time AI communication and exchanges data between users and AI systems.)"
  file_indices: [47, 50]

- name: "계정 관리 모듈 (Accounts Module)"
  description: "사용자와 조직 정보를 관리하고 인증 처리 기능을 제공하는 모듈입니다. (Module that manages user and organization information and provides authentication functions.)"
  file_indices: [1, 2, 3, 6, 7, 9]

- name: "챗봇 세션 관리 (Chat Session Management)"
  description: "사용자의 대화 세션과 메시지를 관리하고 저장하는 구성 요소입니다. (Component that manages and stores user chat sessions and messages.)"
  file_indices: [22, 25, 23]

- name: "지식베이스 관리 (Knowledge Management)"
  description: "조직의 문서와 임베딩 데이터를 관리하며, 문서 검색을 지원합니다. (Management of organization documents and embedding data, supporting document retrieval.)"
  file_indices: [26, 27, 32]

- name: "MLOps 관리 (MLOps Management)"
  description: "분석 결과와 모델 아티팩트를 관리하고 추적하는 시스템입니다. (System that manages and tracks analytics results and model artifacts.)"
  file_indices: [36, 40]

- name: "환경 설정 및 배포 (Environment Setup and Deployment)"
  description: "프로젝트의 환경 설정과 관련된 파일 및 배포 절차를 정의합니다. (Defines environment setup files and deployment procedures.)"
  file_indices: [12, 34, 43]

- name: "백엔드 라우팅 (Backend Routing)"
  description: "Django를 통해 백엔드 API 경로와 뷰를 설정하고 관리합니다. (Configures and manages backend API routes and views using Django.)"
  file_indices: [13, 8, 24]
```
2025-06-29 20:52:50,257 - INFO - PROMPT: 
Based on the following abstractions and relevant code snippets from the project `SKN10-FINAL-1Team`:

List of Abstraction Indices and Names (Names might be in Korean):
0 # AI 에이전트 총괄 시스템 (LangGraph Supervisor)
1 # 문서 검색 전문 에이전트 (RAG Agent)
2 # 데이터 분석 전문 에이전트 (Analytics Agent)
3 # FastAPI 서버
4 # 계정 관리 모듈 (Accounts Module)
5 # 챗봇 세션 관리 (Chat Session Management)
6 # 지식베이스 관리 (Knowledge Management)
7 # MLOps 관리 (MLOps Management)
8 # 환경 설정 및 배포 (Environment Setup and Deployment)
9 # 백엔드 라우팅 (Backend Routing)

Context (Abstractions, Descriptions, Code):
Identified Abstractions:
- Index 0: AI 에이전트 총괄 시스템 (LangGraph Supervisor) (Relevant file indices: [0, 44, 46, 50])
  Description: 사용자의 자연어 요청을 분석하여 적합한 전문 에이전트에 작업을 분배하는 시스템입니다. (System that analyzes user natural language requests and routes tasks to appropriate specialized agents.)
- Index 1: 문서 검색 전문 에이전트 (RAG Agent) (Relevant file indices: [46, 50])
  Description: 사용자의 질문에 대해 회사 내부 문서를 검색하고 답변을 생성하는 에이전트입니다. (Agent that retrieves and generates answers based on company internal documents in response to user queries.)
- Index 2: 데이터 분석 전문 에이전트 (Analytics Agent) (Relevant file indices: [0, 40, 46])
  Description: 사용자의 질문을 바탕으로 데이터베이스를 검색, 분석하여 정보를 제공하는 에이전트입니다. (Agent that analyzes and provides insights from the database based on user queries.)
- Index 3: FastAPI 서버 (Relevant file indices: [47, 50])
  Description: 실시간 AI 통신을 처리하며, 사용자와 AI 시스템 간의 데이터 교환을 담당하는 서버입니다. (Server that handles real-time AI communication and exchanges data between users and AI systems.)
- Index 4: 계정 관리 모듈 (Accounts Module) (Relevant file indices: [1, 2, 3, 6, 7, 9])
  Description: 사용자와 조직 정보를 관리하고 인증 처리 기능을 제공하는 모듈입니다. (Module that manages user and organization information and provides authentication functions.)
- Index 5: 챗봇 세션 관리 (Chat Session Management) (Relevant file indices: [22, 25, 23])
  Description: 사용자의 대화 세션과 메시지를 관리하고 저장하는 구성 요소입니다. (Component that manages and stores user chat sessions and messages.)
- Index 6: 지식베이스 관리 (Knowledge Management) (Relevant file indices: [26, 27, 32])
  Description: 조직의 문서와 임베딩 데이터를 관리하며, 문서 검색을 지원합니다. (Management of organization documents and embedding data, supporting document retrieval.)
- Index 7: MLOps 관리 (MLOps Management) (Relevant file indices: [36, 40])
  Description: 분석 결과와 모델 아티팩트를 관리하고 추적하는 시스템입니다. (System that manages and tracks analytics results and model artifacts.)
- Index 8: 환경 설정 및 배포 (Environment Setup and Deployment) (Relevant file indices: [12, 34, 43])
  Description: 프로젝트의 환경 설정과 관련된 파일 및 배포 절차를 정의합니다. (Defines environment setup files and deployment procedures.)
- Index 9: 백엔드 라우팅 (Backend Routing) (Relevant file indices: [13, 8, 24])
  Description: Django를 통해 백엔드 API 경로와 뷰를 설정하고 관리합니다. (Configures and manages backend API routes and views using Django.)

Relevant File Snippets (Referenced by Index and Path):
--- File: 0 # README.md ---
## TSKN10-FINAL-1Team

## 프로젝트 개요
이 프로젝트는 사용자가 채팅으로 업무를 요청할 수 있는 **지능형 사내 업무 보조 챗봇 시스템**입니다. 사용자의 질문 의도를 **AI 에이전트 총괄 시스템 LangGraph Supervisor**이 파악하여 적절한 전문 에이전트에게 작업을 분배합니다. 마치 오케스트라의 지휘자처럼, 슈퍼바이저는 전체적인 요청을 보고 적임자(에이전트)를 찾아 지시를 내립니다. 예를 들어, 회사 규정 관련 질문은 **문서 검색 전문 에이전트 RAG Agent**에게, 데이터 분석 요청은 **데이터 분석 전문 에이전트 Analytics Agent**에게 전달됩니다. 코드 관련 질문은 **코드 분석 에이전트**가 담당할 수 있습니다. 모든 데이터는 **애플리케이션 데이터 설계도 Django 모델**에 따라 체계적으로 저장되며, 프론트엔드는 **실시간 AI 통신 게이트웨이 FastAPI & WebSocket**를 통해 AI 시스템과 매끄럽게 연결되어 AI 답변 생성 과정을 실시간으로 보여줍니다 (스트리밍). 이 시스템은 복잡한 내부 구조를 몰라도 사용자가 AI를 사람과 대화하듯 편안하게 사용할 수 있도록 설계되었습니다.

## 핵심 기능
*   **AI 에이전트 총괄 시스템 LangGraph Supervisor**: 사용자의 자연어 요청을 분석하여 가장 적합한 전문 에이전트 노드에게 작업을 라우팅하는 역할을 합니다. 슈퍼바이저는 특정 '업무 지침서'(Prompt)를 바탕으로 다음 에이전트를 결정합니다.
*   **문서 검색 전문 에이전트 RAG Agent**: 회사 내부 문서(정책, 매뉴얼, 회의록 등)에 대한 사용자의 질문에 답변합니다. Retrieval-Augmented Generation (RAG) 기술을 사용하며, 질문과 관련 있는 문서 조각을 **임베딩**과 **벡터 데이터베이스 Pinecone**를 통해 먼저 검색한 뒤(Retrieval), 그 내용을 바탕으로 답변을 생성합니다(Generation).
*   **데이터 분석 전문 에이전트 Analytics Agent**: 데이터베이스에 저장된 데이터를 분석하고 통찰력을 제공합니다. 사용자의 자연어 질문을 컴퓨터가 이해하는 SQL 쿼리로 변환하고 데이터베이스에서 실행하여 결과를 가져옵니다. 결과는 텍스트로 요약되거나 **Mermaid 차트** 코드로 시각화됩니다. (논의를 통해 시계열 예측보다는 이상치 모델링 방향으로 고려되었습니다).
*   **코드 분석 에이전트 Code Agent** (논의 중): GitHub 저장소나 사내 코드 베이스의 내용을 분석하고 질의응답하는 것을 목표로 합니다. 코드의 오류 부분을 파악하거나, 특정 함수의 사용 위치나 상호작용하는 파일을 알려주고, 도큐멘테이션을 참고하여 질문에 답변할 수 있습니다. 필요에 따라 코드 변환 기능도 포함될 수 있습니다. 사용자의 코드 언어 버전 탐지 및 해당 버전에 맞는 답변 제공이 중요하게 고려됩니다.
*   **실시간 AI 통신 게이트웨이 FastAPI & WebSocket**: 사용자의 브라우저과 AI 시스템을 연결하는 통신 다리 역할을 합니다. **WebSocket**을 통해 한 번 연결되면 끊기지 않는 '전화 통화'처럼 실시간으로 데이터를 주고받으며, **FastAPI**가 이 통신을 효율적으로 처리합니다. 이를 통해 AI 답변 생성 과정을 실시간 스트리밍으로 사용자에게 보여줍니다.
*   **외부 데이터 수집 및 처리 ETL**: AI 에이전트가 사용할 데이터(고객 정보, 뉴스, 문서 등)를 외부에서 가져와(Extract) 시스템이 사용하기 좋은 형태로 가공한 뒤(Transform), 데이터베이스나 벡터 저장소에 저장하는(Load) 자동화된 스크립트(파이프라인)를 의미합니다. tools 및 lambda 폴더의 파이썬 스크립트가 이 역할을 수행합니다. (CSV 파일의 고객 데이터, 최신 뉴스, 문서 파일(PDF, HTML) 텍스트 및 벡터 변환 등을 처리합니다).
*   **프론트엔드 채팅 UI**: 사용자가 AI와 직접 소통하고 눈으로 볼 수 있는 '얼굴'입니다. 메시지 입력창, 대화 내용이 보이는 말풍선(메시지 목록), 과거 대화 목록을 보여주는 사이드바 등으로 구성됩니다. React(Next.js)의 useState 기능을 사용하여 UI 상태를 관리하고, 서버로부터 받은 메시지를 화면에 그려줍니다.

## 기술 스택
*   **백엔드/AI**:
    *   웹 프레임워크: ![Django](https://img.shields.io/badge/Django-092E20?style=flat-square&logo=django&logoColor=white) (애플리케이션 데이터 설계 및 전통적인 API 연동)
    *   AI 통신 게이트웨이: ![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=flat-square&logo=fastapi&logoColor=white) (실시간 통신 처리 및 에이전트 시스템 연동)
    *   실시간 통신: ![WebSocket](https://img.shields.io/badge/WebSocket-4353FF?style=flat-square&logo=socketdotio&logoColor=white)
    *   AI 오케스트레이션: ![LangGraph](https://img.shields.io/badge/LangGraph-FF5A5F?style=flat-square&logo=langchain&logoColor=white) (다양한 에이전트들의 작업 흐름 및 협업 설계)
    *   LLM: ![GPT](https://img.shields.io/badge/GPT-74aa9c?style=flat-square&logo=openai&logoColor=white) (주요 모델), 필요에 따라 ![Local LLM](https://img.shields.io/badge/Local_LLM-4B32C3?style=flat-square&logo=artificial-intelligence&logoColor=white) (Qwen3 32B 등) 서빙 (Runpod 활용), 다른 오픈소스 모델 (Mistral 등) 및 상용 모델 (Claude, Gemini) 고려.
    *   임베딩 모델: ![OpenAI Embeddings](https://img.shields.io/badge/OpenAI_Embeddings-74aa9c?style=flat-square&logo=openai&logoColor=white) (문서 및 쿼리 벡터 생성)
    *   벡터 데이터베이스: ![Pinecone](https://img.shields.io/badge/Pinecone-000000?style=flat-square&logo=pinecone&logoColor=white) (문서 임베딩 저장 및 검색), ![PostgreSQL](https://img.shields.io/badge/PostgreSQL_pgvector-4169E1?style=flat-square&logo=postgresql&logoColor=white) (논의됨). 하이브리드 서치 및 리랭킹 기능 고려.
    *   관계형 데이터베이스: ![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?style=flat-square&logo=postgresql&logoColor=white) (사용자 정보, 채팅 내용, 분석 결과, 정형 데이터셋 등 저장).
    *   객체 스토리지: ![AWS S3](https://img.shields.io/badge/AWS_S3-569A31?style=flat-square&logo=amazons3&logoColor=white) (업로드 파일, 원본 문서, 모델 저장 등).
    *   ETL 스크립트: ![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=white) ![AWS Lambda](https://img.shields.io/badge/AWS_Lambda-FF9900?style=flat-square&logo=awslambda&logoColor=white) (requests, psycopg2, tqdm, pdfplumber, beautifulsoup, OpenAI API 등 활용).
    *   배포: ![AWS EC2](https://img.shields.io/badge/AWS_EC2-FF9900?style=flat-square&logo=amazonec2&logoColor=white), ![Runpod](https://img.shields.io/badge/Runpod-6C47FF?style=flat-square&logo=runpod&logoColor=white) (VLLM 서빙).
    *   툴 호출 표준: ![MCP](https://img.shields.io/badge/MCP-007ACC?style=flat-square&logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAqFBMVEX///8AAP8AgP8AgIAAgIBVVaoAYIBAgIBAYGBAYIBJbYBJbXFJbW1Nc21NbnZNbnFNbm1QcXFQcXZQcW1SdG1SdHFSdG1VVXFVVXZVVXFVVWpVVW1VVW1VVW1VVW1VVW1VVW1VVW1VVW1VVW1VVW1VVW1VVW1VVW1VVW1)

## 팀원 및 역할 (Roles and Responsibilities)
| 이름 | 이미지 | 역할 |
| ------ | ------ | ------ |
| **신정우** (PM) | <img src="./img/신정우.png" width="150"> | 데이터 분석 에이전트 개발 및 머신러닝 모델링 (프로젝트 기획 및 일정/이슈 관리 포함) |
| **경규휘** | <img src="./img/경규희.png" width="150"> | 문서 검색 전문 에이전트 (RAG) 개발 및 데이터 검색 (Product 문서 데이터 수집 및 RAG 테스트 포함) |
| **남궁승원** | <img src="./img/남궁승원.png" width="150"> | 데이터 분석 에이전트 개발 및 머신러닝 모델링 (ML 부분 포함) (기술 문서 및 사내 정책 문서 데이터 수집 포함) |
| **이태수** | <img src="./img/이태수.png" width="150"> | 시장 조사 및 문서 검색 전문 에이전트 (RAG) 개발 (뉴스 수집 API 개발 및 이슈/동향 수집 포함) |
| **황인호** | <img src="./img/인호.jpeg" width="150"> | AI 에이전트 총괄 시스템 (LangGraph Supervisor), 코드 에이전트, 프론트엔드 개발 (ERD, 배포, 데이터 조회 프로그램 개발 포함) |

## 문서 구조 (Chapters)
프로젝트의 핵심 구성 요소 및 개발 과정에 대한 자세한 내용은 다음 장에서 확인할 수 있습니다.
1.  [애플리케이션 데이터 설계도 (Django 모델)](docs/01_애플리케이션_데이터_설계도__django_모델__.md)
2.  [프론트엔드 채팅 UI](docs/02_프론트엔드_채팅_ui_.md)
3.  [실시간 AI 통신 게이트웨이 (FastAPI & WebSocket)](docs/03_실시간_ai_통신_게이트웨이__fastapi___websocket__.md)
4.  [AI 에이전트 총괄 시스템 (LangGraph Supervisor)](docs/04_ai_에이전트_총괄_시스템__langgraph_supervisor__.md)
5.  [데이터 분석 전문 에이전트 (Analytics Agent)](docs/05_데이터_분석_전문_에이전트__analytics_agent__.md)
6.  [문서 검색 전문 에이전트 (RAG Agent)](docs/06_문서_검색_전문_에이전트__rag_agent__.md)
7.  [외부 데이터 수집 및 처리 (ETL)](docs/07_외부_데이터_수집_및_처리__etl__.md)
8.  [프론트엔드-데이터베이스 연동](docs/08_프론트엔드_데이터베이스_연동_.md)

## 협업 및 일정 관리
*   **회의**: 정기적인 팀 회의를 통해 프로젝트 진행 상황 공유 및 다음 업무 논의.
*   **회의록**: Notion, ClovaNote 등을 활용하여 회의 내용, 결정 사항, 개별 업무 내용 기록 및 공유.
*   **코드 관리**: Git Repository를 사용하여 코드 버전 관리 및 협업.
*   **일정/이슈 관리**: GitHub Project를 활용하여 업무 이슈 등록, 담당자 배정, 진행 상황 추적.
*   **커뮤니케이션**: Discord, KakaoTalk 등을 활용하여 실시간 소통.
*   **기술 스터디**: LangGraph, LangSmith, Pinecone 사용법 등 핵심 기술에 대한 팀원 간 스터디 진행.


--- File: 1 # backend/accounts/__init__.py ---


--- File: 2 # backend/accounts/admin.py ---
from django.contrib import admin
from django.contrib.auth.admin import UserAdmin as BaseUserAdmin
from django.utils.translation import gettext_lazy as _

from .models import Organization, User


@admin.register(Organization)
class OrganizationAdmin(admin.ModelAdmin):
    list_display = ('name', 'created_at')
    search_fields = ('name',)
    ordering = ('name',)


@admin.register(User)
class UserAdmin(BaseUserAdmin):
    list_display = ('email', 'name', 'org', 'role', 'is_staff', 'is_active')
    list_filter = ('is_staff', 'is_superuser', 'is_active', 'role', 'org')
    search_fields = ('email', 'name')
    ordering = ('email',)
    
    fieldsets = (
        (None, {'fields': ('email', 'password')}),
        (_('Personal info'), {'fields': ('name', 'org', 'role')}),
        (_('Permissions'), {
            'fields': ('is_active', 'is_staff', 'is_superuser', 'groups', 'user_permissions'),
        }),
        (_('Important dates'), {'fields': ('last_login', 'created_at')}),
    )
    add_fieldsets = (
        (None, {
            'classes': ('wide',),
            'fields': ('email', 'password1', 'password2', 'org', 'role'),
        }),
    )
    readonly_fields = ('created_at',)


--- File: 3 # backend/accounts/apps.py ---
from django.apps import AppConfig


class AccountsConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'accounts'


--- File: 6 # backend/accounts/models.py ---
"""accounts/models.py  –  조직·사용자"""

import uuid
from django.db import models
from django.contrib.auth.models import AbstractBaseUser, PermissionsMixin, BaseUserManager


class UserRole(models.TextChoices):
    ADMIN = "admin", "Admin"
    ENGINEER = "engineer", "Engineer"
    ANALYST = "analyst", "Analyst"
    GUEST = "guest", "Guest"


class Organization(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    name = models.CharField(max_length=255, unique=True)
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = "organizations"
        ordering = ["name"]

    def __str__(self):
        return self.name


class UserManager(BaseUserManager):
    def create_user(self, email: str, password: str | None = None, **extra):
        if not email:
            raise ValueError("Email is required")
        user = self.model(email=self.normalize_email(email), **extra)
        user.set_password(password)
        user.save()
        return user

    def create_superuser(self, email: str, password: str | None = None, **extra):
        extra.setdefault("role", UserRole.ADMIN)
        extra.setdefault("is_staff", True)
        extra.setdefault("is_superuser", True)
        
        # Organization이 제공되지 않은 경우 기본 Organization 생성 또는 사용
        if 'org' not in extra:
            # 기본 조직이 있는지 확인
            default_org, created = Organization.objects.get_or_create(
                name="Default Organization"
            )
            extra["org"] = default_org
            
        return self.create_user(email, password, **extra)


class User(AbstractBaseUser, PermissionsMixin):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    org = models.ForeignKey(Organization, on_delete=models.CASCADE, related_name="users")
    email = models.EmailField(unique=True)
    name = models.CharField(max_length=100, blank=True)
    role = models.CharField(max_length=20, choices=UserRole.choices, default=UserRole.GUEST)
    created_at = models.DateTimeField(auto_now_add=True)
    last_login = models.DateTimeField(null=True, blank=True)

    is_active = models.BooleanField(default=True)
    is_staff = models.BooleanField(default=False)

    objects = UserManager()
    USERNAME_FIELD = "email"

    class Meta:
        db_table = "users"
        ordering = ["email"]

    def __str__(self):
        return self.email


--- File: 7 # backend/accounts/serializers.py ---
from rest_framework import serializers
from .models import User, Organization

class OrganizationSerializer(serializers.ModelSerializer):
    class Meta:
        model = Organization
        fields = ['id', 'name']

class UserSerializer(serializers.ModelSerializer):
    org = OrganizationSerializer(read_only=True)
    
    class Meta:
        model = User
        fields = ['id', 'email', 'name', 'org', 'role', 'created_at', 'last_login', 'is_active', 'is_staff']
        read_only_fields = ['id', 'email', 'created_at', 'last_login', 'is_active', 'is_staff']


--- File: 8 # backend/accounts/urls.py ---
from django.urls import path, re_path
from rest_framework_simplejwt.views import TokenRefreshView
from . import views

urlpatterns = [
    # 유연한 URL 패턴 사용 - 슬래시 유무 상관없이 처리
    re_path(r'^login/?$', views.login_view, name='login'),
    re_path(r'^logout/?$', views.logout_view, name='logout'),
    re_path(r'^me/?$', views.user_detail, name='user-detail'),
    re_path(r'^profile/?$', views.update_profile, name='update-profile'),
    re_path(r'^token/refresh/?$', TokenRefreshView.as_view(), name='token-refresh'),
]


--- File: 9 # backend/accounts/views.py ---
from django.contrib.auth import authenticate
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated, AllowAny
from rest_framework.response import Response
from rest_framework_simplejwt.tokens import RefreshToken
from rest_framework_simplejwt.views import TokenRefreshView
from .serializers import UserSerializer

@api_view(['POST'])
@permission_classes([AllowAny])
def login_view(request):
    email = request.data.get('email')
    password = request.data.get('password')
    
    if not email or not password:
        return Response({'detail': 'Email and password are required'}, status=status.HTTP_400_BAD_REQUEST)
    
    # Debugging info - remove in production
    print(f"Login attempt with email: {email}")
    
    # Check if the user exists in the database
    from django.contrib.auth import get_user_model
    User = get_user_model()
    
    try:
        user_exists = User.objects.filter(email=email).exists()
        print(f"User exists in database: {user_exists}")
        
        if not user_exists:
            # Create a test user for debugging if it doesn't exist
            print("Creating test user for debugging...")
            from django.contrib.auth.hashers import make_password
            from .models import Organization
            
            # Get or create default organization
            default_org, _ = Organization.objects.get_or_create(name="Default Organization")
            
            # Create test user
            User.objects.create(
                email=email,
                password=make_password(password),  # Properly hash the password
                name="Test User",
                org=default_org,
                role="admin",
                is_active=True,
                is_staff=True
            )
            print(f"Test user created with email: {email}")
    except Exception as e:
        print(f"Error checking/creating user: {e}")
    
    # Django's authenticate expects the USERNAME_FIELD value in the 'username' parameter
    # Since our User model has USERNAME_FIELD = 'email', we pass email to username parameter
    user = authenticate(username=email, password=password)
    print(f"Authentication result: {'Success' if user else 'Failed'}")
    
    if user:
        refresh = RefreshToken.for_user(user)
        return Response({
            'refresh': str(refresh),
            'access': str(refresh.access_token),
            'user': UserSerializer(user).data
        })
    
    # More detailed error for debugging
    return Response({'detail': 'Invalid credentials. Please check your email and password.'}, 
                    status=status.HTTP_401_UNAUTHORIZED)

@api_view(['POST'])
@permission_classes([AllowAny])
def logout_view(request):
    # JWT doesn't really need server-side logout, but we keep the endpoint for API consistency
    return Response({"detail": "Successfully logged out."})

@api_view(['GET'])
@permission_classes([IsAuthenticated])
def user_detail(request):
    serializer = UserSerializer(request.user)
    return Response(serializer.data)

@api_view(['PATCH'])
@permission_classes([IsAuthenticated])
def update_profile(request):
    user = request.user
    serializer = UserSerializer(user, data=request.data, partial=True)
    
    if serializer.is_valid():
        serializer.save()
        return Response(serializer.data)
    
    return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


--- File: 12 # backend/config/settings.py ---
"""
Django settings for config project.

Generated by 'django-admin startproject' using Django 5.2.1.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/5.2/ref/settings/
"""
import os
from dotenv import load_dotenv
from pathlib import Path

load_dotenv()

# Build paths inside the project like this: BASE_DIR / 'subdir'.
BASE_DIR = Path(__file__).resolve().parent.parent


# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/5.2/howto/deployment/checklist/

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = os.getenv('SECRET_KEY')

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = True

ALLOWED_HOSTS = []


# Application definition

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    'rest_framework', 'rest_framework_simplejwt', 'corsheaders',
    'accounts', 'knowledge', 'conversations', 'mlops',
    'pgvector.django'
]

# Custom user model
AUTH_USER_MODEL = 'accounts.User'

MIDDLEWARE = [
    'corsheaders.middleware.CorsMiddleware',  # CORS 미들웨어는 가장 앞에 위치해야 함
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'config.urls'

# URL configuration
APPEND_SLASH = False  # Do not force appending slashes to URLs

# CORS settings
CORS_ALLOWED_ORIGINS = [
    "http://localhost:3000",  # Next.js 개발 서버
]
CORS_ALLOW_CREDENTIALS = True

# Add CORS_ALLOWED_METHODS
CORS_ALLOWED_METHODS = [
    'DELETE',
    'GET',
    'OPTIONS',
    'PATCH',
    'POST',
    'PUT',
]

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'config.wsgi.application'


# Database
# https://docs.djangoproject.com/en/5.2/ref/settings/#databases

# DATABASES = {
#     'default': {
#         'ENGINE': 'django.db.backends.sqlite3',
#         'NAME': BASE_DIR / 'db.sqlite3',
#     }
# }

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.getenv('DB_NAME'),
        'USER': os.getenv('DB_USER'),
        'PASSWORD': os.getenv('DB_PASSWORD'),
        'HOST': os.getenv('DB_HOST'),
        'PORT': os.getenv('DB_PORT', '5432'),
    }
}
#print(DATABASES)


# Password validation
# https://docs.djangoproject.com/en/5.2/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]


# Internationalization
# https://docs.djangoproject.com/en/5.2/topics/i18n/

LANGUAGE_CODE = 'en-us'

TIME_ZONE = 'UTC'

USE_I18N = True

USE_TZ = True


# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/5.2/howto/static-files/

STATIC_URL = 'static/'

# Default primary key field type
# https://docs.djangoproject.com/en/5.2/ref/settings/#default-auto-field

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'

# REST Framework settings
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': (
        'rest_framework_simplejwt.authentication.JWTAuthentication',
    ),
    'DEFAULT_PERMISSION_CLASSES': [
        'rest_framework.permissions.IsAuthenticated',
    ],
}

# JWT settings
from datetime import timedelta
SIMPLE_JWT = {
    'ACCESS_TOKEN_LIFETIME': timedelta(hours=1),
    'REFRESH_TOKEN_LIFETIME': timedelta(days=7),
    'ROTATE_REFRESH_TOKENS': False,
    'BLACKLIST_AFTER_ROTATION': True,
    'ALGORITHM': 'HS256',
    'SIGNING_KEY': SECRET_KEY,
    'VERIFYING_KEY': None,
    'AUTH_HEADER_TYPES': ('Bearer',),
    'USER_ID_FIELD': 'id',
    'USER_ID_CLAIM': 'user_id',
    'AUTH_TOKEN_CLASSES': ('rest_framework_simplejwt.tokens.AccessToken',),
    'TOKEN_TYPE_CLAIM': 'token_type',
}

# CORS settings
CORS_ALLOWED_ORIGINS = [
    'http://localhost:3000',  # Next.js frontend
]
CORS_ALLOW_CREDENTIALS = True


--- File: 13 # backend/config/urls.py ---
"""
URL configuration for config project.

The `urlpatterns` list routes URLs to views. For more information please see:
    https://docs.djangoproject.com/en/5.2/topics/http/urls/
Examples:
Function views
    1. Add an import:  from my_app import views
    2. Add a URL to urlpatterns:  path('', views.home, name='home')
Class-based views
    1. Add an import:  from other_app.views import Home
    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
Including another URLconf
    1. Import the include() function: from django.urls import include, path
    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
"""
from django.contrib import admin
from django.urls import path, include, re_path
from django.http import JsonResponse

def health_check(request):
    return JsonResponse({'status': 'ok'})

urlpatterns = [
    path('admin/', admin.site.urls),
    # 유연한 URL 패턴 사용 - 슬래시 유무 상관없이 처리
    re_path(r'^api/auth/?', include('accounts.urls')),
    re_path(r'^api/chat/?', include('conversations.urls')),
    re_path(r'^api/health-check/?$', health_check, name='health-check'),
]


--- File: 22 # backend/conversations/models.py ---
"""conversations/models.py  –  채팅·LLM 호출"""

import uuid
from django.db import models
from accounts.models import User


class AgentType(models.TextChoices):
    CODE = "code", "Code"
    RAG = "rag", "RAG"
    ANALYTICS = "analytics", "Analytics"
    AUTO = "auto", "Auto"


class ChatSession(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    user = models.ForeignKey(User, on_delete=models.CASCADE, related_name="chat_sessions")
    agent_type = models.CharField(max_length=20, choices=AgentType.choices)
    started_at = models.DateTimeField(auto_now_add=True)
    ended_at = models.DateTimeField(null=True, blank=True)
    title = models.CharField(max_length=60, default="새 세션")

    class Meta:
        db_table = "chat_sessions"


class ChatMessage(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    session = models.ForeignKey(ChatSession, on_delete=models.CASCADE, related_name="messages")
    role = models.CharField(max_length=20)  # user | assistant | system
    content = models.TextField()
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = "chat_messages"
        ordering = ["created_at"]


class LlmCall(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    session = models.ForeignKey(ChatSession, on_delete=models.CASCADE, related_name="llm_calls")
    provider = models.CharField(max_length=50)
    model = models.CharField(max_length=100)
    prompt_tokens = models.PositiveIntegerField()
    completion_tokens = models.PositiveIntegerField()
    cost_usd = models.DecimalField(max_digits=10, decimal_places=4)
    latency_ms = models.PositiveIntegerField(null=True, blank=True)
    called_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = "llm_calls"
        indexes = [models.Index(fields=["called_at"], name="idx_llm_called_at")]



--- File: 23 # backend/conversations/serializers.py ---
from rest_framework import serializers
from .models import ChatSession, ChatMessage, LlmCall, AgentType


class ChatMessageSerializer(serializers.ModelSerializer):
    """ChatMessage 모델 직렬화를 위한 serializer"""
    
    class Meta:
        model = ChatMessage
        fields = ['id', 'session', 'role', 'content', 'created_at']
        read_only_fields = ['id', 'created_at']


class LlmCallSerializer(serializers.ModelSerializer):
    """LlmCall 모델 직렬화를 위한 serializer"""
    
    class Meta:
        model = LlmCall
        fields = ['id', 'session', 'provider', 'model', 'prompt_tokens', 
                 'completion_tokens', 'cost_usd', 'latency_ms', 'called_at']
        read_only_fields = ['id', 'called_at']


class ChatSessionSerializer(serializers.ModelSerializer):
    """ChatSession 모델 직렬화를 위한 serializer"""
    messages = ChatMessageSerializer(many=True, read_only=True)
    
    class Meta:
        model = ChatSession
        fields = ['id', 'user', 'agent_type', 'started_at', 'ended_at', 'title', 'messages']
        read_only_fields = ['id', 'started_at']

    def validate_agent_type(self, value):
        """agent_type 필드 유효성 검사"""
        if value not in [choice[0] for choice in AgentType.choices]:
            raise serializers.ValidationError(f"유효하지 않은 에이전트 유형입니다. 유효한 값: {AgentType.choices}")
        return value


--- File: 24 # backend/conversations/urls.py ---
from django.urls import path, re_path
from . import views

urlpatterns = [
    # 채팅 세션 관련 URL
    re_path(r'^sessions/?$', views.ChatSessionViewSet.as_view(), name='chat_sessions'),
    re_path(r'^sessions/(?P<pk>[0-9a-f-]+)/?$', views.ChatSessionDetailView.as_view(), name='chat_session_detail'),
    
    # 채팅 메시지 관련 URL
    re_path(r'^sessions/(?P<session_pk>[0-9a-f-]+)/messages/?$', views.ChatMessageView.as_view(), name='chat_messages'),
]


--- File: 25 # backend/conversations/views.py ---
from django.utils import timezone
from django.shortcuts import get_object_or_404
from rest_framework import status, viewsets
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated
from rest_framework.response import Response
from rest_framework.views import APIView

from .models import ChatSession, ChatMessage
from .serializers import ChatSessionSerializer, ChatMessageSerializer


class ChatSessionViewSet(APIView):
    """채팅 세션을 관리하는 API 뷰셋"""
    permission_classes = [IsAuthenticated]

    def get(self, request):
        """현재 사용자의 모든 채팅 세션 조회"""
        sessions = ChatSession.objects.filter(user=request.user).order_by('-started_at')
        serializer = ChatSessionSerializer(sessions, many=True)
        return Response(serializer.data)

    def post(self, request):
        """새 채팅 세션 생성"""
        # 요청 데이터에 사용자 ID 추가
        data = request.data.copy()
        data['user'] = request.user.id
        
        serializer = ChatSessionSerializer(data=data)
        if serializer.is_valid():
            session = serializer.save()
            
            # 시스템 메시지 생성 (선택적)
            welcome_message = f"Welcome to your new {session.agent_type} session. How can I help you today?"
            ChatMessage.objects.create(
                session=session,
                role="system",
                content=welcome_message
            )
            
            return Response(serializer.data, status=status.HTTP_201_CREATED)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class ChatSessionDetailView(APIView):
    """특정 채팅 세션을 관리하는 API 뷰"""
    permission_classes = [IsAuthenticated]

    def get(self, request, pk):
        """특정 채팅 세션 조회"""
        session = get_object_or_404(ChatSession, pk=pk, user=request.user)
        serializer = ChatSessionSerializer(session)
        return Response(serializer.data)

    def patch(self, request, pk):
        """채팅 세션 업데이트 (주로 종료 시간)"""
        session = get_object_or_404(ChatSession, pk=pk, user=request.user)
        serializer = ChatSessionSerializer(session, data=request.data, partial=True)
        
        if serializer.is_valid():
            serializer.save()
            return Response(serializer.data)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class ChatMessageView(APIView):
    """채팅 메시지를 관리하는 API 뷰"""
    permission_classes = [IsAuthenticated]

    def get(self, request, session_pk):
        """특정 세션의 모든 메시지 조회"""
        # 해당 세션이 현재 사용자의 것인지 확인
        session = get_object_or_404(ChatSession, pk=session_pk, user=request.user)
        messages = ChatMessage.objects.filter(session=session).order_by('created_at')
        serializer = ChatMessageSerializer(messages, many=True)
        return Response(serializer.data)

    def post(self, request, session_pk):
        """새 메시지 생성 및 AI 응답 생성"""
        # 해당 세션이 현재 사용자의 것인지 확인
        session = get_object_or_404(ChatSession, pk=session_pk, user=request.user)
        
        # 사용자 메시지 생성
        data = request.data.copy()
        data['session'] = session.pk
        data['role'] = 'user'
        
        serializer = ChatMessageSerializer(data=data)
        if serializer.is_valid():
            user_message = serializer.save()
            
            # 여기서 AI 응답을 생성하는 로직을 추가할 수 있습니다
            # 지금은 간단한 예시 응답을 생성합니다
            ai_response_content = f"This is a mock response to your message: {user_message.content}"
            
            # AI 응답 메시지 생성
            ai_message = ChatMessage.objects.create(
                session=session,
                role="assistant",
                content=ai_response_content
            )
            
            # 사용자 메시지와 AI 응답을 모두 포함하여 반환
            both_messages = ChatMessage.objects.filter(id__in=[user_message.id, ai_message.id])
            messages_serializer = ChatMessageSerializer(both_messages, many=True)
            return Response(messages_serializer.data, status=status.HTTP_201_CREATED)
        
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


--- File: 26 # backend/knowledge/__init__.py ---


--- File: 27 # backend/knowledge/admin.py ---
from django.contrib import admin
from django.utils.html import format_html
from .models import Document, GitRepository, CodeFile, EmbedChunk, TelecomCustomers, SummaryNewsKeywords


@admin.register(Document)
class DocumentAdmin(admin.ModelAdmin):
    list_display = ('title', 'doc_type', 'org', 'version', 'created_at')
    list_filter = ('doc_type', 'org')
    search_fields = ('title', 's3_key')
    list_select_related = ('org', 'uploaded_by')
    readonly_fields = ('created_at',)
    date_hierarchy = 'created_at'


@admin.register(GitRepository)
class GitRepositoryAdmin(admin.ModelAdmin):
    list_display = ('repo_url', 'org', 'default_branch', 'fetched_at')
    list_filter = ('org',)
    search_fields = ('repo_url',)
    readonly_fields = ('fetched_at',)


@admin.register(CodeFile)
class CodeFileAdmin(admin.ModelAdmin):
    list_display = ('file_path', 'repo', 'language', 'loc')
    list_filter = ('repo', 'language')
    search_fields = ('file_path', 'latest_commit')
    list_select_related = ('repo',)
    readonly_fields = ('id',)


@admin.register(EmbedChunk)
class EmbedChunkAdmin(admin.ModelAdmin):
    list_display = ('id', 'chunk_index', 'document', 'file', 'hash_short')
    list_filter = ('document', 'file')
    search_fields = ('hash', 'pinecone_id')
    readonly_fields = ('id',)
    list_select_related = ('document', 'file')
    
    def hash_short(self, obj):
        return f"{obj.hash[:10]}..." if obj.hash else ""
    hash_short.short_description = 'Hash'





@admin.register(TelecomCustomers)
class TelecomCustomersAdmin(admin.ModelAdmin) :
    list_display = ('id', 'customer_id', 'gender', 'partner', 'dependents' ,'churn')
    list_filter = ('dependents','churn', 'gender')
    search_fields = ('id','customer_id')
    readonly_fields = ('id', 'customer_id')


@admin.register(SummaryNewsKeywords)
class SummaryNewsKeywordsAdmin(admin.ModelAdmin):
    list_display = ('date', 'keyword_display', 'title_short', 'url_short')
    list_filter = ('date', 'keyword')
    search_fields = ('title', 'summary', 'keyword')
    list_select_related = ()
    date_hierarchy = 'date'
    ordering = ('-date', 'keyword')
    
    def keyword_display(self, obj):
        return obj.keyword
    keyword_display.short_description = 'Keyword'
    
    def title_short(self, obj):
        return f"{obj.title[:50]}..." if len(obj.title) > 50 else obj.title
    title_short.short_description = 'Title'
    
    def url_short(self, obj):
        return format_html('<a href="{}" target="_blank">Link</a>', obj.url)
    url_short.short_description = 'URL'


--- File: 32 # backend/knowledge/models.py ---
"""knowledge/models.py  –  문서·레포·임베딩"""

import uuid
from django.db import models
from django.db.models import Q, CheckConstraint
from accounts.models import Organization, User
from pgvector.django import VectorField

class DocType(models.TextChoices):
    POLICY = "policy", "Policy"
    PRODUCT = "product", "Product"
    TECH_MANUAL = "tech_manual", "Tech Manual"


class Document(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    org = models.ForeignKey(Organization, on_delete=models.CASCADE, related_name="documents")
    title = models.CharField(max_length=255)
    doc_type = models.CharField(max_length=20, choices=DocType.choices)
    s3_key = models.TextField(unique=True)
    version = models.CharField(max_length=50, default="v1")
    pinecone_ns = models.CharField(max_length=100)
    uploaded_by = models.ForeignKey(
        User, null=True, blank=True, on_delete=models.SET_NULL, related_name="uploaded_documents"
    )
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = "documents"
        indexes = [models.Index(fields=["org", "doc_type"], name="idx_docs_org_type")]

    def __str__(self):
        return self.title


class GitRepository(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    org = models.ForeignKey(Organization, on_delete=models.CASCADE, related_name="repositories")
    repo_url = models.TextField(unique=True)
    default_branch = models.CharField(max_length=100, default="main")
    fetched_at = models.DateTimeField(null=True, blank=True)

    class Meta:
        db_table = "git_repositories"

    def __str__(self):
        return self.repo_url


class CodeFile(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    repo = models.ForeignKey(GitRepository, on_delete=models.CASCADE, related_name="code_files")
    file_path = models.TextField()
    language = models.CharField(max_length=50, blank=True)
    latest_commit = models.CharField(max_length=40, blank=True)
    loc = models.PositiveIntegerField(null=True, blank=True)

    class Meta:
        db_table = "code_files"
        unique_together = ("repo", "file_path")
        indexes = [models.Index(fields=["repo"], name="idx_files_repo")]

    def __str__(self):
        return self.file_path


class EmbedChunk(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    document = models.ForeignKey(
        Document, null=True, blank=True, on_delete=models.CASCADE, related_name="chunks"
    )
    file = models.ForeignKey(
        CodeFile, null=True, blank=True, on_delete=models.CASCADE, related_name="chunks"
    )
    chunk_index = models.PositiveIntegerField()
    pinecone_id = models.CharField(max_length=100)
    hash = models.CharField(max_length=64, unique=True)

    class Meta:
        db_table = "embed_chunks"
        constraints = [
            CheckConstraint(
                name="embed_chunks_one_fk",
                check=Q(document__isnull=False, file__isnull=True)
                | Q(document__isnull=True, file__isnull=False),
            )
        ]
        indexes = [models.Index(fields=["document", "file"], name="idx_chunks_source")]

    def __str__(self):
        return self.hash
    



class TelecomCustomers(models.Model) :
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    customer_id = models.CharField(max_length=20, null=False)
    gender = models.CharField(max_length=6)
    senior_citizen = models.BooleanField()
    partner = models.BooleanField()
    dependents = models.BooleanField()
    tenure = models.IntegerField()
    phone_service = models.BooleanField()
    multiple_lines = models.CharField(max_length=20)
    internet_serivce = models.CharField(max_length=20)
    online_security = models.CharField(max_length=20)
    online_backup = models.CharField(max_length=20)
    device_protection = models.CharField(max_length=20)
    tech_support = models.CharField(max_length=20)
    streaming_tv = models.CharField(max_length=20)
    streaming_movies = models.CharField(max_length=20)
    contract = models.CharField(max_length=20)
    paperless_billing = models.BooleanField()
    payment_method = models.CharField(max_length=30)
    monthly_charges = models.DecimalField(max_digits=10, decimal_places=2)
    total_charges = models.DecimalField(max_digits=14, decimal_places=2)
    churn = models.BooleanField()

    class Meta:
        verbose_name_plural = "Telecom customers"  # 복수형 이름 지정
        db_table = 'telecom_customers'  # 테이블 이름도 명시적으로 지정


class SummaryNewsKeywords(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    date = models.DateField()
    keyword = models.TextField()
    title = models.TextField()
    summary = models.TextField()
    url = models.URLField(max_length=500)

    class Meta:
        verbose_name_plural = "Summary news keywords"  # 복수형 이름 지정
        db_table = 'summary_news_keywords'  # 테이블 이름도 명시적으로 지정



    def __str__(self):
        return f"{self.date} - {self.keyword} - {self.title[:50]}..."




--- File: 34 # backend/manage.py ---
#!/usr/bin/env python
"""Django's command-line utility for administrative tasks."""
import os
import sys


def main():
    """Run administrative tasks."""
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')
    try:
        from django.core.management import execute_from_command_line
    except ImportError as exc:
        raise ImportError(
            "Couldn't import Django. Are you sure it's installed and "
            "available on your PYTHONPATH environment variable? Did you "
            "forget to activate a virtual environment?"
        ) from exc
    execute_from_command_line(sys.argv)


if __name__ == '__main__':
    main()


--- File: 36 # backend/mlops/admin.py ---
from django.contrib import admin
from django.utils.html import format_html
from .models import AnalyticsResult, ModelArtifact


@admin.register(AnalyticsResult)
class AnalyticsResultAdmin(admin.ModelAdmin):
    list_display = ('id', 'user', 'result_type', 'created_at', 's3_key_preview')
    list_filter = ('result_type', 'created_at')
    search_fields = ('user__email', 's3_key', 'meta')
    readonly_fields = ('created_at', 'meta_prettified')
    list_select_related = ('user',)
    
    def s3_key_preview(self, obj):
        return obj.s3_key[:50] + '...' if len(obj.s3_key) > 50 else obj.s3_key
    s3_key_preview.short_description = 'S3 Key'
    
    def meta_prettified(self, obj):
        import json
        from pygments import highlight
        from pygments.lexers import JsonLexer
        from pygments.formatters import HtmlFormatter
        from django.utils.safestring import mark_safe
        
        if not obj.meta:
            return ""
            
        response = json.dumps(obj.meta, indent=2, ensure_ascii=False)
        response = response[:5000]  # Limit the size to prevent performance issues
        
        # Truncate and add ellipsis if necessary
        if len(response) > 5000:
            response = response[:5000] + '... (truncated)'
            
        # Format the JSON
        formatter = HtmlFormatter(style='colorful')
        response = highlight(response, JsonLexer(), formatter)
        style = "<style>" + formatter.get_style_defs() + "</style><br>"
        return mark_safe(style + response)
    
    meta_prettified.short_description = 'Metadata'


@admin.register(ModelArtifact)
class ModelArtifactAdmin(admin.ModelAdmin):
    list_display = ('name', 'version', 'stage', 'created_by', 'created_at', 's3_key_preview')
    list_filter = ('stage', 'created_at')
    search_fields = ('name', 'version', 's3_key')
    readonly_fields = ('created_at', 'metrics_prettified')
    list_select_related = ('created_by',)
    
    def s3_key_preview(self, obj):
        return obj.s3_key[:50] + '...' if len(obj.s3_key) > 50 else obj.s3_key
    s3_key_preview.short_description = 'S3 Key'
    
    def metrics_prettified(self, obj):
        if not obj.metrics:
            return ""
            
        import json
        from pygments import highlight
        from pygments.lexers import JsonLexer
        from pygments.formatters import HtmlFormatter
        from django.utils.safestring import mark_safe
        
        response = json.dumps(obj.metrics, indent=2, ensure_ascii=False)
        response = response[:5000]  # Limit the size to prevent performance issues
        
        # Truncate and add ellipsis if necessary
        if len(response) > 5000:
            response = response[:5000] + '... (truncated)'
            
        # Format the JSON
        formatter = HtmlFormatter(style='colorful')
        response = highlight(response, JsonLexer(), formatter)
        style = "<style>" + formatter.get_style_defs() + "</style><br>"
        return mark_safe(style + response)
    
    metrics_prettified.short_description = 'Metrics'


--- File: 40 # backend/mlops/models.py ---
"""mlops/models.py  –  분석 결과 & 모델 레지스트리"""

import uuid
from django.db import models
from accounts.models import User


class ResultType(models.TextChoices):
    CHURN_PRED = "churn_pred", "Churn Prediction"
    VIZ_IMAGE = "viz_image", "Visualization Image"
    TS_FORECAST = "timeseries_forecast", "Time-series Forecast"


class AnalyticsResult(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    user = models.ForeignKey(User, on_delete=models.CASCADE, related_name="analytics_results")
    result_type = models.CharField(max_length=30, choices=ResultType.choices)
    s3_key = models.TextField()
    meta = models.JSONField(null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = "analytics_results"
        indexes = [models.Index(fields=["user", "result_type"], name="idx_analytics_user_type")]

    def __str__(self):
        return f"{self.result_type} - {self.id}"


class ModelStage(models.TextChoices):
    STAGING = "staging", "Staging"
    PRODUCTION = "production", "Production"
    ARCHIVED = "archived", "Archived"


class ModelArtifact(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    name = models.CharField(max_length=120)
    version = models.CharField(max_length=50, default="v1")
    s3_key = models.TextField()
    stage = models.CharField(max_length=20, choices=ModelStage.choices, default=ModelStage.STAGING)
    metrics = models.JSONField(null=True, blank=True)
    created_by = models.ForeignKey(
        User, null=True, on_delete=models.SET_NULL, related_name="model_artifacts"
    )
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        db_table = "model_artifacts"
        unique_together = ("name", "version")
        indexes = [
            models.Index(fields=["name", "stage"], name="idx_model_stage"),
            models.Index(fields=["created_at"], name="idx_model_created"),
        ]
        ordering = ["-created_at"]

    def __str__(self):
        return f"{self.name} ({self.version}) - {self.stage}"


--- File: 43 # backend/path/to/your/app/Makefile ---
.PHONY: all format lint test tests test_watch integration_tests docker_tests help extended_tests

# Default target executed when no arguments are given to make.
all: help

# Define a variable for the test file path.
TEST_FILE ?= tests/unit_tests/

test:
	python -m pytest $(TEST_FILE)

integration_tests:
	python -m pytest tests/integration_tests 

test_watch:
	python -m ptw --snapshot-update --now . -- -vv tests/unit_tests

test_profile:
	python -m pytest -vv tests/unit_tests/ --profile-svg

extended_tests:
	python -m pytest --only-extended $(TEST_FILE)


######################
# LINTING AND FORMATTING
######################

# Define a variable for Python and notebook files.
PYTHON_FILES=src/
MYPY_CACHE=.mypy_cache
lint format: PYTHON_FILES=.
lint_diff format_diff: PYTHON_FILES=$(shell git diff --name-only --diff-filter=d main | grep -E '\.py$$|\.ipynb$$')
lint_package: PYTHON_FILES=src
lint_tests: PYTHON_FILES=tests
lint_tests: MYPY_CACHE=.mypy_cache_test

lint lint_diff lint_package lint_tests:
	python -m ruff check .
	[ "$(PYTHON_FILES)" = "" ] || python -m ruff format $(PYTHON_FILES) --diff
	[ "$(PYTHON_FILES)" = "" ] || python -m ruff check --select I $(PYTHON_FILES)
	[ "$(PYTHON_FILES)" = "" ] || python -m mypy --strict $(PYTHON_FILES)
	[ "$(PYTHON_FILES)" = "" ] || mkdir -p $(MYPY_CACHE) && python -m mypy --strict $(PYTHON_FILES) --cache-dir $(MYPY_CACHE)

format format_diff:
	ruff format $(PYTHON_FILES)
	ruff check --select I --fix $(PYTHON_FILES)

spell_check:
	codespell --toml pyproject.toml

spell_fix:
	codespell --toml pyproject.toml -w

######################
# HELP
######################

help:
	@echo '----'
	@echo 'format                       - run code formatters'
	@echo 'lint                         - run linters'
	@echo 'test                         - run unit tests'
	@echo 'tests                        - run unit tests'
	@echo 'test TEST_FILE=<test_file>   - run all tests in file'
	@echo 'test_watch                   - run unit tests in watch mode'



--- File: 44 # backend/path/to/your/app/README.md ---
# New LangGraph Project

[![CI](https://github.com/langchain-ai/new-langgraph-project/actions/workflows/unit-tests.yml/badge.svg)](https://github.com/langchain-ai/new-langgraph-project/actions/workflows/unit-tests.yml)
[![Integration Tests](https://github.com/langchain-ai/new-langgraph-project/actions/workflows/integration-tests.yml/badge.svg)](https://github.com/langchain-ai/new-langgraph-project/actions/workflows/integration-tests.yml)

This template demonstrates a simple application implemented using [LangGraph](https://github.com/langchain-ai/langgraph), designed for showing how to get started with [LangGraph Server](https://langchain-ai.github.io/langgraph/concepts/langgraph_server/#langgraph-server) and using [LangGraph Studio](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/), a visual debugging IDE.

<div align="center">
  <img src="./static/studio_ui.png" alt="Graph view in LangGraph studio UI" width="75%" />
</div>

The core logic defined in `src/agent/graph.py`, showcases an single-step application that responds with a fixed string and the configuration provided.

You can extend this graph to orchestrate more complex agentic workflows that can be visualized and debugged in LangGraph Studio.

## Getting Started

<!--
Setup instruction auto-generated by `langgraph template lock`. DO NOT EDIT MANUALLY.
-->

<!--
End setup instructions
-->

1. Install dependencies, along with the [LangGraph CLI](https://langchain-ai.github.io/langgraph/concepts/langgraph_cli/), which will be used to run the server.

```bash
cd path/to/your/app
pip install -e . "langgraph-cli[inmem]"
```

2. (Optional) Customize the code and project as needed. Create a `.env` file if you need to use secrets.

```bash
cp .env.example .env
```

If you want to enable LangSmith tracing, add your LangSmith API key to the `.env` file.

```text
# .env
LANGSMITH_API_KEY=lsv2...
```

3. Start the LangGraph Server.

```shell
langgraph dev
```

For more information on getting started with LangGraph Server, [see here](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/).

## How to customize

1. **Define configurable parameters**: Modify the `Configuration` class in the `graph.py` file to expose the arguments you want to configure. For example, in a chatbot application you may want to define a dynamic system prompt or LLM to use. For more information on configurations in LangGraph, [see here](https://langchain-ai.github.io/langgraph/concepts/low_level/?h=configuration#configuration).

2. **Extend the graph**: The core logic of the application is defined in [graph.py](./src/agent/graph.py). You can modify this file to add new nodes, edges, or change the flow of information.

## Development

While iterating on your graph in LangGraph Studio, you can edit past state and rerun your app from previous states to debug specific nodes. Local changes will be automatically applied via hot reload.

Follow-up requests extend the same thread. You can create an entirely new thread, clearing previous history, using the `+` button in the top right.

For more advanced features and examples, refer to the [LangGraph documentation](https://langchain-ai.github.io/langgraph/). These resources can help you adapt this template for your specific use case and build more sophisticated conversational agents.

LangGraph Studio also integrates with [LangSmith](https://smith.langchain.com/) for more in-depth tracing and collaboration with teammates, allowing you to analyze and optimize your chatbot's performance.

<!--
Configuration auto-generated by `langgraph template lock`. DO NOT EDIT MANUALLY.
{
  "config_schemas": {
    "agent": {
      "type": "object",
      "properties": {}
    }
  }
}
-->


--- File: 46 # backend/path/to/your/app/src/agent/graph.py ---
"""LangGraph single-node graph template.

Returns a predefined response. Replace logic and configuration as needed.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, TypedDict

from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph


class Configuration(TypedDict):
    """Configurable parameters for the agent.

    Set these when creating assistants OR when invoking the graph.
    See: https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/
    """

    my_configurable_param: str


@dataclass
class State:
    """Input state for the agent.

    Defines the initial structure of incoming data.
    See: https://langchain-ai.github.io/langgraph/concepts/low_level/#state
    """

    changeme: str = "example"


async def call_model(state: State, config: RunnableConfig) -> Dict[str, Any]:
    """Process input and returns output.

    Can use runtime configuration to alter behavior.
    """
    configuration = config["configurable"]
    return {
        "changeme": "output from call_model. "
        f'Configured with {configuration.get("my_configurable_param")}'
    }


# Define the graph
graph = (
    StateGraph(State, config_schema=Configuration)
    .add_node(call_model)
    .add_edge("__start__", "call_model")
    .compile(name="New Graph")
)


--- File: 47 # fastapi_server/README.md ---
# LangGraph Agent FastAPI Server

이 프로젝트는 LangGraph 기반 멀티 에이전트 시스템을 FastAPI 웹 서버로 서빙하는 어플리케이션입니다.

## 프로젝트 구조

```
fastapi_server/
├── __init__.py          # 패키지 초기화 파일
├── main.py              # FastAPI 애플리케이션 메인 파일
├── agent_service.py     # LangGraph 에이전트와의 인터페이스
├── models.py            # API 요청/응답 모델
├── requirements.txt     # 필요한 의존성
├── start_server.py      # 서버 실행 스크립트
└── README.md            # 이 문서
```

## 설치 및 실행 방법

### 1. 가상 환경 설정

항상 가상 환경을 사용하는 것이 좋습니다. 가상 환경을 생성하고 활성화하세요:

```bash
# 가상 환경 생성
python -m venv venv

# 가상 환경 활성화 (Windows)
venv\Scripts\activate

# 가상 환경 활성화 (Linux/Mac)
source venv/bin/activate
```

### 2. 의존성 설치

필요한 패키지를 설치합니다:

```bash
pip install -r requirements.txt
```

### 3. 환경 변수 설정

프로젝트 루트 디렉토리에 `.env` 파일이 있는지 확인하세요. 다음과 같은 환경 변수가 필요합니다:

```
OPENAI_API_KEY=your_openai_api_key_here
```

### 4. 서버 실행

다음 명령을 사용하여 서버를 시작합니다:

```bash
# 방법 1: start_server.py 스크립트 사용
python start_server.py

# 방법 2: uvicorn 직접 사용
uvicorn fastapi_server.main:app --host 0.0.0.0 --port 8001 --reload
```

서버가 성공적으로 시작되면 http://localhost:8001 에서 접근할 수 있습니다.

## API 엔드포인트

### 1. 상태 확인

- **URL**: GET /
- **응답**: 서버 상태 정보

### 2. 채팅 메시지 전송

- **URL**: POST /api/chat
- **요청 본문**:
  ```json
  {
    "message": "사용자 메시지",
    "thread_id": "선택적_대화_ID"
  }
  ```
- **응답**: 에이전트 응답

### 3. WebSocket 스트리밍 채팅

- **URL**: WebSocket /api/chat/ws/{thread_id}
- **사용법**: 
  - 연결 후, JSON 형식의 메시지 전송: `{"message": "사용자 메시지"}`
  - 서버는 다양한 이벤트 타입을 포함한 JSON 응답을 스트리밍합니다.
  - 이벤트 타입: `token`, `agent_change`, `tool_start`, `tool_end`, `done`, `error`

## 예제 사용 코드

### HTTP API 사용 예제 (Python)

```python
import requests

response = requests.post(
    "http://localhost:8001/api/chat",
    json={"message": "지역별 매출을 분석해줘"}
)
print(response.json())
```

### WebSocket 스트리밍 예제 (JavaScript)

```javascript
const ws = new WebSocket('ws://localhost:8001/api/chat/ws/my-thread-1');

ws.onopen = () => {
  console.log('Connected to server');
  ws.send(JSON.stringify({
    message: '데이터 시각화를 도와줘'
  }));
};

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log(data);
  
  if (data.type === 'token') {
    // 토큰 처리 (점진적으로 UI에 텍스트 추가)
    process.stdout.write(data.content);
  } else if (data.type === 'agent_change') {
    console.log(`Agent changed to: ${data.agent}`);
  } else if (data.type === 'done') {
    console.log('\nResponse complete!');
  }
};
```

## 문제 해결

1. **ImportError**: 필요한 모듈을 찾지 못하는 경우, 가상 환경이 활성화되어 있고 모든 의존성이 설치되어 있는지 확인하세요.

2. **API 키 오류**: OPENAI_API_KEY가 올바르게 설정되어 있는지 확인하세요.

3. **포트 충돌**: 8001 포트가 이미 사용 중인 경우, `main.py`에서 포트 번호를 변경하세요.


--- File: 50 # fastapi_server/agent/agent2.py ---
from __future__ import annotations

import os
from dataclasses import dataclass
from typing import TypedDict, Dict, Sequence, Union, Optional, Any
import asyncio

from asgiref.sync import sync_to_async
from langchain_core.prompts import PromptTemplate, SystemMessagePromptTemplate,HumanMessagePromptTemplate,ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langgraph.graph import END, START, StateGraph
from dotenv import load_dotenv
from openai import OpenAI
from pinecone import Pinecone, ServerlessSpec
from langchain.chat_models import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langgraph.graph.message import add_messages
from fastapi_server.agent.prompt import (
    document_type_system_prompt_agent2,
    proceedings_summary_prompt_agent2,
    internal_policy_summary_prompt_template_agent2,
    product_document_summary_prompt_template_agent2,
    technical_document_summary_prompt_template_agent2,
    unknown_document_type_prompt_agent2,
    rag_answer_generation_prompt_agent2,
    rag_system_message_agent2
)
load_dotenv()

def init_clients():
    # 1-1) OpenAI 클라이언트 생성
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        raise ValueError("⚠️ 환경변수 OPENAI_API_KEY가 설정되지 않았습니다.")
    # OpenAI 인스턴스를 만듭니다.
    openai_client = OpenAI(api_key=openai_api_key)
    print("✅ OpenAI 클라이언트 생성 완료")

    # 1-2) Pinecone 인스턴스 생성
    pinecone_api_key = os.getenv("PINECONE_API_KEY")
    pinecone_env     = os.getenv("PINECONE_ENVIRONMENT")   # 예: "us-east1-gcp" 또는 "us-west1-gcp" 등
    if not pinecone_api_key or not pinecone_env:
        raise ValueError("⚠️ 환경변수 PINECONE_API_KEY 또는 PINECONE_ENVIRONMENT가 누락되었습니다.")

    pc = Pinecone(api_key=pinecone_api_key, environment=pinecone_env)
    print("✅ Pinecone 클라이언트 생성 완료")

    # 1-3) 인덱스 존재 여부 확인
    index_name = "dense-index"  # 실제 사용 중인 인덱스 이름으로 교체하세요
    existing_indexes = pc.list_indexes().names()
    if index_name not in existing_indexes:
        raise ValueError(f"⚠️ 인덱스 '{index_name}'가 Pinecone에 존재하지 않습니다. 현재 인덱스 목록: {existing_indexes}")

    # 1-4) 해당 인덱스 객체 가져오기
    index = pc.Index(index_name)
    print(f"✅ Pinecone 인덱스 '{index_name}' 연결 완료 (Namespaces: {len(index.describe_index_stats().namespaces)})")

    return openai_client, index


# --------------------------------------------------
# 2) 질문 문장을 임베딩 벡터로 변환
# --------------------------------------------------
def embed_query(openai_client: OpenAI, text: str) -> list:
    """
    최신 OpenAI 클라이언트에서는 resp.data[0].embedding 으로 벡터에 접근해야 합니다.
    """
    resp = openai_client.embeddings.create(
        model="text-embedding-3-large",
        input=text
    )
    return resp.data[0].embedding


# --------------------------------------------------
# 3) 여러 네임스페이스 중 “가장 높은 유사도”를 준 네임스페이스와 매칭 결과 반환
# --------------------------------------------------
def retrieve_best_namespace(index, query_vector: list, top_k: int = 5):
    """
    1) index.describe_index_stats()를 통해 모든 네임스페이스 목록을 얻는다.
    2) 각 네임스페이스별로 query_vector를 index.query()로 검색하고,
       matches[0].score 를 비교해서 “최고 유사도”를 찾는다.
    3) 가장 높은 유사도를 준 네임스페이스(best_ns)와 해당 네임스페이스의 전체 매칭 결과(best_matches)를 반환.
    """
    stats = index.describe_index_stats()
    available_namespaces = list(stats.namespaces.keys())
    if not available_namespaces:
        raise ValueError("⚠️ 인덱스에 네임스페이스가 없습니다.")

    best_ns = None
    best_score = -1.0
    best_matches = None

    for ns in available_namespaces:
        count = stats.namespaces[ns]["vector_count"]
        if count == 0:
            # 비어 있는 네임스페이스 건너뛰기
            continue

        res = index.query(
            vector=query_vector,
            namespace=ns,
            top_k=top_k,
            include_metadata=True
        )
        if not res.matches:
            continue

        top_score = res.matches[0].score
        if top_score > best_score:
            best_score = top_score
            best_ns = ns
            best_matches = res.matches

    if best_ns is None:
        raise ValueError("⚠️ 어떤 네임스페이스에서도 매칭 결과를 찾을 수 없습니다.")
    
    print(f"🔍 선택된 네임스페이스: '{best_ns}' (최고 유사도: {best_score:.4f})")
    return best_ns, best_matches


# --------------------------------------------------
# 4) 검색된 매칭 결과에서 실제 텍스트(메타데이터)를 꺼내 Context 로 결합
# --------------------------------------------------
def build_context_from_matches(matches):
    """
    res.matches 리스트 안의 각 item.metadata 에 들어 있는 텍스트 필드를 추출합니다.
    업로드 시 metadata 키가 "text"였다고 가정했습니다.
    """
    contexts = []
    for m in matches:
        chunk_text = m.metadata.get("text", "")
        if chunk_text:
            contexts.append(chunk_text)

    return "\n---\n".join(contexts)


# --------------------------------------------------
# 5) LLM ChatCompletion 호출하여 답변 생성
# --------------------------------------------------
def generate_answer_with_context(openai_client: OpenAI, question: str, context: str) -> str:
    """
    최신 OpenAI 클라이언트에서는 client.chat.completions.create(...) 형태를 씁니다.
    """
    formatted_prompt = rag_answer_generation_prompt_agent2.format(context=context, question=question)
    resp = openai_client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": rag_system_message_agent2},
            {"role": "user", "content": formatted_prompt}
        ],
        temperature=0.0,
        max_tokens=1024
    )
    # resp.choices[0].message.content 으로 답변 추출
    return resp.choices[0].message.content.strip()



@dataclass
class State:
    # Compatible with both direct user_input and messages-based interface
    user_input: str = ""
    document_type: str = ""
    result: str = ""
    messages: Sequence[BaseMessage] = None
    
    def __post_init__(self):
        # If initialized from supervisor with messages but no user_input, extract user_input
        if not self.user_input and self.messages:
            # Extract user input from the last human message
            user_messages = [msg for msg in self.messages if isinstance(msg, HumanMessage)]
            if user_messages:
                self.user_input = user_messages[-1].content
    
    def dict(self):
        """Return dict representation with messages if present"""
        result = {
            "result": self.result,
            "document_type": self.document_type,
            "user_input": self.user_input
        }
        # If this was called with messages, return updated messages too
        if self.messages is not None:
            result["messages"] = self.messages + [AIMessage(content=self.result)] if self.result else self.messages
        return result  # 챗봇 결과


def choose_document_type(message):
    """
    OpenAI 클라이언트를 사용하여 문서 타입을 분류합니다. 리턴 데이터 형식은 기존과 동일하게 유지합니다.
    """
    client = OpenAI()
    formatted_prompt = document_type_system_prompt_agent2.format(user_input=message)
    
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": formatted_prompt}
        ],
        temperature=0,
        max_tokens=100
    )
    
    classified_type = resp.choices[0].message.content.strip()
    print(f"문서 타입 분류 결과: {classified_type}")
    return classified_type

def choose_node(state: State):
    # Extract the user input from the state
    user_input = state.user_input

    # Choose document type
    document_type = choose_document_type(user_input)
    
    # Update state with document type
    state.document_type = document_type
    
    # Print document type for debugging
    # print(f"Document Type: {document_type}")
    
    return state.dict()

def choose_one(state: State) -> str:
    choice = state.document_type
    # Use logging instead of print to avoid output being captured in response
    # print(f"(choice_one) Choice: {choice}")
    # This must return the string key for conditional edge routing
    if choice in ["internal_policy", "product_document", "technical_document", "proceedings"]:
        return choice
    else:
        return "product_document"  # Default fallback

def execute_rag(state: State):
    # print(f"\n📄 RAG 노드 실행: 문서 타입 = '{state.document_type}', 질문 = '{state.user_input}'")
    openai_client, pinecone_index = init_clients()
    # print("   - 클라이언트 초기화 완료")

    query_vector = embed_query(openai_client, state.user_input)
    # print(f"   - 질문 임베딩 완료 (벡터 크기: {len(query_vector)})")

    namespace_to_search = state.document_type
    if not namespace_to_search or namespace_to_search == "unknown":
        message = f"문서 타입이 '{namespace_to_search}'(으)로 분류되어 Pinecone 검색을 수행하지 않습니다."
        # print(f"   - 정보: {message}")
        # 'unknown'일 경우, unknown_handler_node에서 이미 메시지를 설정했을 수 있으므로, 여기서는 덮어쓰지 않거나
        # 혹은 여기서 다른 메시지를 설정할 수 있습니다. 여기서는 검색 불가 메시지만 남깁니다.
        # 실제로는 'unknown' 타입은 이 노드로 오지 않고 unknown_handler_node로 가야 합니다.
        # 이 코드는 execute_rag_node가 'unknown' 타입으로 호출될 경우를 대비한 방어 코드입니다.
        state.result = "적절한 문서 저장소를 찾을 수 없어 검색을 수행할 수 없습니다."
        return state.dict()

    # print(f"   - Pinecone 네임스페이스 '{namespace_to_search}'에서 검색 시작...")
    index_stats = pinecone_index.describe_index_stats()
    if namespace_to_search not in index_stats.namespaces or \
        index_stats.namespaces[namespace_to_search].vector_count == 0:
        message = f"'{namespace_to_search}' 네임스페이스를 Pinecone에서 찾을 수 없거나, 해당 네임스페이스에 데이터가 없습니다. Pinecone 대시보드에서 네임스페이스 이름과 데이터 존재 여부를 확인해주세요."
        # print(f"   - 경고: {message}")
        state.result = message
        return state.dict()

    res = pinecone_index.query(
        vector=query_vector,
        namespace=namespace_to_search,
        top_k=5, # 검색할 문서 수
        include_metadata=True
    )
    matches = res.matches
    # print(f"   - Pinecone 검색 완료: {len(matches)}개 결과 수신")

    if not matches:
        message = f"'{namespace_to_search}' 네임스페이스에서 '{state.user_input}' 질문과 관련된 정보를 찾지 못했습니다."
        # print(f"   - 정보 없음: {message}")
        state.result = message
        return state.dict()
    
    context = build_context_from_matches(matches)
    if not context:
        message = "검색된 정보에서 답변을 생성할 컨텍스트를 추출하지 못했습니다."
        print(f"   - 컨텍스트 구축 실패: {message}")
        state.result = message
        return state.dict()
    print(f"   - 컨텍스트 구축 완료 (길이: {len(context)})")

    state.result = context
    return state.dict()
    

def summarize_node(state: State):
    text = state.result
    document_type = state.document_type
    user_input = state.user_input

    if state.document_type == "proceedings":
        system_message = proceedings_summary_prompt_agent2
    elif state.document_type == "internal_policy":
        system_message = internal_policy_summary_prompt_template_agent2.format(user_input=user_input)
    elif state.document_type == "product_document":
        system_message = product_document_summary_prompt_template_agent2.format(user_input=user_input)
    elif state.document_type == "technical_document":
        system_message = technical_document_summary_prompt_template_agent2.format(user_input=user_input)
    else: # unknown or fallback
        system_message = unknown_document_type_prompt_agent2
    
    system_message = SystemMessagePromptTemplate.from_template(system_message)
    human_message = HumanMessagePromptTemplate.from_template("{text}")

    chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])

    # 2. LLM 생성
    llm = ChatOpenAI(model="gpt-4o")

    # 3. Prompt와 LLM 결합
    chatbot = chat_prompt | llm

    # 4. 실행
    response = chatbot.invoke({"text": text})
    result = response.content
    # print(result)  # 디버깅용 출력 제거
    state.result = result
    
    # 문서 타입이 최종 결과에 포함되지 않도록, document_type을 제외한 상태만 반환
    result_state = state.dict()
    if "document_type" in result_state:
        # document_type 값이 최종 출력에 포함되지 않도록 제거
        del result_state["document_type"]
    
    return result_state

# 비동기 노드 래퍼 함수들 정의
async def async_choose_node(state: State):
    return await sync_to_async(choose_node)(state)

async def async_execute_rag(state: State):
    return await sync_to_async(execute_rag)(state)

async def async_summarize_node(state: State):
    return await sync_to_async(summarize_node)(state)

async def async_choose_one(state: State):
    return await sync_to_async(choose_one)(state)

# Define the graph with async nodes
graph = (
    StateGraph(State)
    # (1) choose_node 분기 노드 등록 (outputs에 리턴 키 명시)
    .add_node("choose_node", async_choose_node)
    # (2) RAG 실행 노드들 등록
    .add_node("product_node", async_execute_rag)
    .add_node("proceedings_node", async_execute_rag)
    .add_node("hr_policy_node", async_execute_rag)
    .add_node("technical_document_node", async_execute_rag)
    # (3) summarize_node 등록 (최종 노드)
    .add_node("summarize_node", async_summarize_node)
    # (4) START → 분기 노드(choose_node) → (next_node 값에 따라) 분기
    .add_edge(START,"choose_node")
    .add_conditional_edges(
        "choose_node",
        async_choose_one,
        {
            "product_document": "product_node",
            "proceedings": "proceedings_node",
            "internal_policy": "hr_policy_node",
            "technical_document": "technical_document_node"
        }
    )
    # (5) 각 RAG 노드 → summarize_node 연결
    .add_edge("product_node", "summarize_node")
    .add_edge("proceedings_node", "summarize_node")
    .add_edge("hr_policy_node", "summarize_node")
    .add_edge("technical_document_node", "summarize_node")
    .add_edge("summarize_node", END)
    # (6) 최종 컴파일
    .compile(name="New Graph")
)

IMPORTANT: Generate the `summary` and relationship `label` fields in **Korean** language. Do NOT use English for these fields.

Please provide:
1. A high-level `summary` of the project's main purpose and functionality in a few beginner-friendly sentences (in Korean). Use markdown formatting with **bold** and *italic* text to highlight important concepts.
2. A list (`relationships`) describing the key interactions between these abstractions. For each relationship, specify:
    - `from_abstraction`: Index of the source abstraction (e.g., `0 # AbstractionName1`)
    - `to_abstraction`: Index of the target abstraction (e.g., `1 # AbstractionName2`)
    - `label`: A brief label for the interaction **in just a few words** (in Korean) (e.g., "Manages", "Inherits", "Uses").
    Ideally the relationship should be backed by one abstraction calling or passing parameters to another.
    Simplify the relationship and exclude those non-important ones.

IMPORTANT: Make sure EVERY abstraction is involved in at least ONE relationship (either as source or target). Each abstraction index must appear at least once across all relationships.

Format the output as YAML:

```yaml
summary: |
  A brief, simple explanation of the project (in Korean).
  Can span multiple lines with **bold** and *italic* for emphasis.
relationships:
  - from_abstraction: 0 # AbstractionName1
    to_abstraction: 1 # AbstractionName2
    label: "Manages" (in Korean)
  - from_abstraction: 2 # AbstractionName3
    to_abstraction: 0 # AbstractionName1
    label: "Provides config" (in Korean)
  # ... other relationships
```

Now, provide the YAML output:

2025-06-29 20:52:50,432 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:53:14,969 - INFO - RESPONSE: ```yaml
summary: |
  이 프로젝트는 사용자가 자연어로 업무 요청을 하면, **AI 에이전트 총괄 시스템**이 *적절한 전문 에이전트*에 작업을 분배하여 처리하는 **지능형 사내 업무 보조 챗봇 시스템**입니다.
  FastAPI를 통한 **실시간 AI 통신 게이트웨이**를 통해 사용자와 AI 시스템 간의 데이터를 교환하며, 문서 검색, 데이터 분석 등의 기능을 제공합니다.

relationships:
  - from_abstraction: 0 # AI 에이전트 총괄 시스템 (LangGraph Supervisor)
    to_abstraction: 1 # 문서 검색 전문 에이전트 (RAG Agent)
    label: "작업 분배"
  - from_abstraction: 0 # AI 에이전트 총괄 시스템 (LangGraph Supervisor)
    to_abstraction: 2 # 데이터 분석 전문 에이전트 (Analytics Agent)
    label: "작업 분배"
  - from_abstraction: 0 # AI 에이전트 총괄 시스템 (LangGraph Supervisor)
    to_abstraction: 3 # FastAPI 서버
    label: "통신"
  - from_abstraction: 2 # 데이터 분석 전문 에이전트 (Analytics Agent)
    to_abstraction: 7 # MLOps 관리 (MLOps Management)
    label: "모델 결과 저장"
  - from_abstraction: 1 # 문서 검색 전문 에이전트 (RAG Agent)
    to_abstraction: 6 # 지식베이스 관리 (Knowledge Management)
    label: "문서 검색"
  - from_abstraction: 4 # 계정 관리 모듈 (Accounts Module)
    to_abstraction: 5 # 챗봇 세션 관리 (Chat Session Management)
    label: "사용자 관리"
  - from_abstraction: 5 # 챗봇 세션 관리 (Chat Session Management)
    to_abstraction: 9 # 백엔드 라우팅 (Backend Routing)
    label: "요청 처리"
  - from_abstraction: 3 # FastAPI 서버
    to_abstraction: 8 # 환경 설정 및 배포 (Environment Setup and Deployment)
    label: "배포"
  - from_abstraction: 3 # FastAPI 서버
    to_abstraction: 0 # AI 에이전트 총괄 시스템 (LangGraph Supervisor)
    label: "연동"
```
2025-06-29 20:53:15,344 - INFO - PROMPT: 
Given the following project abstractions and their relationships for the project ```` SKN10-FINAL-1Team ````:

Abstractions (Index # Name) (Names might be in Korean):
- 0 # AI 에이전트 총괄 시스템 (LangGraph Supervisor)
- 1 # 문서 검색 전문 에이전트 (RAG Agent)
- 2 # 데이터 분석 전문 에이전트 (Analytics Agent)
- 3 # FastAPI 서버
- 4 # 계정 관리 모듈 (Accounts Module)
- 5 # 챗봇 세션 관리 (Chat Session Management)
- 6 # 지식베이스 관리 (Knowledge Management)
- 7 # MLOps 관리 (MLOps Management)
- 8 # 환경 설정 및 배포 (Environment Setup and Deployment)
- 9 # 백엔드 라우팅 (Backend Routing)

Context about relationships and project summary:
Project Summary (Note: Project Summary might be in Korean):
이 프로젝트는 사용자가 자연어로 업무 요청을 하면, **AI 에이전트 총괄 시스템**이 *적절한 전문 에이전트*에 작업을 분배하여 처리하는 **지능형 사내 업무 보조 챗봇 시스템**입니다.
FastAPI를 통한 **실시간 AI 통신 게이트웨이**를 통해 사용자와 AI 시스템 간의 데이터를 교환하며, 문서 검색, 데이터 분석 등의 기능을 제공합니다.


Relationships (Indices refer to abstractions above):
- From 0 (AI 에이전트 총괄 시스템 (LangGraph Supervisor)) to 1 (문서 검색 전문 에이전트 (RAG Agent)): 작업 분배
- From 0 (AI 에이전트 총괄 시스템 (LangGraph Supervisor)) to 2 (데이터 분석 전문 에이전트 (Analytics Agent)): 작업 분배
- From 0 (AI 에이전트 총괄 시스템 (LangGraph Supervisor)) to 3 (FastAPI 서버): 통신
- From 2 (데이터 분석 전문 에이전트 (Analytics Agent)) to 7 (MLOps 관리 (MLOps Management)): 모델 결과 저장
- From 1 (문서 검색 전문 에이전트 (RAG Agent)) to 6 (지식베이스 관리 (Knowledge Management)): 문서 검색
- From 4 (계정 관리 모듈 (Accounts Module)) to 5 (챗봇 세션 관리 (Chat Session Management)): 사용자 관리
- From 5 (챗봇 세션 관리 (Chat Session Management)) to 9 (백엔드 라우팅 (Backend Routing)): 요청 처리
- From 3 (FastAPI 서버) to 8 (환경 설정 및 배포 (Environment Setup and Deployment)): 배포
- From 3 (FastAPI 서버) to 0 (AI 에이전트 총괄 시스템 (LangGraph Supervisor)): 연동


If you are going to make a tutorial for ```` SKN10-FINAL-1Team ````, what is the best order to explain these abstractions, from first to last?
Ideally, first explain those that are the most important or foundational, perhaps user-facing concepts or entry points. Then move to more detailed, lower-level implementation details or supporting concepts.

Output the ordered list of abstraction indices, including the name in a comment for clarity. Use the format `idx # AbstractionName`.

```yaml
- 2 # FoundationalConcept
- 0 # CoreClassA
- 1 # CoreClassB (uses CoreClassA)
- ...
```

Now, provide the YAML output:

2025-06-29 20:53:15,562 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:53:17,028 - INFO - RESPONSE: ```yaml
- 0 # AI 에이전트 총괄 시스템 (LangGraph Supervisor)
- 3 # FastAPI 서버
- 4 # 계정 관리 모듈 (Accounts Module)
- 5 # 챗봇 세션 관리 (Chat Session Management)
- 9 # 백엔드 라우팅 (Backend Routing)
- 1 # 문서 검색 전문 에이전트 (RAG Agent)
- 6 # 지식베이스 관리 (Knowledge Management)
- 2 # 데이터 분석 전문 에이전트 (Analytics Agent)
- 7 # MLOps 관리 (MLOps Management)
- 8 # 환경 설정 및 배포 (Environment Setup and Deployment)
```
2025-06-29 20:53:17,401 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-FINAL-1Team` about the concept: "AI 에이전트 총괄 시스템 (LangGraph Supervisor)". This is Chapter 1.

Concept Details (Note: Provided in Korean):
- Name: AI 에이전트 총괄 시스템 (LangGraph Supervisor)
- Description:
사용자의 자연어 요청을 분석하여 적합한 전문 에이전트에 작업을 분배하는 시스템입니다. (System that analyzes user natural language requests and routes tasks to appropriate specialized agents.)

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [AI 에이전트 총괄 시스템 (LangGraph Supervisor)](01_ai_에이전트_총괄_시스템__langgraph_supervisor_.md)
2. [FastAPI 서버](02_fastapi_서버.md)
3. [계정 관리 모듈 (Accounts Module)](03_계정_관리_모듈__accounts_module_.md)
4. [챗봇 세션 관리 (Chat Session Management)](04_챗봇_세션_관리__chat_session_management_.md)
5. [백엔드 라우팅 (Backend Routing)](05_백엔드_라우팅__backend_routing_.md)
6. [문서 검색 전문 에이전트 (RAG Agent)](06_문서_검색_전문_에이전트__rag_agent_.md)
7. [지식베이스 관리 (Knowledge Management)](07_지식베이스_관리__knowledge_management_.md)
8. [데이터 분석 전문 에이전트 (Analytics Agent)](08_데이터_분석_전문_에이전트__analytics_agent_.md)
9. [MLOps 관리 (MLOps Management)](09_mlops_관리__mlops_management_.md)
10. [환경 설정 및 배포 (Environment Setup and Deployment)](10_환경_설정_및_배포__environment_setup_and_deployment_.md)

Context from previous chapters (Note: This summary might be in Korean):
This is the first chapter.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 1: AI 에이전트 총괄 시스템 (LangGraph Supervisor)`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:53:17,603 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:55:15,957 - INFO - PROMPT: 
Analyze the following codebase for the project 'SKN10-2nd-1Team'.

Available files (total 14):
- 0 # README.md
- 1 # mainpage.py
- 2 # module/analysis_utils.py
- 3 # module/churn_prediction.py
- 4 # module/display_utils.py
- 5 # module/filter_utils.py
- 6 # module/groq_utils.py
- 7 # module/inho_model.py
- 8 # pages/나이별 평균신용점수.py
- 9 # pages/신용점수별 카드수.py
- 10 # pages/연령별 신용카드 및 금융상품 보유 수 변화.py
- 11 # pages/연령별 이탈율 및 활동고객율 분석.py
- 12 # pages/연령별 잔고 및 연봉 변화.py
- 13 # pages/종합 분석.py

Full context of all files:
--- File Index 0: README.md ---
# SKN10-2nd-1Team
# [은행 고객 이탈 예측](https://www.kaggle.com/datasets/gauravtopre/bank-customer-churn-dataset/data)
 SK Networks AI Camp 10기

 개발기간: 25.02.19 - 25.03.05
<br>

# **1. 팀 소개**

### 팀명 : 1 팀
### 팀원 소개
<table align=center>
<tbody>
 <tr>
  <br>
      <td align=center><b>배민경👑</b></td>
      <td align=center><b>장윤홍</b></td>
      <td align=center><b>이유호</b></td>
      <td align=center><b>남궁세정</b></td>
      <td align=center><b>황인호</b></td>
    </tr>
    <br>
 <tr>
    <th> 
      <b>프로젝트 총괄</b><br>
      <b>머신러닝 모델 개발</b><br>
      <b>페이지 제작</b>
    </th>
    <th>
      <b>머신러닝 모델 개발</b><br>
      <b>페이지 제작</b>
    </th>
    <th>
      <b>데이터 분석</b><br>
      <b>페이지 제작</b>
    </th>
    <th>
      <b>페이지 제작</b><br>
      <b>데이터 분석</b>
    </th>
    <th>
      <b>딥러닝 모델 개발</b><br>
      <b>페이지 제작</b>
    </th>
  </tr>
  <tr>
      <td><a href="https://github.com/baeminkyeong"><div align=center>@baeminkyeong</div></a></td>
      <td><a href="https://github.com/yuuunong"><div align=center>@yuuunong</div></a></td>
      <td><a href="https://github.com/netsma"><div align=center>@netsma</div></a></td>
      <td><a href="https://github.com/petoriko"><div align=center>@petoriko</div></a></td>
      <td><a href="https://github.com/HIHO999"><div align=center>@HIHO999</div></a></td>
    </tr>
     </tr>
   </tbody>
</table>
<br>


# 2. 프로젝트 개요

### 프로젝트
- 은행 가입고객 이탈자 분석 및 예측

### 목표
- 본 프로젝트는 데이터 분석 및 머신러닝, 딥러닝을 활용하여 **은행 고객의 이탈 가능성을 예측하는 모델**을 개발하는 것입니다.

### 프로젝트 배경

![alt text](<img/스크린샷 2025-03-04 152946.png>)

- https://www.hanaif.re.kr/boardDetail.do?hmpeSeqNo=35933 하나금융연구소 - "2024년, 은행이 놓치지 말아야 할 3가지" 장혜원 수석연구원

- 금융 시장에서 고객관계 강화는 은행의 최우선 과제 중 하나입니다.

- 그러나 디지털 전환 비용과 함께 다양한 경쟁자 참여로 전통적인 금융기관의 마케팅 비용은 매해 증가하는 반면, 고객 충성도는 하락하고 있는 상황



<br>

![alt text](img/image.png)
- https://www.mkhealth.co.kr/news/articleView.html?idxno=32040 매경이코노미 -"[경영칼럼] 신규 고객 늘리기보다 기존 고객 유지 힘써라" 이성용

- **기존 고객 유지를 하는 것이 신규 고객을 유치하는 것보다 수익성 5 ~ 7배 향상**된다고 알려져 있습니다.

- 따라서, 기존 고객의 이탈을 방지하는 것이 운영 비용 절감 및 수익성 강화에 효과적인 전략이 될 수 있습니다.

- 이에 따라, 사전적으로 고객 이탈을 예측하고 선제적으로 대응할 수 있는 데이터 기반의 고객 이탈 예측 모델이 필요하게 되었습니다.

<br>

### 기대 효과
| 기대효과 |내용|
|------|---|
|고객이탈 방지|이탈 가능성이 높은 고객을 조기에 발견하여 맞춤형 프로모션 및 상담 제공|
|비용절감|고객 유지 비용 절감 및 신규 고객 유치 비용 최소화|
|비즈니스 성장|데이터 기반 의사결정을 통한 은행의 경쟁력 강화 및 고객 만족도 향상|

### 요약
- 본 프로젝트를 통해 은행은 고객 이탈 문제를 보다 효과적으로 해결하고, **장기적인 고객 관계 관리를 강화**할 수 있습니다.

- 데이터 기반의 **예측 모델을 활용**하여 고객 맞춤형 전략을 수립함으로써 전통적인 은행의 지속 가능한 성장을 도모하는 것이 본 프로젝트의 최종 목표입니다.


# 3. 기술 스택

| 분야 |기술|
|------|---|
|협업 및 형상 관리|<img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&logo=Discord&logoColor=white" /> <img src="https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=Git&logoColor=white" /> <img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=GitHub&logoColor=white" />|
|개발 환경 & 언어|<img src="https://img.shields.io/badge/VScode-007ACC?style=for-the-badge&logo=Visual-Studio-Code&logoColor=white" /> <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=Python&logoColor=white" />|
|데이터 분석 & 학습|<img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=Pandas&logoColor=white" /> <img src="https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=NumPy&logoColor=white" /> <img src="https://img.shields.io/badge/Matplotlib-11557C?style=for-the-badge&logo=Matplotlib&logoColor=white" /> <img src="https://img.shields.io/badge/Seaborn-4C8CBF?style=for-the-badge&logo=Seaborn&logoColor=white" /> <img src="https://img.shields.io/badge/Scikit%20Learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white" />|
|대시보드|<img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white" />|

# 4. 데이터 내용 확인
- ABC 은행의 고객 이탈 데이터 <br>
- 출처: https://www.kaggle.com/datasets/gauravtopre/bank-customer-churn-dataset
<br>

| 변수명             | 변수 설명                                             | 변수 타입   |
|-------------------|----------------------------------------------------|------------------|
| customer_id       | 고객을 구별하는 고유 ID               | object      |
| credit_score      | 고객의 신용 점수                    | int64            |
| country           | 고객이 거주하는 국가                | object (범주형)   |
| gender            | 고객의 성별                        | object (범주형)   |
| age               | 고객의 나이                        | int64            |
| tenure            | 고객의 은행 가입 기간             | int64            |
| balance           | 고객의 은행 잔액                  | float64          |
| products_number   | 고객이 보유한 은행 상품 수        | int64            |
| credit_card       | 고객의 신용카드 보유 여부    | int64 (범주형)     |
| active_member     | 고객의 활성 회원 여부       | int64 (범주형)     |
| estimated_salary  | 고객의 추정 급여                   | float64          |
| churn             | 고객의 이탈 여부  | int64 (범주형)     |

- 변수 : credit_score (신용 점수), country (국가), age (나이), tenure (가입 기간), churn (이탈 여부) 등의 변수 <br>
- 데이터 크기: 총 10,000명의 고객 데이터, 12개의 변수 (2개의 object형 변수, 8개의 int형 변수, 2개의 float형 변수) <br>
- 데이터 유형: 5개의 범주형 데이터, 7개의 수치형 데이터
  
# 5. 데이터 전처리

**1. 데이터 요약 및 탐색**
- 특정 수치형 변수(신용점수, 잔액, 나이, 예상 연봉)의 기본 통계량(개수, 평균, 표준편차, 최소값, 25%/50%/75% 백분위수, 최대값)을 확인합니다.
- 효과 : 데이터 분포, 중앙값, 범위 등을 파악하여 이상치나 결측치 등을 확인할 수 있습니다.
  
**2. 값 제한 처리**
- 목적 : 특정 변수의 값이 지나치게 크거나 이상치일 경우 임계값을 설정해 제한하여 데이터 분포의 왜곡을 방지하고, 분석 및 모델 학습 과정에서 안정적인 입력을 확보합니다.
- 효과 : 이상치의 부정적 영향을 줄이고, 모델이 정상 범위의 데이터에 집중하여 예측 성능과 일반화 능력을 향상시키며, 해석과 시각화가 용이해집니다.
  
**3. 수치형 변수의 범주화**
- 목적 : 신용점수, 잔액, 나이 등 연속형 데이터를 의미 있는 구간으로 나누어 데이터를 단순화하고 해석하기 쉽게 합니다.
- 효과 : 범주화된 데이터는 그룹별 비교를 용이하게 하고 이상치의 영향을 줄여 모델의 성능을 향상시킵니다.
  
**4. 데이터 시각화 및 이상치 처리**
- 목적 : 연속형 데이터를 몇 개의 범주로 나누어 데이터를 단순화하고 이해하기 쉽게 만듭니다.
- 효과 : 모델 성능 개선과 그룹별 분석을 용이하게 하여 이상치의 영향을 줄입니다.


![alt text](img/full_count.png)

 # 6. 머신러닝
 
## 효과 좋은 방법

- **스케일링:**  
  데이터를 StandardScaler나 MinMaxScaler와 같은 방법으로 정규화하여, 머신러닝 알고리즘(예: 로지스틱 회귀, SVM 등)이 각 특성의 영향을 균형 있게 받아들이도록 함으로써 학습의 안정성과 예측 성능을 크게 향상시켰습니다.

- **SMOTE (Synthetic Minority Over-sampling Technique):**  
  데이터 불균형 문제를 해결하기 위해 SMOTE를 적용하여 소수 클래스 데이터를 증강하였습니다. 이로 인해 클래스 간 균형이 개선되어, 특히 불균형 데이터셋에서 모델의 예측 성능이 향상되었습니다.
  
# 7. 딥러닝

- **복잡한 패턴 학습 :** 딥러닝의 특성을 활용하여 데이터 내 복잡한 비선형 패턴과 변수 간 상호작용을 효과적으로 학습, 고객 이탈 예측 문제에 적합합니다.
- **특성 공학 감소 :** 자동으로 중요한 특성을 추출하므로, 별도의 복잡한 특성 가공 과정 없이도 효율적인 모델링이 가능합니다.
- **모델 성능 :** 초기 실험에서 LLM은 랜덤 포레스트 등 전통적인 모델보다 높은 AUC와 정확도를 보이며, 실제 운영 환경에서 신뢰성 있는 예측 결과를 제공했습니다.

## 데이터 불균형 문제 해결 시도:
- 초기에는 데이터 불균형 문제를 해결하기 위해 SMOTE(Synthetic Minority Over-sampling Technique)를 적용하려고 했습니다. 이탈자와 비이탈자의 비율이 2:8로 불균형하여, SMOTE를 통해 이탈자 데이터를 증강하여 균형을 맞추고자 했습니다.
- 그러나 SMOTE를 적용한 결과, 이탈자에 대한 정확도는 개선되었지만, 주류인 비이탈자에 대한 정확도가 떨어지는 문제가 발생했습니다. 이는 모델이 이탈자 데이터를 과대적합하게 학습하여 전체적인 성능이 저하되는 결과를 초래했습니다.
- 따라서 최종적으로 SMOTE를 제외하고 원본 데이터로 모델을 학습하였습니다.

# 8. 실행 결과
![alt text](img/실행화면01.png)
![alt text](img/실행화면02.png)
![alt text](img/실행화면03.png)
![alt text](img/실행화면04.png)
![alt text](img/실행화면05.png)
![alt text](img/실행화면06.png)
![alt text](img/실행화면07.png)

# 9.  회고
- **배민경 :**
  데이터 전처리를 하며 모델 스코어 향상에 집중하였습니다.<br> 모델 스코어 보다는 의미 있는 피쳐를 찾아내고 분석하여 데이터를 알아가는 시간을 좀 더 보냈을면 좋았을 것 같습니다. 
- **장윤홍 :**
  아무리 데이터를 전처리하고 모델 튜닝을 하여도 의미있는 스코어 상승이 별로 없었던 것 같습니다.<br> 모델을 튜닝하는것도 중요하지만 좋은 피쳐 데이터를 수집하는 것도 중요하다는 것을 알게 되었습니다.
- **이유호 :**
  데이터를 추출하고 분석해 그래프를 그리는데, 엑셀에서 작성한 수준만큼 파이썬에서 구현할 수는 없었고 시간 소모도 상대적으로 많았습니다.<br> 엑셀보다는 파이썬을 다루는 것이 더 편하도록 코딩 실력을 더 키워야겠습니다.
- **남궁세정 :**
  이번에 chatgpt를 많이 활용했는데 명령하는데 고생했습니다. 그래서 명령을 구체적으로 하는 방법을 익혔고 chatgpt활용방법을 알게되었습니다.<br> 무엇보다도 깨달은 것은 백업이 중요성입니다.백업 항상해야하는구나. 그 뒤로 절대로 휴지통 절대 안비워요.
- **황인호 :**
  llm을 활용하게 되면서 llm이 분석을 하기 위한 정보들을 무엇을 어떤 식으로 전달할지를 고심하였습니다.<br> 또한 llm이 각 시도 마다 다른 형식의 출력을 하는것을 막기위해 프롬프트를 어떤식으로 제한해야하는지에 대해 공부하게 되었습니다.


--- File Index 1: mainpage.py ---
import streamlit as st
import pandas as pd
import joblib
import warnings
import pickle
import torch
from sklearn.preprocessing import PowerTransformer, StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from module.inho_model import load_data
from module.churn_prediction import predict_churn
from module.analysis_utils import generate_churn_analysis_data, generate_prompt_from_analysis
from module.groq_utils import get_churn_reasons_solutions
from module.filter_utils import setup_filters, filter_data  # Import the new module
from module.display_utils import display_metrics, display_risk_customers, calculate_risk_info  # Import the new module
import matplotlib.pyplot as plt

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
warnings.filterwarnings("ignore")

# 한글 폰트 설정
plt.rcParams['font.family'] = 'Malgun Gothic'  # 윈도우 사용자
plt.rcParams['font.size'] = 12

# 스타일 설정
st.set_page_config(page_title="은행 고객 이탈 예측", layout="wide")
st.markdown("""
    <style>
    .main {
        background-color: #f4f4f4;
        display: flex;
        justify-content: center;
        align-items: center;
        flex-direction: column;
    }
    .stSlider {
        color: #0073e6;
    }
    .stDataFrame {
        border-radius: 10px;
        border: 1px solid #ddd;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    .high-risk {
        color: #ff4b4b;
        font-weight: bold;
    }
    .low-risk {
        color: #00cc00;
        font-weight: bold;
    }
    </style>
""", unsafe_allow_html=True)

def main():
    st.title('은행 고객 이탈 예측 시스템')
    
    # 데이터 로드
    df = load_data('./data/Bank Customer Churn Prediction.csv')
    
    # 표시할 컬럼 설정
    display_columns = ['customer_id', 'country', 'age', 'balance', '이탈 예측', '이탈 확률']
    
    # 세션 상태 초기화
    if 'results_df' not in st.session_state:
        st.session_state.results_df = None
    
    # 필터 설정
    filters = setup_filters(df)
    
    # 데이터 필터링
    filtered_df = filter_data(df, filters)
    
    # 필터링된 데이터 표시
    st.write(f"필터링된 고객 수: {len(filtered_df):,}명")
    st.dataframe(filtered_df)
    
    accuracy_dict = {
        'Gradient Boosting': 0.8730,
        'Random Forest': 0.8340,
        'Deep Learning': 0.8640
    }
    auc_dict = {
        'Gradient Boosting': 0.8633,
        'Random Forest': 0.8589,
        'Deep Learning': 0.8612
    }

    # 예측 버튼과 모델 선택 박스
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        model_select = st.selectbox('모델 선택', ['Gradient Boosting (AUC: 0.8585)', 'Random Forest (AUC: 0.8589)', 'Deep Learning (AUC: 0.8612)'], index=0)
        if st.button('이탈 예측하기', use_container_width=True):
            if len(filtered_df) > 0:
                with st.spinner('예측 중...'):
                    results_df = filtered_df.copy()
                    predictions, probabilities = predict_churn(filtered_df, model_select)
                    
                    # 결과를 데이터프레임에 추가
                    
                    results_df['이탈 예측'] = ['이탈 예정' if p == 1 else '유지 예정' for p in predictions]
                    results_df['이탈 확률'] = probabilities
                    
                    # 결과를 세션 상태에 저장
                    st.session_state.results_df = results_df
                    
                    # 결과 표시
                    st.success('예측이 완료되었습니다!')
                    
                    # 통계 지표
                    total_customers = len(results_df)
                    predicted_churns = sum(predictions)
                    churn_rate = (predicted_churns / total_customers) * 100
                    
                    # 위험도별 고객 수 계산
                    high_risk = len(results_df[results_df['이탈 확률'] >= 0.7])
                    medium_risk = len(results_df[(results_df['이탈 확률'] >= 0.4) & (results_df['이탈 확률'] < 0.7)])
                    low_risk = len(results_df[results_df['이탈 확률'] < 0.4])
                    
                    # 메트릭 표시
                    display_metrics(total_customers, predicted_churns, churn_rate, high_risk, medium_risk, low_risk)

                    # 구분선 추가
                    st.markdown("---")
                    
                    # 위험도별 고객 목록 표시
                    display_risk_customers(results_df, display_columns)
                    
                    # 각 위험 수준에 속한 고객들의 정보 계산
                    high_risk_info = calculate_risk_info(results_df[results_df['이탈 확률'] >= 0.7])
                    medium_risk_info = calculate_risk_info(results_df[(results_df['이탈 확률'] >= 0.4) & (results_df['이탈 확률'] < 0.7)])
                    low_risk_info = calculate_risk_info(results_df[results_df['이탈 확률'] < 0.4])
                    
                    # 분석 데이터 생성
                    analysis_data = generate_churn_analysis_data(results_df)

                    # Groq API 요청
                    churn_reasons_solutions = get_churn_reasons_solutions(analysis_data)

                    # Streamlit에 표시
                    st.markdown("### 고객 이탈 원인 및 해결 방안")
                    st.markdown(churn_reasons_solutions)

                    # 위험도 기준 설명
                    st.markdown("""
                    ### 위험도 기준
                    - 🔴 높은 위험: 이탈 확률 70% 이상
                    - 🟡 중간 위험: 이탈 확률 40% ~ 70% 미만
                    - 🟢 낮은 위험: 이탈 확률 40% 미만
                    """)

                    # 구분선 추가
                    st.markdown("---")
                    
            else:
                st.error('필터링된 데이터가 없습니다. 필터 조건을 조정해주세요.')

if __name__ == '__main__':
    main()

--- File Index 2: module/analysis_utils.py ---
import pandas as pd

def generate_churn_analysis_data(results_df):
    """ 모델 예측 결과 기반으로 위험도별 주요 분석 데이터를 생성 """
    
    results_df["risk_level"] = pd.cut(results_df["이탈 확률"], bins=[0, 0.4, 0.7, 1.0], labels=["낮음", "중간", "높음"])
    risk_counts = results_df["risk_level"].value_counts().to_dict()
    risk_group_means = results_df.groupby("risk_level")[["credit_score", "balance", "estimated_salary"]].mean().to_dict()

    results_df["age_group"] = pd.cut(results_df["age"], bins=[18, 30, 40, 50, 60, 100], labels=["20대", "30대", "40대", "50대", "60대 이상"])
    age_churn_rates = results_df.groupby("age_group")["이탈 확률"].mean() * 100
    country_churn_rates = results_df.groupby("country")["이탈 확률"].mean() * 100
    gender_churn_rates = results_df.groupby("gender")["이탈 확률"].mean() * 100

    return {
        "risk_counts": risk_counts,
        "risk_group_means": risk_group_means,
        "age_churn_rates": age_churn_rates.to_dict(),
        "country_churn_rates": country_churn_rates.to_dict(),
        "gender_churn_rates": gender_churn_rates.to_dict()
    }

def generate_prompt_from_analysis(analysis_data):
    """ 분석된 데이터를 바탕으로 Groq API 요청을 위한 프롬프트 생성 """
    
    prompt = f"""
    
    ### 고객 이탈 분석 요청 (한국어로 작성)
    주어진 데이터를 바탕으로 고객 이탈 원인과 해결 방안을 도출하시오.
    돈단위는 유로(€)로 표기합니다.
    참고해야되는 정보는 다음과같아.
    🔹 기본 정보
    - 총 고객 수: {sum(analysis_data["risk_counts"].values())}명
    - 높은 위험: 이탈 확률 70% 이상
    - 중간 위험: 이탈 확률 40% ~ 70% 미만
    - 낮은 위험: 이탈 확률 40% 미만
    - 높은 위험 고객 수: {analysis_data["risk_counts"].get("높음", 0)}명
    - 중간 위험 고객 수: {analysis_data["risk_counts"].get("중간", 0)}명
    - 낮은 위험 고객 수: {analysis_data["risk_counts"].get("낮음", 0)}명

    🔹 위험 수준별 고객 특성
    📌 **높은 위험 고객**
    - 평균 신용 점수: {analysis_data["risk_group_means"]["credit_score"].get("높음", "N/A")}
    - 평균 계좌 잔액: {analysis_data["risk_group_means"]["balance"].get("높음", "N/A")}
    - 평균 연봉: {analysis_data["risk_group_means"]["estimated_salary"].get("높음", "N/A")}

    📌 **중간 위험 고객**
    - 평균 신용 점수: {analysis_data["risk_group_means"]["credit_score"].get("중간", "N/A")}
    - 평균 계좌 잔액: {analysis_data["risk_group_means"]["balance"].get("중간", "N/A")}
    - 평균 연봉: {analysis_data["risk_group_means"]["estimated_salary"].get("중간", "N/A")}

    📌 **낮은 위험 고객**
    - 평균 신용 점수: {analysis_data["risk_group_means"]["credit_score"].get("낮음", "N/A")}
    - 평균 계좌 잔액: {analysis_data["risk_group_means"]["balance"].get("낮음", "N/A")}
    - 평균 연봉: {analysis_data["risk_group_means"]["estimated_salary"].get("낮음", "N/A")}

    🔹 연령대별, 국가별, 성별 이탈률
    📌 **연령대별 이탈률 (%)**
    {analysis_data["age_churn_rates"]}

    📌 **국가별 이탈률 (%)**
    {analysis_data["country_churn_rates"]}

    📌 **성별 이탈률 (%)**
    {analysis_data["gender_churn_rates"]}


    
    ### 출력 형식 (항상 이 형식 유지)
    원인이 수치적 데이터와 관련있다면 수치적으로 분석할것(비교군이 있다면 비교군과 수치로 비교)
    출력은 아래 예시와 같은 형식으로만 제공해야함 (형식 외 다른 문장 출력 금지)
    원인은 연령대,국가,성별,신용점수,연봉,잔고 등 다양한 요소에 따라 다를 수 있음
    중요한 원인 3가지만 추려서 제시할것

    - **예: 연령대** 
        - 설명: 연령대에 따른 이탈률을 보면, 특히 40대와 50대 고객의 이탈률이 높은 것으로 나타났습니다. 특히 50대 고객의 이탈률이 54.44%로 가장 높습니다. 이는 이 연령대의 고객들이 퇴직 기간에 다가 다가오거나, 또는 건강 관리 위한 비용 증가 등으로 인해 우리 은행에서 자금을 이탈하거나 이용을 중단할 가능성이 높다는 것을 시사할 수 있습니다.
        - 해결방안: 이러한 연령대의 고객들에게는 세금 및 재산 관리, 건강 관련 보험 서비스가 필요한 것으로 추정됩니다. 따라서 은행이 이러한 제안을 제공하거나 적극적인 고객 관계 관리로 신용도를 높이고, 리테일 은행 서비스 외에 생명보험, 건강보험 제품 등을 개발하거나 제공하여 고객의 긍정적인 이직률을 유지해야 합니다.
    - **예: 국가** 
        - 설명: 국가는 기대 이탈률과 관련이 있습니다. 독일의 경우 특히 높은 이탈률(32.73%)을 보였는데 이는 독일 문화 중 금융 서비스의 다양성과 선택의 폭이 좁은 경우 더 높은 이탈률을 보이는 경향이 있으며, 이는 유럽의 경쟁 환경에서 독일이 비교적 낮은 점유율을 보이는 한 가지 그 원인이 될 수 있습니다.
        - 해결방안: 독일을 포함한 대상 국가들에 대한 조사를 통해 시장 특성을 파악하고 더욱 맞춤형 금융 서비스를 제공해야 합니다. 추가적으로 거대한 유럽 시장에서 경쟁 우위를 가져올 수 있는 혁신적인 제품을 개발하거나, 파트너십을 맺기 위한 다양한 네트워크 구축에도 노력해야 합니다.
    - **예: 성별** 
        - 설명: 성별로 보면 여성이 남성보다 이탈률이 높습니다 (여성 24.50%, 남성 17.67%). 이는 여성이 일반적으로 남성보다 금융 상담을 받는 편이고, 이 과정에서 혼란스러움을 경험할 가능성이 높아서 그렇습니다. 또한 여성의 금융 정보 접근성이나 금융 상담 만족도가 낮을 가능성이 큽니다.
        - 해결방안: 그려본 문제를 해결하기 위해서는 성별에 따른 금융 교육 프로그램을 강화하거나 다양한 성별 고객을 대상으로 금융 상담 서비스를 제공해야 합니다. 또한 여성이 더 많이 활용하는 디지털 채널을 통해 금융 서비스를 제공하여 여성이 금융 상담에 대한 접근성을 높이고, 성별 차별을 없애는 문화적 변화를 적극적으로 유도해야 합니다.
    """




    return prompt

--- File Index 3: module/churn_prediction.py ---
import pandas as pd
import joblib
import pickle
import torch
from sklearn.preprocessing import PowerTransformer, StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from module.inho_model import load_model

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def predict_churn(filtered_data, model_select:str, df=pd.read_csv('./data/Bank Customer Churn Prediction.csv')):
    if model_select == 'Gradient Boosting (AUC: 0.8585)':
        # customer_id 컬럼이 있다면 제거
        if 'customer_id' in filtered_data.columns:
            filtered_data = filtered_data.drop('customer_id', axis=1)
        
        # churn 컬럼이 있다면 제거
        if 'churn' in filtered_data.columns:
            filtered_data = filtered_data.drop('churn', axis=1)
        
        # 원-핫 인코딩 적용
        X_new = pd.get_dummies(filtered_data, drop_first=True)
        
        # 저장된 모델 불러오기
        try:
            pipeline = joblib.load('./model/churn_prediction_model.joblib')
        except FileNotFoundError:
            raise Exception("모델 파일을 찾을 수 없습니다. 먼저 모델을 학습하고 저장해주세요.")
        
        # 예측 수행
        predictions = pipeline.predict(X_new)
        probabilities = pipeline.predict_proba(X_new)[:, 1]

        return predictions, probabilities
    
    elif model_select == 'Random Forest (AUC: 0.8589)':
        # 전처리
        filtered_data['country_France'] = filtered_data['country'].apply(lambda x: 1 if x == 'France' else 0)
        filtered_data['country_Germany'] = filtered_data['country'].apply(lambda x: 1 if x == 'Germany' else 0)
        filtered_data['country_Spain'] = filtered_data['country'].apply(lambda x: 1 if x == 'Spain' else 0)

        filtered_data['gender'] = filtered_data['gender'].apply(lambda x: 1 if x == 'Male' else 0)

        pt = PowerTransformer(method='yeo-johnson')
        pt.fit_transform(df['credit_score'].values.reshape(-1, 1))
        df['credit_score'] = pt.transform(df['credit_score'].values.reshape(-1,1))
        filtered_data['credit_score'] = pt.transform(filtered_data['credit_score'].values.reshape(-1,1))
        pt.fit_transform(df['age'].values.reshape(-1, 1))
        df['age'] = pt.transform(df['age'].values.reshape(-1,1))
        filtered_data['age'] = pt.transform(filtered_data['age'].values.reshape(-1,1))

        scaler = StandardScaler()
        scaler.fit_transform(df['credit_score'].values.reshape(-1, 1))
        filtered_data['credit_score'] = scaler.transform(filtered_data['credit_score'].values.reshape(-1,1))
        scaler.fit_transform(df['age'].values.reshape(-1, 1))
        filtered_data['age'] = scaler.transform(filtered_data['age'].values.reshape(-1,1))
        scaler.fit_transform(df['balance'].values.reshape(-1, 1))
        filtered_data['balance'] = scaler.transform(filtered_data['balance'].values.reshape(-1,1))
        scaler.fit_transform(df['estimated_salary'].values.reshape(-1, 1))
        filtered_data['estimated_salary'] = scaler.transform(filtered_data['estimated_salary'].values.reshape(-1,1))

        # 모델 불러오기
        model = pickle.load(open("./model/randomforest_model.pkl", "rb"))

        # 예측
        X = filtered_data[['credit_score', 'gender', 'age', 'tenure', 'balance',
                           'products_number', 'credit_card', 'active_member', 'estimated_salary',
                           'country_France', 'country_Germany', 'country_Spain']]
        predictions = model.predict(X)
        probabilities = model.predict_proba(X)[:, 1]

        return predictions, probabilities

    if model_select == 'Deep Learning (AUC: 0.8612)':
        # 범주형과 수치형 특성 정의
        categorical_features = ['country', 'gender', 'credit_card', 'active_member']
        numeric_features = ['credit_score', 'age', 'tenure', 'balance', 'products_number', 'estimated_salary']

        # 전처리된 데이터의 열 수 확인
        imputer = SimpleImputer(strategy='mean')
        df[numeric_features] = imputer.fit_transform(df[numeric_features])
        filtered_data[numeric_features] = imputer.transform(filtered_data[numeric_features])

        preprocessor = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), numeric_features),
                ('cat', OneHotEncoder(), categorical_features)
            ])

        preprocessed_data = preprocessor.fit_transform(df)
        preprocessed_filtered_data = preprocessor.transform(filtered_data)
        preprocessed_df = pd.DataFrame(preprocessed_filtered_data, columns=numeric_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)))
        input_dim = preprocessed_df.shape[1]
        print(f'Input dimension: {input_dim}')  # 전처리된 데이터의 열 수 확인

        # 모델 불러오기
        model = load_model('model/churn_model_DL.pth', input_dim=input_dim)
        model.eval()

        # 예측 수행
        X_tensor = torch.tensor(preprocessed_df.values).float().to(device)
        with torch.no_grad():
            outputs = model(X_tensor)
            probabilities = outputs.squeeze().cpu().numpy()
            predictions = (probabilities > 0.5).astype(int)

        return predictions, probabilities

--- File Index 4: module/display_utils.py ---
import streamlit as st

def display_metrics(total_customers, predicted_churns, churn_rate, high_risk, medium_risk, low_risk):
    st.markdown("### 예측 결과 요약")
    
    st.markdown("""
    <style>
    [data-testid="stMetricValue"] {
        font-size: 24px;
    }
    [data-testid="stMetricDelta"] {
        font-size: 16px;
    }
    [data-testid="stMetricLabel"] {
        font-size: 16px;
        font-weight: bold;
    }
    </style>
    """, unsafe_allow_html=True)
    
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("전체 고객", f"{total_customers:,}명")
    
    with col2:
        st.metric("이탈 예정", f"{predicted_churns:,}명", f"{churn_rate:.1f}%")
    
    with col3:
        st.metric("높은 위험", f"{high_risk:,}명", f"{(high_risk/total_customers)*100:.1f}%")
    
    with col4:
        st.metric("중간 위험", f"{medium_risk:,}명", f"{(medium_risk/total_customers)*100:.1f}%")
    
    with col5:
        st.metric("낮은 위험", f"{low_risk:,}명", f"{(low_risk/total_customers)*100:.1f}%")

def display_risk_customers(results_df, display_columns):
    st.markdown("### 위험도별 고객 목록")
    
    tab1, tab2, tab3 = st.tabs(["🔴 높은 위험", "🟡 중간 위험", "🟢 낮은 위험"])
    
    def style_dataframe(df):
        def highlight_risk(val):
            try:
                prob = float(val.strip('%')) / 100
                if prob >= 0.7:
                    return 'background-color: #ffcccc'
                elif prob >= 0.4:
                    return 'background-color: #fff2cc'
                else:
                    return 'background-color: #d9ead3'
            except:
                return ''
        
        return df.style.apply(lambda x: [''] * len(x) if x.name != '이탈 확률' 
                            else [highlight_risk(v) for v in x], axis=0)\
                    .set_properties(**{
                        'text-align': 'left',
                        'white-space': 'pre-wrap',
                        'font-size': '14px',
                        'padding': '10px'
                    })\
                    .set_table_styles([
                        {'selector': 'th',
                         'props': [('font-size', '14px'),
                                  ('text-align', 'left'),
                                  ('padding', '10px'),
                                  ('white-space', 'pre-wrap')]},
                        {'selector': 'td',
                         'props': [('min-width', '100px')]}
                    ])
    
    with tab1:
        high_risk_df = results_df[results_df['이탈 확률'] >= 0.7].copy()
        if not high_risk_df.empty:
            high_risk_df['이탈 확률'] = high_risk_df['이탈 확률'].apply(lambda x: f"{x:.1%}")
            st.dataframe(style_dataframe(high_risk_df[display_columns].sort_values('이탈 확률', ascending=False)),
                         height=400, use_container_width=True)
        else:
            st.info("높은 위험군에 해당하는 고객이 없습니다.")
    
    with tab2:
        medium_risk_df = results_df[(results_df['이탈 확률'] >= 0.4) & 
                                    (results_df['이탈 확률'] < 0.7)].copy()
        if not medium_risk_df.empty:
            medium_risk_df['이탈 확률'] = medium_risk_df['이탈 확률'].apply(lambda x: f"{x:.1%}")
            st.dataframe(style_dataframe(medium_risk_df[display_columns].sort_values('이탈 확률', ascending=False)),
                         height=400, use_container_width=True)
        else:
            st.info("중간 위험군에 해당하는 고객이 없습니다.")
    
    with tab3:
        low_risk_df = results_df[results_df['이탈 확률'] < 0.4].copy()
        if not low_risk_df.empty:
            low_risk_df['이탈 확률'] = low_risk_df['이탈 확률'].apply(lambda x: f"{x:.1%}")
            st.dataframe(style_dataframe(low_risk_df[display_columns].sort_values('이탈 확률', ascending=False)),
                         height=400, use_container_width=True)
        else:
            st.info("낮은 위험군에 해당하는 고객이 없습니다.")

def calculate_risk_info(df):
    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns
    
    numeric_info = df[numeric_cols].mean().to_dict()
    categorical_info = df[categorical_cols].apply(lambda x: x.value_counts().to_dict()).to_dict()
    
    return {**numeric_info, **categorical_info}

--- File Index 5: module/filter_utils.py ---
import streamlit as st

def setup_filters(df):
    st.sidebar.header('필터 옵션')
    
    credit_score = st.sidebar.slider(
        '신용점수',
        int(df['credit_score'].min()),
        int(df['credit_score'].max()),
        (int(df['credit_score'].min()), int(df['credit_score'].max()))
    )
    
    age = st.sidebar.slider(
        '나이',
        int(df['age'].min()),
        int(df['age'].max()),
        (int(df['age'].min()), int(df['age'].max()))
    )
    
    tenure = st.sidebar.slider(
        '거래기간',
        int(df['tenure'].min()),
        int(df['tenure'].max()),
        (int(df['tenure'].min()), int(df['tenure'].max()))
    )
    
    balance = st.sidebar.slider(
        '계좌잔액',
        float(df['balance'].min()),
        float(df['balance'].max()),
        (float(df['balance'].min()), float(df['balance'].max()))
    )
    
    country = st.sidebar.multiselect(
        '국가',
        df['country'].unique().tolist(),
        default=df['country'].unique().tolist()
    )
    
    gender = st.sidebar.multiselect(
        '성별',
        df['gender'].unique().tolist(),
        default=df['gender'].unique().tolist()
    )
    
    products_number = st.sidebar.multiselect(
        '상품 수',
        df['products_number'].unique().tolist(),
        default=df['products_number'].unique().tolist()
    )
    
    credit_card = st.sidebar.multiselect(
        '신용카드 보유',
        [0, 1],
        default=[0, 1]
    )
    
    active_member = st.sidebar.multiselect(
        '활성 회원',
        [0, 1],
        default=[0, 1]
    )
    
    
    filters = {
        'credit_score': credit_score,
        'age': age,
        'tenure': tenure,
        'balance': balance,
        'country': country,
        'gender': gender,
        'products_number': products_number,
        'credit_card': credit_card,
        'active_member': active_member,
    }
    
    return filters

def filter_data(df, filters):
    filtered_df = df[
        (df['credit_score'].between(filters['credit_score'][0], filters['credit_score'][1])) &
        (df['age'].between(filters['age'][0], filters['age'][1])) &
        (df['tenure'].between(filters['tenure'][0], filters['tenure'][1])) &
        (df['balance'].between(filters['balance'][0], filters['balance'][1])) &
        (df['country'].isin(filters['country'])) &
        (df['gender'].isin(filters['gender'])) &
        (df['products_number'].isin(filters['products_number'])) &
        (df['credit_card'].isin(filters['credit_card'])) &
        (df['active_member'].isin(filters['active_member'])) 
    ]
    
    return filtered_df

--- File Index 6: module/groq_utils.py ---
from groq import Groq
from module.analysis_utils import generate_churn_analysis_data, generate_prompt_from_analysis
import os
# Groq API 키 설정
GROQ_API_KEY = os.getenv('GROQ_API_KEY')
# env에 키를 등록해야 함
# 방법: $env:GROQ_API_KEY= "your_api_key" (PowerShell)


# Groq 클라이언트 초기화
client = Groq(api_key=GROQ_API_KEY)

def get_churn_reasons_solutions(analysis_data):
    churn_analysis_prompt = generate_prompt_from_analysis(analysis_data)
    response = client.chat.completions.create(
        messages=[{"role": "user", "content": churn_analysis_prompt}],
        model="qwen-2.5-coder-32b",
    )
    return response.choices[0].message.content

--- File Index 7: module/inho_model.py ---
import torch
import torch.nn as nn
import pandas as pd
from sklearn.preprocessing import StandardScaler, PowerTransformer, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer

# 랜덤 시드 고정
torch.manual_seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(42)

# CUDA 설정
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 데이터 로드
def load_data(filepath):
    data = pd.read_csv(filepath)
    return data

# 데이터 전처리
def preprocess_data(data):
    # 범주형과 수치형 특성 정의
    categorical_features = ['country', 'gender', 'credit_card', 'active_member']
    numeric_features = ['credit_score', 'age', 'tenure', 'balance', 'products_number', 'estimated_salary']

    # 결측값 처리
    imputer = SimpleImputer(strategy='mean')
    data[numeric_features] = imputer.fit_transform(data[numeric_features])

    # 전처리
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numeric_features),
            ('cat', OneHotEncoder(), categorical_features)
        ])

    preprocessed_data = preprocessor.fit_transform(data)
    preprocessed_df = pd.DataFrame(preprocessed_data, columns=numeric_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)))

    return preprocessed_df

# 모델 정의
class ChurnModel(nn.Module):
    def __init__(self, input_dim):
        super(ChurnModel, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.network(x)

# 모델 로드 함수
def load_model(filepath, input_dim):
    model = ChurnModel(input_dim=input_dim)
    model.load_state_dict(torch.load(filepath))
    model.eval()
    return model

# 예측 함수
def predict(model, data, preprocessor, numeric_features, categorical_features):
    preprocessed_data = preprocessor.transform(data)
    preprocessed_df = pd.DataFrame(preprocessed_data, columns=numeric_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)))
    X_tensor = torch.tensor(preprocessed_df.values).float().to(device)
    with torch.no_grad():
        outputs = model(X_tensor)
        probabilities = outputs.squeeze().cpu().numpy()
        predictions = (probabilities > 0.5).astype(int)
    return predictions, probabilities

--- File Index 8: pages/나이별 평균신용점수.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 파일 로드 함수
def load_data():
    file_path = "./data/Bank Customer Churn Prediction(분석)2.xlsx"
    sheet_name = "Bank Customer Churn Prediction"
    
    # 데이터 읽기
    df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=30)
    
    # 데이터프레임 구조 확인 (Streamlit 앱 실행 중에는 출력되지 않으므로 주석 처리 가능)
    # st.write(df.head())
    
    # 필요한 열 선택 (열 이름으로 선택)
    try:
        #df = df[["credit_score", "age", "credit_card", "churn"]]
        df = df.iloc[:, [1, 4, 8, 11]]  # 유효한 데이터 열 선택
        df.columns = ["credit_score", "age", "credit_card", "churn"]
    except KeyError as e:
        st.error(f"열 이름이 유효하지 않습니다: {e}")
        st.stop()
    
    # 결측값 제거
    df = df.dropna(subset=["credit_score"])  # 신용점수 NaN 제거
    
    return df

# 데이터 처리
df = load_data()

# churn 값에 따라 데이터 분리
df_churn_1 = df[df['churn'] == 1]
df_churn_0 = df[df['churn'] == 0]

# 막대그래프 생성 함수
def plot_grouped_bar(df_subset, churn_value, color):
    grouped_data = df_subset.groupby('age')['credit_score'].mean().reset_index()

    ages = grouped_data['age']
    credit_scores = grouped_data['credit_score']

    x = np.arange(len(ages))  # x축 위치 설정
    bar_width = 0.4

    fig, ax = plt.subplots(figsize=(36, 12))
    ax.bar(x, credit_scores, bar_width, label='Credit Score', color=color)

    # 그래프 설정
    ax.set_xlabel('Age')
    ax.set_ylabel('Average Credit Score')
    ax.set_title(f'Grouped Bar Chart for churn = {churn_value}')
    ax.set_xticks(x)
    ax.set_xticklabels(ages.astype(int), rotation=45)  # 나이를 정수로 변환하여 표시
    ax.legend()

    return fig

# 스트림릿 앱 시작
st.title("📊 나이별 평균신용점수")

st.markdown(
    """
    ## 🔍 데이터 분석 요약
    - **나이, 신용점수, 이탈 사이에는 상관관계가 부족함**
    """
)

# 그래프 생성 및 표시
fig1 = plot_grouped_bar(df_churn_1, churn_value=1, color='skyblue')
fig2 = plot_grouped_bar(df_churn_0, churn_value=0, color='orange')

st.pyplot(fig1)
st.pyplot(fig2)

--- File Index 9: pages/신용점수별 카드수.py ---

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 파일 로드 함수
def load_data():
    file_path = "./data/Bank Customer Churn Prediction(분석)2.xlsx"
    sheet_name = "Bank Customer Churn Prediction"
    
    # 데이터 읽기
    df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=30)
    
    # 필요한 열 선택 (열 이름으로 선택)
    try:
        df = df.iloc[:, [1, 4, 8, 11]]  # 유효한 데이터 열 선택
        df.columns = ["credit_score", "age", "credit_card", "churn"]
    except KeyError as e:
        st.error(f"열 이름이 유효하지 않습니다: {e}")
        st.stop()
    
    # 결측값 제거
    df = df.dropna(subset=["credit_score"])  # 신용점수 NaN 제거
    
    return df

# 데이터 처리
df = load_data()

# churn 값에 따라 데이터 분리
df_churn_1 = df[df['churn'] == 1]
df_churn_0 = df[df['churn'] == 0]

# 막대그래프 생성 함수 (두 데이터를 하나의 그래프에 표시)
def plot_combined_bar(df_churn_0, df_churn_1):
    # churn=0 데이터 그룹화
    grouped_data_0 = df_churn_0.groupby('credit_score')['credit_card'].sum().reset_index()
    grouped_data_1 = df_churn_1.groupby('credit_score')['credit_card'].sum().reset_index()

    # 두 그룹의 신용점수를 동일한 x축에 맞추기 위해 병합
    combined_data = pd.merge(grouped_data_0, grouped_data_1, on='credit_score', how='outer', suffixes=('_churn_0', '_churn_1')).fillna(0)

    credit_scores = combined_data['credit_score']
    credit_cards_0 = combined_data['credit_card_churn_0']
    credit_cards_1 = combined_data['credit_card_churn_1']

    x = np.arange(len(credit_scores))  # x축 위치 설정
    bar_width = 0.4

    fig, ax = plt.subplots(figsize=(16, 8))
    
    # 막대그래프 생성 (churn=0과 churn=1 각각)
    ax.bar(x - bar_width/2, credit_cards_0, bar_width, label='churn=0', color='orange')
    ax.bar(x + bar_width/2, credit_cards_1, bar_width, label='churn=1', color='skyblue')

    # 그래프 설정
    ax.set_xlabel('Credit Score')
    ax.set_ylabel('Total Number of Credit Cards')
    ax.set_title('Credit Score vs Credit Cards (churn=0 and churn=1)')

    # x축 레이블 간격 조정 (최대 20개만 표시)
    step_size = max(1, len(credit_scores) // 20)
    ax.set_xticks(x[::step_size])
    ax.set_xticklabels(credit_scores[::step_size].astype(int), rotation=45)  # 신용점수를 정수로 변환하여 표시
    
    ax.legend()
    return fig

# 스트림릿 앱
st.title("📊 신용점수와 이탈수 관계")

st.markdown(
    """
    ## 🔍 데이터 분석 요약
    - **신용점수 350점(최저점)** 도 신용카드를 보유한 고객이 존재합니다.
    - **신용점수 350~404점** 사이의 고객들은 **전부 이탈**하는 경향을 보입니다.
    - **그 외 신용점수와 이탈수의 상관관계는 크지 않은 것으로 분석됩니다.**
    - **신용점수 850점(만점) 고객** 이 과도하게 포진되어 있어, **이상치로 고려해야할 수 있습니다.**
    """
)
# 그래프 생성 및 표시
fig = plot_combined_bar(df_churn_0, df_churn_1)
st.pyplot(fig)

--- File Index 10: pages/연령별 신용카드 및 금융상품 보유 수 변화.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 파일 로드
def load_data():
    file_path = "./data/Bank Customer Churn Prediction(분석)2.xlsx"
    sheet_name = "Sheet2 (5)"
    df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=31)  # 31번째 행부터 데이터 시작
    df = df.iloc[:, [1, 2, 3, 6, 7]]  # 유효한 데이터 열 선택
    df.columns = ["Age", "Credit_Card", "Products", "Total_Credit_Card", "Total_Products"]
    df = df.dropna(subset=["Age"])  # 연령대 NaN 제거
    return df

# 데이터 처리
df = load_data()
df["Age"] = pd.to_numeric(df["Age"], errors='coerce')
df = df.dropna(subset=["Age"])  # NaN 값 다시 제거
df.set_index("Age", inplace=True)
df = df.apply(pd.to_numeric, errors='coerce')

# 스트림릿 앱
st.title("📊 연령별 신용카드 및 금융상품 보유 수 변화")

st.markdown(
    """
    ## 🔍 연령별 신용카드 및 금융상품 보유 수 변화
    - **유지 고객 중 34~37세**의 신용카드 보유 및 금융상품 수가 가장 높으며, 이후 점점 감소합니다.
    - **이탈 고객 중 40대**의 신용카드 보유 및 금융상품 수가 가장 높으며, 이후 점점 감소하는 경향을 보입니다.
    
    ### 📌 연령대별 차이 분석
    - **18~37세:** 신용카드 보유 및 금융상품 수가 점점 증가함.
    - **38~52세:** 신용카드 보유 및 금융상품 수가 점점 감소함 (**고객 관리 필요**).
    - **53~92세:** 신용카드 보유 및 금융상품 수가 유지됨 (**자연적 감소 요인 포함**).
    """
)

# 그래프 생성
fig, ax = plt.subplots(figsize=(25, 7))  # 그래프 크기 조정

# X축 샘플링 조정 (더 넓게 표시)
sample_rate = max(1, len(df) // 60)  # 60개 이하의 점만 표시
sampled_df = df.iloc[::sample_rate]

# X축 레이블(연령대)
x = np.arange(len(sampled_df.index))  # 연령 인덱스 생성
width = 0.2  # 막대 너비 조정

# 여러 개의 데이터 세트 플로팅
df_columns = ["Credit_Card", "Products", "Total_Credit_Card", "Total_Products"]
colors = ['#4472C4', '#ED7D31', '#A5A5A5', '#FFC000']  # 엑셀 원본 색상 적용
labels = ["신용카드 보유 수", "금융상품 수", "총 신용카드 보유 수", "총 금융상품 수"]

for i, col in enumerate(df_columns):
    ax.bar(x + i * width, sampled_df[col], width=width, label=labels[i], color=colors[i])

# 그래프 설정
ax.set_title("연령별 신용카드 및 금융상품 보유 수 변화", fontsize=16, fontweight='bold')
ax.set_xlabel("연령", fontsize=12)
ax.set_ylabel("보유 수", fontsize=12)
ax.set_xticks(x + width * 1.5)  # x축 정렬
ax.set_xticklabels(sampled_df.index.astype(int), rotation=45, fontsize=10)
ax.legend()
ax.grid(axis="y", linestyle="--", alpha=0.7)

st.pyplot(fig)

--- File Index 11: pages/연령별 이탈율 및 활동고객율 분석.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 파일 로드
def load_data():
    file_path = "./data/Bank Customer Churn Prediction(분석)2.xlsx"
    sheet_name = "Sheet2 (6)"
    df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=30)  # 30번째 행부터 데이터 시작
    df = df.iloc[:, [1, 2, 3]]  # 유효한 데이터 열 선택
    df.columns = ["Age", "Churn_Rate", "Active_Member"]
    df = df.dropna(subset=["Age"])  # 연령대 NaN 제거
    return df

# 데이터 처리
df = load_data()
df["Age"] = pd.to_numeric(df["Age"], errors='coerce')
df = df.dropna(subset=["Age"])  # NaN 값 다시 제거
df.set_index("Age", inplace=True)
df = df.apply(pd.to_numeric, errors='coerce')

# 스트림릿 앱
st.title("📊 연령별 이탈율 및 활동고객율 변화")

st.markdown(
    """
    ## 🔍 연령별 이탈율 및 활동고객율 분석
    - **18~39세:** 이탈율이 낮음.
    - **40~56세:** 이탈율이 계속 증가하여 고객 관리가 필요함.
    - **57~65세:** 이탈율이 점점 줄어들지만 여전히 높아 고객 관리가 필요함.
    
    ### 📌 활동 고객 비율 분석
    - **50세 이후:** 활동 고객 비율이 증가하는 경향을 보임.
    - **이전 나이대(50세 미만):** 활동 고객율이 약 50% 수준이므로 향상을 위한 전략 필요.
    """
)

# 그래프 생성
fig, ax = plt.subplots(figsize=(25, 7))  # 그래프 크기 조정

# X축 샘플링 조정
sample_rate = max(1, len(df) // 70)  # 70개 이하의 점만 표시
sampled_df = df.iloc[::sample_rate]

# X축 레이블(연령대)
x = np.arange(len(sampled_df.index))  # 연령 인덱스 생성
width = 0.35  # 막대 너비 조정

# 여러 개의 데이터 세트 플로팅
df_columns = ["Churn_Rate", "Active_Member"]
colors = ['#ED7D31', '#5B9BD5']  # 원본 엑셀 색상 적용 (주황: 이탈율, 파랑: 활동 고객율)
labels = ["이탈율 (Churn Rate)", "활동 고객율 (Active Member)"]

for i, col in enumerate(df_columns):
    ax.bar(x + i * width, sampled_df[col], width=width, label=labels[i], color=colors[i])

# 그래프 설정
ax.set_title("연령별 이탈율 및 활동고객율 변화", fontsize=16, fontweight='bold')
ax.set_xlabel("연령", fontsize=12)
ax.set_ylabel("비율", fontsize=12)
ax.set_xticks(x + width * 0.5)  # x축 정렬
ax.set_xticklabels(sampled_df.index.astype(int), rotation=45, fontsize=10)
ax.legend()
ax.grid(axis="y", linestyle="--", alpha=0.7)

st.pyplot(fig)

--- File Index 12: pages/연령별 잔고 및 연봉 변화.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 파일 로드
def load_data():
    file_path = "./data/Bank Customer Churn Prediction(분석)2.xlsx"
    sheet_name = "Sheet2 (4)"
    df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=31)  # 31번째 행부터 데이터 시작
    df = df.iloc[:, [1, 2, 3, 4, 6, 7]]  # 유효한 데이터 열 선택
    df.columns = ["Age", "Balance", "Salary", "Prev_Balance", "Total_Balance", "Total_Salary"]
    df = df.dropna(subset=["Age"])  # 연령대 NaN 제거
    return df

# 데이터 처리
df = load_data()
df["Age"] = pd.to_numeric(df["Age"], errors='coerce')
df = df.dropna(subset=["Age"])  # NaN 값 다시 제거
df.set_index("Age", inplace=True)
df = df.apply(pd.to_numeric, errors='coerce')

# 스트림릿 앱
st.title("📊 연령별 잔고 및 연봉 변화")

st.markdown(
    """
    ## 🔍 연령별 연봉 및 잔고 변화 분석
    - **유지 고객 중 34~38세**의 연봉 및 잔고가 가장 높으며, 이후 점점 감소합니다.
    - **이탈 고객 중 40대**의 연봉 및 잔고가 가장 높으며, 이후 점점 감소하는 경향을 보입니다.
    
    ### 📌 연령대별 차이 분석
    - **18~48세:** 유지 고객이 이탈 고객보다 연봉 및 잔고가 더 많음.
    - **49~60세:** 유지 고객이 이탈 고객보다 연봉 및 잔고가 더 적음 (**고객 관리 필요**).
    - **61~92세:** 유지 고객이 이탈 고객보다 연봉 및 잔고가 더 많음.
    """
)

# 그래프 생성
fig, ax = plt.subplots(figsize=(25, 7))  # 그래프 크기 조정

# X축 샘플링 조정 (더 넓게 표시)
sample_rate = max(1, len(df) // 60)  # 60개 이하의 점만 표시
sampled_df = df.iloc[::sample_rate]

# X축 레이블(연령대)
x = np.arange(len(sampled_df.index))  # 연령 인덱스 생성
width = 0.2  # 막대 너비 조정

# 여러 개의 데이터 세트 플로팅
df_columns = ["Balance", "Salary", "Prev_Balance", "Total_Balance", "Total_Salary"]
colors = ['#4472C4', '#ED7D31', '#A5A5A5', '#FFC000', '#70AD47']  # 엑셀 원본 색상 적용
labels = ["잔고(Balance)", "연봉(Salary)", "과거 잔고(Prev_Balance)", "총 잔고(Total_Balance)", "총 연봉(Total_Salary)"]

for i, col in enumerate(df_columns):
    ax.bar(x + i * width, sampled_df[col], width=width, label=labels[i], color=colors[i])

# 그래프 설정
ax.set_title("연령별 잔고 및 연봉 변화", fontsize=16, fontweight='bold')
ax.set_xlabel("연령", fontsize=12)
ax.set_ylabel("금액", fontsize=12)
ax.set_xticks(x + width * 2)  # x축 정렬
ax.set_xticklabels(sampled_df.index.astype(int), rotation=45, fontsize=10)
ax.legend()
ax.grid(axis="y", linestyle="--", alpha=0.7)

st.pyplot(fig)

--- File Index 13: pages/종합 분석.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

# 한글 폰트 설정
plt.rcParams['font.family'] = 'Malgun Gothic'  # 윈도우 사용자
plt.rcParams['font.size'] = 12

# 파일 로드 함수
def load_data():
    file_path = "./data/Bank Customer Churn Prediction(분석)2.xlsx"
    if not os.path.exists(file_path):
        st.error("파일을 찾을 수 없습니다. 파일을 업로드하세요.")
        return None
    
    try:
        xls = pd.ExcelFile(file_path)
        if "Bank Customer Churn Prediction" in xls.sheet_names:
            df = pd.read_excel(xls, sheet_name="Bank Customer Churn Prediction")
            return df
        else:
            st.error("❌ 'Bank Customer Churn Prediction' 시트를 찾을 수 없습니다.")
            return None
    except Exception as e:
        st.error(f"데이터 로드 중 오류 발생: {e}")
        return None

df = load_data()

if df is not None:
    # 데이터 정리: 첫 번째 행이 컬럼명일 경우 수정
    if df.iloc[0].isna().sum() == 0:
        df.columns = df.iloc[0]
        df = df[1:].reset_index(drop=True)

    st.title("📊 Bank Customer Churn Prediction 분석")

    # 1. 고객 이탈 현황 분석
    if 'churn' in df.columns:
        st.subheader("📌 고객 이탈 현황")
        churn_counts = df['churn'].value_counts()

        if len(churn_counts) > 1:
            labels = churn_counts.index.astype(str)
            fig, ax = plt.subplots()
            colors = ['lightblue', 'salmon']
            explode = (0, 0.1) if len(labels) == 2 else None
            ax.pie(churn_counts, labels=labels, autopct='%1.1f%%', colors=colors[:len(labels)], explode=explode, startangle=90)
            plt.axis('equal')
            st.pyplot(fig)
        else:
            st.write("⚠️ 데이터가 하나의 클래스만 포함하고 있어 바 차트를 표시합니다.")
            fig, ax = plt.subplots()
            churn_counts.plot(kind='bar', color='salmon', ax=ax)
            ax.set_ylabel("고객 수")
            st.pyplot(fig)

        st.write("▪ **여성 고객이 남성 고객보다 급여가 더 많음에도 이탈을 더 많이 함. (고객 관리 필요)**\n")

    # 2. 성별별 고객 이탈률
    if 'gender' in df.columns and 'churn' in df.columns:
        st.subheader("📌 성별별 고객 이탈률")
        gender_churn = df.groupby("gender")["churn"].mean().sort_values()
        fig, ax = plt.subplots(figsize=(6, 4))
        gender_churn.plot(kind='bar', color=["blue", "red"], ax=ax)
        ax.set_ylabel("이탈률")
        st.pyplot(fig)

    # 3. 연령대별 잔고 및 연봉 분석 (유지 고객만)
    if 'age' in df.columns and 'balance' in df.columns and 'estimated_salary' in df.columns:
        st.subheader("📌 연령대별 잔고 및 연봉 분석 (유지 고객)")
        age_bins = list(range(18, 80, 5))
        df["age_group"] = pd.cut(df["age"], bins=age_bins, right=False)

        if 'churn' in df.columns:
            churn_0 = df[df["churn"] == 0]
            balance_avg = churn_0.groupby("age_group")["balance"].mean()
            salary_avg = churn_0.groupby("age_group")["estimated_salary"].mean()

            fig, ax1 = plt.subplots(figsize=(8, 5))
            ax1.plot(balance_avg.index.astype(str), balance_avg, marker="o", linestyle="-", color="blue", label="잔고")
            ax1.set_ylabel("잔고", color="blue")
            ax1.tick_params(axis="y", labelcolor="blue")

            ax2 = ax1.twinx()
            ax2.plot(salary_avg.index.astype(str), salary_avg, marker="o", linestyle="--", color="red", label="연봉")
            ax2.set_ylabel("연봉", color="red")
            ax2.tick_params(axis="y", labelcolor="red")

            plt.title("연령대별 잔고 및 연봉 변화 (유지 고객)")
            st.pyplot(fig)

            st.write("▪ **34~38세 유지 고객의 잔고 및 연봉이 가장 높고 이후 점차 감소함.**\n")


    # 4. 고객 이탈 분석 - 신용 점수
    if 'churn' in df.columns and 'credit_score' in df.columns:
        st.subheader("📌 이탈 여부에 따른 신용 점수 분포")
        fig, ax = plt.subplots()
        sns.boxplot(x='churn', y='credit_score', data=df, ax=ax)
        st.pyplot(fig)

        st.write("▪ **이탈 고객의 평균 신용 점수가 유지 고객보다 낮음.**\n")

    # 5. 국가별 고객 이탈률
    if 'country' in df.columns and 'churn' in df.columns:
        st.subheader("📌 국가별 고객 이탈률")
        country_churn = df.groupby("country")["churn"].mean().sort_values()
        fig, ax = plt.subplots(figsize=(8, 4))
        country_churn.plot(kind='bar', color="salmon", ax=ax)
        ax.set_ylabel("이탈률")
        st.pyplot(fig)

    # 6. 연령대별 고객 분포 (추가된 그래프)
    if 'age' in df.columns:
        st.subheader("📌 연령대별 고객 분포")
        fig, ax = plt.subplots(figsize=(8, 4))
        sns.histplot(df["age"], bins=20, kde=True, color="purple", ax=ax)
        ax.set_xlabel("나이")
        ax.set_ylabel("고객 수")
        st.pyplot(fig)

        st.write("▪ **연령대별로 보면 특정 연령층에서 고객 수가 집중됨.**\n\n\n")

    # 분석 설명 추가
st.markdown("""
    ### 🔍 **활동 고객과 이탈 관계**
    ▪ 활동 고객과 이탈은 **음의 상관관계**\n
    ▪ 비활동 고객이 금융 상품을 **이용하도록 혜택 제공 필요**\n\n\n
    
            
    ### 💳 **금융 상품과 이탈 관계**
    ▪ 신용카드 1개만 있는 고객이 **이탈 가능성 높음**\n
    ▪ 금융 상품 2종 이상 유지 시 **이탈 감소** (입출금 통장 등 크로스셀링 필요)\n\n\n
    
            
    ### 👩‍💼 **성별과 이탈 분석**
    ▪ **여성 신용카드 고객**이 남성보다 이탈률 높음\n\n\n
    
            
    ### 💰 **잔고 및 급여와 이탈**
    ▪ 여성 고객이 남성보다 잔고 많지만 **이탈 더 많음** (고객 관리 필요)\n
    ▪ **프랑스 남성 고객**은 잔고 가장 높고 이탈률 가장 적음\n
    ▪ **독일 여성 고객**은 이탈 시 잔고가 높음 (고객 관리 필요)\n\n\n
    
            
    ### 🔄 **신용카드 활성 고객 분석**
    ▪ **장기 고객**의 이탈이 적음\n
    ▪ 신용카드 **비활성 고객은 장기/단기 이탈률 높음** (상관관계 낮음)\n
    ▪ 신용카드 활성 고객은 **단기 고객의 이탈이 높음** (장기 유지 필요)\n\n\n
            
            
    """)



Based on the provided codebase, identify the key abstractions that are central to understanding this project. 
These abstractions should represent the core components, modules, or concepts.

Desired output format is a YAML list of objects, where each object has:
- 'name': A concise name for the abstraction (in korean).
- 'description': A brief explanation of what this abstraction represents and its role (in korean).
- 'file_indices': A list of integer file indices that are most relevant to this abstraction. Choose from the file list above.

Return at most 10 key abstractions.

Example for a different project (simple web server):
```yaml
- name: "HTTP 요청 핸들러 (HTTP Request Handler)"
  description: "수신 HTTP 요청을 처리하고 적절한 응답을 생성하는 구성 요소입니다. (Component that processes incoming HTTP requests and generates appropriate responses.)"
  file_indices: [0, 2]
- name: "라우팅 설정 (Routing Configuration)"
  description: "URL 경로를 특정 요청 핸들러 함수에 매핑하는 규칙을 정의합니다. (Defines rules for mapping URL paths to specific request handler functions.)"
  file_indices: [1]
```

Your response should be only the YAML list, enclosed in triple backticks (```yaml ... ```).
Ensure the output is valid YAML.

2025-06-29 20:55:16,146 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:55:24,679 - INFO - RESPONSE: ```yaml
- name: "은행 고객 이탈 예측 시스템"
  description: "Streamlit을 이용해 구현된 은행 고객 이탈 예측 대시보드로, 고객의 다양한 정보를 기반으로 이탈 가능성을 예측하고 분석 결과를 시각화하여 사용자에게 제공합니다."
  file_indices: [0, 1, 4, 5]

- name: "데이터 전처리 및 로드"
  description: "고객 데이터를 로드하고, 결측값 처리, 범주형 및 수치형 데이터 전처리를 통해 모델이 잘 학습할 수 있도록 준비하는 단계입니다."
  file_indices: [7]

- name: "모델 예측 및 성능 측정"
  description: "고객 데이터에 대해 Gradient Boosting, Random Forest, Deep Learning 모델을 사용하여 이탈 예측을 수행하고 성능을 측정합니다."
  file_indices: [3, 9, 12]

- name: "고객 이탈 분석 데이터 생성"
  description: "모델 예측 결과를 바탕으로 위험도별 주요 분석 데이터를 생성하여 고객 이탈 원인과 해결 방안을 도출하는 데 사용됩니다."
  file_indices: [2, 6]

- name: "데이터 시각화 및 대시보드 구성"
  description: "Streamlit을 통해 데이터 시각화를 구현하여 사용자에게 이해하기 쉬운 방식으로 분석 결과를 전달하는 대시보드를 구성합니다."
  file_indices: [1, 4]

- name: "필터링 기능"
  description: "사용자가 설정한 필터 옵션에 따라 고객 데이터를 필터링하여 특정 조건에 해당하는 데이터만을 분석할 수 있도록 지원합니다."
  file_indices: [5]

- name: "고객 이탈 원인과 해결 방안"
  description: "고객 이탈 원인을 분석하고 Groq API를 통해 해결 방안을 도출하여 조직의 전략 수립에 기여합니다."
  file_indices: [2, 6]

- name: "나이별 데이터 분석"
  description: "나이에 따른 평균 신용점수, 금융상품 보유 수 등의 분석을 통해 연령대를 기반으로 고객 특성을 파악합니다."
  file_indices: [8, 10, 11]

- name: "모델 로드 및 관리"
  description: "저장된 머신러닝 및 딥러닝 모델을 로드하여 예측에 활용하며, 모델의 상태를 유지 관리합니다."
  file_indices: [3, 7]

- name: "디스플레이 유틸리티"
  description: "계산된 예측 결과를 UI에 표시하기 위한 여러 유틸리티 함수로, 직접적인 고객 관련 정보를 제공하는 데 사용됩니다."
  file_indices: [4]
```
2025-06-29 20:55:25,045 - INFO - PROMPT: 
Based on the following abstractions and relevant code snippets from the project `SKN10-2nd-1Team`:

List of Abstraction Indices and Names (Names might be in Korean):
0 # 은행 고객 이탈 예측 시스템
1 # 데이터 전처리 및 로드
2 # 모델 예측 및 성능 측정
3 # 고객 이탈 분석 데이터 생성
4 # 데이터 시각화 및 대시보드 구성
5 # 필터링 기능
6 # 고객 이탈 원인과 해결 방안
7 # 나이별 데이터 분석
8 # 모델 로드 및 관리
9 # 디스플레이 유틸리티

Context (Abstractions, Descriptions, Code):
Identified Abstractions:
- Index 0: 은행 고객 이탈 예측 시스템 (Relevant file indices: [0, 1, 4, 5])
  Description: Streamlit을 이용해 구현된 은행 고객 이탈 예측 대시보드로, 고객의 다양한 정보를 기반으로 이탈 가능성을 예측하고 분석 결과를 시각화하여 사용자에게 제공합니다.
- Index 1: 데이터 전처리 및 로드 (Relevant file indices: [7])
  Description: 고객 데이터를 로드하고, 결측값 처리, 범주형 및 수치형 데이터 전처리를 통해 모델이 잘 학습할 수 있도록 준비하는 단계입니다.
- Index 2: 모델 예측 및 성능 측정 (Relevant file indices: [3, 9, 12])
  Description: 고객 데이터에 대해 Gradient Boosting, Random Forest, Deep Learning 모델을 사용하여 이탈 예측을 수행하고 성능을 측정합니다.
- Index 3: 고객 이탈 분석 데이터 생성 (Relevant file indices: [2, 6])
  Description: 모델 예측 결과를 바탕으로 위험도별 주요 분석 데이터를 생성하여 고객 이탈 원인과 해결 방안을 도출하는 데 사용됩니다.
- Index 4: 데이터 시각화 및 대시보드 구성 (Relevant file indices: [1, 4])
  Description: Streamlit을 통해 데이터 시각화를 구현하여 사용자에게 이해하기 쉬운 방식으로 분석 결과를 전달하는 대시보드를 구성합니다.
- Index 5: 필터링 기능 (Relevant file indices: [5])
  Description: 사용자가 설정한 필터 옵션에 따라 고객 데이터를 필터링하여 특정 조건에 해당하는 데이터만을 분석할 수 있도록 지원합니다.
- Index 6: 고객 이탈 원인과 해결 방안 (Relevant file indices: [2, 6])
  Description: 고객 이탈 원인을 분석하고 Groq API를 통해 해결 방안을 도출하여 조직의 전략 수립에 기여합니다.
- Index 7: 나이별 데이터 분석 (Relevant file indices: [8, 10, 11])
  Description: 나이에 따른 평균 신용점수, 금융상품 보유 수 등의 분석을 통해 연령대를 기반으로 고객 특성을 파악합니다.
- Index 8: 모델 로드 및 관리 (Relevant file indices: [3, 7])
  Description: 저장된 머신러닝 및 딥러닝 모델을 로드하여 예측에 활용하며, 모델의 상태를 유지 관리합니다.
- Index 9: 디스플레이 유틸리티 (Relevant file indices: [4])
  Description: 계산된 예측 결과를 UI에 표시하기 위한 여러 유틸리티 함수로, 직접적인 고객 관련 정보를 제공하는 데 사용됩니다.

Relevant File Snippets (Referenced by Index and Path):
--- File: 0 # README.md ---
# SKN10-2nd-1Team
# [은행 고객 이탈 예측](https://www.kaggle.com/datasets/gauravtopre/bank-customer-churn-dataset/data)
 SK Networks AI Camp 10기

 개발기간: 25.02.19 - 25.03.05
<br>

# **1. 팀 소개**

### 팀명 : 1 팀
### 팀원 소개
<table align=center>
<tbody>
 <tr>
  <br>
      <td align=center><b>배민경👑</b></td>
      <td align=center><b>장윤홍</b></td>
      <td align=center><b>이유호</b></td>
      <td align=center><b>남궁세정</b></td>
      <td align=center><b>황인호</b></td>
    </tr>
    <br>
 <tr>
    <th> 
      <b>프로젝트 총괄</b><br>
      <b>머신러닝 모델 개발</b><br>
      <b>페이지 제작</b>
    </th>
    <th>
      <b>머신러닝 모델 개발</b><br>
      <b>페이지 제작</b>
    </th>
    <th>
      <b>데이터 분석</b><br>
      <b>페이지 제작</b>
    </th>
    <th>
      <b>페이지 제작</b><br>
      <b>데이터 분석</b>
    </th>
    <th>
      <b>딥러닝 모델 개발</b><br>
      <b>페이지 제작</b>
    </th>
  </tr>
  <tr>
      <td><a href="https://github.com/baeminkyeong"><div align=center>@baeminkyeong</div></a></td>
      <td><a href="https://github.com/yuuunong"><div align=center>@yuuunong</div></a></td>
      <td><a href="https://github.com/netsma"><div align=center>@netsma</div></a></td>
      <td><a href="https://github.com/petoriko"><div align=center>@petoriko</div></a></td>
      <td><a href="https://github.com/HIHO999"><div align=center>@HIHO999</div></a></td>
    </tr>
     </tr>
   </tbody>
</table>
<br>


# 2. 프로젝트 개요

### 프로젝트
- 은행 가입고객 이탈자 분석 및 예측

### 목표
- 본 프로젝트는 데이터 분석 및 머신러닝, 딥러닝을 활용하여 **은행 고객의 이탈 가능성을 예측하는 모델**을 개발하는 것입니다.

### 프로젝트 배경

![alt text](<img/스크린샷 2025-03-04 152946.png>)

- https://www.hanaif.re.kr/boardDetail.do?hmpeSeqNo=35933 하나금융연구소 - "2024년, 은행이 놓치지 말아야 할 3가지" 장혜원 수석연구원

- 금융 시장에서 고객관계 강화는 은행의 최우선 과제 중 하나입니다.

- 그러나 디지털 전환 비용과 함께 다양한 경쟁자 참여로 전통적인 금융기관의 마케팅 비용은 매해 증가하는 반면, 고객 충성도는 하락하고 있는 상황



<br>

![alt text](img/image.png)
- https://www.mkhealth.co.kr/news/articleView.html?idxno=32040 매경이코노미 -"[경영칼럼] 신규 고객 늘리기보다 기존 고객 유지 힘써라" 이성용

- **기존 고객 유지를 하는 것이 신규 고객을 유치하는 것보다 수익성 5 ~ 7배 향상**된다고 알려져 있습니다.

- 따라서, 기존 고객의 이탈을 방지하는 것이 운영 비용 절감 및 수익성 강화에 효과적인 전략이 될 수 있습니다.

- 이에 따라, 사전적으로 고객 이탈을 예측하고 선제적으로 대응할 수 있는 데이터 기반의 고객 이탈 예측 모델이 필요하게 되었습니다.

<br>

### 기대 효과
| 기대효과 |내용|
|------|---|
|고객이탈 방지|이탈 가능성이 높은 고객을 조기에 발견하여 맞춤형 프로모션 및 상담 제공|
|비용절감|고객 유지 비용 절감 및 신규 고객 유치 비용 최소화|
|비즈니스 성장|데이터 기반 의사결정을 통한 은행의 경쟁력 강화 및 고객 만족도 향상|

### 요약
- 본 프로젝트를 통해 은행은 고객 이탈 문제를 보다 효과적으로 해결하고, **장기적인 고객 관계 관리를 강화**할 수 있습니다.

- 데이터 기반의 **예측 모델을 활용**하여 고객 맞춤형 전략을 수립함으로써 전통적인 은행의 지속 가능한 성장을 도모하는 것이 본 프로젝트의 최종 목표입니다.


# 3. 기술 스택

| 분야 |기술|
|------|---|
|협업 및 형상 관리|<img src="https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&logo=Discord&logoColor=white" /> <img src="https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=Git&logoColor=white" /> <img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=GitHub&logoColor=white" />|
|개발 환경 & 언어|<img src="https://img.shields.io/badge/VScode-007ACC?style=for-the-badge&logo=Visual-Studio-Code&logoColor=white" /> <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=Python&logoColor=white" />|
|데이터 분석 & 학습|<img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=Pandas&logoColor=white" /> <img src="https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=NumPy&logoColor=white" /> <img src="https://img.shields.io/badge/Matplotlib-11557C?style=for-the-badge&logo=Matplotlib&logoColor=white" /> <img src="https://img.shields.io/badge/Seaborn-4C8CBF?style=for-the-badge&logo=Seaborn&logoColor=white" /> <img src="https://img.shields.io/badge/Scikit%20Learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white" />|
|대시보드|<img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white" />|

# 4. 데이터 내용 확인
- ABC 은행의 고객 이탈 데이터 <br>
- 출처: https://www.kaggle.com/datasets/gauravtopre/bank-customer-churn-dataset
<br>

| 변수명             | 변수 설명                                             | 변수 타입   |
|-------------------|----------------------------------------------------|------------------|
| customer_id       | 고객을 구별하는 고유 ID               | object      |
| credit_score      | 고객의 신용 점수                    | int64            |
| country           | 고객이 거주하는 국가                | object (범주형)   |
| gender            | 고객의 성별                        | object (범주형)   |
| age               | 고객의 나이                        | int64            |
| tenure            | 고객의 은행 가입 기간             | int64            |
| balance           | 고객의 은행 잔액                  | float64          |
| products_number   | 고객이 보유한 은행 상품 수        | int64            |
| credit_card       | 고객의 신용카드 보유 여부    | int64 (범주형)     |
| active_member     | 고객의 활성 회원 여부       | int64 (범주형)     |
| estimated_salary  | 고객의 추정 급여                   | float64          |
| churn             | 고객의 이탈 여부  | int64 (범주형)     |

- 변수 : credit_score (신용 점수), country (국가), age (나이), tenure (가입 기간), churn (이탈 여부) 등의 변수 <br>
- 데이터 크기: 총 10,000명의 고객 데이터, 12개의 변수 (2개의 object형 변수, 8개의 int형 변수, 2개의 float형 변수) <br>
- 데이터 유형: 5개의 범주형 데이터, 7개의 수치형 데이터
  
# 5. 데이터 전처리

**1. 데이터 요약 및 탐색**
- 특정 수치형 변수(신용점수, 잔액, 나이, 예상 연봉)의 기본 통계량(개수, 평균, 표준편차, 최소값, 25%/50%/75% 백분위수, 최대값)을 확인합니다.
- 효과 : 데이터 분포, 중앙값, 범위 등을 파악하여 이상치나 결측치 등을 확인할 수 있습니다.
  
**2. 값 제한 처리**
- 목적 : 특정 변수의 값이 지나치게 크거나 이상치일 경우 임계값을 설정해 제한하여 데이터 분포의 왜곡을 방지하고, 분석 및 모델 학습 과정에서 안정적인 입력을 확보합니다.
- 효과 : 이상치의 부정적 영향을 줄이고, 모델이 정상 범위의 데이터에 집중하여 예측 성능과 일반화 능력을 향상시키며, 해석과 시각화가 용이해집니다.
  
**3. 수치형 변수의 범주화**
- 목적 : 신용점수, 잔액, 나이 등 연속형 데이터를 의미 있는 구간으로 나누어 데이터를 단순화하고 해석하기 쉽게 합니다.
- 효과 : 범주화된 데이터는 그룹별 비교를 용이하게 하고 이상치의 영향을 줄여 모델의 성능을 향상시킵니다.
  
**4. 데이터 시각화 및 이상치 처리**
- 목적 : 연속형 데이터를 몇 개의 범주로 나누어 데이터를 단순화하고 이해하기 쉽게 만듭니다.
- 효과 : 모델 성능 개선과 그룹별 분석을 용이하게 하여 이상치의 영향을 줄입니다.


![alt text](img/full_count.png)

 # 6. 머신러닝
 
## 효과 좋은 방법

- **스케일링:**  
  데이터를 StandardScaler나 MinMaxScaler와 같은 방법으로 정규화하여, 머신러닝 알고리즘(예: 로지스틱 회귀, SVM 등)이 각 특성의 영향을 균형 있게 받아들이도록 함으로써 학습의 안정성과 예측 성능을 크게 향상시켰습니다.

- **SMOTE (Synthetic Minority Over-sampling Technique):**  
  데이터 불균형 문제를 해결하기 위해 SMOTE를 적용하여 소수 클래스 데이터를 증강하였습니다. 이로 인해 클래스 간 균형이 개선되어, 특히 불균형 데이터셋에서 모델의 예측 성능이 향상되었습니다.
  
# 7. 딥러닝

- **복잡한 패턴 학습 :** 딥러닝의 특성을 활용하여 데이터 내 복잡한 비선형 패턴과 변수 간 상호작용을 효과적으로 학습, 고객 이탈 예측 문제에 적합합니다.
- **특성 공학 감소 :** 자동으로 중요한 특성을 추출하므로, 별도의 복잡한 특성 가공 과정 없이도 효율적인 모델링이 가능합니다.
- **모델 성능 :** 초기 실험에서 LLM은 랜덤 포레스트 등 전통적인 모델보다 높은 AUC와 정확도를 보이며, 실제 운영 환경에서 신뢰성 있는 예측 결과를 제공했습니다.

## 데이터 불균형 문제 해결 시도:
- 초기에는 데이터 불균형 문제를 해결하기 위해 SMOTE(Synthetic Minority Over-sampling Technique)를 적용하려고 했습니다. 이탈자와 비이탈자의 비율이 2:8로 불균형하여, SMOTE를 통해 이탈자 데이터를 증강하여 균형을 맞추고자 했습니다.
- 그러나 SMOTE를 적용한 결과, 이탈자에 대한 정확도는 개선되었지만, 주류인 비이탈자에 대한 정확도가 떨어지는 문제가 발생했습니다. 이는 모델이 이탈자 데이터를 과대적합하게 학습하여 전체적인 성능이 저하되는 결과를 초래했습니다.
- 따라서 최종적으로 SMOTE를 제외하고 원본 데이터로 모델을 학습하였습니다.

# 8. 실행 결과
![alt text](img/실행화면01.png)
![alt text](img/실행화면02.png)
![alt text](img/실행화면03.png)
![alt text](img/실행화면04.png)
![alt text](img/실행화면05.png)
![alt text](img/실행화면06.png)
![alt text](img/실행화면07.png)

# 9.  회고
- **배민경 :**
  데이터 전처리를 하며 모델 스코어 향상에 집중하였습니다.<br> 모델 스코어 보다는 의미 있는 피쳐를 찾아내고 분석하여 데이터를 알아가는 시간을 좀 더 보냈을면 좋았을 것 같습니다. 
- **장윤홍 :**
  아무리 데이터를 전처리하고 모델 튜닝을 하여도 의미있는 스코어 상승이 별로 없었던 것 같습니다.<br> 모델을 튜닝하는것도 중요하지만 좋은 피쳐 데이터를 수집하는 것도 중요하다는 것을 알게 되었습니다.
- **이유호 :**
  데이터를 추출하고 분석해 그래프를 그리는데, 엑셀에서 작성한 수준만큼 파이썬에서 구현할 수는 없었고 시간 소모도 상대적으로 많았습니다.<br> 엑셀보다는 파이썬을 다루는 것이 더 편하도록 코딩 실력을 더 키워야겠습니다.
- **남궁세정 :**
  이번에 chatgpt를 많이 활용했는데 명령하는데 고생했습니다. 그래서 명령을 구체적으로 하는 방법을 익혔고 chatgpt활용방법을 알게되었습니다.<br> 무엇보다도 깨달은 것은 백업이 중요성입니다.백업 항상해야하는구나. 그 뒤로 절대로 휴지통 절대 안비워요.
- **황인호 :**
  llm을 활용하게 되면서 llm이 분석을 하기 위한 정보들을 무엇을 어떤 식으로 전달할지를 고심하였습니다.<br> 또한 llm이 각 시도 마다 다른 형식의 출력을 하는것을 막기위해 프롬프트를 어떤식으로 제한해야하는지에 대해 공부하게 되었습니다.


--- File: 1 # mainpage.py ---
import streamlit as st
import pandas as pd
import joblib
import warnings
import pickle
import torch
from sklearn.preprocessing import PowerTransformer, StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from module.inho_model import load_data
from module.churn_prediction import predict_churn
from module.analysis_utils import generate_churn_analysis_data, generate_prompt_from_analysis
from module.groq_utils import get_churn_reasons_solutions
from module.filter_utils import setup_filters, filter_data  # Import the new module
from module.display_utils import display_metrics, display_risk_customers, calculate_risk_info  # Import the new module
import matplotlib.pyplot as plt

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
warnings.filterwarnings("ignore")

# 한글 폰트 설정
plt.rcParams['font.family'] = 'Malgun Gothic'  # 윈도우 사용자
plt.rcParams['font.size'] = 12

# 스타일 설정
st.set_page_config(page_title="은행 고객 이탈 예측", layout="wide")
st.markdown("""
    <style>
    .main {
        background-color: #f4f4f4;
        display: flex;
        justify-content: center;
        align-items: center;
        flex-direction: column;
    }
    .stSlider {
        color: #0073e6;
    }
    .stDataFrame {
        border-radius: 10px;
        border: 1px solid #ddd;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    .high-risk {
        color: #ff4b4b;
        font-weight: bold;
    }
    .low-risk {
        color: #00cc00;
        font-weight: bold;
    }
    </style>
""", unsafe_allow_html=True)

def main():
    st.title('은행 고객 이탈 예측 시스템')
    
    # 데이터 로드
    df = load_data('./data/Bank Customer Churn Prediction.csv')
    
    # 표시할 컬럼 설정
    display_columns = ['customer_id', 'country', 'age', 'balance', '이탈 예측', '이탈 확률']
    
    # 세션 상태 초기화
    if 'results_df' not in st.session_state:
        st.session_state.results_df = None
    
    # 필터 설정
    filters = setup_filters(df)
    
    # 데이터 필터링
    filtered_df = filter_data(df, filters)
    
    # 필터링된 데이터 표시
    st.write(f"필터링된 고객 수: {len(filtered_df):,}명")
    st.dataframe(filtered_df)
    
    accuracy_dict = {
        'Gradient Boosting': 0.8730,
        'Random Forest': 0.8340,
        'Deep Learning': 0.8640
    }
    auc_dict = {
        'Gradient Boosting': 0.8633,
        'Random Forest': 0.8589,
        'Deep Learning': 0.8612
    }

    # 예측 버튼과 모델 선택 박스
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        model_select = st.selectbox('모델 선택', ['Gradient Boosting (AUC: 0.8585)', 'Random Forest (AUC: 0.8589)', 'Deep Learning (AUC: 0.8612)'], index=0)
        if st.button('이탈 예측하기', use_container_width=True):
            if len(filtered_df) > 0:
                with st.spinner('예측 중...'):
                    results_df = filtered_df.copy()
                    predictions, probabilities = predict_churn(filtered_df, model_select)
                    
                    # 결과를 데이터프레임에 추가
                    
                    results_df['이탈 예측'] = ['이탈 예정' if p == 1 else '유지 예정' for p in predictions]
                    results_df['이탈 확률'] = probabilities
                    
                    # 결과를 세션 상태에 저장
                    st.session_state.results_df = results_df
                    
                    # 결과 표시
                    st.success('예측이 완료되었습니다!')
                    
                    # 통계 지표
                    total_customers = len(results_df)
                    predicted_churns = sum(predictions)
                    churn_rate = (predicted_churns / total_customers) * 100
                    
                    # 위험도별 고객 수 계산
                    high_risk = len(results_df[results_df['이탈 확률'] >= 0.7])
                    medium_risk = len(results_df[(results_df['이탈 확률'] >= 0.4) & (results_df['이탈 확률'] < 0.7)])
                    low_risk = len(results_df[results_df['이탈 확률'] < 0.4])
                    
                    # 메트릭 표시
                    display_metrics(total_customers, predicted_churns, churn_rate, high_risk, medium_risk, low_risk)

                    # 구분선 추가
                    st.markdown("---")
                    
                    # 위험도별 고객 목록 표시
                    display_risk_customers(results_df, display_columns)
                    
                    # 각 위험 수준에 속한 고객들의 정보 계산
                    high_risk_info = calculate_risk_info(results_df[results_df['이탈 확률'] >= 0.7])
                    medium_risk_info = calculate_risk_info(results_df[(results_df['이탈 확률'] >= 0.4) & (results_df['이탈 확률'] < 0.7)])
                    low_risk_info = calculate_risk_info(results_df[results_df['이탈 확률'] < 0.4])
                    
                    # 분석 데이터 생성
                    analysis_data = generate_churn_analysis_data(results_df)

                    # Groq API 요청
                    churn_reasons_solutions = get_churn_reasons_solutions(analysis_data)

                    # Streamlit에 표시
                    st.markdown("### 고객 이탈 원인 및 해결 방안")
                    st.markdown(churn_reasons_solutions)

                    # 위험도 기준 설명
                    st.markdown("""
                    ### 위험도 기준
                    - 🔴 높은 위험: 이탈 확률 70% 이상
                    - 🟡 중간 위험: 이탈 확률 40% ~ 70% 미만
                    - 🟢 낮은 위험: 이탈 확률 40% 미만
                    """)

                    # 구분선 추가
                    st.markdown("---")
                    
            else:
                st.error('필터링된 데이터가 없습니다. 필터 조건을 조정해주세요.')

if __name__ == '__main__':
    main()

--- File: 2 # module/analysis_utils.py ---
import pandas as pd

def generate_churn_analysis_data(results_df):
    """ 모델 예측 결과 기반으로 위험도별 주요 분석 데이터를 생성 """
    
    results_df["risk_level"] = pd.cut(results_df["이탈 확률"], bins=[0, 0.4, 0.7, 1.0], labels=["낮음", "중간", "높음"])
    risk_counts = results_df["risk_level"].value_counts().to_dict()
    risk_group_means = results_df.groupby("risk_level")[["credit_score", "balance", "estimated_salary"]].mean().to_dict()

    results_df["age_group"] = pd.cut(results_df["age"], bins=[18, 30, 40, 50, 60, 100], labels=["20대", "30대", "40대", "50대", "60대 이상"])
    age_churn_rates = results_df.groupby("age_group")["이탈 확률"].mean() * 100
    country_churn_rates = results_df.groupby("country")["이탈 확률"].mean() * 100
    gender_churn_rates = results_df.groupby("gender")["이탈 확률"].mean() * 100

    return {
        "risk_counts": risk_counts,
        "risk_group_means": risk_group_means,
        "age_churn_rates": age_churn_rates.to_dict(),
        "country_churn_rates": country_churn_rates.to_dict(),
        "gender_churn_rates": gender_churn_rates.to_dict()
    }

def generate_prompt_from_analysis(analysis_data):
    """ 분석된 데이터를 바탕으로 Groq API 요청을 위한 프롬프트 생성 """
    
    prompt = f"""
    
    ### 고객 이탈 분석 요청 (한국어로 작성)
    주어진 데이터를 바탕으로 고객 이탈 원인과 해결 방안을 도출하시오.
    돈단위는 유로(€)로 표기합니다.
    참고해야되는 정보는 다음과같아.
    🔹 기본 정보
    - 총 고객 수: {sum(analysis_data["risk_counts"].values())}명
    - 높은 위험: 이탈 확률 70% 이상
    - 중간 위험: 이탈 확률 40% ~ 70% 미만
    - 낮은 위험: 이탈 확률 40% 미만
    - 높은 위험 고객 수: {analysis_data["risk_counts"].get("높음", 0)}명
    - 중간 위험 고객 수: {analysis_data["risk_counts"].get("중간", 0)}명
    - 낮은 위험 고객 수: {analysis_data["risk_counts"].get("낮음", 0)}명

    🔹 위험 수준별 고객 특성
    📌 **높은 위험 고객**
    - 평균 신용 점수: {analysis_data["risk_group_means"]["credit_score"].get("높음", "N/A")}
    - 평균 계좌 잔액: {analysis_data["risk_group_means"]["balance"].get("높음", "N/A")}
    - 평균 연봉: {analysis_data["risk_group_means"]["estimated_salary"].get("높음", "N/A")}

    📌 **중간 위험 고객**
    - 평균 신용 점수: {analysis_data["risk_group_means"]["credit_score"].get("중간", "N/A")}
    - 평균 계좌 잔액: {analysis_data["risk_group_means"]["balance"].get("중간", "N/A")}
    - 평균 연봉: {analysis_data["risk_group_means"]["estimated_salary"].get("중간", "N/A")}

    📌 **낮은 위험 고객**
    - 평균 신용 점수: {analysis_data["risk_group_means"]["credit_score"].get("낮음", "N/A")}
    - 평균 계좌 잔액: {analysis_data["risk_group_means"]["balance"].get("낮음", "N/A")}
    - 평균 연봉: {analysis_data["risk_group_means"]["estimated_salary"].get("낮음", "N/A")}

    🔹 연령대별, 국가별, 성별 이탈률
    📌 **연령대별 이탈률 (%)**
    {analysis_data["age_churn_rates"]}

    📌 **국가별 이탈률 (%)**
    {analysis_data["country_churn_rates"]}

    📌 **성별 이탈률 (%)**
    {analysis_data["gender_churn_rates"]}


    
    ### 출력 형식 (항상 이 형식 유지)
    원인이 수치적 데이터와 관련있다면 수치적으로 분석할것(비교군이 있다면 비교군과 수치로 비교)
    출력은 아래 예시와 같은 형식으로만 제공해야함 (형식 외 다른 문장 출력 금지)
    원인은 연령대,국가,성별,신용점수,연봉,잔고 등 다양한 요소에 따라 다를 수 있음
    중요한 원인 3가지만 추려서 제시할것

    - **예: 연령대** 
        - 설명: 연령대에 따른 이탈률을 보면, 특히 40대와 50대 고객의 이탈률이 높은 것으로 나타났습니다. 특히 50대 고객의 이탈률이 54.44%로 가장 높습니다. 이는 이 연령대의 고객들이 퇴직 기간에 다가 다가오거나, 또는 건강 관리 위한 비용 증가 등으로 인해 우리 은행에서 자금을 이탈하거나 이용을 중단할 가능성이 높다는 것을 시사할 수 있습니다.
        - 해결방안: 이러한 연령대의 고객들에게는 세금 및 재산 관리, 건강 관련 보험 서비스가 필요한 것으로 추정됩니다. 따라서 은행이 이러한 제안을 제공하거나 적극적인 고객 관계 관리로 신용도를 높이고, 리테일 은행 서비스 외에 생명보험, 건강보험 제품 등을 개발하거나 제공하여 고객의 긍정적인 이직률을 유지해야 합니다.
    - **예: 국가** 
        - 설명: 국가는 기대 이탈률과 관련이 있습니다. 독일의 경우 특히 높은 이탈률(32.73%)을 보였는데 이는 독일 문화 중 금융 서비스의 다양성과 선택의 폭이 좁은 경우 더 높은 이탈률을 보이는 경향이 있으며, 이는 유럽의 경쟁 환경에서 독일이 비교적 낮은 점유율을 보이는 한 가지 그 원인이 될 수 있습니다.
        - 해결방안: 독일을 포함한 대상 국가들에 대한 조사를 통해 시장 특성을 파악하고 더욱 맞춤형 금융 서비스를 제공해야 합니다. 추가적으로 거대한 유럽 시장에서 경쟁 우위를 가져올 수 있는 혁신적인 제품을 개발하거나, 파트너십을 맺기 위한 다양한 네트워크 구축에도 노력해야 합니다.
    - **예: 성별** 
        - 설명: 성별로 보면 여성이 남성보다 이탈률이 높습니다 (여성 24.50%, 남성 17.67%). 이는 여성이 일반적으로 남성보다 금융 상담을 받는 편이고, 이 과정에서 혼란스러움을 경험할 가능성이 높아서 그렇습니다. 또한 여성의 금융 정보 접근성이나 금융 상담 만족도가 낮을 가능성이 큽니다.
        - 해결방안: 그려본 문제를 해결하기 위해서는 성별에 따른 금융 교육 프로그램을 강화하거나 다양한 성별 고객을 대상으로 금융 상담 서비스를 제공해야 합니다. 또한 여성이 더 많이 활용하는 디지털 채널을 통해 금융 서비스를 제공하여 여성이 금융 상담에 대한 접근성을 높이고, 성별 차별을 없애는 문화적 변화를 적극적으로 유도해야 합니다.
    """




    return prompt

--- File: 3 # module/churn_prediction.py ---
import pandas as pd
import joblib
import pickle
import torch
from sklearn.preprocessing import PowerTransformer, StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from module.inho_model import load_model

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def predict_churn(filtered_data, model_select:str, df=pd.read_csv('./data/Bank Customer Churn Prediction.csv')):
    if model_select == 'Gradient Boosting (AUC: 0.8585)':
        # customer_id 컬럼이 있다면 제거
        if 'customer_id' in filtered_data.columns:
            filtered_data = filtered_data.drop('customer_id', axis=1)
        
        # churn 컬럼이 있다면 제거
        if 'churn' in filtered_data.columns:
            filtered_data = filtered_data.drop('churn', axis=1)
        
        # 원-핫 인코딩 적용
        X_new = pd.get_dummies(filtered_data, drop_first=True)
        
        # 저장된 모델 불러오기
        try:
            pipeline = joblib.load('./model/churn_prediction_model.joblib')
        except FileNotFoundError:
            raise Exception("모델 파일을 찾을 수 없습니다. 먼저 모델을 학습하고 저장해주세요.")
        
        # 예측 수행
        predictions = pipeline.predict(X_new)
        probabilities = pipeline.predict_proba(X_new)[:, 1]

        return predictions, probabilities
    
    elif model_select == 'Random Forest (AUC: 0.8589)':
        # 전처리
        filtered_data['country_France'] = filtered_data['country'].apply(lambda x: 1 if x == 'France' else 0)
        filtered_data['country_Germany'] = filtered_data['country'].apply(lambda x: 1 if x == 'Germany' else 0)
        filtered_data['country_Spain'] = filtered_data['country'].apply(lambda x: 1 if x == 'Spain' else 0)

        filtered_data['gender'] = filtered_data['gender'].apply(lambda x: 1 if x == 'Male' else 0)

        pt = PowerTransformer(method='yeo-johnson')
        pt.fit_transform(df['credit_score'].values.reshape(-1, 1))
        df['credit_score'] = pt.transform(df['credit_score'].values.reshape(-1,1))
        filtered_data['credit_score'] = pt.transform(filtered_data['credit_score'].values.reshape(-1,1))
        pt.fit_transform(df['age'].values.reshape(-1, 1))
        df['age'] = pt.transform(df['age'].values.reshape(-1,1))
        filtered_data['age'] = pt.transform(filtered_data['age'].values.reshape(-1,1))

        scaler = StandardScaler()
        scaler.fit_transform(df['credit_score'].values.reshape(-1, 1))
        filtered_data['credit_score'] = scaler.transform(filtered_data['credit_score'].values.reshape(-1,1))
        scaler.fit_transform(df['age'].values.reshape(-1, 1))
        filtered_data['age'] = scaler.transform(filtered_data['age'].values.reshape(-1,1))
        scaler.fit_transform(df['balance'].values.reshape(-1, 1))
        filtered_data['balance'] = scaler.transform(filtered_data['balance'].values.reshape(-1,1))
        scaler.fit_transform(df['estimated_salary'].values.reshape(-1, 1))
        filtered_data['estimated_salary'] = scaler.transform(filtered_data['estimated_salary'].values.reshape(-1,1))

        # 모델 불러오기
        model = pickle.load(open("./model/randomforest_model.pkl", "rb"))

        # 예측
        X = filtered_data[['credit_score', 'gender', 'age', 'tenure', 'balance',
                           'products_number', 'credit_card', 'active_member', 'estimated_salary',
                           'country_France', 'country_Germany', 'country_Spain']]
        predictions = model.predict(X)
        probabilities = model.predict_proba(X)[:, 1]

        return predictions, probabilities

    if model_select == 'Deep Learning (AUC: 0.8612)':
        # 범주형과 수치형 특성 정의
        categorical_features = ['country', 'gender', 'credit_card', 'active_member']
        numeric_features = ['credit_score', 'age', 'tenure', 'balance', 'products_number', 'estimated_salary']

        # 전처리된 데이터의 열 수 확인
        imputer = SimpleImputer(strategy='mean')
        df[numeric_features] = imputer.fit_transform(df[numeric_features])
        filtered_data[numeric_features] = imputer.transform(filtered_data[numeric_features])

        preprocessor = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), numeric_features),
                ('cat', OneHotEncoder(), categorical_features)
            ])

        preprocessed_data = preprocessor.fit_transform(df)
        preprocessed_filtered_data = preprocessor.transform(filtered_data)
        preprocessed_df = pd.DataFrame(preprocessed_filtered_data, columns=numeric_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)))
        input_dim = preprocessed_df.shape[1]
        print(f'Input dimension: {input_dim}')  # 전처리된 데이터의 열 수 확인

        # 모델 불러오기
        model = load_model('model/churn_model_DL.pth', input_dim=input_dim)
        model.eval()

        # 예측 수행
        X_tensor = torch.tensor(preprocessed_df.values).float().to(device)
        with torch.no_grad():
            outputs = model(X_tensor)
            probabilities = outputs.squeeze().cpu().numpy()
            predictions = (probabilities > 0.5).astype(int)

        return predictions, probabilities

--- File: 4 # module/display_utils.py ---
import streamlit as st

def display_metrics(total_customers, predicted_churns, churn_rate, high_risk, medium_risk, low_risk):
    st.markdown("### 예측 결과 요약")
    
    st.markdown("""
    <style>
    [data-testid="stMetricValue"] {
        font-size: 24px;
    }
    [data-testid="stMetricDelta"] {
        font-size: 16px;
    }
    [data-testid="stMetricLabel"] {
        font-size: 16px;
        font-weight: bold;
    }
    </style>
    """, unsafe_allow_html=True)
    
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("전체 고객", f"{total_customers:,}명")
    
    with col2:
        st.metric("이탈 예정", f"{predicted_churns:,}명", f"{churn_rate:.1f}%")
    
    with col3:
        st.metric("높은 위험", f"{high_risk:,}명", f"{(high_risk/total_customers)*100:.1f}%")
    
    with col4:
        st.metric("중간 위험", f"{medium_risk:,}명", f"{(medium_risk/total_customers)*100:.1f}%")
    
    with col5:
        st.metric("낮은 위험", f"{low_risk:,}명", f"{(low_risk/total_customers)*100:.1f}%")

def display_risk_customers(results_df, display_columns):
    st.markdown("### 위험도별 고객 목록")
    
    tab1, tab2, tab3 = st.tabs(["🔴 높은 위험", "🟡 중간 위험", "🟢 낮은 위험"])
    
    def style_dataframe(df):
        def highlight_risk(val):
            try:
                prob = float(val.strip('%')) / 100
                if prob >= 0.7:
                    return 'background-color: #ffcccc'
                elif prob >= 0.4:
                    return 'background-color: #fff2cc'
                else:
                    return 'background-color: #d9ead3'
            except:
                return ''
        
        return df.style.apply(lambda x: [''] * len(x) if x.name != '이탈 확률' 
                            else [highlight_risk(v) for v in x], axis=0)\
                    .set_properties(**{
                        'text-align': 'left',
                        'white-space': 'pre-wrap',
                        'font-size': '14px',
                        'padding': '10px'
                    })\
                    .set_table_styles([
                        {'selector': 'th',
                         'props': [('font-size', '14px'),
                                  ('text-align', 'left'),
                                  ('padding', '10px'),
                                  ('white-space', 'pre-wrap')]},
                        {'selector': 'td',
                         'props': [('min-width', '100px')]}
                    ])
    
    with tab1:
        high_risk_df = results_df[results_df['이탈 확률'] >= 0.7].copy()
        if not high_risk_df.empty:
            high_risk_df['이탈 확률'] = high_risk_df['이탈 확률'].apply(lambda x: f"{x:.1%}")
            st.dataframe(style_dataframe(high_risk_df[display_columns].sort_values('이탈 확률', ascending=False)),
                         height=400, use_container_width=True)
        else:
            st.info("높은 위험군에 해당하는 고객이 없습니다.")
    
    with tab2:
        medium_risk_df = results_df[(results_df['이탈 확률'] >= 0.4) & 
                                    (results_df['이탈 확률'] < 0.7)].copy()
        if not medium_risk_df.empty:
            medium_risk_df['이탈 확률'] = medium_risk_df['이탈 확률'].apply(lambda x: f"{x:.1%}")
            st.dataframe(style_dataframe(medium_risk_df[display_columns].sort_values('이탈 확률', ascending=False)),
                         height=400, use_container_width=True)
        else:
            st.info("중간 위험군에 해당하는 고객이 없습니다.")
    
    with tab3:
        low_risk_df = results_df[results_df['이탈 확률'] < 0.4].copy()
        if not low_risk_df.empty:
            low_risk_df['이탈 확률'] = low_risk_df['이탈 확률'].apply(lambda x: f"{x:.1%}")
            st.dataframe(style_dataframe(low_risk_df[display_columns].sort_values('이탈 확률', ascending=False)),
                         height=400, use_container_width=True)
        else:
            st.info("낮은 위험군에 해당하는 고객이 없습니다.")

def calculate_risk_info(df):
    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns
    
    numeric_info = df[numeric_cols].mean().to_dict()
    categorical_info = df[categorical_cols].apply(lambda x: x.value_counts().to_dict()).to_dict()
    
    return {**numeric_info, **categorical_info}

--- File: 5 # module/filter_utils.py ---
import streamlit as st

def setup_filters(df):
    st.sidebar.header('필터 옵션')
    
    credit_score = st.sidebar.slider(
        '신용점수',
        int(df['credit_score'].min()),
        int(df['credit_score'].max()),
        (int(df['credit_score'].min()), int(df['credit_score'].max()))
    )
    
    age = st.sidebar.slider(
        '나이',
        int(df['age'].min()),
        int(df['age'].max()),
        (int(df['age'].min()), int(df['age'].max()))
    )
    
    tenure = st.sidebar.slider(
        '거래기간',
        int(df['tenure'].min()),
        int(df['tenure'].max()),
        (int(df['tenure'].min()), int(df['tenure'].max()))
    )
    
    balance = st.sidebar.slider(
        '계좌잔액',
        float(df['balance'].min()),
        float(df['balance'].max()),
        (float(df['balance'].min()), float(df['balance'].max()))
    )
    
    country = st.sidebar.multiselect(
        '국가',
        df['country'].unique().tolist(),
        default=df['country'].unique().tolist()
    )
    
    gender = st.sidebar.multiselect(
        '성별',
        df['gender'].unique().tolist(),
        default=df['gender'].unique().tolist()
    )
    
    products_number = st.sidebar.multiselect(
        '상품 수',
        df['products_number'].unique().tolist(),
        default=df['products_number'].unique().tolist()
    )
    
    credit_card = st.sidebar.multiselect(
        '신용카드 보유',
        [0, 1],
        default=[0, 1]
    )
    
    active_member = st.sidebar.multiselect(
        '활성 회원',
        [0, 1],
        default=[0, 1]
    )
    
    
    filters = {
        'credit_score': credit_score,
        'age': age,
        'tenure': tenure,
        'balance': balance,
        'country': country,
        'gender': gender,
        'products_number': products_number,
        'credit_card': credit_card,
        'active_member': active_member,
    }
    
    return filters

def filter_data(df, filters):
    filtered_df = df[
        (df['credit_score'].between(filters['credit_score'][0], filters['credit_score'][1])) &
        (df['age'].between(filters['age'][0], filters['age'][1])) &
        (df['tenure'].between(filters['tenure'][0], filters['tenure'][1])) &
        (df['balance'].between(filters['balance'][0], filters['balance'][1])) &
        (df['country'].isin(filters['country'])) &
        (df['gender'].isin(filters['gender'])) &
        (df['products_number'].isin(filters['products_number'])) &
        (df['credit_card'].isin(filters['credit_card'])) &
        (df['active_member'].isin(filters['active_member'])) 
    ]
    
    return filtered_df

--- File: 6 # module/groq_utils.py ---
from groq import Groq
from module.analysis_utils import generate_churn_analysis_data, generate_prompt_from_analysis
import os
# Groq API 키 설정
GROQ_API_KEY = os.getenv('GROQ_API_KEY')
# env에 키를 등록해야 함
# 방법: $env:GROQ_API_KEY= "your_api_key" (PowerShell)


# Groq 클라이언트 초기화
client = Groq(api_key=GROQ_API_KEY)

def get_churn_reasons_solutions(analysis_data):
    churn_analysis_prompt = generate_prompt_from_analysis(analysis_data)
    response = client.chat.completions.create(
        messages=[{"role": "user", "content": churn_analysis_prompt}],
        model="qwen-2.5-coder-32b",
    )
    return response.choices[0].message.content

--- File: 7 # module/inho_model.py ---
import torch
import torch.nn as nn
import pandas as pd
from sklearn.preprocessing import StandardScaler, PowerTransformer, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer

# 랜덤 시드 고정
torch.manual_seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(42)

# CUDA 설정
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 데이터 로드
def load_data(filepath):
    data = pd.read_csv(filepath)
    return data

# 데이터 전처리
def preprocess_data(data):
    # 범주형과 수치형 특성 정의
    categorical_features = ['country', 'gender', 'credit_card', 'active_member']
    numeric_features = ['credit_score', 'age', 'tenure', 'balance', 'products_number', 'estimated_salary']

    # 결측값 처리
    imputer = SimpleImputer(strategy='mean')
    data[numeric_features] = imputer.fit_transform(data[numeric_features])

    # 전처리
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numeric_features),
            ('cat', OneHotEncoder(), categorical_features)
        ])

    preprocessed_data = preprocessor.fit_transform(data)
    preprocessed_df = pd.DataFrame(preprocessed_data, columns=numeric_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)))

    return preprocessed_df

# 모델 정의
class ChurnModel(nn.Module):
    def __init__(self, input_dim):
        super(ChurnModel, self).__init__()
        self.network = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.network(x)

# 모델 로드 함수
def load_model(filepath, input_dim):
    model = ChurnModel(input_dim=input_dim)
    model.load_state_dict(torch.load(filepath))
    model.eval()
    return model

# 예측 함수
def predict(model, data, preprocessor, numeric_features, categorical_features):
    preprocessed_data = preprocessor.transform(data)
    preprocessed_df = pd.DataFrame(preprocessed_data, columns=numeric_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)))
    X_tensor = torch.tensor(preprocessed_df.values).float().to(device)
    with torch.no_grad():
        outputs = model(X_tensor)
        probabilities = outputs.squeeze().cpu().numpy()
        predictions = (probabilities > 0.5).astype(int)
    return predictions, probabilities

--- File: 8 # pages/나이별 평균신용점수.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 파일 로드 함수
def load_data():
    file_path = "./data/Bank Customer Churn Prediction(분석)2.xlsx"
    sheet_name = "Bank Customer Churn Prediction"
    
    # 데이터 읽기
    df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=30)
    
    # 데이터프레임 구조 확인 (Streamlit 앱 실행 중에는 출력되지 않으므로 주석 처리 가능)
    # st.write(df.head())
    
    # 필요한 열 선택 (열 이름으로 선택)
    try:
        #df = df[["credit_score", "age", "credit_card", "churn"]]
        df = df.iloc[:, [1, 4, 8, 11]]  # 유효한 데이터 열 선택
        df.columns = ["credit_score", "age", "credit_card", "churn"]
    except KeyError as e:
        st.error(f"열 이름이 유효하지 않습니다: {e}")
        st.stop()
    
    # 결측값 제거
    df = df.dropna(subset=["credit_score"])  # 신용점수 NaN 제거
    
    return df

# 데이터 처리
df = load_data()

# churn 값에 따라 데이터 분리
df_churn_1 = df[df['churn'] == 1]
df_churn_0 = df[df['churn'] == 0]

# 막대그래프 생성 함수
def plot_grouped_bar(df_subset, churn_value, color):
    grouped_data = df_subset.groupby('age')['credit_score'].mean().reset_index()

    ages = grouped_data['age']
    credit_scores = grouped_data['credit_score']

    x = np.arange(len(ages))  # x축 위치 설정
    bar_width = 0.4

    fig, ax = plt.subplots(figsize=(36, 12))
    ax.bar(x, credit_scores, bar_width, label='Credit Score', color=color)

    # 그래프 설정
    ax.set_xlabel('Age')
    ax.set_ylabel('Average Credit Score')
    ax.set_title(f'Grouped Bar Chart for churn = {churn_value}')
    ax.set_xticks(x)
    ax.set_xticklabels(ages.astype(int), rotation=45)  # 나이를 정수로 변환하여 표시
    ax.legend()

    return fig

# 스트림릿 앱 시작
st.title("📊 나이별 평균신용점수")

st.markdown(
    """
    ## 🔍 데이터 분석 요약
    - **나이, 신용점수, 이탈 사이에는 상관관계가 부족함**
    """
)

# 그래프 생성 및 표시
fig1 = plot_grouped_bar(df_churn_1, churn_value=1, color='skyblue')
fig2 = plot_grouped_bar(df_churn_0, churn_value=0, color='orange')

st.pyplot(fig1)
st.pyplot(fig2)

--- File: 9 # pages/신용점수별 카드수.py ---

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 파일 로드 함수
def load_data():
    file_path = "./data/Bank Customer Churn Prediction(분석)2.xlsx"
    sheet_name = "Bank Customer Churn Prediction"
    
    # 데이터 읽기
    df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=30)
    
    # 필요한 열 선택 (열 이름으로 선택)
    try:
        df = df.iloc[:, [1, 4, 8, 11]]  # 유효한 데이터 열 선택
        df.columns = ["credit_score", "age", "credit_card", "churn"]
    except KeyError as e:
        st.error(f"열 이름이 유효하지 않습니다: {e}")
        st.stop()
    
    # 결측값 제거
    df = df.dropna(subset=["credit_score"])  # 신용점수 NaN 제거
    
    return df

# 데이터 처리
df = load_data()

# churn 값에 따라 데이터 분리
df_churn_1 = df[df['churn'] == 1]
df_churn_0 = df[df['churn'] == 0]

# 막대그래프 생성 함수 (두 데이터를 하나의 그래프에 표시)
def plot_combined_bar(df_churn_0, df_churn_1):
    # churn=0 데이터 그룹화
    grouped_data_0 = df_churn_0.groupby('credit_score')['credit_card'].sum().reset_index()
    grouped_data_1 = df_churn_1.groupby('credit_score')['credit_card'].sum().reset_index()

    # 두 그룹의 신용점수를 동일한 x축에 맞추기 위해 병합
    combined_data = pd.merge(grouped_data_0, grouped_data_1, on='credit_score', how='outer', suffixes=('_churn_0', '_churn_1')).fillna(0)

    credit_scores = combined_data['credit_score']
    credit_cards_0 = combined_data['credit_card_churn_0']
    credit_cards_1 = combined_data['credit_card_churn_1']

    x = np.arange(len(credit_scores))  # x축 위치 설정
    bar_width = 0.4

    fig, ax = plt.subplots(figsize=(16, 8))
    
    # 막대그래프 생성 (churn=0과 churn=1 각각)
    ax.bar(x - bar_width/2, credit_cards_0, bar_width, label='churn=0', color='orange')
    ax.bar(x + bar_width/2, credit_cards_1, bar_width, label='churn=1', color='skyblue')

    # 그래프 설정
    ax.set_xlabel('Credit Score')
    ax.set_ylabel('Total Number of Credit Cards')
    ax.set_title('Credit Score vs Credit Cards (churn=0 and churn=1)')

    # x축 레이블 간격 조정 (최대 20개만 표시)
    step_size = max(1, len(credit_scores) // 20)
    ax.set_xticks(x[::step_size])
    ax.set_xticklabels(credit_scores[::step_size].astype(int), rotation=45)  # 신용점수를 정수로 변환하여 표시
    
    ax.legend()
    return fig

# 스트림릿 앱
st.title("📊 신용점수와 이탈수 관계")

st.markdown(
    """
    ## 🔍 데이터 분석 요약
    - **신용점수 350점(최저점)** 도 신용카드를 보유한 고객이 존재합니다.
    - **신용점수 350~404점** 사이의 고객들은 **전부 이탈**하는 경향을 보입니다.
    - **그 외 신용점수와 이탈수의 상관관계는 크지 않은 것으로 분석됩니다.**
    - **신용점수 850점(만점) 고객** 이 과도하게 포진되어 있어, **이상치로 고려해야할 수 있습니다.**
    """
)
# 그래프 생성 및 표시
fig = plot_combined_bar(df_churn_0, df_churn_1)
st.pyplot(fig)

--- File: 10 # pages/연령별 신용카드 및 금융상품 보유 수 변화.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 파일 로드
def load_data():
    file_path = "./data/Bank Customer Churn Prediction(분석)2.xlsx"
    sheet_name = "Sheet2 (5)"
    df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=31)  # 31번째 행부터 데이터 시작
    df = df.iloc[:, [1, 2, 3, 6, 7]]  # 유효한 데이터 열 선택
    df.columns = ["Age", "Credit_Card", "Products", "Total_Credit_Card", "Total_Products"]
    df = df.dropna(subset=["Age"])  # 연령대 NaN 제거
    return df

# 데이터 처리
df = load_data()
df["Age"] = pd.to_numeric(df["Age"], errors='coerce')
df = df.dropna(subset=["Age"])  # NaN 값 다시 제거
df.set_index("Age", inplace=True)
df = df.apply(pd.to_numeric, errors='coerce')

# 스트림릿 앱
st.title("📊 연령별 신용카드 및 금융상품 보유 수 변화")

st.markdown(
    """
    ## 🔍 연령별 신용카드 및 금융상품 보유 수 변화
    - **유지 고객 중 34~37세**의 신용카드 보유 및 금융상품 수가 가장 높으며, 이후 점점 감소합니다.
    - **이탈 고객 중 40대**의 신용카드 보유 및 금융상품 수가 가장 높으며, 이후 점점 감소하는 경향을 보입니다.
    
    ### 📌 연령대별 차이 분석
    - **18~37세:** 신용카드 보유 및 금융상품 수가 점점 증가함.
    - **38~52세:** 신용카드 보유 및 금융상품 수가 점점 감소함 (**고객 관리 필요**).
    - **53~92세:** 신용카드 보유 및 금융상품 수가 유지됨 (**자연적 감소 요인 포함**).
    """
)

# 그래프 생성
fig, ax = plt.subplots(figsize=(25, 7))  # 그래프 크기 조정

# X축 샘플링 조정 (더 넓게 표시)
sample_rate = max(1, len(df) // 60)  # 60개 이하의 점만 표시
sampled_df = df.iloc[::sample_rate]

# X축 레이블(연령대)
x = np.arange(len(sampled_df.index))  # 연령 인덱스 생성
width = 0.2  # 막대 너비 조정

# 여러 개의 데이터 세트 플로팅
df_columns = ["Credit_Card", "Products", "Total_Credit_Card", "Total_Products"]
colors = ['#4472C4', '#ED7D31', '#A5A5A5', '#FFC000']  # 엑셀 원본 색상 적용
labels = ["신용카드 보유 수", "금융상품 수", "총 신용카드 보유 수", "총 금융상품 수"]

for i, col in enumerate(df_columns):
    ax.bar(x + i * width, sampled_df[col], width=width, label=labels[i], color=colors[i])

# 그래프 설정
ax.set_title("연령별 신용카드 및 금융상품 보유 수 변화", fontsize=16, fontweight='bold')
ax.set_xlabel("연령", fontsize=12)
ax.set_ylabel("보유 수", fontsize=12)
ax.set_xticks(x + width * 1.5)  # x축 정렬
ax.set_xticklabels(sampled_df.index.astype(int), rotation=45, fontsize=10)
ax.legend()
ax.grid(axis="y", linestyle="--", alpha=0.7)

st.pyplot(fig)

--- File: 11 # pages/연령별 이탈율 및 활동고객율 분석.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 파일 로드
def load_data():
    file_path = "./data/Bank Customer Churn Prediction(분석)2.xlsx"
    sheet_name = "Sheet2 (6)"
    df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=30)  # 30번째 행부터 데이터 시작
    df = df.iloc[:, [1, 2, 3]]  # 유효한 데이터 열 선택
    df.columns = ["Age", "Churn_Rate", "Active_Member"]
    df = df.dropna(subset=["Age"])  # 연령대 NaN 제거
    return df

# 데이터 처리
df = load_data()
df["Age"] = pd.to_numeric(df["Age"], errors='coerce')
df = df.dropna(subset=["Age"])  # NaN 값 다시 제거
df.set_index("Age", inplace=True)
df = df.apply(pd.to_numeric, errors='coerce')

# 스트림릿 앱
st.title("📊 연령별 이탈율 및 활동고객율 변화")

st.markdown(
    """
    ## 🔍 연령별 이탈율 및 활동고객율 분석
    - **18~39세:** 이탈율이 낮음.
    - **40~56세:** 이탈율이 계속 증가하여 고객 관리가 필요함.
    - **57~65세:** 이탈율이 점점 줄어들지만 여전히 높아 고객 관리가 필요함.
    
    ### 📌 활동 고객 비율 분석
    - **50세 이후:** 활동 고객 비율이 증가하는 경향을 보임.
    - **이전 나이대(50세 미만):** 활동 고객율이 약 50% 수준이므로 향상을 위한 전략 필요.
    """
)

# 그래프 생성
fig, ax = plt.subplots(figsize=(25, 7))  # 그래프 크기 조정

# X축 샘플링 조정
sample_rate = max(1, len(df) // 70)  # 70개 이하의 점만 표시
sampled_df = df.iloc[::sample_rate]

# X축 레이블(연령대)
x = np.arange(len(sampled_df.index))  # 연령 인덱스 생성
width = 0.35  # 막대 너비 조정

# 여러 개의 데이터 세트 플로팅
df_columns = ["Churn_Rate", "Active_Member"]
colors = ['#ED7D31', '#5B9BD5']  # 원본 엑셀 색상 적용 (주황: 이탈율, 파랑: 활동 고객율)
labels = ["이탈율 (Churn Rate)", "활동 고객율 (Active Member)"]

for i, col in enumerate(df_columns):
    ax.bar(x + i * width, sampled_df[col], width=width, label=labels[i], color=colors[i])

# 그래프 설정
ax.set_title("연령별 이탈율 및 활동고객율 변화", fontsize=16, fontweight='bold')
ax.set_xlabel("연령", fontsize=12)
ax.set_ylabel("비율", fontsize=12)
ax.set_xticks(x + width * 0.5)  # x축 정렬
ax.set_xticklabels(sampled_df.index.astype(int), rotation=45, fontsize=10)
ax.legend()
ax.grid(axis="y", linestyle="--", alpha=0.7)

st.pyplot(fig)

--- File: 12 # pages/연령별 잔고 및 연봉 변화.py ---
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# 파일 로드
def load_data():
    file_path = "./data/Bank Customer Churn Prediction(분석)2.xlsx"
    sheet_name = "Sheet2 (4)"
    df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=31)  # 31번째 행부터 데이터 시작
    df = df.iloc[:, [1, 2, 3, 4, 6, 7]]  # 유효한 데이터 열 선택
    df.columns = ["Age", "Balance", "Salary", "Prev_Balance", "Total_Balance", "Total_Salary"]
    df = df.dropna(subset=["Age"])  # 연령대 NaN 제거
    return df

# 데이터 처리
df = load_data()
df["Age"] = pd.to_numeric(df["Age"], errors='coerce')
df = df.dropna(subset=["Age"])  # NaN 값 다시 제거
df.set_index("Age", inplace=True)
df = df.apply(pd.to_numeric, errors='coerce')

# 스트림릿 앱
st.title("📊 연령별 잔고 및 연봉 변화")

st.markdown(
    """
    ## 🔍 연령별 연봉 및 잔고 변화 분석
    - **유지 고객 중 34~38세**의 연봉 및 잔고가 가장 높으며, 이후 점점 감소합니다.
    - **이탈 고객 중 40대**의 연봉 및 잔고가 가장 높으며, 이후 점점 감소하는 경향을 보입니다.
    
    ### 📌 연령대별 차이 분석
    - **18~48세:** 유지 고객이 이탈 고객보다 연봉 및 잔고가 더 많음.
    - **49~60세:** 유지 고객이 이탈 고객보다 연봉 및 잔고가 더 적음 (**고객 관리 필요**).
    - **61~92세:** 유지 고객이 이탈 고객보다 연봉 및 잔고가 더 많음.
    """
)

# 그래프 생성
fig, ax = plt.subplots(figsize=(25, 7))  # 그래프 크기 조정

# X축 샘플링 조정 (더 넓게 표시)
sample_rate = max(1, len(df) // 60)  # 60개 이하의 점만 표시
sampled_df = df.iloc[::sample_rate]

# X축 레이블(연령대)
x = np.arange(len(sampled_df.index))  # 연령 인덱스 생성
width = 0.2  # 막대 너비 조정

# 여러 개의 데이터 세트 플로팅
df_columns = ["Balance", "Salary", "Prev_Balance", "Total_Balance", "Total_Salary"]
colors = ['#4472C4', '#ED7D31', '#A5A5A5', '#FFC000', '#70AD47']  # 엑셀 원본 색상 적용
labels = ["잔고(Balance)", "연봉(Salary)", "과거 잔고(Prev_Balance)", "총 잔고(Total_Balance)", "총 연봉(Total_Salary)"]

for i, col in enumerate(df_columns):
    ax.bar(x + i * width, sampled_df[col], width=width, label=labels[i], color=colors[i])

# 그래프 설정
ax.set_title("연령별 잔고 및 연봉 변화", fontsize=16, fontweight='bold')
ax.set_xlabel("연령", fontsize=12)
ax.set_ylabel("금액", fontsize=12)
ax.set_xticks(x + width * 2)  # x축 정렬
ax.set_xticklabels(sampled_df.index.astype(int), rotation=45, fontsize=10)
ax.legend()
ax.grid(axis="y", linestyle="--", alpha=0.7)

st.pyplot(fig)

IMPORTANT: Generate the `summary` and relationship `label` fields in **Korean** language. Do NOT use English for these fields.

Please provide:
1. A high-level `summary` of the project's main purpose and functionality in a few beginner-friendly sentences (in Korean). Use markdown formatting with **bold** and *italic* text to highlight important concepts.
2. A list (`relationships`) describing the key interactions between these abstractions. For each relationship, specify:
    - `from_abstraction`: Index of the source abstraction (e.g., `0 # AbstractionName1`)
    - `to_abstraction`: Index of the target abstraction (e.g., `1 # AbstractionName2`)
    - `label`: A brief label for the interaction **in just a few words** (in Korean) (e.g., "Manages", "Inherits", "Uses").
    Ideally the relationship should be backed by one abstraction calling or passing parameters to another.
    Simplify the relationship and exclude those non-important ones.

IMPORTANT: Make sure EVERY abstraction is involved in at least ONE relationship (either as source or target). Each abstraction index must appear at least once across all relationships.

Format the output as YAML:

```yaml
summary: |
  A brief, simple explanation of the project (in Korean).
  Can span multiple lines with **bold** and *italic* for emphasis.
relationships:
  - from_abstraction: 0 # AbstractionName1
    to_abstraction: 1 # AbstractionName2
    label: "Manages" (in Korean)
  - from_abstraction: 2 # AbstractionName3
    to_abstraction: 0 # AbstractionName1
    label: "Provides config" (in Korean)
  # ... other relationships
```

Now, provide the YAML output:

2025-06-29 20:55:25,211 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:55:35,485 - INFO - RESPONSE: ```yaml
summary: |
  **은행 고객 이탈 예측 시스템**은 데이터 분석과 *머신러닝* 및 *딥러닝* 기술을 활용하여 **고객의 이탈 가능성을 예측**하는 모델을 개발하고 이를 통해 고객 이탈을 예방하려 합니다. **대시보드**를 통해 사용자는 시각적으로 이해하기 쉽게 분석 결과를 받아볼 수 있으며, **필터 기능**을 통해 원하는 데이터를 선택하고 분석할 수 있습니다.

relationships:
  - from_abstraction: 0 # 은행 고객 이탈 예측 시스템
    to_abstraction: 4 # 데이터 시각화 및 대시보드 구성
    label: "시각화 제공"
  - from_abstraction: 0 # 은행 고객 이탈 예측 시스템
    to_abstraction: 5 # 필터링 기능
    label: "데이터 필터링"
  - from_abstraction: 1 # 데이터 전처리 및 로드
    to_abstraction: 2 # 모델 예측 및 성능 측정
    label: "데이터 제공"
  - from_abstraction: 2 # 모델 예측 및 성능 측정
    to_abstraction: 4 # 데이터 시각화 및 대시보드 구성
    label: "결과 제공"
  - from_abstraction: 3 # 고객 이탈 분석 데이터 생성
    to_abstraction: 6 # 고객 이탈 원인과 해결 방안
    label: "분석 데이터 생성"
  - from_abstraction: 4 # 데이터 시각화 및 대시보드 구성
    to_abstraction: 9 # 디스플레이 유틸리티
    label: "유틸리티 사용"
  - from_abstraction: 5 # 필터링 기능
    to_abstraction: 1 # 데이터 전처리 및 로드
    label: "필터 적용"
  - from_abstraction: 7 # 나이별 데이터 분석
    to_abstraction: 6 # 고객 이탈 원인과 해결 방안
    label: "데이터 분석"
  - from_abstraction: 8 # 모델 로드 및 관리
    to_abstraction: 2 # 모델 예측 및 성능 측정
    label: "모델 제공"
  - from_abstraction: 9 # 디스플레이 유틸리티
    to_abstraction: 0 # 은행 고객 이탈 예측 시스템
    label: "정보 디스플레이"
```
2025-06-29 20:55:35,851 - INFO - PROMPT: 
Given the following project abstractions and their relationships for the project ```` SKN10-2nd-1Team ````:

Abstractions (Index # Name) (Names might be in Korean):
- 0 # 은행 고객 이탈 예측 시스템
- 1 # 데이터 전처리 및 로드
- 2 # 모델 예측 및 성능 측정
- 3 # 고객 이탈 분석 데이터 생성
- 4 # 데이터 시각화 및 대시보드 구성
- 5 # 필터링 기능
- 6 # 고객 이탈 원인과 해결 방안
- 7 # 나이별 데이터 분석
- 8 # 모델 로드 및 관리
- 9 # 디스플레이 유틸리티

Context about relationships and project summary:
Project Summary (Note: Project Summary might be in Korean):
**은행 고객 이탈 예측 시스템**은 데이터 분석과 *머신러닝* 및 *딥러닝* 기술을 활용하여 **고객의 이탈 가능성을 예측**하는 모델을 개발하고 이를 통해 고객 이탈을 예방하려 합니다. **대시보드**를 통해 사용자는 시각적으로 이해하기 쉽게 분석 결과를 받아볼 수 있으며, **필터 기능**을 통해 원하는 데이터를 선택하고 분석할 수 있습니다.


Relationships (Indices refer to abstractions above):
- From 0 (은행 고객 이탈 예측 시스템) to 4 (데이터 시각화 및 대시보드 구성): 시각화 제공
- From 0 (은행 고객 이탈 예측 시스템) to 5 (필터링 기능): 데이터 필터링
- From 1 (데이터 전처리 및 로드) to 2 (모델 예측 및 성능 측정): 데이터 제공
- From 2 (모델 예측 및 성능 측정) to 4 (데이터 시각화 및 대시보드 구성): 결과 제공
- From 3 (고객 이탈 분석 데이터 생성) to 6 (고객 이탈 원인과 해결 방안): 분석 데이터 생성
- From 4 (데이터 시각화 및 대시보드 구성) to 9 (디스플레이 유틸리티): 유틸리티 사용
- From 5 (필터링 기능) to 1 (데이터 전처리 및 로드): 필터 적용
- From 7 (나이별 데이터 분석) to 6 (고객 이탈 원인과 해결 방안): 데이터 분석
- From 8 (모델 로드 및 관리) to 2 (모델 예측 및 성능 측정): 모델 제공
- From 9 (디스플레이 유틸리티) to 0 (은행 고객 이탈 예측 시스템): 정보 디스플레이


If you are going to make a tutorial for ```` SKN10-2nd-1Team ````, what is the best order to explain these abstractions, from first to last?
Ideally, first explain those that are the most important or foundational, perhaps user-facing concepts or entry points. Then move to more detailed, lower-level implementation details or supporting concepts.

Output the ordered list of abstraction indices, including the name in a comment for clarity. Use the format `idx # AbstractionName`.

```yaml
- 2 # FoundationalConcept
- 0 # CoreClassA
- 1 # CoreClassB (uses CoreClassA)
- ...
```

Now, provide the YAML output:

2025-06-29 20:55:36,076 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:55:37,379 - INFO - RESPONSE: ```yaml
- 0 # 은행 고객 이탈 예측 시스템
- 4 # 데이터 시각화 및 대시보드 구성
- 9 # 디스플레이 유틸리티
- 5 # 필터링 기능
- 1 # 데이터 전처리 및 로드
- 2 # 모델 예측 및 성능 측정
- 8 # 모델 로드 및 관리
- 3 # 고객 이탈 분석 데이터 생성
- 7 # 나이별 데이터 분석
- 6 # 고객 이탈 원인과 해결 방안
```
2025-06-29 20:55:37,745 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-2nd-1Team` about the concept: "은행 고객 이탈 예측 시스템". This is Chapter 1.

Concept Details (Note: Provided in Korean):
- Name: 은행 고객 이탈 예측 시스템
- Description:
Streamlit을 이용해 구현된 은행 고객 이탈 예측 대시보드로, 고객의 다양한 정보를 기반으로 이탈 가능성을 예측하고 분석 결과를 시각화하여 사용자에게 제공합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)
2. [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)
3. [디스플레이 유틸리티](03_디스플레이_유틸리티.md)
4. [필터링 기능](04_필터링_기능.md)
5. [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)
6. [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)
7. [모델 로드 및 관리](07_모델_로드_및_관리.md)
8. [고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)
9. [나이별 데이터 분석](09_나이별_데이터_분석.md)
10. [고객 이탈 원인과 해결 방안](10_고객_이탈_원인과_해결_방안.md)

Context from previous chapters (Note: This summary might be in Korean):
This is the first chapter.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 1: 은행 고객 이탈 예측 시스템`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:55:37,921 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:55:48,498 - INFO - RESPONSE: # Chapter 1: 은행 고객 이탈 예측 시스템

은행 고객 이탈 예측 시스템은 고객 데이터에 기반하여 이탈 가능성을 분석하고 예측하는 대시보드입니다. 이 시스템은 특히 은행이 고객의 이탈을 미리 예측할 수 있도록 도와주어, 적절한 대응 전략을 세울 수 있게 합니다. 

## 동기

은행은 고객 이탈을 줄이는 것이 매우 중요합니다. 고객이 은행을 떠나기 전, 이를 예측할 수 있다면 추가적인 대응조치를 통해 고객 유지율을 높일 수 있습니다. 예를 들어, 한 고객이 최근 거래가 줄어들고 대출 상환에 문제가 있는 경우 이를 빠르게 인지하고 대책을 세우는 것이 가능해집니다.

## 핵심 개념 설명

이 시스템은 여러 단계로 나뉘어 고객의 이탈 가능성을 예측합니다:

1. **데이터 수집**: 고객의 나이, 거래 내역, 고객 만족도 등 다양한 데이터를 수집합니다.
2. **모델 학습**: 수집된 데이터를 사용하여 머신 러닝 모델을 학습시킵니다.
3. **이탈 예측**: 학습된 모델을 통해 고객의 이탈 가능성을 예측합니다.

### Streamlit을 이용한 대시보드

Streamlit은 쉽게 대시보드를 구성할 수 있게 해주는 파이썬 라이브러리입니다. 코드를 한 줄 한 줄 변경하면서, 바로 변경된 부분을 확인할 수 있어 빠르게 대시보드를 개발할 수 있습니다.

```python
import streamlit as st

# 간단한 대시보드 제목 설정
st.title('은행 고객 이탈 예측 대시보드')
```

이 코드는 대시보드의 기본 제목을 설정합니다. **`streamlit`**은 파이썬 코드로 웹 애플리케이션을 쉽게 만들도록 도와줍니다.

## 이탈 예측 시스템의 내부 구현

### 주요 단계 설명

1. **데이터 로드**: 고객 데이터를 읽어옵니다.
2. **예측 실행**: 모델을 사용하여 이탈 위험을 계산합니다.
3. **결과 시각화**: 대시보드에 예측 결과를 표현합니다.

이 과정은 다음의 시퀀스 다이어그램으로 이해할 수 있습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 모델
    사용자->>대시보드: 데이터 입력
    대시보드->>모델: 예측 요청
    모델-->>대시보드: 예측 결과
    대시보드-->>사용자: 결과 시각화
```

### 데이터 로드

고객 데이터를 로드하는 과정을 살펴보겠습니다.

```python
import pandas as pd

# CSV 파일에서 고객 데이터 로드
data = pd.read_csv('customer_data.csv')
```

이 코드는 고객 데이터를 저장한 CSV 파일을 읽어옵니다. **pandas** 라이브러리를 사용하면 데이터를 다루는 과정이 매우 간단해집니다.

### 예측 실행

모델을 이용하여 이탈 가능성을 예측합니다.

```python
# 머신러닝 모델을 불러와서 예측 수행
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(train_X, train_y)

# 예측하기
predictions = model.predict(test_X)
```

위 예제에서는 **RandomForestClassifier**를 사용하여 모델을 학습하고 예측합니다. 간단한 관계를 통해 예측을 수행하며, 이 결과는 대시보드에서 시각화됩니다.

## 결론

이 장에서는 은행 고객 이탈 예측 시스템의 기본 개념과 구현 과정을 간단하게 살펴보았습니다. 다음 장에서는 [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)을 통해 얻어진 결과를 어떻게 구성하고 표현할 수 있는지에 대한 내용을 알아보겠습니다. 이 시스템을 활용하여 은행이 고객 이탈을 효과적으로 관리할 수 있게 됩니다.
2025-06-29 20:55:48,506 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-2nd-1Team` about the concept: "데이터 시각화 및 대시보드 구성". This is Chapter 2.

Concept Details (Note: Provided in Korean):
- Name: 데이터 시각화 및 대시보드 구성
- Description:
Streamlit을 통해 데이터 시각화를 구현하여 사용자에게 이해하기 쉬운 방식으로 분석 결과를 전달하는 대시보드를 구성합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)
2. [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)
3. [디스플레이 유틸리티](03_디스플레이_유틸리티.md)
4. [필터링 기능](04_필터링_기능.md)
5. [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)
6. [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)
7. [모델 로드 및 관리](07_모델_로드_및_관리.md)
8. [고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)
9. [나이별 데이터 분석](09_나이별_데이터_분석.md)
10. [고객 이탈 원인과 해결 방안](10_고객_이탈_원인과_해결_방안.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 은행 고객 이탈 예측 시스템

은행 고객 이탈 예측 시스템은 고객 데이터에 기반하여 이탈 가능성을 분석하고 예측하는 대시보드입니다. 이 시스템은 특히 은행이 고객의 이탈을 미리 예측할 수 있도록 도와주어, 적절한 대응 전략을 세울 수 있게 합니다. 

## 동기

은행은 고객 이탈을 줄이는 것이 매우 중요합니다. 고객이 은행을 떠나기 전, 이를 예측할 수 있다면 추가적인 대응조치를 통해 고객 유지율을 높일 수 있습니다. 예를 들어, 한 고객이 최근 거래가 줄어들고 대출 상환에 문제가 있는 경우 이를 빠르게 인지하고 대책을 세우는 것이 가능해집니다.

## 핵심 개념 설명

이 시스템은 여러 단계로 나뉘어 고객의 이탈 가능성을 예측합니다:

1. **데이터 수집**: 고객의 나이, 거래 내역, 고객 만족도 등 다양한 데이터를 수집합니다.
2. **모델 학습**: 수집된 데이터를 사용하여 머신 러닝 모델을 학습시킵니다.
3. **이탈 예측**: 학습된 모델을 통해 고객의 이탈 가능성을 예측합니다.

### Streamlit을 이용한 대시보드

Streamlit은 쉽게 대시보드를 구성할 수 있게 해주는 파이썬 라이브러리입니다. 코드를 한 줄 한 줄 변경하면서, 바로 변경된 부분을 확인할 수 있어 빠르게 대시보드를 개발할 수 있습니다.

```python
import streamlit as st

# 간단한 대시보드 제목 설정
st.title('은행 고객 이탈 예측 대시보드')
```

이 코드는 대시보드의 기본 제목을 설정합니다. **`streamlit`**은 파이썬 코드로 웹 애플리케이션을 쉽게 만들도록 도와줍니다.

## 이탈 예측 시스템의 내부 구현

### 주요 단계 설명

1. **데이터 로드**: 고객 데이터를 읽어옵니다.
2. **예측 실행**: 모델을 사용하여 이탈 위험을 계산합니다.
3. **결과 시각화**: 대시보드에 예측 결과를 표현합니다.

이 과정은 다음의 시퀀스 다이어그램으로 이해할 수 있습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 모델
    사용자->>대시보드: 데이터 입력
    대시보드->>모델: 예측 요청
    모델-->>대시보드: 예측 결과
    대시보드-->>사용자: 결과 시각화
```

### 데이터 로드

고객 데이터를 로드하는 과정을 살펴보겠습니다.

```python
import pandas as pd

# CSV 파일에서 고객 데이터 로드
data = pd.read_csv('customer_data.csv')
```

이 코드는 고객 데이터를 저장한 CSV 파일을 읽어옵니다. **pandas** 라이브러리를 사용하면 데이터를 다루는 과정이 매우 간단해집니다.

### 예측 실행

모델을 이용하여 이탈 가능성을 예측합니다.

```python
# 머신러닝 모델을 불러와서 예측 수행
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(train_X, train_y)

# 예측하기
predictions = model.predict(test_X)
```

위 예제에서는 **RandomForestClassifier**를 사용하여 모델을 학습하고 예측합니다. 간단한 관계를 통해 예측을 수행하며, 이 결과는 대시보드에서 시각화됩니다.

## 결론

이 장에서는 은행 고객 이탈 예측 시스템의 기본 개념과 구현 과정을 간단하게 살펴보았습니다. 다음 장에서는 [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)을 통해 얻어진 결과를 어떻게 구성하고 표현할 수 있는지에 대한 내용을 알아보겠습니다. 이 시스템을 활용하여 은행이 고객 이탈을 효과적으로 관리할 수 있게 됩니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 2: 데이터 시각화 및 대시보드 구성`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:55:48,721 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:56:01,302 - INFO - RESPONSE: # Chapter 2: 데이터 시각화 및 대시보드 구성

[이전 장: 은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)에서는 고객 이탈을 예측하는 시스템의 기본 개념과 구현 방법을 소개했습니다. 이번 장에서는 그 결과를 더욱 효과적으로 전달하기 위해 데이터 시각화와 대시보드 구성을 다루어보겠습니다.

## 동기

데이터 시각화는 복잡한 데이터를 이해하기 쉽게 만들어줍니다. 예를 들어, 수많은 숫자 데이터에서 패턴이나 추세를 식별하기 어렵지만, 이를 그래프로 나타내면 한눈에 이해하기가 쉬워집니다. 이처럼 손쉽게 데이터에서 인사이트를 얻는 방식으로, 대시보드는 사용자와 데이터를 연결하는 중요한 역할을 합니다.

## Streamlit을 사용한 시각화 및 대시보드 생성

Streamlit을 사용하면 복잡한 대시보드를 간단한 코드로 쉽게 개발할 수 있습니다. 데이터 시각화를 사용하여 어떠한 정보가 중요한지 사용자에게 명확히 전달할 수 있습니다.

### 기본적인 대시보드 구성

Streamlit의 간단한 코드를 통해 기본적인 대시보드를 구현하는 방법을 살펴봅시다.

```python
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

# 데이터를 로드
data = pd.read_csv('customer_data.csv')

# 데이터의 일부를 시각화
st.title('데이터 시각화 예제')
st.write("고객 데이터 미리보기:")
st.write(data.head())

# 플롯 생성
st.line_chart(data['Age'])
```

위 코드는 Streamlit을 통해 고객 데이터의 일부를 화면에 표시하고, 'Age' 컬럼을 선 그래프로 시각화합니다. **`st.line_chart`** 는 데이터 시각화를 매우 신속하게 수행할 수 있도록 도와줍니다.

### 대시보드에 추가할 다른 요소

대시보드를 더욱 풍부하게 하기 위해 다양한 그래프와 인터랙티브한 원소들을 추가할 수 있습니다.

```python
# 히스토그램 생성
fig, ax = plt.subplots()
ax.hist(data['Age'], bins=20)

# Streamlit에 Matplotlib 플롯 표시
st.pyplot(fig)
```

위 예제에서는 **Matplotlib**을 사용하여 'Age' 컬럼에 대한 히스토그램을 생성하고, 이를 Streamlit 대시보드에 표시합니다. 이러한 플롯은 데이터의 분포를 시각적으로 파악하는데 유용합니다.

## 내부 구현 상세 설명

대시보드의 작동 방식을 이해하기 위해 간단한 시퀀스 다이어그램을 살펴봅시다.

```mermaid
sequenceDiagram
    participant 사용자
    participant 웹페이지
    participant 스트림릿
    사용자->>웹페이지: 접속 요청
    웹페이지->>스트림릿: 데이터 요청
    스트림릿-->>웹페이지: 시각화 데이터
    웹페이지-->>사용자: 데이터 및 시각화 표시
```

이 과정은 사용자가 웹페이지에 접속하여 데이터를 요청하면, 스트림릿이 적절한 시각화 데이터를 준비하고 이를 사용자에게 전달하는 흐름으로 구성됩니다.

## 결론

이 장에서는 Streamlit을 사용한 데이터 시각화 및 대시보드 구성 방법을 살펴보았습니다. 대시보드는 데이터 해석을 용이하게 해주며, 사용자가 원하는 정보를 효과적으로 전달합니다. 다음 장에서는 [디스플레이 유틸리티](03_디스플레이_유틸리티.md)를 통해 대시보드를 보다 다채롭게 구성하는 방법을 배워보겠습니다. 대시보드의 유익한 시각화 요소들을 더해, 앞으로의 분석이 더욱 직관적으로 이루어질 것입니다.
2025-06-29 20:56:01,311 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-2nd-1Team` about the concept: "디스플레이 유틸리티". This is Chapter 3.

Concept Details (Note: Provided in Korean):
- Name: 디스플레이 유틸리티
- Description:
계산된 예측 결과를 UI에 표시하기 위한 여러 유틸리티 함수로, 직접적인 고객 관련 정보를 제공하는 데 사용됩니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)
2. [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)
3. [디스플레이 유틸리티](03_디스플레이_유틸리티.md)
4. [필터링 기능](04_필터링_기능.md)
5. [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)
6. [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)
7. [모델 로드 및 관리](07_모델_로드_및_관리.md)
8. [고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)
9. [나이별 데이터 분석](09_나이별_데이터_분석.md)
10. [고객 이탈 원인과 해결 방안](10_고객_이탈_원인과_해결_방안.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 은행 고객 이탈 예측 시스템

은행 고객 이탈 예측 시스템은 고객 데이터에 기반하여 이탈 가능성을 분석하고 예측하는 대시보드입니다. 이 시스템은 특히 은행이 고객의 이탈을 미리 예측할 수 있도록 도와주어, 적절한 대응 전략을 세울 수 있게 합니다. 

## 동기

은행은 고객 이탈을 줄이는 것이 매우 중요합니다. 고객이 은행을 떠나기 전, 이를 예측할 수 있다면 추가적인 대응조치를 통해 고객 유지율을 높일 수 있습니다. 예를 들어, 한 고객이 최근 거래가 줄어들고 대출 상환에 문제가 있는 경우 이를 빠르게 인지하고 대책을 세우는 것이 가능해집니다.

## 핵심 개념 설명

이 시스템은 여러 단계로 나뉘어 고객의 이탈 가능성을 예측합니다:

1. **데이터 수집**: 고객의 나이, 거래 내역, 고객 만족도 등 다양한 데이터를 수집합니다.
2. **모델 학습**: 수집된 데이터를 사용하여 머신 러닝 모델을 학습시킵니다.
3. **이탈 예측**: 학습된 모델을 통해 고객의 이탈 가능성을 예측합니다.

### Streamlit을 이용한 대시보드

Streamlit은 쉽게 대시보드를 구성할 수 있게 해주는 파이썬 라이브러리입니다. 코드를 한 줄 한 줄 변경하면서, 바로 변경된 부분을 확인할 수 있어 빠르게 대시보드를 개발할 수 있습니다.

```python
import streamlit as st

# 간단한 대시보드 제목 설정
st.title('은행 고객 이탈 예측 대시보드')
```

이 코드는 대시보드의 기본 제목을 설정합니다. **`streamlit`**은 파이썬 코드로 웹 애플리케이션을 쉽게 만들도록 도와줍니다.

## 이탈 예측 시스템의 내부 구현

### 주요 단계 설명

1. **데이터 로드**: 고객 데이터를 읽어옵니다.
2. **예측 실행**: 모델을 사용하여 이탈 위험을 계산합니다.
3. **결과 시각화**: 대시보드에 예측 결과를 표현합니다.

이 과정은 다음의 시퀀스 다이어그램으로 이해할 수 있습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 모델
    사용자->>대시보드: 데이터 입력
    대시보드->>모델: 예측 요청
    모델-->>대시보드: 예측 결과
    대시보드-->>사용자: 결과 시각화
```

### 데이터 로드

고객 데이터를 로드하는 과정을 살펴보겠습니다.

```python
import pandas as pd

# CSV 파일에서 고객 데이터 로드
data = pd.read_csv('customer_data.csv')
```

이 코드는 고객 데이터를 저장한 CSV 파일을 읽어옵니다. **pandas** 라이브러리를 사용하면 데이터를 다루는 과정이 매우 간단해집니다.

### 예측 실행

모델을 이용하여 이탈 가능성을 예측합니다.

```python
# 머신러닝 모델을 불러와서 예측 수행
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(train_X, train_y)

# 예측하기
predictions = model.predict(test_X)
```

위 예제에서는 **RandomForestClassifier**를 사용하여 모델을 학습하고 예측합니다. 간단한 관계를 통해 예측을 수행하며, 이 결과는 대시보드에서 시각화됩니다.

## 결론

이 장에서는 은행 고객 이탈 예측 시스템의 기본 개념과 구현 과정을 간단하게 살펴보았습니다. 다음 장에서는 [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)을 통해 얻어진 결과를 어떻게 구성하고 표현할 수 있는지에 대한 내용을 알아보겠습니다. 이 시스템을 활용하여 은행이 고객 이탈을 효과적으로 관리할 수 있게 됩니다.
---
# Chapter 2: 데이터 시각화 및 대시보드 구성

[이전 장: 은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)에서는 고객 이탈을 예측하는 시스템의 기본 개념과 구현 방법을 소개했습니다. 이번 장에서는 그 결과를 더욱 효과적으로 전달하기 위해 데이터 시각화와 대시보드 구성을 다루어보겠습니다.

## 동기

데이터 시각화는 복잡한 데이터를 이해하기 쉽게 만들어줍니다. 예를 들어, 수많은 숫자 데이터에서 패턴이나 추세를 식별하기 어렵지만, 이를 그래프로 나타내면 한눈에 이해하기가 쉬워집니다. 이처럼 손쉽게 데이터에서 인사이트를 얻는 방식으로, 대시보드는 사용자와 데이터를 연결하는 중요한 역할을 합니다.

## Streamlit을 사용한 시각화 및 대시보드 생성

Streamlit을 사용하면 복잡한 대시보드를 간단한 코드로 쉽게 개발할 수 있습니다. 데이터 시각화를 사용하여 어떠한 정보가 중요한지 사용자에게 명확히 전달할 수 있습니다.

### 기본적인 대시보드 구성

Streamlit의 간단한 코드를 통해 기본적인 대시보드를 구현하는 방법을 살펴봅시다.

```python
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

# 데이터를 로드
data = pd.read_csv('customer_data.csv')

# 데이터의 일부를 시각화
st.title('데이터 시각화 예제')
st.write("고객 데이터 미리보기:")
st.write(data.head())

# 플롯 생성
st.line_chart(data['Age'])
```

위 코드는 Streamlit을 통해 고객 데이터의 일부를 화면에 표시하고, 'Age' 컬럼을 선 그래프로 시각화합니다. **`st.line_chart`** 는 데이터 시각화를 매우 신속하게 수행할 수 있도록 도와줍니다.

### 대시보드에 추가할 다른 요소

대시보드를 더욱 풍부하게 하기 위해 다양한 그래프와 인터랙티브한 원소들을 추가할 수 있습니다.

```python
# 히스토그램 생성
fig, ax = plt.subplots()
ax.hist(data['Age'], bins=20)

# Streamlit에 Matplotlib 플롯 표시
st.pyplot(fig)
```

위 예제에서는 **Matplotlib**을 사용하여 'Age' 컬럼에 대한 히스토그램을 생성하고, 이를 Streamlit 대시보드에 표시합니다. 이러한 플롯은 데이터의 분포를 시각적으로 파악하는데 유용합니다.

## 내부 구현 상세 설명

대시보드의 작동 방식을 이해하기 위해 간단한 시퀀스 다이어그램을 살펴봅시다.

```mermaid
sequenceDiagram
    participant 사용자
    participant 웹페이지
    participant 스트림릿
    사용자->>웹페이지: 접속 요청
    웹페이지->>스트림릿: 데이터 요청
    스트림릿-->>웹페이지: 시각화 데이터
    웹페이지-->>사용자: 데이터 및 시각화 표시
```

이 과정은 사용자가 웹페이지에 접속하여 데이터를 요청하면, 스트림릿이 적절한 시각화 데이터를 준비하고 이를 사용자에게 전달하는 흐름으로 구성됩니다.

## 결론

이 장에서는 Streamlit을 사용한 데이터 시각화 및 대시보드 구성 방법을 살펴보았습니다. 대시보드는 데이터 해석을 용이하게 해주며, 사용자가 원하는 정보를 효과적으로 전달합니다. 다음 장에서는 [디스플레이 유틸리티](03_디스플레이_유틸리티.md)를 통해 대시보드를 보다 다채롭게 구성하는 방법을 배워보겠습니다. 대시보드의 유익한 시각화 요소들을 더해, 앞으로의 분석이 더욱 직관적으로 이루어질 것입니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 3: 디스플레이 유틸리티`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:56:01,526 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:56:15,524 - INFO - RESPONSE: # Chapter 3: 디스플레이 유틸리티

[이전 장: 데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)에서는 대시보드를 통해 고객 이탈 데이터를 효과적으로 시각화하는 방법을 배웠습니다. 이번 장에서는 대시보드를 보다 직관적이고 사용자 친화적으로 만드는 데에 필요한 **디스플레이 유틸리티**를 소개하겠습니다.

## 동기

우리가 고객 이탈 예측 결과를 분석할 때, 단순히 숫자나 그래프만 보이면 직관적으로 이해하기 힘들 수 있습니다. 이런 데이터를 더 쉽게 이해하고 활용하기 위해, UI에 표현하는 방식에 다양한 유틸리티를 추가할 수 있습니다. 

예시로, 고객의 이탈 예측 점수를 색깔로 강조하여 중요하고 볼만한 정보를 쉽게 전달할 수 있습니다. 예를 들어, 이탈 가능성이 높은 고객을 빨간색으로 표시하면 곧바로 주의를 기울일 수 있게 됩니다.

## 디스플레이 유틸리티의 핵심 개념

### 데이터 포맷팅
디스플레이 유틸리티에서 가장 기본이 되는 개념은 데이터를 사용자가 쉽게 볼 수 있도록 가공하는 것입니다. 여기에는 날짜 형식 변환, 금액을 통화 형식으로 변환하는 등의 작업이 포함됩니다.

```python
import pandas as pd

# 예시 데이터
data = {'고객': ['A', 'B', 'C'],
        '예측 점수': [0.8, 0.2, 0.5]}

df = pd.DataFrame(data)

# 예측 점수에 따라 색상 적용
df['점수 상태'] = df['예측 점수'].apply(lambda x: '위험' if x > 0.7 else '안전')

print(df)
```

위의 코드에서는 고객의 예측 점수를 기반으로 '위험'과 '안전' 상태로 분류합니다. 이렇게 분류된 데이터는 그에 따라 색깔 등을 통해 대시보드에서 표시할 수 있습니다.

### 조건부 포맷팅
조건부 포맷팅은 사용자에게 중요한 데이터를 강조하는 데 유용합니다. 이 방법을 통해 예측 점수에 따라 색상을 변경할 수 있습니다.

```python
import seaborn as sns

def highlight_rows(row):
    return ['background-color: yellow' if row['점수 상태'] == '위험' else '' for _ in row]

# 스타일 적용
styled_df = df.style.apply(highlight_rows, axis=1)
```

**Seaborn**과 같은 라이브러리를 사용하면, 조건부 포맷팅을 통해 데이터의 시각적 강조를 쉽게 할 수 있습니다.

### 웹 페이지에 적합한 포맷팅
위에서 언급한 기능들을 활용하여 대시보드에도 적용할 수 있습니다.

```python
import streamlit as st

# 대시보드에 데이터 표시
st.title('디스플레이 유틸리티 예제')
st.write(styled_df)
```

위 코드를 통해 Streamlit 대시보드에 조건부 포맷팅이 적용된 데이터를 쉽게 표시할 수 있습니다. Streamlit의 **`st.write()`** 함수는 데이터프레임에 대해 다양한 포맷팅을 지원합니다.

## 디스플레이 유틸리티 내부 구현

디스플레이 유틸리티의 작동 방식을 이해하기 위해 시퀀스 다이어그램을 사용해봅시다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 디스플레이 유틸리티
    사용자->>대시보드: 데이터 요청
    대시보드->>디스플레이 유틸리티: 데이터 형식 지정 요청
    디스플레이 유틸리티-->>대시보드: 포맷팅된 데이터 반환
    대시보드-->>사용자: 결과 표시
```

위 다이어그램은 디스플레이 유틸리티가 데이터를 대시보드에 표시하기 전에 어떻게 처리하는지를 보여줍니다.

### 내부 코드 구현

디스플레이 유틸리티의 내부는 다양한 형식 지정 및 조건부 포맷팅을 통해 구성됩니다. 각 단계에서 데이터를 보다 직관적으로 보이도록 만드는 다양한 함수들을 활용합니다.

```python
def format_currency(value):
    return "${:,.2f}".format(value)

formatted_value = format_currency(1500)
print(formatted_value)  # 출력: $1,500.00
```

위 함수는 금액 데이터를 통화 형식으로 변환합니다. 이러한 형식을 통해 사용자가 데이터를 쉽게 이해할 수 있게 됩니다.

## 결론

이번 장에서 우리는 디스플레이 유틸리티를 활용하여 데이터를 보다 사용자 친화적으로 변환하고 강조하는 방법을 배웠습니다. 이렇게 변환된 데이터를 통해 사용자는 더욱 직관적으로 정보를 받아들일 수 있습니다. 다음 장에서는 [필터링 기능](04_필터링_기능.md)을 통해 대시보드 상에서 데이터를 효율적으로 필터링하는 방법을 알아보겠습니다. 이를 통해 우리는 사용자에게 더 개인화된 데이터 뷰를 제공합니다.
2025-06-29 20:56:15,534 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-2nd-1Team` about the concept: "필터링 기능". This is Chapter 4.

Concept Details (Note: Provided in Korean):
- Name: 필터링 기능
- Description:
사용자가 설정한 필터 옵션에 따라 고객 데이터를 필터링하여 특정 조건에 해당하는 데이터만을 분석할 수 있도록 지원합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)
2. [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)
3. [디스플레이 유틸리티](03_디스플레이_유틸리티.md)
4. [필터링 기능](04_필터링_기능.md)
5. [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)
6. [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)
7. [모델 로드 및 관리](07_모델_로드_및_관리.md)
8. [고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)
9. [나이별 데이터 분석](09_나이별_데이터_분석.md)
10. [고객 이탈 원인과 해결 방안](10_고객_이탈_원인과_해결_방안.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 은행 고객 이탈 예측 시스템

은행 고객 이탈 예측 시스템은 고객 데이터에 기반하여 이탈 가능성을 분석하고 예측하는 대시보드입니다. 이 시스템은 특히 은행이 고객의 이탈을 미리 예측할 수 있도록 도와주어, 적절한 대응 전략을 세울 수 있게 합니다. 

## 동기

은행은 고객 이탈을 줄이는 것이 매우 중요합니다. 고객이 은행을 떠나기 전, 이를 예측할 수 있다면 추가적인 대응조치를 통해 고객 유지율을 높일 수 있습니다. 예를 들어, 한 고객이 최근 거래가 줄어들고 대출 상환에 문제가 있는 경우 이를 빠르게 인지하고 대책을 세우는 것이 가능해집니다.

## 핵심 개념 설명

이 시스템은 여러 단계로 나뉘어 고객의 이탈 가능성을 예측합니다:

1. **데이터 수집**: 고객의 나이, 거래 내역, 고객 만족도 등 다양한 데이터를 수집합니다.
2. **모델 학습**: 수집된 데이터를 사용하여 머신 러닝 모델을 학습시킵니다.
3. **이탈 예측**: 학습된 모델을 통해 고객의 이탈 가능성을 예측합니다.

### Streamlit을 이용한 대시보드

Streamlit은 쉽게 대시보드를 구성할 수 있게 해주는 파이썬 라이브러리입니다. 코드를 한 줄 한 줄 변경하면서, 바로 변경된 부분을 확인할 수 있어 빠르게 대시보드를 개발할 수 있습니다.

```python
import streamlit as st

# 간단한 대시보드 제목 설정
st.title('은행 고객 이탈 예측 대시보드')
```

이 코드는 대시보드의 기본 제목을 설정합니다. **`streamlit`**은 파이썬 코드로 웹 애플리케이션을 쉽게 만들도록 도와줍니다.

## 이탈 예측 시스템의 내부 구현

### 주요 단계 설명

1. **데이터 로드**: 고객 데이터를 읽어옵니다.
2. **예측 실행**: 모델을 사용하여 이탈 위험을 계산합니다.
3. **결과 시각화**: 대시보드에 예측 결과를 표현합니다.

이 과정은 다음의 시퀀스 다이어그램으로 이해할 수 있습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 모델
    사용자->>대시보드: 데이터 입력
    대시보드->>모델: 예측 요청
    모델-->>대시보드: 예측 결과
    대시보드-->>사용자: 결과 시각화
```

### 데이터 로드

고객 데이터를 로드하는 과정을 살펴보겠습니다.

```python
import pandas as pd

# CSV 파일에서 고객 데이터 로드
data = pd.read_csv('customer_data.csv')
```

이 코드는 고객 데이터를 저장한 CSV 파일을 읽어옵니다. **pandas** 라이브러리를 사용하면 데이터를 다루는 과정이 매우 간단해집니다.

### 예측 실행

모델을 이용하여 이탈 가능성을 예측합니다.

```python
# 머신러닝 모델을 불러와서 예측 수행
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(train_X, train_y)

# 예측하기
predictions = model.predict(test_X)
```

위 예제에서는 **RandomForestClassifier**를 사용하여 모델을 학습하고 예측합니다. 간단한 관계를 통해 예측을 수행하며, 이 결과는 대시보드에서 시각화됩니다.

## 결론

이 장에서는 은행 고객 이탈 예측 시스템의 기본 개념과 구현 과정을 간단하게 살펴보았습니다. 다음 장에서는 [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)을 통해 얻어진 결과를 어떻게 구성하고 표현할 수 있는지에 대한 내용을 알아보겠습니다. 이 시스템을 활용하여 은행이 고객 이탈을 효과적으로 관리할 수 있게 됩니다.
---
# Chapter 2: 데이터 시각화 및 대시보드 구성

[이전 장: 은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)에서는 고객 이탈을 예측하는 시스템의 기본 개념과 구현 방법을 소개했습니다. 이번 장에서는 그 결과를 더욱 효과적으로 전달하기 위해 데이터 시각화와 대시보드 구성을 다루어보겠습니다.

## 동기

데이터 시각화는 복잡한 데이터를 이해하기 쉽게 만들어줍니다. 예를 들어, 수많은 숫자 데이터에서 패턴이나 추세를 식별하기 어렵지만, 이를 그래프로 나타내면 한눈에 이해하기가 쉬워집니다. 이처럼 손쉽게 데이터에서 인사이트를 얻는 방식으로, 대시보드는 사용자와 데이터를 연결하는 중요한 역할을 합니다.

## Streamlit을 사용한 시각화 및 대시보드 생성

Streamlit을 사용하면 복잡한 대시보드를 간단한 코드로 쉽게 개발할 수 있습니다. 데이터 시각화를 사용하여 어떠한 정보가 중요한지 사용자에게 명확히 전달할 수 있습니다.

### 기본적인 대시보드 구성

Streamlit의 간단한 코드를 통해 기본적인 대시보드를 구현하는 방법을 살펴봅시다.

```python
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

# 데이터를 로드
data = pd.read_csv('customer_data.csv')

# 데이터의 일부를 시각화
st.title('데이터 시각화 예제')
st.write("고객 데이터 미리보기:")
st.write(data.head())

# 플롯 생성
st.line_chart(data['Age'])
```

위 코드는 Streamlit을 통해 고객 데이터의 일부를 화면에 표시하고, 'Age' 컬럼을 선 그래프로 시각화합니다. **`st.line_chart`** 는 데이터 시각화를 매우 신속하게 수행할 수 있도록 도와줍니다.

### 대시보드에 추가할 다른 요소

대시보드를 더욱 풍부하게 하기 위해 다양한 그래프와 인터랙티브한 원소들을 추가할 수 있습니다.

```python
# 히스토그램 생성
fig, ax = plt.subplots()
ax.hist(data['Age'], bins=20)

# Streamlit에 Matplotlib 플롯 표시
st.pyplot(fig)
```

위 예제에서는 **Matplotlib**을 사용하여 'Age' 컬럼에 대한 히스토그램을 생성하고, 이를 Streamlit 대시보드에 표시합니다. 이러한 플롯은 데이터의 분포를 시각적으로 파악하는데 유용합니다.

## 내부 구현 상세 설명

대시보드의 작동 방식을 이해하기 위해 간단한 시퀀스 다이어그램을 살펴봅시다.

```mermaid
sequenceDiagram
    participant 사용자
    participant 웹페이지
    participant 스트림릿
    사용자->>웹페이지: 접속 요청
    웹페이지->>스트림릿: 데이터 요청
    스트림릿-->>웹페이지: 시각화 데이터
    웹페이지-->>사용자: 데이터 및 시각화 표시
```

이 과정은 사용자가 웹페이지에 접속하여 데이터를 요청하면, 스트림릿이 적절한 시각화 데이터를 준비하고 이를 사용자에게 전달하는 흐름으로 구성됩니다.

## 결론

이 장에서는 Streamlit을 사용한 데이터 시각화 및 대시보드 구성 방법을 살펴보았습니다. 대시보드는 데이터 해석을 용이하게 해주며, 사용자가 원하는 정보를 효과적으로 전달합니다. 다음 장에서는 [디스플레이 유틸리티](03_디스플레이_유틸리티.md)를 통해 대시보드를 보다 다채롭게 구성하는 방법을 배워보겠습니다. 대시보드의 유익한 시각화 요소들을 더해, 앞으로의 분석이 더욱 직관적으로 이루어질 것입니다.
---
# Chapter 3: 디스플레이 유틸리티

[이전 장: 데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)에서는 대시보드를 통해 고객 이탈 데이터를 효과적으로 시각화하는 방법을 배웠습니다. 이번 장에서는 대시보드를 보다 직관적이고 사용자 친화적으로 만드는 데에 필요한 **디스플레이 유틸리티**를 소개하겠습니다.

## 동기

우리가 고객 이탈 예측 결과를 분석할 때, 단순히 숫자나 그래프만 보이면 직관적으로 이해하기 힘들 수 있습니다. 이런 데이터를 더 쉽게 이해하고 활용하기 위해, UI에 표현하는 방식에 다양한 유틸리티를 추가할 수 있습니다. 

예시로, 고객의 이탈 예측 점수를 색깔로 강조하여 중요하고 볼만한 정보를 쉽게 전달할 수 있습니다. 예를 들어, 이탈 가능성이 높은 고객을 빨간색으로 표시하면 곧바로 주의를 기울일 수 있게 됩니다.

## 디스플레이 유틸리티의 핵심 개념

### 데이터 포맷팅
디스플레이 유틸리티에서 가장 기본이 되는 개념은 데이터를 사용자가 쉽게 볼 수 있도록 가공하는 것입니다. 여기에는 날짜 형식 변환, 금액을 통화 형식으로 변환하는 등의 작업이 포함됩니다.

```python
import pandas as pd

# 예시 데이터
data = {'고객': ['A', 'B', 'C'],
        '예측 점수': [0.8, 0.2, 0.5]}

df = pd.DataFrame(data)

# 예측 점수에 따라 색상 적용
df['점수 상태'] = df['예측 점수'].apply(lambda x: '위험' if x > 0.7 else '안전')

print(df)
```

위의 코드에서는 고객의 예측 점수를 기반으로 '위험'과 '안전' 상태로 분류합니다. 이렇게 분류된 데이터는 그에 따라 색깔 등을 통해 대시보드에서 표시할 수 있습니다.

### 조건부 포맷팅
조건부 포맷팅은 사용자에게 중요한 데이터를 강조하는 데 유용합니다. 이 방법을 통해 예측 점수에 따라 색상을 변경할 수 있습니다.

```python
import seaborn as sns

def highlight_rows(row):
    return ['background-color: yellow' if row['점수 상태'] == '위험' else '' for _ in row]

# 스타일 적용
styled_df = df.style.apply(highlight_rows, axis=1)
```

**Seaborn**과 같은 라이브러리를 사용하면, 조건부 포맷팅을 통해 데이터의 시각적 강조를 쉽게 할 수 있습니다.

### 웹 페이지에 적합한 포맷팅
위에서 언급한 기능들을 활용하여 대시보드에도 적용할 수 있습니다.

```python
import streamlit as st

# 대시보드에 데이터 표시
st.title('디스플레이 유틸리티 예제')
st.write(styled_df)
```

위 코드를 통해 Streamlit 대시보드에 조건부 포맷팅이 적용된 데이터를 쉽게 표시할 수 있습니다. Streamlit의 **`st.write()`** 함수는 데이터프레임에 대해 다양한 포맷팅을 지원합니다.

## 디스플레이 유틸리티 내부 구현

디스플레이 유틸리티의 작동 방식을 이해하기 위해 시퀀스 다이어그램을 사용해봅시다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 디스플레이 유틸리티
    사용자->>대시보드: 데이터 요청
    대시보드->>디스플레이 유틸리티: 데이터 형식 지정 요청
    디스플레이 유틸리티-->>대시보드: 포맷팅된 데이터 반환
    대시보드-->>사용자: 결과 표시
```

위 다이어그램은 디스플레이 유틸리티가 데이터를 대시보드에 표시하기 전에 어떻게 처리하는지를 보여줍니다.

### 내부 코드 구현

디스플레이 유틸리티의 내부는 다양한 형식 지정 및 조건부 포맷팅을 통해 구성됩니다. 각 단계에서 데이터를 보다 직관적으로 보이도록 만드는 다양한 함수들을 활용합니다.

```python
def format_currency(value):
    return "${:,.2f}".format(value)

formatted_value = format_currency(1500)
print(formatted_value)  # 출력: $1,500.00
```

위 함수는 금액 데이터를 통화 형식으로 변환합니다. 이러한 형식을 통해 사용자가 데이터를 쉽게 이해할 수 있게 됩니다.

## 결론

이번 장에서 우리는 디스플레이 유틸리티를 활용하여 데이터를 보다 사용자 친화적으로 변환하고 강조하는 방법을 배웠습니다. 이렇게 변환된 데이터를 통해 사용자는 더욱 직관적으로 정보를 받아들일 수 있습니다. 다음 장에서는 [필터링 기능](04_필터링_기능.md)을 통해 대시보드 상에서 데이터를 효율적으로 필터링하는 방법을 알아보겠습니다. 이를 통해 우리는 사용자에게 더 개인화된 데이터 뷰를 제공합니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 4: 필터링 기능`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:56:15,737 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:56:28,878 - INFO - RESPONSE: # Chapter 4: 필터링 기능

[이전 장: 디스플레이 유틸리티](03_디스플레이_유틸리티.md)에서는 다양한 유틸리티를 통해 데이터를 쉽게 이해할 수 있도록 돕는 방법에 대해 알아보았습니다. 이번 장에서는 대시보드에서 사용자에게 필요한 정보만 선택적으로 보여줄 수 있는 필터링 기능을 소개하겠습니다.

## 동기

고객 데이터를 통해 인사이트를 얻고자 할 때, 모든 데이터를 한 번에 살펴보는 것은 어렵고 시간이 많이 소요될 수 있습니다. 이러한 문제를 해결하기 위해 우리는 필터링 기능을 사용할 수 있습니다. 필터링 기능을 통해 사용자는 자신이 원하는 특정 조건에 맞는 데이터만을 선별적으로 볼 수 있습니다. 예를 들어, 특정 연령대의 고객만을 대상으로 이탈 가능성을 분석하고자 할 때 유용합니다.

## 필터링 기능의 핵심 개념

### 필터링의 기본 원리
필터링 기능은 사용자로 하여금 자신의 요구에 맞는 데이터를 선택할 수 있도록 합니다. 보통 필터링은 특정 조건을 설정하고 데이터 중 해당 조건에 일치하는 항목만을 추출하는 방식으로 이루어집니다.

```python
import pandas as pd

# 데이터 예시
data = {'고객': ['A', 'B', 'C'],
        '나이': [25, 30, 22],
        '이탈 가능성': [0.1, 0.4, 0.8]}

df = pd.DataFrame(data)

# 나이가 25세 이상인 고객 데이터 필터링
filtered_data = df[df['나이'] >= 25]
print(filtered_data)
```

위 코드에서는 '나이'가 25세 이상인 고객들만 필터링하여 표시합니다. 이 기능은 다양한 조건을 통해 데이터를 세분화하고 분석하는데 매우 유용합니다.

### 코드 활용 및 예시

사용자가 필요로 하는 데이터만을 선택할 수 있는 필터를 구성하는 방법은 다음과 같습니다.

```python
import streamlit as st

# 스트림릿 슬라이더를 통한 나이 기준 필터링 설정
age_filter = st.slider('필터링 나이', 0, 100, 25)

# 설정된 나이 기준에 따른 데이터 필터링
filtered_data = df[df['나이'] >= age_filter]
st.write(filtered_data)
```

이 코드는 Streamlit 슬라이더를 사용하여 사용자가 나이 기준을 설정하고, 그에 맞춰 데이터를 필터링합니다. 이로 인해 대시보드 사용자가 실시간으로 필터링 조건을 변경할 수 있습니다.

## 내부 구현 방식을 통한 이해

필터링 기능이 어떻게 내부에서 작동하는지를 이해하기 위해 시퀀스 다이어그램을 참고합니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 필터링 모듈
    사용자->>대시보드: 필터 조건 설정
    대시보드->>필터링 모듈: 조건 전달
    필터링 모듈-->>대시보드: 필터링된 데이터 반환
    대시보드-->>사용자: 결과 데이터 표시
```

위의 다이어그램은 사용자가 설정한 조건에 따라 데이터가 필터링되고 그 결과가 대시보드에 표시되는 과정을 설명합니다.

### 내부 코드 구현

필터링 기능은 조건을 기반으로 데이터를 선별하는 다양한 알고리즘과 함수를 사용할 수 있습니다. 다음은 pandas 라이브러리를 사용하는 기본적인 방법입니다.

```python
def filter_data(data_frame, condition):
    return data_frame.query(condition)

# 예시: 이탈 가능성이 0.3 이상인 데이터를 필터링
condition = "이탈 가능성 > 0.3"
filtered_result = filter_data(df, condition)
print(filtered_result)
```

위 함수는 pandas의 **`query()`** 메서드를 사용하여 조건에 맞는 데이터를 추출합니다. 이러한 방법을 통해 데이터를 자유롭게 필터링할 수 있습니다.

## 결론

이번 장에서는 대시보드에서 필터링 기능을 통해 사용자가 원하는 특정 조건의 데이터를 선별적으로 확인하는 방법에 대해 배웠습니다. 이런 기능을 사용하면 더 개인화된 데이터 분석이 가능해집니다. 다음 장에서는 [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)를 통해 데이터를 로드하고 준비하는 방법에 대해 더 알아보겠습니다.
2025-06-29 20:56:28,888 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-2nd-1Team` about the concept: "데이터 전처리 및 로드". This is Chapter 5.

Concept Details (Note: Provided in Korean):
- Name: 데이터 전처리 및 로드
- Description:
고객 데이터를 로드하고, 결측값 처리, 범주형 및 수치형 데이터 전처리를 통해 모델이 잘 학습할 수 있도록 준비하는 단계입니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)
2. [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)
3. [디스플레이 유틸리티](03_디스플레이_유틸리티.md)
4. [필터링 기능](04_필터링_기능.md)
5. [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)
6. [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)
7. [모델 로드 및 관리](07_모델_로드_및_관리.md)
8. [고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)
9. [나이별 데이터 분석](09_나이별_데이터_분석.md)
10. [고객 이탈 원인과 해결 방안](10_고객_이탈_원인과_해결_방안.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 은행 고객 이탈 예측 시스템

은행 고객 이탈 예측 시스템은 고객 데이터에 기반하여 이탈 가능성을 분석하고 예측하는 대시보드입니다. 이 시스템은 특히 은행이 고객의 이탈을 미리 예측할 수 있도록 도와주어, 적절한 대응 전략을 세울 수 있게 합니다. 

## 동기

은행은 고객 이탈을 줄이는 것이 매우 중요합니다. 고객이 은행을 떠나기 전, 이를 예측할 수 있다면 추가적인 대응조치를 통해 고객 유지율을 높일 수 있습니다. 예를 들어, 한 고객이 최근 거래가 줄어들고 대출 상환에 문제가 있는 경우 이를 빠르게 인지하고 대책을 세우는 것이 가능해집니다.

## 핵심 개념 설명

이 시스템은 여러 단계로 나뉘어 고객의 이탈 가능성을 예측합니다:

1. **데이터 수집**: 고객의 나이, 거래 내역, 고객 만족도 등 다양한 데이터를 수집합니다.
2. **모델 학습**: 수집된 데이터를 사용하여 머신 러닝 모델을 학습시킵니다.
3. **이탈 예측**: 학습된 모델을 통해 고객의 이탈 가능성을 예측합니다.

### Streamlit을 이용한 대시보드

Streamlit은 쉽게 대시보드를 구성할 수 있게 해주는 파이썬 라이브러리입니다. 코드를 한 줄 한 줄 변경하면서, 바로 변경된 부분을 확인할 수 있어 빠르게 대시보드를 개발할 수 있습니다.

```python
import streamlit as st

# 간단한 대시보드 제목 설정
st.title('은행 고객 이탈 예측 대시보드')
```

이 코드는 대시보드의 기본 제목을 설정합니다. **`streamlit`**은 파이썬 코드로 웹 애플리케이션을 쉽게 만들도록 도와줍니다.

## 이탈 예측 시스템의 내부 구현

### 주요 단계 설명

1. **데이터 로드**: 고객 데이터를 읽어옵니다.
2. **예측 실행**: 모델을 사용하여 이탈 위험을 계산합니다.
3. **결과 시각화**: 대시보드에 예측 결과를 표현합니다.

이 과정은 다음의 시퀀스 다이어그램으로 이해할 수 있습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 모델
    사용자->>대시보드: 데이터 입력
    대시보드->>모델: 예측 요청
    모델-->>대시보드: 예측 결과
    대시보드-->>사용자: 결과 시각화
```

### 데이터 로드

고객 데이터를 로드하는 과정을 살펴보겠습니다.

```python
import pandas as pd

# CSV 파일에서 고객 데이터 로드
data = pd.read_csv('customer_data.csv')
```

이 코드는 고객 데이터를 저장한 CSV 파일을 읽어옵니다. **pandas** 라이브러리를 사용하면 데이터를 다루는 과정이 매우 간단해집니다.

### 예측 실행

모델을 이용하여 이탈 가능성을 예측합니다.

```python
# 머신러닝 모델을 불러와서 예측 수행
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(train_X, train_y)

# 예측하기
predictions = model.predict(test_X)
```

위 예제에서는 **RandomForestClassifier**를 사용하여 모델을 학습하고 예측합니다. 간단한 관계를 통해 예측을 수행하며, 이 결과는 대시보드에서 시각화됩니다.

## 결론

이 장에서는 은행 고객 이탈 예측 시스템의 기본 개념과 구현 과정을 간단하게 살펴보았습니다. 다음 장에서는 [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)을 통해 얻어진 결과를 어떻게 구성하고 표현할 수 있는지에 대한 내용을 알아보겠습니다. 이 시스템을 활용하여 은행이 고객 이탈을 효과적으로 관리할 수 있게 됩니다.
---
# Chapter 2: 데이터 시각화 및 대시보드 구성

[이전 장: 은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)에서는 고객 이탈을 예측하는 시스템의 기본 개념과 구현 방법을 소개했습니다. 이번 장에서는 그 결과를 더욱 효과적으로 전달하기 위해 데이터 시각화와 대시보드 구성을 다루어보겠습니다.

## 동기

데이터 시각화는 복잡한 데이터를 이해하기 쉽게 만들어줍니다. 예를 들어, 수많은 숫자 데이터에서 패턴이나 추세를 식별하기 어렵지만, 이를 그래프로 나타내면 한눈에 이해하기가 쉬워집니다. 이처럼 손쉽게 데이터에서 인사이트를 얻는 방식으로, 대시보드는 사용자와 데이터를 연결하는 중요한 역할을 합니다.

## Streamlit을 사용한 시각화 및 대시보드 생성

Streamlit을 사용하면 복잡한 대시보드를 간단한 코드로 쉽게 개발할 수 있습니다. 데이터 시각화를 사용하여 어떠한 정보가 중요한지 사용자에게 명확히 전달할 수 있습니다.

### 기본적인 대시보드 구성

Streamlit의 간단한 코드를 통해 기본적인 대시보드를 구현하는 방법을 살펴봅시다.

```python
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

# 데이터를 로드
data = pd.read_csv('customer_data.csv')

# 데이터의 일부를 시각화
st.title('데이터 시각화 예제')
st.write("고객 데이터 미리보기:")
st.write(data.head())

# 플롯 생성
st.line_chart(data['Age'])
```

위 코드는 Streamlit을 통해 고객 데이터의 일부를 화면에 표시하고, 'Age' 컬럼을 선 그래프로 시각화합니다. **`st.line_chart`** 는 데이터 시각화를 매우 신속하게 수행할 수 있도록 도와줍니다.

### 대시보드에 추가할 다른 요소

대시보드를 더욱 풍부하게 하기 위해 다양한 그래프와 인터랙티브한 원소들을 추가할 수 있습니다.

```python
# 히스토그램 생성
fig, ax = plt.subplots()
ax.hist(data['Age'], bins=20)

# Streamlit에 Matplotlib 플롯 표시
st.pyplot(fig)
```

위 예제에서는 **Matplotlib**을 사용하여 'Age' 컬럼에 대한 히스토그램을 생성하고, 이를 Streamlit 대시보드에 표시합니다. 이러한 플롯은 데이터의 분포를 시각적으로 파악하는데 유용합니다.

## 내부 구현 상세 설명

대시보드의 작동 방식을 이해하기 위해 간단한 시퀀스 다이어그램을 살펴봅시다.

```mermaid
sequenceDiagram
    participant 사용자
    participant 웹페이지
    participant 스트림릿
    사용자->>웹페이지: 접속 요청
    웹페이지->>스트림릿: 데이터 요청
    스트림릿-->>웹페이지: 시각화 데이터
    웹페이지-->>사용자: 데이터 및 시각화 표시
```

이 과정은 사용자가 웹페이지에 접속하여 데이터를 요청하면, 스트림릿이 적절한 시각화 데이터를 준비하고 이를 사용자에게 전달하는 흐름으로 구성됩니다.

## 결론

이 장에서는 Streamlit을 사용한 데이터 시각화 및 대시보드 구성 방법을 살펴보았습니다. 대시보드는 데이터 해석을 용이하게 해주며, 사용자가 원하는 정보를 효과적으로 전달합니다. 다음 장에서는 [디스플레이 유틸리티](03_디스플레이_유틸리티.md)를 통해 대시보드를 보다 다채롭게 구성하는 방법을 배워보겠습니다. 대시보드의 유익한 시각화 요소들을 더해, 앞으로의 분석이 더욱 직관적으로 이루어질 것입니다.
---
# Chapter 3: 디스플레이 유틸리티

[이전 장: 데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)에서는 대시보드를 통해 고객 이탈 데이터를 효과적으로 시각화하는 방법을 배웠습니다. 이번 장에서는 대시보드를 보다 직관적이고 사용자 친화적으로 만드는 데에 필요한 **디스플레이 유틸리티**를 소개하겠습니다.

## 동기

우리가 고객 이탈 예측 결과를 분석할 때, 단순히 숫자나 그래프만 보이면 직관적으로 이해하기 힘들 수 있습니다. 이런 데이터를 더 쉽게 이해하고 활용하기 위해, UI에 표현하는 방식에 다양한 유틸리티를 추가할 수 있습니다. 

예시로, 고객의 이탈 예측 점수를 색깔로 강조하여 중요하고 볼만한 정보를 쉽게 전달할 수 있습니다. 예를 들어, 이탈 가능성이 높은 고객을 빨간색으로 표시하면 곧바로 주의를 기울일 수 있게 됩니다.

## 디스플레이 유틸리티의 핵심 개념

### 데이터 포맷팅
디스플레이 유틸리티에서 가장 기본이 되는 개념은 데이터를 사용자가 쉽게 볼 수 있도록 가공하는 것입니다. 여기에는 날짜 형식 변환, 금액을 통화 형식으로 변환하는 등의 작업이 포함됩니다.

```python
import pandas as pd

# 예시 데이터
data = {'고객': ['A', 'B', 'C'],
        '예측 점수': [0.8, 0.2, 0.5]}

df = pd.DataFrame(data)

# 예측 점수에 따라 색상 적용
df['점수 상태'] = df['예측 점수'].apply(lambda x: '위험' if x > 0.7 else '안전')

print(df)
```

위의 코드에서는 고객의 예측 점수를 기반으로 '위험'과 '안전' 상태로 분류합니다. 이렇게 분류된 데이터는 그에 따라 색깔 등을 통해 대시보드에서 표시할 수 있습니다.

### 조건부 포맷팅
조건부 포맷팅은 사용자에게 중요한 데이터를 강조하는 데 유용합니다. 이 방법을 통해 예측 점수에 따라 색상을 변경할 수 있습니다.

```python
import seaborn as sns

def highlight_rows(row):
    return ['background-color: yellow' if row['점수 상태'] == '위험' else '' for _ in row]

# 스타일 적용
styled_df = df.style.apply(highlight_rows, axis=1)
```

**Seaborn**과 같은 라이브러리를 사용하면, 조건부 포맷팅을 통해 데이터의 시각적 강조를 쉽게 할 수 있습니다.

### 웹 페이지에 적합한 포맷팅
위에서 언급한 기능들을 활용하여 대시보드에도 적용할 수 있습니다.

```python
import streamlit as st

# 대시보드에 데이터 표시
st.title('디스플레이 유틸리티 예제')
st.write(styled_df)
```

위 코드를 통해 Streamlit 대시보드에 조건부 포맷팅이 적용된 데이터를 쉽게 표시할 수 있습니다. Streamlit의 **`st.write()`** 함수는 데이터프레임에 대해 다양한 포맷팅을 지원합니다.

## 디스플레이 유틸리티 내부 구현

디스플레이 유틸리티의 작동 방식을 이해하기 위해 시퀀스 다이어그램을 사용해봅시다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 디스플레이 유틸리티
    사용자->>대시보드: 데이터 요청
    대시보드->>디스플레이 유틸리티: 데이터 형식 지정 요청
    디스플레이 유틸리티-->>대시보드: 포맷팅된 데이터 반환
    대시보드-->>사용자: 결과 표시
```

위 다이어그램은 디스플레이 유틸리티가 데이터를 대시보드에 표시하기 전에 어떻게 처리하는지를 보여줍니다.

### 내부 코드 구현

디스플레이 유틸리티의 내부는 다양한 형식 지정 및 조건부 포맷팅을 통해 구성됩니다. 각 단계에서 데이터를 보다 직관적으로 보이도록 만드는 다양한 함수들을 활용합니다.

```python
def format_currency(value):
    return "${:,.2f}".format(value)

formatted_value = format_currency(1500)
print(formatted_value)  # 출력: $1,500.00
```

위 함수는 금액 데이터를 통화 형식으로 변환합니다. 이러한 형식을 통해 사용자가 데이터를 쉽게 이해할 수 있게 됩니다.

## 결론

이번 장에서 우리는 디스플레이 유틸리티를 활용하여 데이터를 보다 사용자 친화적으로 변환하고 강조하는 방법을 배웠습니다. 이렇게 변환된 데이터를 통해 사용자는 더욱 직관적으로 정보를 받아들일 수 있습니다. 다음 장에서는 [필터링 기능](04_필터링_기능.md)을 통해 대시보드 상에서 데이터를 효율적으로 필터링하는 방법을 알아보겠습니다. 이를 통해 우리는 사용자에게 더 개인화된 데이터 뷰를 제공합니다.
---
# Chapter 4: 필터링 기능

[이전 장: 디스플레이 유틸리티](03_디스플레이_유틸리티.md)에서는 다양한 유틸리티를 통해 데이터를 쉽게 이해할 수 있도록 돕는 방법에 대해 알아보았습니다. 이번 장에서는 대시보드에서 사용자에게 필요한 정보만 선택적으로 보여줄 수 있는 필터링 기능을 소개하겠습니다.

## 동기

고객 데이터를 통해 인사이트를 얻고자 할 때, 모든 데이터를 한 번에 살펴보는 것은 어렵고 시간이 많이 소요될 수 있습니다. 이러한 문제를 해결하기 위해 우리는 필터링 기능을 사용할 수 있습니다. 필터링 기능을 통해 사용자는 자신이 원하는 특정 조건에 맞는 데이터만을 선별적으로 볼 수 있습니다. 예를 들어, 특정 연령대의 고객만을 대상으로 이탈 가능성을 분석하고자 할 때 유용합니다.

## 필터링 기능의 핵심 개념

### 필터링의 기본 원리
필터링 기능은 사용자로 하여금 자신의 요구에 맞는 데이터를 선택할 수 있도록 합니다. 보통 필터링은 특정 조건을 설정하고 데이터 중 해당 조건에 일치하는 항목만을 추출하는 방식으로 이루어집니다.

```python
import pandas as pd

# 데이터 예시
data = {'고객': ['A', 'B', 'C'],
        '나이': [25, 30, 22],
        '이탈 가능성': [0.1, 0.4, 0.8]}

df = pd.DataFrame(data)

# 나이가 25세 이상인 고객 데이터 필터링
filtered_data = df[df['나이'] >= 25]
print(filtered_data)
```

위 코드에서는 '나이'가 25세 이상인 고객들만 필터링하여 표시합니다. 이 기능은 다양한 조건을 통해 데이터를 세분화하고 분석하는데 매우 유용합니다.

### 코드 활용 및 예시

사용자가 필요로 하는 데이터만을 선택할 수 있는 필터를 구성하는 방법은 다음과 같습니다.

```python
import streamlit as st

# 스트림릿 슬라이더를 통한 나이 기준 필터링 설정
age_filter = st.slider('필터링 나이', 0, 100, 25)

# 설정된 나이 기준에 따른 데이터 필터링
filtered_data = df[df['나이'] >= age_filter]
st.write(filtered_data)
```

이 코드는 Streamlit 슬라이더를 사용하여 사용자가 나이 기준을 설정하고, 그에 맞춰 데이터를 필터링합니다. 이로 인해 대시보드 사용자가 실시간으로 필터링 조건을 변경할 수 있습니다.

## 내부 구현 방식을 통한 이해

필터링 기능이 어떻게 내부에서 작동하는지를 이해하기 위해 시퀀스 다이어그램을 참고합니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 필터링 모듈
    사용자->>대시보드: 필터 조건 설정
    대시보드->>필터링 모듈: 조건 전달
    필터링 모듈-->>대시보드: 필터링된 데이터 반환
    대시보드-->>사용자: 결과 데이터 표시
```

위의 다이어그램은 사용자가 설정한 조건에 따라 데이터가 필터링되고 그 결과가 대시보드에 표시되는 과정을 설명합니다.

### 내부 코드 구현

필터링 기능은 조건을 기반으로 데이터를 선별하는 다양한 알고리즘과 함수를 사용할 수 있습니다. 다음은 pandas 라이브러리를 사용하는 기본적인 방법입니다.

```python
def filter_data(data_frame, condition):
    return data_frame.query(condition)

# 예시: 이탈 가능성이 0.3 이상인 데이터를 필터링
condition = "이탈 가능성 > 0.3"
filtered_result = filter_data(df, condition)
print(filtered_result)
```

위 함수는 pandas의 **`query()`** 메서드를 사용하여 조건에 맞는 데이터를 추출합니다. 이러한 방법을 통해 데이터를 자유롭게 필터링할 수 있습니다.

## 결론

이번 장에서는 대시보드에서 필터링 기능을 통해 사용자가 원하는 특정 조건의 데이터를 선별적으로 확인하는 방법에 대해 배웠습니다. 이런 기능을 사용하면 더 개인화된 데이터 분석이 가능해집니다. 다음 장에서는 [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)를 통해 데이터를 로드하고 준비하는 방법에 대해 더 알아보겠습니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 5: 데이터 전처리 및 로드`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:56:29,065 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:56:42,386 - INFO - RESPONSE: # Chapter 5: 데이터 전처리 및 로드

[이전 장: 필터링 기능](04_필터링_기능.md)에서는 대시보드를 통해 원하는 데이터를 필터링하는 방법을 배웠습니다. 이번 장에서는 머신러닝 모델을 위한 중요한 단계인 **데이터 전처리 및 로드**에 대해 알아보겠습니다.

## 동기

데이터 전처리는 머신러닝 모델의 성공적인 학습을 위해 필수적으로 필요합니다. 데이터를 로드하고 사용하기 용이하게 준비하지 않으면 결측값이나 형식 문제로 인해 예측 정확도에 영향을 줄 수 있습니다. 따라서 데이터 전처리를 적절히 수행하는 것은 매우 중요합니다.

### 예시 상황

예시로, 고객 데이터에서 누락된 값이 있는 상황을 고려해 봅시다. 이런 데이터로 모델을 훈련하면 부정확한 결과를 초래할 수 있습니다. 데이터 전처리는 이러한 문제를 해결하기 위해 데이터 형식 변환, 결측값 대체 등의 작업을 포함합니다.

## 데이터 전처리의 핵심 개념

### 데이터 로드

먼저, 데이터를 로딩하는 단계부터 시작해야 합니다. 이 예제에서는 CSV 파일을 읽어옵니다.

```python
import pandas as pd

# 고객 데이터를 CSV에서 읽어오기
data = pd.read_csv('customer_data.csv')
```

**`pandas`**를 사용하여 CSV 파일을 읽어옵니다. 이러면 데이터를 DataFrame 형식으로 쉽게 다룰 수 있습니다.

### 결측값 처리

데이터 중 결측값 또는 누락된 값을 처리해야 합니다. 데이터의 일관성을 확보하는 것이 중요하기 때문입니다.

```python
# 결측값을 평균값으로 대체
data.fillna(data.mean(), inplace=True)
```

위 코드에서는 결측값을 각 열의 평균값으로 대체하여 데이터의 완전성을 확보합니다.

### 범주형 데이터 처리

데이터에 범주형 값을 시계열이나 숫자로 변환하는 것이 중요합니다.

```python
# 범주형 변수를 수치형으로 변환
data['Gender'] = data['Gender'].map({'Male': 0, 'Female': 1})
```

여기서 성별 데이터를 'Male'을 0으로, 'Female'을 1로 변환하여 수치형 변수로 변경합니다.

### 수치형 데이터 정규화

데이터의 스케일링을 통해 모델 훈련 성능을 향상시킬 수 있습니다.

```python
from sklearn.preprocessing import MinMaxScaler

# 스케일러 초기화 및 적용
scaler = MinMaxScaler()
data[['Age', 'Salary']] = scaler.fit_transform(data[['Age', 'Salary']])
```

위 코드에서는 **`MinMaxScaler`**를 사용하여 'Age'와 'Salary' 열을 정규화합니다. 이로 인해 각각의 값이 0과 1 사이로 조정됩니다.

## 데이터 전처리 흐름

이제 전체 데이터를 전처리하는 흐름을 이해할 수 있습니다. 다음 시퀀스 다이어그램은 전처리 과정을 시각적으로 나타냅니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 시스템
    participant 전처리 모듈
    사용자->>시스템: 데이터 로드 요청
    시스템->>전처리 모듈: 데이터 전달
    전처리 모듈-->>시스템: 전처리된 데이터 반환
    시스템-->>사용자: 처리 완료된 데이터 표시
```

이 과정에서는 사용자가 데이터 로드를 요청하면 시스템이 전처리 모듈을 통해 데이터를 준비하고, 완성된 데이터를 반환받아 사용자에게 전달합니다.

### 전처리 코드 내부 구현

데이터 전처리의 실제 코드를 확인해보겠습니다. 데이터 전처리는 체계적인 단계를 통해 수행됩니다.

```python
def preprocess_data(file_path):
    df = pd.read_csv(file_path)
    
    # 결측값 확인 및 대체
    df.fillna(df.mean(), inplace=True)
    
    # 범주형 변수 변환
    df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})
    
    # 수치형 데이터 정규화
    scaler = MinMaxScaler()
    df[['Age', 'Salary']] = scaler.fit_transform(df[['Age', 'Salary']])
    
    return df

processed_data = preprocess_data('customer_data.csv')
```

함수 **`preprocess_data`**는 데이터를 로드하고, 결측값 처리, 범주형 변수 변환, 데이터 정규화를 포함한 모든 전처리 과정을 실행합니다. 결과적으로 모델에 알맞은 형태로 데이터를 변환합니다.

## 결론

이번 장에서는 데이터 전처리와 로드 과정을 통해 데이터의 품질을 높이고 모델 학습에 대비하는 방법을 배웠습니다. 전처리 과정을 잘 이해하면 향후 머신러닝 모델의 성능을 향상시킬 수 있습니다. 다음 장 [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)에서는 준비된 데이터를 사용하여 모델을 학습시키고 예측 성능을 측정하는 방법에 대해 알아보겠습니다.
2025-06-29 20:56:42,400 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-2nd-1Team` about the concept: "모델 예측 및 성능 측정". This is Chapter 6.

Concept Details (Note: Provided in Korean):
- Name: 모델 예측 및 성능 측정
- Description:
고객 데이터에 대해 Gradient Boosting, Random Forest, Deep Learning 모델을 사용하여 이탈 예측을 수행하고 성능을 측정합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)
2. [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)
3. [디스플레이 유틸리티](03_디스플레이_유틸리티.md)
4. [필터링 기능](04_필터링_기능.md)
5. [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)
6. [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)
7. [모델 로드 및 관리](07_모델_로드_및_관리.md)
8. [고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)
9. [나이별 데이터 분석](09_나이별_데이터_분석.md)
10. [고객 이탈 원인과 해결 방안](10_고객_이탈_원인과_해결_방안.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 은행 고객 이탈 예측 시스템

은행 고객 이탈 예측 시스템은 고객 데이터에 기반하여 이탈 가능성을 분석하고 예측하는 대시보드입니다. 이 시스템은 특히 은행이 고객의 이탈을 미리 예측할 수 있도록 도와주어, 적절한 대응 전략을 세울 수 있게 합니다. 

## 동기

은행은 고객 이탈을 줄이는 것이 매우 중요합니다. 고객이 은행을 떠나기 전, 이를 예측할 수 있다면 추가적인 대응조치를 통해 고객 유지율을 높일 수 있습니다. 예를 들어, 한 고객이 최근 거래가 줄어들고 대출 상환에 문제가 있는 경우 이를 빠르게 인지하고 대책을 세우는 것이 가능해집니다.

## 핵심 개념 설명

이 시스템은 여러 단계로 나뉘어 고객의 이탈 가능성을 예측합니다:

1. **데이터 수집**: 고객의 나이, 거래 내역, 고객 만족도 등 다양한 데이터를 수집합니다.
2. **모델 학습**: 수집된 데이터를 사용하여 머신 러닝 모델을 학습시킵니다.
3. **이탈 예측**: 학습된 모델을 통해 고객의 이탈 가능성을 예측합니다.

### Streamlit을 이용한 대시보드

Streamlit은 쉽게 대시보드를 구성할 수 있게 해주는 파이썬 라이브러리입니다. 코드를 한 줄 한 줄 변경하면서, 바로 변경된 부분을 확인할 수 있어 빠르게 대시보드를 개발할 수 있습니다.

```python
import streamlit as st

# 간단한 대시보드 제목 설정
st.title('은행 고객 이탈 예측 대시보드')
```

이 코드는 대시보드의 기본 제목을 설정합니다. **`streamlit`**은 파이썬 코드로 웹 애플리케이션을 쉽게 만들도록 도와줍니다.

## 이탈 예측 시스템의 내부 구현

### 주요 단계 설명

1. **데이터 로드**: 고객 데이터를 읽어옵니다.
2. **예측 실행**: 모델을 사용하여 이탈 위험을 계산합니다.
3. **결과 시각화**: 대시보드에 예측 결과를 표현합니다.

이 과정은 다음의 시퀀스 다이어그램으로 이해할 수 있습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 모델
    사용자->>대시보드: 데이터 입력
    대시보드->>모델: 예측 요청
    모델-->>대시보드: 예측 결과
    대시보드-->>사용자: 결과 시각화
```

### 데이터 로드

고객 데이터를 로드하는 과정을 살펴보겠습니다.

```python
import pandas as pd

# CSV 파일에서 고객 데이터 로드
data = pd.read_csv('customer_data.csv')
```

이 코드는 고객 데이터를 저장한 CSV 파일을 읽어옵니다. **pandas** 라이브러리를 사용하면 데이터를 다루는 과정이 매우 간단해집니다.

### 예측 실행

모델을 이용하여 이탈 가능성을 예측합니다.

```python
# 머신러닝 모델을 불러와서 예측 수행
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(train_X, train_y)

# 예측하기
predictions = model.predict(test_X)
```

위 예제에서는 **RandomForestClassifier**를 사용하여 모델을 학습하고 예측합니다. 간단한 관계를 통해 예측을 수행하며, 이 결과는 대시보드에서 시각화됩니다.

## 결론

이 장에서는 은행 고객 이탈 예측 시스템의 기본 개념과 구현 과정을 간단하게 살펴보았습니다. 다음 장에서는 [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)을 통해 얻어진 결과를 어떻게 구성하고 표현할 수 있는지에 대한 내용을 알아보겠습니다. 이 시스템을 활용하여 은행이 고객 이탈을 효과적으로 관리할 수 있게 됩니다.
---
# Chapter 2: 데이터 시각화 및 대시보드 구성

[이전 장: 은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)에서는 고객 이탈을 예측하는 시스템의 기본 개념과 구현 방법을 소개했습니다. 이번 장에서는 그 결과를 더욱 효과적으로 전달하기 위해 데이터 시각화와 대시보드 구성을 다루어보겠습니다.

## 동기

데이터 시각화는 복잡한 데이터를 이해하기 쉽게 만들어줍니다. 예를 들어, 수많은 숫자 데이터에서 패턴이나 추세를 식별하기 어렵지만, 이를 그래프로 나타내면 한눈에 이해하기가 쉬워집니다. 이처럼 손쉽게 데이터에서 인사이트를 얻는 방식으로, 대시보드는 사용자와 데이터를 연결하는 중요한 역할을 합니다.

## Streamlit을 사용한 시각화 및 대시보드 생성

Streamlit을 사용하면 복잡한 대시보드를 간단한 코드로 쉽게 개발할 수 있습니다. 데이터 시각화를 사용하여 어떠한 정보가 중요한지 사용자에게 명확히 전달할 수 있습니다.

### 기본적인 대시보드 구성

Streamlit의 간단한 코드를 통해 기본적인 대시보드를 구현하는 방법을 살펴봅시다.

```python
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

# 데이터를 로드
data = pd.read_csv('customer_data.csv')

# 데이터의 일부를 시각화
st.title('데이터 시각화 예제')
st.write("고객 데이터 미리보기:")
st.write(data.head())

# 플롯 생성
st.line_chart(data['Age'])
```

위 코드는 Streamlit을 통해 고객 데이터의 일부를 화면에 표시하고, 'Age' 컬럼을 선 그래프로 시각화합니다. **`st.line_chart`** 는 데이터 시각화를 매우 신속하게 수행할 수 있도록 도와줍니다.

### 대시보드에 추가할 다른 요소

대시보드를 더욱 풍부하게 하기 위해 다양한 그래프와 인터랙티브한 원소들을 추가할 수 있습니다.

```python
# 히스토그램 생성
fig, ax = plt.subplots()
ax.hist(data['Age'], bins=20)

# Streamlit에 Matplotlib 플롯 표시
st.pyplot(fig)
```

위 예제에서는 **Matplotlib**을 사용하여 'Age' 컬럼에 대한 히스토그램을 생성하고, 이를 Streamlit 대시보드에 표시합니다. 이러한 플롯은 데이터의 분포를 시각적으로 파악하는데 유용합니다.

## 내부 구현 상세 설명

대시보드의 작동 방식을 이해하기 위해 간단한 시퀀스 다이어그램을 살펴봅시다.

```mermaid
sequenceDiagram
    participant 사용자
    participant 웹페이지
    participant 스트림릿
    사용자->>웹페이지: 접속 요청
    웹페이지->>스트림릿: 데이터 요청
    스트림릿-->>웹페이지: 시각화 데이터
    웹페이지-->>사용자: 데이터 및 시각화 표시
```

이 과정은 사용자가 웹페이지에 접속하여 데이터를 요청하면, 스트림릿이 적절한 시각화 데이터를 준비하고 이를 사용자에게 전달하는 흐름으로 구성됩니다.

## 결론

이 장에서는 Streamlit을 사용한 데이터 시각화 및 대시보드 구성 방법을 살펴보았습니다. 대시보드는 데이터 해석을 용이하게 해주며, 사용자가 원하는 정보를 효과적으로 전달합니다. 다음 장에서는 [디스플레이 유틸리티](03_디스플레이_유틸리티.md)를 통해 대시보드를 보다 다채롭게 구성하는 방법을 배워보겠습니다. 대시보드의 유익한 시각화 요소들을 더해, 앞으로의 분석이 더욱 직관적으로 이루어질 것입니다.
---
# Chapter 3: 디스플레이 유틸리티

[이전 장: 데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)에서는 대시보드를 통해 고객 이탈 데이터를 효과적으로 시각화하는 방법을 배웠습니다. 이번 장에서는 대시보드를 보다 직관적이고 사용자 친화적으로 만드는 데에 필요한 **디스플레이 유틸리티**를 소개하겠습니다.

## 동기

우리가 고객 이탈 예측 결과를 분석할 때, 단순히 숫자나 그래프만 보이면 직관적으로 이해하기 힘들 수 있습니다. 이런 데이터를 더 쉽게 이해하고 활용하기 위해, UI에 표현하는 방식에 다양한 유틸리티를 추가할 수 있습니다. 

예시로, 고객의 이탈 예측 점수를 색깔로 강조하여 중요하고 볼만한 정보를 쉽게 전달할 수 있습니다. 예를 들어, 이탈 가능성이 높은 고객을 빨간색으로 표시하면 곧바로 주의를 기울일 수 있게 됩니다.

## 디스플레이 유틸리티의 핵심 개념

### 데이터 포맷팅
디스플레이 유틸리티에서 가장 기본이 되는 개념은 데이터를 사용자가 쉽게 볼 수 있도록 가공하는 것입니다. 여기에는 날짜 형식 변환, 금액을 통화 형식으로 변환하는 등의 작업이 포함됩니다.

```python
import pandas as pd

# 예시 데이터
data = {'고객': ['A', 'B', 'C'],
        '예측 점수': [0.8, 0.2, 0.5]}

df = pd.DataFrame(data)

# 예측 점수에 따라 색상 적용
df['점수 상태'] = df['예측 점수'].apply(lambda x: '위험' if x > 0.7 else '안전')

print(df)
```

위의 코드에서는 고객의 예측 점수를 기반으로 '위험'과 '안전' 상태로 분류합니다. 이렇게 분류된 데이터는 그에 따라 색깔 등을 통해 대시보드에서 표시할 수 있습니다.

### 조건부 포맷팅
조건부 포맷팅은 사용자에게 중요한 데이터를 강조하는 데 유용합니다. 이 방법을 통해 예측 점수에 따라 색상을 변경할 수 있습니다.

```python
import seaborn as sns

def highlight_rows(row):
    return ['background-color: yellow' if row['점수 상태'] == '위험' else '' for _ in row]

# 스타일 적용
styled_df = df.style.apply(highlight_rows, axis=1)
```

**Seaborn**과 같은 라이브러리를 사용하면, 조건부 포맷팅을 통해 데이터의 시각적 강조를 쉽게 할 수 있습니다.

### 웹 페이지에 적합한 포맷팅
위에서 언급한 기능들을 활용하여 대시보드에도 적용할 수 있습니다.

```python
import streamlit as st

# 대시보드에 데이터 표시
st.title('디스플레이 유틸리티 예제')
st.write(styled_df)
```

위 코드를 통해 Streamlit 대시보드에 조건부 포맷팅이 적용된 데이터를 쉽게 표시할 수 있습니다. Streamlit의 **`st.write()`** 함수는 데이터프레임에 대해 다양한 포맷팅을 지원합니다.

## 디스플레이 유틸리티 내부 구현

디스플레이 유틸리티의 작동 방식을 이해하기 위해 시퀀스 다이어그램을 사용해봅시다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 디스플레이 유틸리티
    사용자->>대시보드: 데이터 요청
    대시보드->>디스플레이 유틸리티: 데이터 형식 지정 요청
    디스플레이 유틸리티-->>대시보드: 포맷팅된 데이터 반환
    대시보드-->>사용자: 결과 표시
```

위 다이어그램은 디스플레이 유틸리티가 데이터를 대시보드에 표시하기 전에 어떻게 처리하는지를 보여줍니다.

### 내부 코드 구현

디스플레이 유틸리티의 내부는 다양한 형식 지정 및 조건부 포맷팅을 통해 구성됩니다. 각 단계에서 데이터를 보다 직관적으로 보이도록 만드는 다양한 함수들을 활용합니다.

```python
def format_currency(value):
    return "${:,.2f}".format(value)

formatted_value = format_currency(1500)
print(formatted_value)  # 출력: $1,500.00
```

위 함수는 금액 데이터를 통화 형식으로 변환합니다. 이러한 형식을 통해 사용자가 데이터를 쉽게 이해할 수 있게 됩니다.

## 결론

이번 장에서 우리는 디스플레이 유틸리티를 활용하여 데이터를 보다 사용자 친화적으로 변환하고 강조하는 방법을 배웠습니다. 이렇게 변환된 데이터를 통해 사용자는 더욱 직관적으로 정보를 받아들일 수 있습니다. 다음 장에서는 [필터링 기능](04_필터링_기능.md)을 통해 대시보드 상에서 데이터를 효율적으로 필터링하는 방법을 알아보겠습니다. 이를 통해 우리는 사용자에게 더 개인화된 데이터 뷰를 제공합니다.
---
# Chapter 4: 필터링 기능

[이전 장: 디스플레이 유틸리티](03_디스플레이_유틸리티.md)에서는 다양한 유틸리티를 통해 데이터를 쉽게 이해할 수 있도록 돕는 방법에 대해 알아보았습니다. 이번 장에서는 대시보드에서 사용자에게 필요한 정보만 선택적으로 보여줄 수 있는 필터링 기능을 소개하겠습니다.

## 동기

고객 데이터를 통해 인사이트를 얻고자 할 때, 모든 데이터를 한 번에 살펴보는 것은 어렵고 시간이 많이 소요될 수 있습니다. 이러한 문제를 해결하기 위해 우리는 필터링 기능을 사용할 수 있습니다. 필터링 기능을 통해 사용자는 자신이 원하는 특정 조건에 맞는 데이터만을 선별적으로 볼 수 있습니다. 예를 들어, 특정 연령대의 고객만을 대상으로 이탈 가능성을 분석하고자 할 때 유용합니다.

## 필터링 기능의 핵심 개념

### 필터링의 기본 원리
필터링 기능은 사용자로 하여금 자신의 요구에 맞는 데이터를 선택할 수 있도록 합니다. 보통 필터링은 특정 조건을 설정하고 데이터 중 해당 조건에 일치하는 항목만을 추출하는 방식으로 이루어집니다.

```python
import pandas as pd

# 데이터 예시
data = {'고객': ['A', 'B', 'C'],
        '나이': [25, 30, 22],
        '이탈 가능성': [0.1, 0.4, 0.8]}

df = pd.DataFrame(data)

# 나이가 25세 이상인 고객 데이터 필터링
filtered_data = df[df['나이'] >= 25]
print(filtered_data)
```

위 코드에서는 '나이'가 25세 이상인 고객들만 필터링하여 표시합니다. 이 기능은 다양한 조건을 통해 데이터를 세분화하고 분석하는데 매우 유용합니다.

### 코드 활용 및 예시

사용자가 필요로 하는 데이터만을 선택할 수 있는 필터를 구성하는 방법은 다음과 같습니다.

```python
import streamlit as st

# 스트림릿 슬라이더를 통한 나이 기준 필터링 설정
age_filter = st.slider('필터링 나이', 0, 100, 25)

# 설정된 나이 기준에 따른 데이터 필터링
filtered_data = df[df['나이'] >= age_filter]
st.write(filtered_data)
```

이 코드는 Streamlit 슬라이더를 사용하여 사용자가 나이 기준을 설정하고, 그에 맞춰 데이터를 필터링합니다. 이로 인해 대시보드 사용자가 실시간으로 필터링 조건을 변경할 수 있습니다.

## 내부 구현 방식을 통한 이해

필터링 기능이 어떻게 내부에서 작동하는지를 이해하기 위해 시퀀스 다이어그램을 참고합니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 필터링 모듈
    사용자->>대시보드: 필터 조건 설정
    대시보드->>필터링 모듈: 조건 전달
    필터링 모듈-->>대시보드: 필터링된 데이터 반환
    대시보드-->>사용자: 결과 데이터 표시
```

위의 다이어그램은 사용자가 설정한 조건에 따라 데이터가 필터링되고 그 결과가 대시보드에 표시되는 과정을 설명합니다.

### 내부 코드 구현

필터링 기능은 조건을 기반으로 데이터를 선별하는 다양한 알고리즘과 함수를 사용할 수 있습니다. 다음은 pandas 라이브러리를 사용하는 기본적인 방법입니다.

```python
def filter_data(data_frame, condition):
    return data_frame.query(condition)

# 예시: 이탈 가능성이 0.3 이상인 데이터를 필터링
condition = "이탈 가능성 > 0.3"
filtered_result = filter_data(df, condition)
print(filtered_result)
```

위 함수는 pandas의 **`query()`** 메서드를 사용하여 조건에 맞는 데이터를 추출합니다. 이러한 방법을 통해 데이터를 자유롭게 필터링할 수 있습니다.

## 결론

이번 장에서는 대시보드에서 필터링 기능을 통해 사용자가 원하는 특정 조건의 데이터를 선별적으로 확인하는 방법에 대해 배웠습니다. 이런 기능을 사용하면 더 개인화된 데이터 분석이 가능해집니다. 다음 장에서는 [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)를 통해 데이터를 로드하고 준비하는 방법에 대해 더 알아보겠습니다.
---
# Chapter 5: 데이터 전처리 및 로드

[이전 장: 필터링 기능](04_필터링_기능.md)에서는 대시보드를 통해 원하는 데이터를 필터링하는 방법을 배웠습니다. 이번 장에서는 머신러닝 모델을 위한 중요한 단계인 **데이터 전처리 및 로드**에 대해 알아보겠습니다.

## 동기

데이터 전처리는 머신러닝 모델의 성공적인 학습을 위해 필수적으로 필요합니다. 데이터를 로드하고 사용하기 용이하게 준비하지 않으면 결측값이나 형식 문제로 인해 예측 정확도에 영향을 줄 수 있습니다. 따라서 데이터 전처리를 적절히 수행하는 것은 매우 중요합니다.

### 예시 상황

예시로, 고객 데이터에서 누락된 값이 있는 상황을 고려해 봅시다. 이런 데이터로 모델을 훈련하면 부정확한 결과를 초래할 수 있습니다. 데이터 전처리는 이러한 문제를 해결하기 위해 데이터 형식 변환, 결측값 대체 등의 작업을 포함합니다.

## 데이터 전처리의 핵심 개념

### 데이터 로드

먼저, 데이터를 로딩하는 단계부터 시작해야 합니다. 이 예제에서는 CSV 파일을 읽어옵니다.

```python
import pandas as pd

# 고객 데이터를 CSV에서 읽어오기
data = pd.read_csv('customer_data.csv')
```

**`pandas`**를 사용하여 CSV 파일을 읽어옵니다. 이러면 데이터를 DataFrame 형식으로 쉽게 다룰 수 있습니다.

### 결측값 처리

데이터 중 결측값 또는 누락된 값을 처리해야 합니다. 데이터의 일관성을 확보하는 것이 중요하기 때문입니다.

```python
# 결측값을 평균값으로 대체
data.fillna(data.mean(), inplace=True)
```

위 코드에서는 결측값을 각 열의 평균값으로 대체하여 데이터의 완전성을 확보합니다.

### 범주형 데이터 처리

데이터에 범주형 값을 시계열이나 숫자로 변환하는 것이 중요합니다.

```python
# 범주형 변수를 수치형으로 변환
data['Gender'] = data['Gender'].map({'Male': 0, 'Female': 1})
```

여기서 성별 데이터를 'Male'을 0으로, 'Female'을 1로 변환하여 수치형 변수로 변경합니다.

### 수치형 데이터 정규화

데이터의 스케일링을 통해 모델 훈련 성능을 향상시킬 수 있습니다.

```python
from sklearn.preprocessing import MinMaxScaler

# 스케일러 초기화 및 적용
scaler = MinMaxScaler()
data[['Age', 'Salary']] = scaler.fit_transform(data[['Age', 'Salary']])
```

위 코드에서는 **`MinMaxScaler`**를 사용하여 'Age'와 'Salary' 열을 정규화합니다. 이로 인해 각각의 값이 0과 1 사이로 조정됩니다.

## 데이터 전처리 흐름

이제 전체 데이터를 전처리하는 흐름을 이해할 수 있습니다. 다음 시퀀스 다이어그램은 전처리 과정을 시각적으로 나타냅니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 시스템
    participant 전처리 모듈
    사용자->>시스템: 데이터 로드 요청
    시스템->>전처리 모듈: 데이터 전달
    전처리 모듈-->>시스템: 전처리된 데이터 반환
    시스템-->>사용자: 처리 완료된 데이터 표시
```

이 과정에서는 사용자가 데이터 로드를 요청하면 시스템이 전처리 모듈을 통해 데이터를 준비하고, 완성된 데이터를 반환받아 사용자에게 전달합니다.

### 전처리 코드 내부 구현

데이터 전처리의 실제 코드를 확인해보겠습니다. 데이터 전처리는 체계적인 단계를 통해 수행됩니다.

```python
def preprocess_data(file_path):
    df = pd.read_csv(file_path)
    
    # 결측값 확인 및 대체
    df.fillna(df.mean(), inplace=True)
    
    # 범주형 변수 변환
    df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})
    
    # 수치형 데이터 정규화
    scaler = MinMaxScaler()
    df[['Age', 'Salary']] = scaler.fit_transform(df[['Age', 'Salary']])
    
    return df

processed_data = preprocess_data('customer_data.csv')
```

함수 **`preprocess_data`**는 데이터를 로드하고, 결측값 처리, 범주형 변수 변환, 데이터 정규화를 포함한 모든 전처리 과정을 실행합니다. 결과적으로 모델에 알맞은 형태로 데이터를 변환합니다.

## 결론

이번 장에서는 데이터 전처리와 로드 과정을 통해 데이터의 품질을 높이고 모델 학습에 대비하는 방법을 배웠습니다. 전처리 과정을 잘 이해하면 향후 머신러닝 모델의 성능을 향상시킬 수 있습니다. 다음 장 [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)에서는 준비된 데이터를 사용하여 모델을 학습시키고 예측 성능을 측정하는 방법에 대해 알아보겠습니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 6: 모델 예측 및 성능 측정`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:56:42,619 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:56:54,430 - INFO - RESPONSE: # Chapter 6: 모델 예측 및 성능 측정

[이전 장: 데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)에서는 머신러닝 모델에 데이터를 준비하는 방법을 배웠습니다. 이번 장에서는 이러한 데이터를 사용하여 실제로 모델을 예측하고, 그 성능을 측정하는 방법을 알아보겠습니다.

## 동기

예를 들어, 우리는 고객의 이탈 가능성을 예측하는 모델을 만들려고 합니다. 이를 위해 Random Forest, Gradient Boosting, 그리고 Deep Learning 모델을 사용합니다. 이 예측이 정확하다면 은행은 고객 이탈을 사전에 예방할 수 있습니다. 하지만 예측의 정확도를 어떻게 평가할 수 있을까요? 정확도로만 충분할까요? 이번 장에서는 이러한 질문에 답하기 위해 모델을 예측하고 그 성능을 평가하는 방법을 설명합니다.

## 모델 예측 및 성능 측정의 핵심 개념

### 1. 모델 예측

모델 예측은 준비된 데이터에 기반하여 결과를 예측하는 단계입니다. 이는 예를 들어 고객의 이탈 여부를 예측하는 것과 같습니다.

```python
from sklearn.ensemble import RandomForestClassifier

# 모델 초기화
model = RandomForestClassifier()

# 예측
predictions = model.predict(test_data)
```

위 코드에서는 Random Forest 모델을 통해 데이터를 예측합니다. `test_data`에 대한 결과를 예측하여 그 결과를 `predictions`에 저장합니다.

### 2. 성능 측정

예측의 성능을 평가하는 데 여러 가지 방법이 있습니다. 대표적으로 정확도, 정밀도, 재현율 등이 있습니다.

```python
from sklearn.metrics import accuracy_score

# 정확도 계산
accuracy = accuracy_score(true_labels, predictions)
print(f"정확도: {accuracy}")
```

여기서는 정확도를 사용합니다. **정확도**란 전체 중 맞춘 비율을 의미하며, `true_labels`는 실제 레이블을 나타냅니다.

## 성능 측정의 내부 구현

예측과 성능 측정 과정이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 모델
    participant 성능 측정 모듈
    사용자->>모델: 데이터 입력
    모델-->>사용자: 예측 결과 반환
    사용자->>성능 측정 모듈: 결과와 실제 레이블 전달
    성능 측정 모듈-->>사용자: 성능 평가 지표 반환
```

### 내부 구현 코드

성능 평가 코드는 결과를 비교하여 각 평가 지표를 계산합니다.

```python
def evaluate_model(predictions, actuals):
    accuracy = accuracy_score(actuals, predictions)
    precision = precision_score(actuals, predictions)
    recall = recall_score(actuals, predictions)
    return accuracy, precision, recall

# 평가 실행
acc, prec, rec = evaluate_model(predictions, true_labels)
```

위의 함수는 `predictions`와 `actuals`를 통해 다양한 지표를 반환합니다. 정확도, 정밀도, 재현율을 포함한 결과는 모델의 성능을 종합적으로 평가하는 데 중요한 역할을 합니다.

## 결론

이번 장에서는 모델 예측과 성능 측정 방법에 대해 배웠습니다. 이를 통해 고객의 이탈 가능성을 효과적으로 예측하고, 예측 모델의 성능을 평가하는 방법을 이해할 수 있습니다. 다음 장에서는 [모델 로드 및 관리](07_모델_로드_및_관리.md)에서 이 모델들을 어떻게 저장하고, 재사용하며 관리하는지에 대해 알아보겠습니다.   

2025-06-29 20:56:54,440 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-2nd-1Team` about the concept: "모델 로드 및 관리". This is Chapter 7.

Concept Details (Note: Provided in Korean):
- Name: 모델 로드 및 관리
- Description:
저장된 머신러닝 및 딥러닝 모델을 로드하여 예측에 활용하며, 모델의 상태를 유지 관리합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)
2. [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)
3. [디스플레이 유틸리티](03_디스플레이_유틸리티.md)
4. [필터링 기능](04_필터링_기능.md)
5. [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)
6. [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)
7. [모델 로드 및 관리](07_모델_로드_및_관리.md)
8. [고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)
9. [나이별 데이터 분석](09_나이별_데이터_분석.md)
10. [고객 이탈 원인과 해결 방안](10_고객_이탈_원인과_해결_방안.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 은행 고객 이탈 예측 시스템

은행 고객 이탈 예측 시스템은 고객 데이터에 기반하여 이탈 가능성을 분석하고 예측하는 대시보드입니다. 이 시스템은 특히 은행이 고객의 이탈을 미리 예측할 수 있도록 도와주어, 적절한 대응 전략을 세울 수 있게 합니다. 

## 동기

은행은 고객 이탈을 줄이는 것이 매우 중요합니다. 고객이 은행을 떠나기 전, 이를 예측할 수 있다면 추가적인 대응조치를 통해 고객 유지율을 높일 수 있습니다. 예를 들어, 한 고객이 최근 거래가 줄어들고 대출 상환에 문제가 있는 경우 이를 빠르게 인지하고 대책을 세우는 것이 가능해집니다.

## 핵심 개념 설명

이 시스템은 여러 단계로 나뉘어 고객의 이탈 가능성을 예측합니다:

1. **데이터 수집**: 고객의 나이, 거래 내역, 고객 만족도 등 다양한 데이터를 수집합니다.
2. **모델 학습**: 수집된 데이터를 사용하여 머신 러닝 모델을 학습시킵니다.
3. **이탈 예측**: 학습된 모델을 통해 고객의 이탈 가능성을 예측합니다.

### Streamlit을 이용한 대시보드

Streamlit은 쉽게 대시보드를 구성할 수 있게 해주는 파이썬 라이브러리입니다. 코드를 한 줄 한 줄 변경하면서, 바로 변경된 부분을 확인할 수 있어 빠르게 대시보드를 개발할 수 있습니다.

```python
import streamlit as st

# 간단한 대시보드 제목 설정
st.title('은행 고객 이탈 예측 대시보드')
```

이 코드는 대시보드의 기본 제목을 설정합니다. **`streamlit`**은 파이썬 코드로 웹 애플리케이션을 쉽게 만들도록 도와줍니다.

## 이탈 예측 시스템의 내부 구현

### 주요 단계 설명

1. **데이터 로드**: 고객 데이터를 읽어옵니다.
2. **예측 실행**: 모델을 사용하여 이탈 위험을 계산합니다.
3. **결과 시각화**: 대시보드에 예측 결과를 표현합니다.

이 과정은 다음의 시퀀스 다이어그램으로 이해할 수 있습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 모델
    사용자->>대시보드: 데이터 입력
    대시보드->>모델: 예측 요청
    모델-->>대시보드: 예측 결과
    대시보드-->>사용자: 결과 시각화
```

### 데이터 로드

고객 데이터를 로드하는 과정을 살펴보겠습니다.

```python
import pandas as pd

# CSV 파일에서 고객 데이터 로드
data = pd.read_csv('customer_data.csv')
```

이 코드는 고객 데이터를 저장한 CSV 파일을 읽어옵니다. **pandas** 라이브러리를 사용하면 데이터를 다루는 과정이 매우 간단해집니다.

### 예측 실행

모델을 이용하여 이탈 가능성을 예측합니다.

```python
# 머신러닝 모델을 불러와서 예측 수행
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(train_X, train_y)

# 예측하기
predictions = model.predict(test_X)
```

위 예제에서는 **RandomForestClassifier**를 사용하여 모델을 학습하고 예측합니다. 간단한 관계를 통해 예측을 수행하며, 이 결과는 대시보드에서 시각화됩니다.

## 결론

이 장에서는 은행 고객 이탈 예측 시스템의 기본 개념과 구현 과정을 간단하게 살펴보았습니다. 다음 장에서는 [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)을 통해 얻어진 결과를 어떻게 구성하고 표현할 수 있는지에 대한 내용을 알아보겠습니다. 이 시스템을 활용하여 은행이 고객 이탈을 효과적으로 관리할 수 있게 됩니다.
---
# Chapter 2: 데이터 시각화 및 대시보드 구성

[이전 장: 은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)에서는 고객 이탈을 예측하는 시스템의 기본 개념과 구현 방법을 소개했습니다. 이번 장에서는 그 결과를 더욱 효과적으로 전달하기 위해 데이터 시각화와 대시보드 구성을 다루어보겠습니다.

## 동기

데이터 시각화는 복잡한 데이터를 이해하기 쉽게 만들어줍니다. 예를 들어, 수많은 숫자 데이터에서 패턴이나 추세를 식별하기 어렵지만, 이를 그래프로 나타내면 한눈에 이해하기가 쉬워집니다. 이처럼 손쉽게 데이터에서 인사이트를 얻는 방식으로, 대시보드는 사용자와 데이터를 연결하는 중요한 역할을 합니다.

## Streamlit을 사용한 시각화 및 대시보드 생성

Streamlit을 사용하면 복잡한 대시보드를 간단한 코드로 쉽게 개발할 수 있습니다. 데이터 시각화를 사용하여 어떠한 정보가 중요한지 사용자에게 명확히 전달할 수 있습니다.

### 기본적인 대시보드 구성

Streamlit의 간단한 코드를 통해 기본적인 대시보드를 구현하는 방법을 살펴봅시다.

```python
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

# 데이터를 로드
data = pd.read_csv('customer_data.csv')

# 데이터의 일부를 시각화
st.title('데이터 시각화 예제')
st.write("고객 데이터 미리보기:")
st.write(data.head())

# 플롯 생성
st.line_chart(data['Age'])
```

위 코드는 Streamlit을 통해 고객 데이터의 일부를 화면에 표시하고, 'Age' 컬럼을 선 그래프로 시각화합니다. **`st.line_chart`** 는 데이터 시각화를 매우 신속하게 수행할 수 있도록 도와줍니다.

### 대시보드에 추가할 다른 요소

대시보드를 더욱 풍부하게 하기 위해 다양한 그래프와 인터랙티브한 원소들을 추가할 수 있습니다.

```python
# 히스토그램 생성
fig, ax = plt.subplots()
ax.hist(data['Age'], bins=20)

# Streamlit에 Matplotlib 플롯 표시
st.pyplot(fig)
```

위 예제에서는 **Matplotlib**을 사용하여 'Age' 컬럼에 대한 히스토그램을 생성하고, 이를 Streamlit 대시보드에 표시합니다. 이러한 플롯은 데이터의 분포를 시각적으로 파악하는데 유용합니다.

## 내부 구현 상세 설명

대시보드의 작동 방식을 이해하기 위해 간단한 시퀀스 다이어그램을 살펴봅시다.

```mermaid
sequenceDiagram
    participant 사용자
    participant 웹페이지
    participant 스트림릿
    사용자->>웹페이지: 접속 요청
    웹페이지->>스트림릿: 데이터 요청
    스트림릿-->>웹페이지: 시각화 데이터
    웹페이지-->>사용자: 데이터 및 시각화 표시
```

이 과정은 사용자가 웹페이지에 접속하여 데이터를 요청하면, 스트림릿이 적절한 시각화 데이터를 준비하고 이를 사용자에게 전달하는 흐름으로 구성됩니다.

## 결론

이 장에서는 Streamlit을 사용한 데이터 시각화 및 대시보드 구성 방법을 살펴보았습니다. 대시보드는 데이터 해석을 용이하게 해주며, 사용자가 원하는 정보를 효과적으로 전달합니다. 다음 장에서는 [디스플레이 유틸리티](03_디스플레이_유틸리티.md)를 통해 대시보드를 보다 다채롭게 구성하는 방법을 배워보겠습니다. 대시보드의 유익한 시각화 요소들을 더해, 앞으로의 분석이 더욱 직관적으로 이루어질 것입니다.
---
# Chapter 3: 디스플레이 유틸리티

[이전 장: 데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)에서는 대시보드를 통해 고객 이탈 데이터를 효과적으로 시각화하는 방법을 배웠습니다. 이번 장에서는 대시보드를 보다 직관적이고 사용자 친화적으로 만드는 데에 필요한 **디스플레이 유틸리티**를 소개하겠습니다.

## 동기

우리가 고객 이탈 예측 결과를 분석할 때, 단순히 숫자나 그래프만 보이면 직관적으로 이해하기 힘들 수 있습니다. 이런 데이터를 더 쉽게 이해하고 활용하기 위해, UI에 표현하는 방식에 다양한 유틸리티를 추가할 수 있습니다. 

예시로, 고객의 이탈 예측 점수를 색깔로 강조하여 중요하고 볼만한 정보를 쉽게 전달할 수 있습니다. 예를 들어, 이탈 가능성이 높은 고객을 빨간색으로 표시하면 곧바로 주의를 기울일 수 있게 됩니다.

## 디스플레이 유틸리티의 핵심 개념

### 데이터 포맷팅
디스플레이 유틸리티에서 가장 기본이 되는 개념은 데이터를 사용자가 쉽게 볼 수 있도록 가공하는 것입니다. 여기에는 날짜 형식 변환, 금액을 통화 형식으로 변환하는 등의 작업이 포함됩니다.

```python
import pandas as pd

# 예시 데이터
data = {'고객': ['A', 'B', 'C'],
        '예측 점수': [0.8, 0.2, 0.5]}

df = pd.DataFrame(data)

# 예측 점수에 따라 색상 적용
df['점수 상태'] = df['예측 점수'].apply(lambda x: '위험' if x > 0.7 else '안전')

print(df)
```

위의 코드에서는 고객의 예측 점수를 기반으로 '위험'과 '안전' 상태로 분류합니다. 이렇게 분류된 데이터는 그에 따라 색깔 등을 통해 대시보드에서 표시할 수 있습니다.

### 조건부 포맷팅
조건부 포맷팅은 사용자에게 중요한 데이터를 강조하는 데 유용합니다. 이 방법을 통해 예측 점수에 따라 색상을 변경할 수 있습니다.

```python
import seaborn as sns

def highlight_rows(row):
    return ['background-color: yellow' if row['점수 상태'] == '위험' else '' for _ in row]

# 스타일 적용
styled_df = df.style.apply(highlight_rows, axis=1)
```

**Seaborn**과 같은 라이브러리를 사용하면, 조건부 포맷팅을 통해 데이터의 시각적 강조를 쉽게 할 수 있습니다.

### 웹 페이지에 적합한 포맷팅
위에서 언급한 기능들을 활용하여 대시보드에도 적용할 수 있습니다.

```python
import streamlit as st

# 대시보드에 데이터 표시
st.title('디스플레이 유틸리티 예제')
st.write(styled_df)
```

위 코드를 통해 Streamlit 대시보드에 조건부 포맷팅이 적용된 데이터를 쉽게 표시할 수 있습니다. Streamlit의 **`st.write()`** 함수는 데이터프레임에 대해 다양한 포맷팅을 지원합니다.

## 디스플레이 유틸리티 내부 구현

디스플레이 유틸리티의 작동 방식을 이해하기 위해 시퀀스 다이어그램을 사용해봅시다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 디스플레이 유틸리티
    사용자->>대시보드: 데이터 요청
    대시보드->>디스플레이 유틸리티: 데이터 형식 지정 요청
    디스플레이 유틸리티-->>대시보드: 포맷팅된 데이터 반환
    대시보드-->>사용자: 결과 표시
```

위 다이어그램은 디스플레이 유틸리티가 데이터를 대시보드에 표시하기 전에 어떻게 처리하는지를 보여줍니다.

### 내부 코드 구현

디스플레이 유틸리티의 내부는 다양한 형식 지정 및 조건부 포맷팅을 통해 구성됩니다. 각 단계에서 데이터를 보다 직관적으로 보이도록 만드는 다양한 함수들을 활용합니다.

```python
def format_currency(value):
    return "${:,.2f}".format(value)

formatted_value = format_currency(1500)
print(formatted_value)  # 출력: $1,500.00
```

위 함수는 금액 데이터를 통화 형식으로 변환합니다. 이러한 형식을 통해 사용자가 데이터를 쉽게 이해할 수 있게 됩니다.

## 결론

이번 장에서 우리는 디스플레이 유틸리티를 활용하여 데이터를 보다 사용자 친화적으로 변환하고 강조하는 방법을 배웠습니다. 이렇게 변환된 데이터를 통해 사용자는 더욱 직관적으로 정보를 받아들일 수 있습니다. 다음 장에서는 [필터링 기능](04_필터링_기능.md)을 통해 대시보드 상에서 데이터를 효율적으로 필터링하는 방법을 알아보겠습니다. 이를 통해 우리는 사용자에게 더 개인화된 데이터 뷰를 제공합니다.
---
# Chapter 4: 필터링 기능

[이전 장: 디스플레이 유틸리티](03_디스플레이_유틸리티.md)에서는 다양한 유틸리티를 통해 데이터를 쉽게 이해할 수 있도록 돕는 방법에 대해 알아보았습니다. 이번 장에서는 대시보드에서 사용자에게 필요한 정보만 선택적으로 보여줄 수 있는 필터링 기능을 소개하겠습니다.

## 동기

고객 데이터를 통해 인사이트를 얻고자 할 때, 모든 데이터를 한 번에 살펴보는 것은 어렵고 시간이 많이 소요될 수 있습니다. 이러한 문제를 해결하기 위해 우리는 필터링 기능을 사용할 수 있습니다. 필터링 기능을 통해 사용자는 자신이 원하는 특정 조건에 맞는 데이터만을 선별적으로 볼 수 있습니다. 예를 들어, 특정 연령대의 고객만을 대상으로 이탈 가능성을 분석하고자 할 때 유용합니다.

## 필터링 기능의 핵심 개념

### 필터링의 기본 원리
필터링 기능은 사용자로 하여금 자신의 요구에 맞는 데이터를 선택할 수 있도록 합니다. 보통 필터링은 특정 조건을 설정하고 데이터 중 해당 조건에 일치하는 항목만을 추출하는 방식으로 이루어집니다.

```python
import pandas as pd

# 데이터 예시
data = {'고객': ['A', 'B', 'C'],
        '나이': [25, 30, 22],
        '이탈 가능성': [0.1, 0.4, 0.8]}

df = pd.DataFrame(data)

# 나이가 25세 이상인 고객 데이터 필터링
filtered_data = df[df['나이'] >= 25]
print(filtered_data)
```

위 코드에서는 '나이'가 25세 이상인 고객들만 필터링하여 표시합니다. 이 기능은 다양한 조건을 통해 데이터를 세분화하고 분석하는데 매우 유용합니다.

### 코드 활용 및 예시

사용자가 필요로 하는 데이터만을 선택할 수 있는 필터를 구성하는 방법은 다음과 같습니다.

```python
import streamlit as st

# 스트림릿 슬라이더를 통한 나이 기준 필터링 설정
age_filter = st.slider('필터링 나이', 0, 100, 25)

# 설정된 나이 기준에 따른 데이터 필터링
filtered_data = df[df['나이'] >= age_filter]
st.write(filtered_data)
```

이 코드는 Streamlit 슬라이더를 사용하여 사용자가 나이 기준을 설정하고, 그에 맞춰 데이터를 필터링합니다. 이로 인해 대시보드 사용자가 실시간으로 필터링 조건을 변경할 수 있습니다.

## 내부 구현 방식을 통한 이해

필터링 기능이 어떻게 내부에서 작동하는지를 이해하기 위해 시퀀스 다이어그램을 참고합니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 필터링 모듈
    사용자->>대시보드: 필터 조건 설정
    대시보드->>필터링 모듈: 조건 전달
    필터링 모듈-->>대시보드: 필터링된 데이터 반환
    대시보드-->>사용자: 결과 데이터 표시
```

위의 다이어그램은 사용자가 설정한 조건에 따라 데이터가 필터링되고 그 결과가 대시보드에 표시되는 과정을 설명합니다.

### 내부 코드 구현

필터링 기능은 조건을 기반으로 데이터를 선별하는 다양한 알고리즘과 함수를 사용할 수 있습니다. 다음은 pandas 라이브러리를 사용하는 기본적인 방법입니다.

```python
def filter_data(data_frame, condition):
    return data_frame.query(condition)

# 예시: 이탈 가능성이 0.3 이상인 데이터를 필터링
condition = "이탈 가능성 > 0.3"
filtered_result = filter_data(df, condition)
print(filtered_result)
```

위 함수는 pandas의 **`query()`** 메서드를 사용하여 조건에 맞는 데이터를 추출합니다. 이러한 방법을 통해 데이터를 자유롭게 필터링할 수 있습니다.

## 결론

이번 장에서는 대시보드에서 필터링 기능을 통해 사용자가 원하는 특정 조건의 데이터를 선별적으로 확인하는 방법에 대해 배웠습니다. 이런 기능을 사용하면 더 개인화된 데이터 분석이 가능해집니다. 다음 장에서는 [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)를 통해 데이터를 로드하고 준비하는 방법에 대해 더 알아보겠습니다.
---
# Chapter 5: 데이터 전처리 및 로드

[이전 장: 필터링 기능](04_필터링_기능.md)에서는 대시보드를 통해 원하는 데이터를 필터링하는 방법을 배웠습니다. 이번 장에서는 머신러닝 모델을 위한 중요한 단계인 **데이터 전처리 및 로드**에 대해 알아보겠습니다.

## 동기

데이터 전처리는 머신러닝 모델의 성공적인 학습을 위해 필수적으로 필요합니다. 데이터를 로드하고 사용하기 용이하게 준비하지 않으면 결측값이나 형식 문제로 인해 예측 정확도에 영향을 줄 수 있습니다. 따라서 데이터 전처리를 적절히 수행하는 것은 매우 중요합니다.

### 예시 상황

예시로, 고객 데이터에서 누락된 값이 있는 상황을 고려해 봅시다. 이런 데이터로 모델을 훈련하면 부정확한 결과를 초래할 수 있습니다. 데이터 전처리는 이러한 문제를 해결하기 위해 데이터 형식 변환, 결측값 대체 등의 작업을 포함합니다.

## 데이터 전처리의 핵심 개념

### 데이터 로드

먼저, 데이터를 로딩하는 단계부터 시작해야 합니다. 이 예제에서는 CSV 파일을 읽어옵니다.

```python
import pandas as pd

# 고객 데이터를 CSV에서 읽어오기
data = pd.read_csv('customer_data.csv')
```

**`pandas`**를 사용하여 CSV 파일을 읽어옵니다. 이러면 데이터를 DataFrame 형식으로 쉽게 다룰 수 있습니다.

### 결측값 처리

데이터 중 결측값 또는 누락된 값을 처리해야 합니다. 데이터의 일관성을 확보하는 것이 중요하기 때문입니다.

```python
# 결측값을 평균값으로 대체
data.fillna(data.mean(), inplace=True)
```

위 코드에서는 결측값을 각 열의 평균값으로 대체하여 데이터의 완전성을 확보합니다.

### 범주형 데이터 처리

데이터에 범주형 값을 시계열이나 숫자로 변환하는 것이 중요합니다.

```python
# 범주형 변수를 수치형으로 변환
data['Gender'] = data['Gender'].map({'Male': 0, 'Female': 1})
```

여기서 성별 데이터를 'Male'을 0으로, 'Female'을 1로 변환하여 수치형 변수로 변경합니다.

### 수치형 데이터 정규화

데이터의 스케일링을 통해 모델 훈련 성능을 향상시킬 수 있습니다.

```python
from sklearn.preprocessing import MinMaxScaler

# 스케일러 초기화 및 적용
scaler = MinMaxScaler()
data[['Age', 'Salary']] = scaler.fit_transform(data[['Age', 'Salary']])
```

위 코드에서는 **`MinMaxScaler`**를 사용하여 'Age'와 'Salary' 열을 정규화합니다. 이로 인해 각각의 값이 0과 1 사이로 조정됩니다.

## 데이터 전처리 흐름

이제 전체 데이터를 전처리하는 흐름을 이해할 수 있습니다. 다음 시퀀스 다이어그램은 전처리 과정을 시각적으로 나타냅니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 시스템
    participant 전처리 모듈
    사용자->>시스템: 데이터 로드 요청
    시스템->>전처리 모듈: 데이터 전달
    전처리 모듈-->>시스템: 전처리된 데이터 반환
    시스템-->>사용자: 처리 완료된 데이터 표시
```

이 과정에서는 사용자가 데이터 로드를 요청하면 시스템이 전처리 모듈을 통해 데이터를 준비하고, 완성된 데이터를 반환받아 사용자에게 전달합니다.

### 전처리 코드 내부 구현

데이터 전처리의 실제 코드를 확인해보겠습니다. 데이터 전처리는 체계적인 단계를 통해 수행됩니다.

```python
def preprocess_data(file_path):
    df = pd.read_csv(file_path)
    
    # 결측값 확인 및 대체
    df.fillna(df.mean(), inplace=True)
    
    # 범주형 변수 변환
    df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})
    
    # 수치형 데이터 정규화
    scaler = MinMaxScaler()
    df[['Age', 'Salary']] = scaler.fit_transform(df[['Age', 'Salary']])
    
    return df

processed_data = preprocess_data('customer_data.csv')
```

함수 **`preprocess_data`**는 데이터를 로드하고, 결측값 처리, 범주형 변수 변환, 데이터 정규화를 포함한 모든 전처리 과정을 실행합니다. 결과적으로 모델에 알맞은 형태로 데이터를 변환합니다.

## 결론

이번 장에서는 데이터 전처리와 로드 과정을 통해 데이터의 품질을 높이고 모델 학습에 대비하는 방법을 배웠습니다. 전처리 과정을 잘 이해하면 향후 머신러닝 모델의 성능을 향상시킬 수 있습니다. 다음 장 [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)에서는 준비된 데이터를 사용하여 모델을 학습시키고 예측 성능을 측정하는 방법에 대해 알아보겠습니다.
---
# Chapter 6: 모델 예측 및 성능 측정

[이전 장: 데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)에서는 머신러닝 모델에 데이터를 준비하는 방법을 배웠습니다. 이번 장에서는 이러한 데이터를 사용하여 실제로 모델을 예측하고, 그 성능을 측정하는 방법을 알아보겠습니다.

## 동기

예를 들어, 우리는 고객의 이탈 가능성을 예측하는 모델을 만들려고 합니다. 이를 위해 Random Forest, Gradient Boosting, 그리고 Deep Learning 모델을 사용합니다. 이 예측이 정확하다면 은행은 고객 이탈을 사전에 예방할 수 있습니다. 하지만 예측의 정확도를 어떻게 평가할 수 있을까요? 정확도로만 충분할까요? 이번 장에서는 이러한 질문에 답하기 위해 모델을 예측하고 그 성능을 평가하는 방법을 설명합니다.

## 모델 예측 및 성능 측정의 핵심 개념

### 1. 모델 예측

모델 예측은 준비된 데이터에 기반하여 결과를 예측하는 단계입니다. 이는 예를 들어 고객의 이탈 여부를 예측하는 것과 같습니다.

```python
from sklearn.ensemble import RandomForestClassifier

# 모델 초기화
model = RandomForestClassifier()

# 예측
predictions = model.predict(test_data)
```

위 코드에서는 Random Forest 모델을 통해 데이터를 예측합니다. `test_data`에 대한 결과를 예측하여 그 결과를 `predictions`에 저장합니다.

### 2. 성능 측정

예측의 성능을 평가하는 데 여러 가지 방법이 있습니다. 대표적으로 정확도, 정밀도, 재현율 등이 있습니다.

```python
from sklearn.metrics import accuracy_score

# 정확도 계산
accuracy = accuracy_score(true_labels, predictions)
print(f"정확도: {accuracy}")
```

여기서는 정확도를 사용합니다. **정확도**란 전체 중 맞춘 비율을 의미하며, `true_labels`는 실제 레이블을 나타냅니다.

## 성능 측정의 내부 구현

예측과 성능 측정 과정이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 모델
    participant 성능 측정 모듈
    사용자->>모델: 데이터 입력
    모델-->>사용자: 예측 결과 반환
    사용자->>성능 측정 모듈: 결과와 실제 레이블 전달
    성능 측정 모듈-->>사용자: 성능 평가 지표 반환
```

### 내부 구현 코드

성능 평가 코드는 결과를 비교하여 각 평가 지표를 계산합니다.

```python
def evaluate_model(predictions, actuals):
    accuracy = accuracy_score(actuals, predictions)
    precision = precision_score(actuals, predictions)
    recall = recall_score(actuals, predictions)
    return accuracy, precision, recall

# 평가 실행
acc, prec, rec = evaluate_model(predictions, true_labels)
```

위의 함수는 `predictions`와 `actuals`를 통해 다양한 지표를 반환합니다. 정확도, 정밀도, 재현율을 포함한 결과는 모델의 성능을 종합적으로 평가하는 데 중요한 역할을 합니다.

## 결론

이번 장에서는 모델 예측과 성능 측정 방법에 대해 배웠습니다. 이를 통해 고객의 이탈 가능성을 효과적으로 예측하고, 예측 모델의 성능을 평가하는 방법을 이해할 수 있습니다. 다음 장에서는 [모델 로드 및 관리](07_모델_로드_및_관리.md)에서 이 모델들을 어떻게 저장하고, 재사용하며 관리하는지에 대해 알아보겠습니다.   


Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 7: 모델 로드 및 관리`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:56:54,614 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:57:04,058 - INFO - RESPONSE: # Chapter 7: 모델 로드 및 관리

[이전 장: 모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)에서는 은행 고객 이탈 예측 모델의 예측 결과와 성능을 평가하는 방법에 대해 배웠습니다. 이번 장에서는 예측 모델을 저장하고, 추후 필요할 때 다시 불러올 수 있게 관리하는 방법을 알아보겠습니다.

## 동기

모델 학습은 많은 계산 시간과 자원을 필요로 합니다. 따라서 매번 새롭게 모델을 학습시키기보다는 한번 저장해 두고 필요할 때 불러와 사용하는 것이 매우 효율적입니다. 예를 들어, 은행이 매주 고객 이탈을 예측하고자 할 때, 이전에 학습한 모델을 불러와 활용할 수 있습니다. 이 과정에서는 **모델 저장**과 **모델 로드**를 다루어 보겠습니다.

## 모델 로드 및 관리의 핵심 개념

### 1. 모델 저장

모델을 저장하면 나중에도 동일한 모델을 사용하여 예측할 수 있습니다. Scikit-learn에서는 `joblib` 라이브러리를 활용하여 간단히 모델을 저장할 수 있습니다.

```python
import joblib

# 학습된 모델을 저장
joblib.dump(model, 'customer_churn_model.pkl')
```

위 코드는 학습된 모델 객체를 'customer_churn_model.pkl' 파일로 저장합니다. 이렇게 저장한 모델은 언제든지 불러올 수 있습니다.

### 2. 모델 로드

저장한 모델을 불러와 사용하려면 `joblib`의 `load` 함수를 사용합니다.

```python
# 저장된 모델 로드
loaded_model = joblib.load('customer_churn_model.pkl')
```

`loaded_model`은 이제 저장된 모델과 동일한 상태를 가지며, 바로 예측에 사용할 수 있습니다.

## 모델 관리 흐름

모델 저장 및 로드 과정이 어떻게 진행되는지를 이해하기 위해 시퀀스 다이어그램을 이용합니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 모델 관리 시스템
    사용자->>모델 관리 시스템: 모델 저장 요청
    모델 관리 시스템-->>사용자: 저장 완료 확인
    사용자->>모델 관리 시스템: 모델 로드 요청
    모델 관리 시스템-->>사용자: 로드된 모델 반환
```

### 내부 구현 코드

모델 저장 및 로드는 간단한 코드를 통해 이루어집니다. 파일 저장 경로만 정확히 지정해주면, 필요할 때 쉽게 불러와서 사용할 수 있습니다.

```python
def save_model(model, filename):
    # 모델을 파일로 저장
    joblib.dump(model, filename)

def load_model(filename):
    # 파일에서 모델 로드
    return joblib.load(filename)

# 모델 학습 후 저장하기
save_model(model, 'churn_model.pkl')

# 필요할 때 모델 불러오기
loaded_model = load_model('churn_model.pkl')
```

**`save_model`** 함수는 모델을 지정된 파일로 저장하고, **`load_model`** 함수는 해당 파일에서 모델을 불러옵니다. 이러한 기능을 통해 모델을 쉽게 관리하고 이용할 수 있습니다.

## 결론

이번 장에서는 머신러닝 모델을 저장하고 불러오는 방법에 대해 알아보았습니다. 이렇게 하면 학습한 모델을 영구적으로 보관하고, 필요할 때 빠르게 재사용할 수 있습니다. 다음 장에서는 [고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)을 통해 은행 고객 이탈 분석과 관련된 데이터를 어떻게 생성하는지 살펴보겠습니다. 이 데이터는 더 나은 예측을 위한 중요한 자료가 됩니다.
2025-06-29 20:57:04,069 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-2nd-1Team` about the concept: "고객 이탈 분석 데이터 생성". This is Chapter 8.

Concept Details (Note: Provided in Korean):
- Name: 고객 이탈 분석 데이터 생성
- Description:
모델 예측 결과를 바탕으로 위험도별 주요 분석 데이터를 생성하여 고객 이탈 원인과 해결 방안을 도출하는 데 사용됩니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)
2. [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)
3. [디스플레이 유틸리티](03_디스플레이_유틸리티.md)
4. [필터링 기능](04_필터링_기능.md)
5. [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)
6. [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)
7. [모델 로드 및 관리](07_모델_로드_및_관리.md)
8. [고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)
9. [나이별 데이터 분석](09_나이별_데이터_분석.md)
10. [고객 이탈 원인과 해결 방안](10_고객_이탈_원인과_해결_방안.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 은행 고객 이탈 예측 시스템

은행 고객 이탈 예측 시스템은 고객 데이터에 기반하여 이탈 가능성을 분석하고 예측하는 대시보드입니다. 이 시스템은 특히 은행이 고객의 이탈을 미리 예측할 수 있도록 도와주어, 적절한 대응 전략을 세울 수 있게 합니다. 

## 동기

은행은 고객 이탈을 줄이는 것이 매우 중요합니다. 고객이 은행을 떠나기 전, 이를 예측할 수 있다면 추가적인 대응조치를 통해 고객 유지율을 높일 수 있습니다. 예를 들어, 한 고객이 최근 거래가 줄어들고 대출 상환에 문제가 있는 경우 이를 빠르게 인지하고 대책을 세우는 것이 가능해집니다.

## 핵심 개념 설명

이 시스템은 여러 단계로 나뉘어 고객의 이탈 가능성을 예측합니다:

1. **데이터 수집**: 고객의 나이, 거래 내역, 고객 만족도 등 다양한 데이터를 수집합니다.
2. **모델 학습**: 수집된 데이터를 사용하여 머신 러닝 모델을 학습시킵니다.
3. **이탈 예측**: 학습된 모델을 통해 고객의 이탈 가능성을 예측합니다.

### Streamlit을 이용한 대시보드

Streamlit은 쉽게 대시보드를 구성할 수 있게 해주는 파이썬 라이브러리입니다. 코드를 한 줄 한 줄 변경하면서, 바로 변경된 부분을 확인할 수 있어 빠르게 대시보드를 개발할 수 있습니다.

```python
import streamlit as st

# 간단한 대시보드 제목 설정
st.title('은행 고객 이탈 예측 대시보드')
```

이 코드는 대시보드의 기본 제목을 설정합니다. **`streamlit`**은 파이썬 코드로 웹 애플리케이션을 쉽게 만들도록 도와줍니다.

## 이탈 예측 시스템의 내부 구현

### 주요 단계 설명

1. **데이터 로드**: 고객 데이터를 읽어옵니다.
2. **예측 실행**: 모델을 사용하여 이탈 위험을 계산합니다.
3. **결과 시각화**: 대시보드에 예측 결과를 표현합니다.

이 과정은 다음의 시퀀스 다이어그램으로 이해할 수 있습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 모델
    사용자->>대시보드: 데이터 입력
    대시보드->>모델: 예측 요청
    모델-->>대시보드: 예측 결과
    대시보드-->>사용자: 결과 시각화
```

### 데이터 로드

고객 데이터를 로드하는 과정을 살펴보겠습니다.

```python
import pandas as pd

# CSV 파일에서 고객 데이터 로드
data = pd.read_csv('customer_data.csv')
```

이 코드는 고객 데이터를 저장한 CSV 파일을 읽어옵니다. **pandas** 라이브러리를 사용하면 데이터를 다루는 과정이 매우 간단해집니다.

### 예측 실행

모델을 이용하여 이탈 가능성을 예측합니다.

```python
# 머신러닝 모델을 불러와서 예측 수행
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(train_X, train_y)

# 예측하기
predictions = model.predict(test_X)
```

위 예제에서는 **RandomForestClassifier**를 사용하여 모델을 학습하고 예측합니다. 간단한 관계를 통해 예측을 수행하며, 이 결과는 대시보드에서 시각화됩니다.

## 결론

이 장에서는 은행 고객 이탈 예측 시스템의 기본 개념과 구현 과정을 간단하게 살펴보았습니다. 다음 장에서는 [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)을 통해 얻어진 결과를 어떻게 구성하고 표현할 수 있는지에 대한 내용을 알아보겠습니다. 이 시스템을 활용하여 은행이 고객 이탈을 효과적으로 관리할 수 있게 됩니다.
---
# Chapter 2: 데이터 시각화 및 대시보드 구성

[이전 장: 은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)에서는 고객 이탈을 예측하는 시스템의 기본 개념과 구현 방법을 소개했습니다. 이번 장에서는 그 결과를 더욱 효과적으로 전달하기 위해 데이터 시각화와 대시보드 구성을 다루어보겠습니다.

## 동기

데이터 시각화는 복잡한 데이터를 이해하기 쉽게 만들어줍니다. 예를 들어, 수많은 숫자 데이터에서 패턴이나 추세를 식별하기 어렵지만, 이를 그래프로 나타내면 한눈에 이해하기가 쉬워집니다. 이처럼 손쉽게 데이터에서 인사이트를 얻는 방식으로, 대시보드는 사용자와 데이터를 연결하는 중요한 역할을 합니다.

## Streamlit을 사용한 시각화 및 대시보드 생성

Streamlit을 사용하면 복잡한 대시보드를 간단한 코드로 쉽게 개발할 수 있습니다. 데이터 시각화를 사용하여 어떠한 정보가 중요한지 사용자에게 명확히 전달할 수 있습니다.

### 기본적인 대시보드 구성

Streamlit의 간단한 코드를 통해 기본적인 대시보드를 구현하는 방법을 살펴봅시다.

```python
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

# 데이터를 로드
data = pd.read_csv('customer_data.csv')

# 데이터의 일부를 시각화
st.title('데이터 시각화 예제')
st.write("고객 데이터 미리보기:")
st.write(data.head())

# 플롯 생성
st.line_chart(data['Age'])
```

위 코드는 Streamlit을 통해 고객 데이터의 일부를 화면에 표시하고, 'Age' 컬럼을 선 그래프로 시각화합니다. **`st.line_chart`** 는 데이터 시각화를 매우 신속하게 수행할 수 있도록 도와줍니다.

### 대시보드에 추가할 다른 요소

대시보드를 더욱 풍부하게 하기 위해 다양한 그래프와 인터랙티브한 원소들을 추가할 수 있습니다.

```python
# 히스토그램 생성
fig, ax = plt.subplots()
ax.hist(data['Age'], bins=20)

# Streamlit에 Matplotlib 플롯 표시
st.pyplot(fig)
```

위 예제에서는 **Matplotlib**을 사용하여 'Age' 컬럼에 대한 히스토그램을 생성하고, 이를 Streamlit 대시보드에 표시합니다. 이러한 플롯은 데이터의 분포를 시각적으로 파악하는데 유용합니다.

## 내부 구현 상세 설명

대시보드의 작동 방식을 이해하기 위해 간단한 시퀀스 다이어그램을 살펴봅시다.

```mermaid
sequenceDiagram
    participant 사용자
    participant 웹페이지
    participant 스트림릿
    사용자->>웹페이지: 접속 요청
    웹페이지->>스트림릿: 데이터 요청
    스트림릿-->>웹페이지: 시각화 데이터
    웹페이지-->>사용자: 데이터 및 시각화 표시
```

이 과정은 사용자가 웹페이지에 접속하여 데이터를 요청하면, 스트림릿이 적절한 시각화 데이터를 준비하고 이를 사용자에게 전달하는 흐름으로 구성됩니다.

## 결론

이 장에서는 Streamlit을 사용한 데이터 시각화 및 대시보드 구성 방법을 살펴보았습니다. 대시보드는 데이터 해석을 용이하게 해주며, 사용자가 원하는 정보를 효과적으로 전달합니다. 다음 장에서는 [디스플레이 유틸리티](03_디스플레이_유틸리티.md)를 통해 대시보드를 보다 다채롭게 구성하는 방법을 배워보겠습니다. 대시보드의 유익한 시각화 요소들을 더해, 앞으로의 분석이 더욱 직관적으로 이루어질 것입니다.
---
# Chapter 3: 디스플레이 유틸리티

[이전 장: 데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)에서는 대시보드를 통해 고객 이탈 데이터를 효과적으로 시각화하는 방법을 배웠습니다. 이번 장에서는 대시보드를 보다 직관적이고 사용자 친화적으로 만드는 데에 필요한 **디스플레이 유틸리티**를 소개하겠습니다.

## 동기

우리가 고객 이탈 예측 결과를 분석할 때, 단순히 숫자나 그래프만 보이면 직관적으로 이해하기 힘들 수 있습니다. 이런 데이터를 더 쉽게 이해하고 활용하기 위해, UI에 표현하는 방식에 다양한 유틸리티를 추가할 수 있습니다. 

예시로, 고객의 이탈 예측 점수를 색깔로 강조하여 중요하고 볼만한 정보를 쉽게 전달할 수 있습니다. 예를 들어, 이탈 가능성이 높은 고객을 빨간색으로 표시하면 곧바로 주의를 기울일 수 있게 됩니다.

## 디스플레이 유틸리티의 핵심 개념

### 데이터 포맷팅
디스플레이 유틸리티에서 가장 기본이 되는 개념은 데이터를 사용자가 쉽게 볼 수 있도록 가공하는 것입니다. 여기에는 날짜 형식 변환, 금액을 통화 형식으로 변환하는 등의 작업이 포함됩니다.

```python
import pandas as pd

# 예시 데이터
data = {'고객': ['A', 'B', 'C'],
        '예측 점수': [0.8, 0.2, 0.5]}

df = pd.DataFrame(data)

# 예측 점수에 따라 색상 적용
df['점수 상태'] = df['예측 점수'].apply(lambda x: '위험' if x > 0.7 else '안전')

print(df)
```

위의 코드에서는 고객의 예측 점수를 기반으로 '위험'과 '안전' 상태로 분류합니다. 이렇게 분류된 데이터는 그에 따라 색깔 등을 통해 대시보드에서 표시할 수 있습니다.

### 조건부 포맷팅
조건부 포맷팅은 사용자에게 중요한 데이터를 강조하는 데 유용합니다. 이 방법을 통해 예측 점수에 따라 색상을 변경할 수 있습니다.

```python
import seaborn as sns

def highlight_rows(row):
    return ['background-color: yellow' if row['점수 상태'] == '위험' else '' for _ in row]

# 스타일 적용
styled_df = df.style.apply(highlight_rows, axis=1)
```

**Seaborn**과 같은 라이브러리를 사용하면, 조건부 포맷팅을 통해 데이터의 시각적 강조를 쉽게 할 수 있습니다.

### 웹 페이지에 적합한 포맷팅
위에서 언급한 기능들을 활용하여 대시보드에도 적용할 수 있습니다.

```python
import streamlit as st

# 대시보드에 데이터 표시
st.title('디스플레이 유틸리티 예제')
st.write(styled_df)
```

위 코드를 통해 Streamlit 대시보드에 조건부 포맷팅이 적용된 데이터를 쉽게 표시할 수 있습니다. Streamlit의 **`st.write()`** 함수는 데이터프레임에 대해 다양한 포맷팅을 지원합니다.

## 디스플레이 유틸리티 내부 구현

디스플레이 유틸리티의 작동 방식을 이해하기 위해 시퀀스 다이어그램을 사용해봅시다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 디스플레이 유틸리티
    사용자->>대시보드: 데이터 요청
    대시보드->>디스플레이 유틸리티: 데이터 형식 지정 요청
    디스플레이 유틸리티-->>대시보드: 포맷팅된 데이터 반환
    대시보드-->>사용자: 결과 표시
```

위 다이어그램은 디스플레이 유틸리티가 데이터를 대시보드에 표시하기 전에 어떻게 처리하는지를 보여줍니다.

### 내부 코드 구현

디스플레이 유틸리티의 내부는 다양한 형식 지정 및 조건부 포맷팅을 통해 구성됩니다. 각 단계에서 데이터를 보다 직관적으로 보이도록 만드는 다양한 함수들을 활용합니다.

```python
def format_currency(value):
    return "${:,.2f}".format(value)

formatted_value = format_currency(1500)
print(formatted_value)  # 출력: $1,500.00
```

위 함수는 금액 데이터를 통화 형식으로 변환합니다. 이러한 형식을 통해 사용자가 데이터를 쉽게 이해할 수 있게 됩니다.

## 결론

이번 장에서 우리는 디스플레이 유틸리티를 활용하여 데이터를 보다 사용자 친화적으로 변환하고 강조하는 방법을 배웠습니다. 이렇게 변환된 데이터를 통해 사용자는 더욱 직관적으로 정보를 받아들일 수 있습니다. 다음 장에서는 [필터링 기능](04_필터링_기능.md)을 통해 대시보드 상에서 데이터를 효율적으로 필터링하는 방법을 알아보겠습니다. 이를 통해 우리는 사용자에게 더 개인화된 데이터 뷰를 제공합니다.
---
# Chapter 4: 필터링 기능

[이전 장: 디스플레이 유틸리티](03_디스플레이_유틸리티.md)에서는 다양한 유틸리티를 통해 데이터를 쉽게 이해할 수 있도록 돕는 방법에 대해 알아보았습니다. 이번 장에서는 대시보드에서 사용자에게 필요한 정보만 선택적으로 보여줄 수 있는 필터링 기능을 소개하겠습니다.

## 동기

고객 데이터를 통해 인사이트를 얻고자 할 때, 모든 데이터를 한 번에 살펴보는 것은 어렵고 시간이 많이 소요될 수 있습니다. 이러한 문제를 해결하기 위해 우리는 필터링 기능을 사용할 수 있습니다. 필터링 기능을 통해 사용자는 자신이 원하는 특정 조건에 맞는 데이터만을 선별적으로 볼 수 있습니다. 예를 들어, 특정 연령대의 고객만을 대상으로 이탈 가능성을 분석하고자 할 때 유용합니다.

## 필터링 기능의 핵심 개념

### 필터링의 기본 원리
필터링 기능은 사용자로 하여금 자신의 요구에 맞는 데이터를 선택할 수 있도록 합니다. 보통 필터링은 특정 조건을 설정하고 데이터 중 해당 조건에 일치하는 항목만을 추출하는 방식으로 이루어집니다.

```python
import pandas as pd

# 데이터 예시
data = {'고객': ['A', 'B', 'C'],
        '나이': [25, 30, 22],
        '이탈 가능성': [0.1, 0.4, 0.8]}

df = pd.DataFrame(data)

# 나이가 25세 이상인 고객 데이터 필터링
filtered_data = df[df['나이'] >= 25]
print(filtered_data)
```

위 코드에서는 '나이'가 25세 이상인 고객들만 필터링하여 표시합니다. 이 기능은 다양한 조건을 통해 데이터를 세분화하고 분석하는데 매우 유용합니다.

### 코드 활용 및 예시

사용자가 필요로 하는 데이터만을 선택할 수 있는 필터를 구성하는 방법은 다음과 같습니다.

```python
import streamlit as st

# 스트림릿 슬라이더를 통한 나이 기준 필터링 설정
age_filter = st.slider('필터링 나이', 0, 100, 25)

# 설정된 나이 기준에 따른 데이터 필터링
filtered_data = df[df['나이'] >= age_filter]
st.write(filtered_data)
```

이 코드는 Streamlit 슬라이더를 사용하여 사용자가 나이 기준을 설정하고, 그에 맞춰 데이터를 필터링합니다. 이로 인해 대시보드 사용자가 실시간으로 필터링 조건을 변경할 수 있습니다.

## 내부 구현 방식을 통한 이해

필터링 기능이 어떻게 내부에서 작동하는지를 이해하기 위해 시퀀스 다이어그램을 참고합니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 필터링 모듈
    사용자->>대시보드: 필터 조건 설정
    대시보드->>필터링 모듈: 조건 전달
    필터링 모듈-->>대시보드: 필터링된 데이터 반환
    대시보드-->>사용자: 결과 데이터 표시
```

위의 다이어그램은 사용자가 설정한 조건에 따라 데이터가 필터링되고 그 결과가 대시보드에 표시되는 과정을 설명합니다.

### 내부 코드 구현

필터링 기능은 조건을 기반으로 데이터를 선별하는 다양한 알고리즘과 함수를 사용할 수 있습니다. 다음은 pandas 라이브러리를 사용하는 기본적인 방법입니다.

```python
def filter_data(data_frame, condition):
    return data_frame.query(condition)

# 예시: 이탈 가능성이 0.3 이상인 데이터를 필터링
condition = "이탈 가능성 > 0.3"
filtered_result = filter_data(df, condition)
print(filtered_result)
```

위 함수는 pandas의 **`query()`** 메서드를 사용하여 조건에 맞는 데이터를 추출합니다. 이러한 방법을 통해 데이터를 자유롭게 필터링할 수 있습니다.

## 결론

이번 장에서는 대시보드에서 필터링 기능을 통해 사용자가 원하는 특정 조건의 데이터를 선별적으로 확인하는 방법에 대해 배웠습니다. 이런 기능을 사용하면 더 개인화된 데이터 분석이 가능해집니다. 다음 장에서는 [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)를 통해 데이터를 로드하고 준비하는 방법에 대해 더 알아보겠습니다.
---
# Chapter 5: 데이터 전처리 및 로드

[이전 장: 필터링 기능](04_필터링_기능.md)에서는 대시보드를 통해 원하는 데이터를 필터링하는 방법을 배웠습니다. 이번 장에서는 머신러닝 모델을 위한 중요한 단계인 **데이터 전처리 및 로드**에 대해 알아보겠습니다.

## 동기

데이터 전처리는 머신러닝 모델의 성공적인 학습을 위해 필수적으로 필요합니다. 데이터를 로드하고 사용하기 용이하게 준비하지 않으면 결측값이나 형식 문제로 인해 예측 정확도에 영향을 줄 수 있습니다. 따라서 데이터 전처리를 적절히 수행하는 것은 매우 중요합니다.

### 예시 상황

예시로, 고객 데이터에서 누락된 값이 있는 상황을 고려해 봅시다. 이런 데이터로 모델을 훈련하면 부정확한 결과를 초래할 수 있습니다. 데이터 전처리는 이러한 문제를 해결하기 위해 데이터 형식 변환, 결측값 대체 등의 작업을 포함합니다.

## 데이터 전처리의 핵심 개념

### 데이터 로드

먼저, 데이터를 로딩하는 단계부터 시작해야 합니다. 이 예제에서는 CSV 파일을 읽어옵니다.

```python
import pandas as pd

# 고객 데이터를 CSV에서 읽어오기
data = pd.read_csv('customer_data.csv')
```

**`pandas`**를 사용하여 CSV 파일을 읽어옵니다. 이러면 데이터를 DataFrame 형식으로 쉽게 다룰 수 있습니다.

### 결측값 처리

데이터 중 결측값 또는 누락된 값을 처리해야 합니다. 데이터의 일관성을 확보하는 것이 중요하기 때문입니다.

```python
# 결측값을 평균값으로 대체
data.fillna(data.mean(), inplace=True)
```

위 코드에서는 결측값을 각 열의 평균값으로 대체하여 데이터의 완전성을 확보합니다.

### 범주형 데이터 처리

데이터에 범주형 값을 시계열이나 숫자로 변환하는 것이 중요합니다.

```python
# 범주형 변수를 수치형으로 변환
data['Gender'] = data['Gender'].map({'Male': 0, 'Female': 1})
```

여기서 성별 데이터를 'Male'을 0으로, 'Female'을 1로 변환하여 수치형 변수로 변경합니다.

### 수치형 데이터 정규화

데이터의 스케일링을 통해 모델 훈련 성능을 향상시킬 수 있습니다.

```python
from sklearn.preprocessing import MinMaxScaler

# 스케일러 초기화 및 적용
scaler = MinMaxScaler()
data[['Age', 'Salary']] = scaler.fit_transform(data[['Age', 'Salary']])
```

위 코드에서는 **`MinMaxScaler`**를 사용하여 'Age'와 'Salary' 열을 정규화합니다. 이로 인해 각각의 값이 0과 1 사이로 조정됩니다.

## 데이터 전처리 흐름

이제 전체 데이터를 전처리하는 흐름을 이해할 수 있습니다. 다음 시퀀스 다이어그램은 전처리 과정을 시각적으로 나타냅니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 시스템
    participant 전처리 모듈
    사용자->>시스템: 데이터 로드 요청
    시스템->>전처리 모듈: 데이터 전달
    전처리 모듈-->>시스템: 전처리된 데이터 반환
    시스템-->>사용자: 처리 완료된 데이터 표시
```

이 과정에서는 사용자가 데이터 로드를 요청하면 시스템이 전처리 모듈을 통해 데이터를 준비하고, 완성된 데이터를 반환받아 사용자에게 전달합니다.

### 전처리 코드 내부 구현

데이터 전처리의 실제 코드를 확인해보겠습니다. 데이터 전처리는 체계적인 단계를 통해 수행됩니다.

```python
def preprocess_data(file_path):
    df = pd.read_csv(file_path)
    
    # 결측값 확인 및 대체
    df.fillna(df.mean(), inplace=True)
    
    # 범주형 변수 변환
    df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})
    
    # 수치형 데이터 정규화
    scaler = MinMaxScaler()
    df[['Age', 'Salary']] = scaler.fit_transform(df[['Age', 'Salary']])
    
    return df

processed_data = preprocess_data('customer_data.csv')
```

함수 **`preprocess_data`**는 데이터를 로드하고, 결측값 처리, 범주형 변수 변환, 데이터 정규화를 포함한 모든 전처리 과정을 실행합니다. 결과적으로 모델에 알맞은 형태로 데이터를 변환합니다.

## 결론

이번 장에서는 데이터 전처리와 로드 과정을 통해 데이터의 품질을 높이고 모델 학습에 대비하는 방법을 배웠습니다. 전처리 과정을 잘 이해하면 향후 머신러닝 모델의 성능을 향상시킬 수 있습니다. 다음 장 [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)에서는 준비된 데이터를 사용하여 모델을 학습시키고 예측 성능을 측정하는 방법에 대해 알아보겠습니다.
---
# Chapter 6: 모델 예측 및 성능 측정

[이전 장: 데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)에서는 머신러닝 모델에 데이터를 준비하는 방법을 배웠습니다. 이번 장에서는 이러한 데이터를 사용하여 실제로 모델을 예측하고, 그 성능을 측정하는 방법을 알아보겠습니다.

## 동기

예를 들어, 우리는 고객의 이탈 가능성을 예측하는 모델을 만들려고 합니다. 이를 위해 Random Forest, Gradient Boosting, 그리고 Deep Learning 모델을 사용합니다. 이 예측이 정확하다면 은행은 고객 이탈을 사전에 예방할 수 있습니다. 하지만 예측의 정확도를 어떻게 평가할 수 있을까요? 정확도로만 충분할까요? 이번 장에서는 이러한 질문에 답하기 위해 모델을 예측하고 그 성능을 평가하는 방법을 설명합니다.

## 모델 예측 및 성능 측정의 핵심 개념

### 1. 모델 예측

모델 예측은 준비된 데이터에 기반하여 결과를 예측하는 단계입니다. 이는 예를 들어 고객의 이탈 여부를 예측하는 것과 같습니다.

```python
from sklearn.ensemble import RandomForestClassifier

# 모델 초기화
model = RandomForestClassifier()

# 예측
predictions = model.predict(test_data)
```

위 코드에서는 Random Forest 모델을 통해 데이터를 예측합니다. `test_data`에 대한 결과를 예측하여 그 결과를 `predictions`에 저장합니다.

### 2. 성능 측정

예측의 성능을 평가하는 데 여러 가지 방법이 있습니다. 대표적으로 정확도, 정밀도, 재현율 등이 있습니다.

```python
from sklearn.metrics import accuracy_score

# 정확도 계산
accuracy = accuracy_score(true_labels, predictions)
print(f"정확도: {accuracy}")
```

여기서는 정확도를 사용합니다. **정확도**란 전체 중 맞춘 비율을 의미하며, `true_labels`는 실제 레이블을 나타냅니다.

## 성능 측정의 내부 구현

예측과 성능 측정 과정이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 모델
    participant 성능 측정 모듈
    사용자->>모델: 데이터 입력
    모델-->>사용자: 예측 결과 반환
    사용자->>성능 측정 모듈: 결과와 실제 레이블 전달
    성능 측정 모듈-->>사용자: 성능 평가 지표 반환
```

### 내부 구현 코드

성능 평가 코드는 결과를 비교하여 각 평가 지표를 계산합니다.

```python
def evaluate_model(predictions, actuals):
    accuracy = accuracy_score(actuals, predictions)
    precision = precision_score(actuals, predictions)
    recall = recall_score(actuals, predictions)
    return accuracy, precision, recall

# 평가 실행
acc, prec, rec = evaluate_model(predictions, true_labels)
```

위의 함수는 `predictions`와 `actuals`를 통해 다양한 지표를 반환합니다. 정확도, 정밀도, 재현율을 포함한 결과는 모델의 성능을 종합적으로 평가하는 데 중요한 역할을 합니다.

## 결론

이번 장에서는 모델 예측과 성능 측정 방법에 대해 배웠습니다. 이를 통해 고객의 이탈 가능성을 효과적으로 예측하고, 예측 모델의 성능을 평가하는 방법을 이해할 수 있습니다. 다음 장에서는 [모델 로드 및 관리](07_모델_로드_및_관리.md)에서 이 모델들을 어떻게 저장하고, 재사용하며 관리하는지에 대해 알아보겠습니다.   

---
# Chapter 7: 모델 로드 및 관리

[이전 장: 모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)에서는 은행 고객 이탈 예측 모델의 예측 결과와 성능을 평가하는 방법에 대해 배웠습니다. 이번 장에서는 예측 모델을 저장하고, 추후 필요할 때 다시 불러올 수 있게 관리하는 방법을 알아보겠습니다.

## 동기

모델 학습은 많은 계산 시간과 자원을 필요로 합니다. 따라서 매번 새롭게 모델을 학습시키기보다는 한번 저장해 두고 필요할 때 불러와 사용하는 것이 매우 효율적입니다. 예를 들어, 은행이 매주 고객 이탈을 예측하고자 할 때, 이전에 학습한 모델을 불러와 활용할 수 있습니다. 이 과정에서는 **모델 저장**과 **모델 로드**를 다루어 보겠습니다.

## 모델 로드 및 관리의 핵심 개념

### 1. 모델 저장

모델을 저장하면 나중에도 동일한 모델을 사용하여 예측할 수 있습니다. Scikit-learn에서는 `joblib` 라이브러리를 활용하여 간단히 모델을 저장할 수 있습니다.

```python
import joblib

# 학습된 모델을 저장
joblib.dump(model, 'customer_churn_model.pkl')
```

위 코드는 학습된 모델 객체를 'customer_churn_model.pkl' 파일로 저장합니다. 이렇게 저장한 모델은 언제든지 불러올 수 있습니다.

### 2. 모델 로드

저장한 모델을 불러와 사용하려면 `joblib`의 `load` 함수를 사용합니다.

```python
# 저장된 모델 로드
loaded_model = joblib.load('customer_churn_model.pkl')
```

`loaded_model`은 이제 저장된 모델과 동일한 상태를 가지며, 바로 예측에 사용할 수 있습니다.

## 모델 관리 흐름

모델 저장 및 로드 과정이 어떻게 진행되는지를 이해하기 위해 시퀀스 다이어그램을 이용합니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 모델 관리 시스템
    사용자->>모델 관리 시스템: 모델 저장 요청
    모델 관리 시스템-->>사용자: 저장 완료 확인
    사용자->>모델 관리 시스템: 모델 로드 요청
    모델 관리 시스템-->>사용자: 로드된 모델 반환
```

### 내부 구현 코드

모델 저장 및 로드는 간단한 코드를 통해 이루어집니다. 파일 저장 경로만 정확히 지정해주면, 필요할 때 쉽게 불러와서 사용할 수 있습니다.

```python
def save_model(model, filename):
    # 모델을 파일로 저장
    joblib.dump(model, filename)

def load_model(filename):
    # 파일에서 모델 로드
    return joblib.load(filename)

# 모델 학습 후 저장하기
save_model(model, 'churn_model.pkl')

# 필요할 때 모델 불러오기
loaded_model = load_model('churn_model.pkl')
```

**`save_model`** 함수는 모델을 지정된 파일로 저장하고, **`load_model`** 함수는 해당 파일에서 모델을 불러옵니다. 이러한 기능을 통해 모델을 쉽게 관리하고 이용할 수 있습니다.

## 결론

이번 장에서는 머신러닝 모델을 저장하고 불러오는 방법에 대해 알아보았습니다. 이렇게 하면 학습한 모델을 영구적으로 보관하고, 필요할 때 빠르게 재사용할 수 있습니다. 다음 장에서는 [고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)을 통해 은행 고객 이탈 분석과 관련된 데이터를 어떻게 생성하는지 살펴보겠습니다. 이 데이터는 더 나은 예측을 위한 중요한 자료가 됩니다.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 8: 고객 이탈 분석 데이터 생성`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:57:04,252 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:57:21,250 - INFO - RESPONSE: # Chapter 8: 고객 이탈 분석 데이터 생성

[이전 장: 모델 로드 및 관리](07_모델_로드_및_관리.md)에서는 학습된 머신러닝 모델을 저장하고 관리하는 방법을 배웠습니다. 이번 장에서는 모델 예측 결과를 바탕으로 고객 이탈 분석 데이터를 생성하는 방법에 대해 다루겠습니다. 이 데이터는 고객의 이탈 원인을 이해하고 이를 해결하는 데 중요한 자료로 활용됩니다.

## 동기

은행에서는 고객의 이탈을 사전에 예방하고 이를 줄이는 것이 매우 중요합니다. 이를 위해 우리는 고객 이탈 가능성을 예측하는 모델을 활용하여 중요한 데이터를 생성할 수 있습니다. 이러한 데이터를 통해 고객이 왜 이탈할 가능성이 있는지를 분석하고, 그에 대한 대책을 마련할 수 있습니다. 예를 들어, 특정 고객이 높은 이탈 가능성을 가지고 있다면 그 원인을 분석하고, 고객 유지 전략을 세울 수 있습니다.

## 주요 개념

### 1. 위험도별 데이터 생성

모델 예측 결과를 기반으로 고객을 위험도에 따라 분류하고, 각 위험도에 따른 데이터를 생성합니다. 이는 고객 맞춤형 솔루션을 제안하는 데 유용합니다.

```python
import pandas as pd

# 예측 점수 데이터 예제
data = {'고객': ['A', 'B', 'C'],
        '이탈 가능성': [0.8, 0.2, 0.5]}

df = pd.DataFrame(data)

# 위험도별 분류
df['위험도'] = df['이탈 가능성'].apply(lambda x: '높음' if x > 0.7 else '낮음')
print(df)
```

위 코드에서는 고객의 이탈 가능성을 기준으로 '높음', '낮음'으로 분류합니다. 이를 통해 어떤 고객이 현재 이탈 위험이 높은지를 파악할 수 있습니다.

### 2. 분석 데이터 생성

고객의 이탈 위험도가 높은 그룹에 대해서는 더욱 심층적인 분석이 필요합니다. 이를 위해 추가적인 분석 데이터를 생성할 수 있습니다.

```python
# 위험도가 높은 고객 필터링
high_risk_customers = df[df['위험도'] == '높음']

# 심층 분석 데이터 생성 (예시)
detailed_analysis = high_risk_customers.assign(해결_방안='고객 서비스 강화')
print(detailed_analysis)
```

위 코드에서는 위험도가 높은 고객을 필터링하고, 이들에게 추가적인 해결 방안을 제안합니다. 이는 구체적인 고객 대응 전략을 만드는데 도움을 줍니다.

## 내부 구현 이해

고객 이탈 분석 데이터 생성 과정은 다음과 같이 이루어집니다. 시퀀스 다이어그램을 통해 내부 흐름을 이해할 수 있습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 분석 모듈
    participant 데이터 생성 모듈
    사용자->>분석 모듈: 고객 이탈 예측 결과 전달
    분석 모듈->>데이터 생성 모듈: 위험도별 데이터 요청
    데이터 생성 모듈-->>분석 모듈: 분석 데이터 반환
    분석 모듈-->>사용자: 분석 완료된 데이터 제공
```

### 구현 코드

아래의 함수 예시는 고객 이탈 예측 결과를 토대로 분석 데이터를 생성합니다.

```python
def generate_churn_analysis(predictions):
    # 고객 데이터 프레임 생성
    df = pd.DataFrame(predictions, columns=['고객', '이탈 가능성'])
    
    # 위험 단계 계산
    df['위험도'] = df['이탈 가능성'].apply(lambda x: '높음' if x > 0.7 else '낮음')
    
    # 심층 분석 제안
    df['추천 조치'] = df['위험도'].apply(
        lambda x: '고객 재방문을 유도하는 마케팅 제공' if x == '높음' else ' '
    )
    
    return df

# 예제 예측 데이터
predictions = [('A', 0.8), ('B', 0.2), ('C', 0.5)]

# 데이터 생성 실행
analysis_results = generate_churn_analysis(predictions)
print(analysis_results)
```

이 함수는 고객의 예측 데이터를 받아 위험도를 계산하고, 추천 조치를 추가합니다. 이를 통해 보다 구체적인 고객 유지 전략을 수립할 수 있습니다.

## 결론

이번 장에서는 고객 이탈 분석 데이터를 생성하는 방법에 대해 배웠습니다. 이를 통해 우리는 고객의 이탈 가능성을 예측하고, 그에 따른 대응 방안을 구체적으로 마련할 수 있습니다. 다음 장인 [나이별 데이터 분석](09_나이별_데이터_분석.md)에서는 나이별로 고객 데이터를 분석하여 더 세분화된 인사이트를 얻는 방법을 알아보겠습니다.   

이 장에서 배운 내용을 바탕으로 실제 데이터를 적용하여 고객 유지 전략을 더욱 강화해보세요!
2025-06-29 20:57:21,260 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-2nd-1Team` about the concept: "나이별 데이터 분석". This is Chapter 9.

Concept Details (Note: Provided in Korean):
- Name: 나이별 데이터 분석
- Description:
나이에 따른 평균 신용점수, 금융상품 보유 수 등의 분석을 통해 연령대를 기반으로 고객 특성을 파악합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)
2. [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)
3. [디스플레이 유틸리티](03_디스플레이_유틸리티.md)
4. [필터링 기능](04_필터링_기능.md)
5. [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)
6. [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)
7. [모델 로드 및 관리](07_모델_로드_및_관리.md)
8. [고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)
9. [나이별 데이터 분석](09_나이별_데이터_분석.md)
10. [고객 이탈 원인과 해결 방안](10_고객_이탈_원인과_해결_방안.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 은행 고객 이탈 예측 시스템

은행 고객 이탈 예측 시스템은 고객 데이터에 기반하여 이탈 가능성을 분석하고 예측하는 대시보드입니다. 이 시스템은 특히 은행이 고객의 이탈을 미리 예측할 수 있도록 도와주어, 적절한 대응 전략을 세울 수 있게 합니다. 

## 동기

은행은 고객 이탈을 줄이는 것이 매우 중요합니다. 고객이 은행을 떠나기 전, 이를 예측할 수 있다면 추가적인 대응조치를 통해 고객 유지율을 높일 수 있습니다. 예를 들어, 한 고객이 최근 거래가 줄어들고 대출 상환에 문제가 있는 경우 이를 빠르게 인지하고 대책을 세우는 것이 가능해집니다.

## 핵심 개념 설명

이 시스템은 여러 단계로 나뉘어 고객의 이탈 가능성을 예측합니다:

1. **데이터 수집**: 고객의 나이, 거래 내역, 고객 만족도 등 다양한 데이터를 수집합니다.
2. **모델 학습**: 수집된 데이터를 사용하여 머신 러닝 모델을 학습시킵니다.
3. **이탈 예측**: 학습된 모델을 통해 고객의 이탈 가능성을 예측합니다.

### Streamlit을 이용한 대시보드

Streamlit은 쉽게 대시보드를 구성할 수 있게 해주는 파이썬 라이브러리입니다. 코드를 한 줄 한 줄 변경하면서, 바로 변경된 부분을 확인할 수 있어 빠르게 대시보드를 개발할 수 있습니다.

```python
import streamlit as st

# 간단한 대시보드 제목 설정
st.title('은행 고객 이탈 예측 대시보드')
```

이 코드는 대시보드의 기본 제목을 설정합니다. **`streamlit`**은 파이썬 코드로 웹 애플리케이션을 쉽게 만들도록 도와줍니다.

## 이탈 예측 시스템의 내부 구현

### 주요 단계 설명

1. **데이터 로드**: 고객 데이터를 읽어옵니다.
2. **예측 실행**: 모델을 사용하여 이탈 위험을 계산합니다.
3. **결과 시각화**: 대시보드에 예측 결과를 표현합니다.

이 과정은 다음의 시퀀스 다이어그램으로 이해할 수 있습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 모델
    사용자->>대시보드: 데이터 입력
    대시보드->>모델: 예측 요청
    모델-->>대시보드: 예측 결과
    대시보드-->>사용자: 결과 시각화
```

### 데이터 로드

고객 데이터를 로드하는 과정을 살펴보겠습니다.

```python
import pandas as pd

# CSV 파일에서 고객 데이터 로드
data = pd.read_csv('customer_data.csv')
```

이 코드는 고객 데이터를 저장한 CSV 파일을 읽어옵니다. **pandas** 라이브러리를 사용하면 데이터를 다루는 과정이 매우 간단해집니다.

### 예측 실행

모델을 이용하여 이탈 가능성을 예측합니다.

```python
# 머신러닝 모델을 불러와서 예측 수행
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(train_X, train_y)

# 예측하기
predictions = model.predict(test_X)
```

위 예제에서는 **RandomForestClassifier**를 사용하여 모델을 학습하고 예측합니다. 간단한 관계를 통해 예측을 수행하며, 이 결과는 대시보드에서 시각화됩니다.

## 결론

이 장에서는 은행 고객 이탈 예측 시스템의 기본 개념과 구현 과정을 간단하게 살펴보았습니다. 다음 장에서는 [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)을 통해 얻어진 결과를 어떻게 구성하고 표현할 수 있는지에 대한 내용을 알아보겠습니다. 이 시스템을 활용하여 은행이 고객 이탈을 효과적으로 관리할 수 있게 됩니다.
---
# Chapter 2: 데이터 시각화 및 대시보드 구성

[이전 장: 은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)에서는 고객 이탈을 예측하는 시스템의 기본 개념과 구현 방법을 소개했습니다. 이번 장에서는 그 결과를 더욱 효과적으로 전달하기 위해 데이터 시각화와 대시보드 구성을 다루어보겠습니다.

## 동기

데이터 시각화는 복잡한 데이터를 이해하기 쉽게 만들어줍니다. 예를 들어, 수많은 숫자 데이터에서 패턴이나 추세를 식별하기 어렵지만, 이를 그래프로 나타내면 한눈에 이해하기가 쉬워집니다. 이처럼 손쉽게 데이터에서 인사이트를 얻는 방식으로, 대시보드는 사용자와 데이터를 연결하는 중요한 역할을 합니다.

## Streamlit을 사용한 시각화 및 대시보드 생성

Streamlit을 사용하면 복잡한 대시보드를 간단한 코드로 쉽게 개발할 수 있습니다. 데이터 시각화를 사용하여 어떠한 정보가 중요한지 사용자에게 명확히 전달할 수 있습니다.

### 기본적인 대시보드 구성

Streamlit의 간단한 코드를 통해 기본적인 대시보드를 구현하는 방법을 살펴봅시다.

```python
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

# 데이터를 로드
data = pd.read_csv('customer_data.csv')

# 데이터의 일부를 시각화
st.title('데이터 시각화 예제')
st.write("고객 데이터 미리보기:")
st.write(data.head())

# 플롯 생성
st.line_chart(data['Age'])
```

위 코드는 Streamlit을 통해 고객 데이터의 일부를 화면에 표시하고, 'Age' 컬럼을 선 그래프로 시각화합니다. **`st.line_chart`** 는 데이터 시각화를 매우 신속하게 수행할 수 있도록 도와줍니다.

### 대시보드에 추가할 다른 요소

대시보드를 더욱 풍부하게 하기 위해 다양한 그래프와 인터랙티브한 원소들을 추가할 수 있습니다.

```python
# 히스토그램 생성
fig, ax = plt.subplots()
ax.hist(data['Age'], bins=20)

# Streamlit에 Matplotlib 플롯 표시
st.pyplot(fig)
```

위 예제에서는 **Matplotlib**을 사용하여 'Age' 컬럼에 대한 히스토그램을 생성하고, 이를 Streamlit 대시보드에 표시합니다. 이러한 플롯은 데이터의 분포를 시각적으로 파악하는데 유용합니다.

## 내부 구현 상세 설명

대시보드의 작동 방식을 이해하기 위해 간단한 시퀀스 다이어그램을 살펴봅시다.

```mermaid
sequenceDiagram
    participant 사용자
    participant 웹페이지
    participant 스트림릿
    사용자->>웹페이지: 접속 요청
    웹페이지->>스트림릿: 데이터 요청
    스트림릿-->>웹페이지: 시각화 데이터
    웹페이지-->>사용자: 데이터 및 시각화 표시
```

이 과정은 사용자가 웹페이지에 접속하여 데이터를 요청하면, 스트림릿이 적절한 시각화 데이터를 준비하고 이를 사용자에게 전달하는 흐름으로 구성됩니다.

## 결론

이 장에서는 Streamlit을 사용한 데이터 시각화 및 대시보드 구성 방법을 살펴보았습니다. 대시보드는 데이터 해석을 용이하게 해주며, 사용자가 원하는 정보를 효과적으로 전달합니다. 다음 장에서는 [디스플레이 유틸리티](03_디스플레이_유틸리티.md)를 통해 대시보드를 보다 다채롭게 구성하는 방법을 배워보겠습니다. 대시보드의 유익한 시각화 요소들을 더해, 앞으로의 분석이 더욱 직관적으로 이루어질 것입니다.
---
# Chapter 3: 디스플레이 유틸리티

[이전 장: 데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)에서는 대시보드를 통해 고객 이탈 데이터를 효과적으로 시각화하는 방법을 배웠습니다. 이번 장에서는 대시보드를 보다 직관적이고 사용자 친화적으로 만드는 데에 필요한 **디스플레이 유틸리티**를 소개하겠습니다.

## 동기

우리가 고객 이탈 예측 결과를 분석할 때, 단순히 숫자나 그래프만 보이면 직관적으로 이해하기 힘들 수 있습니다. 이런 데이터를 더 쉽게 이해하고 활용하기 위해, UI에 표현하는 방식에 다양한 유틸리티를 추가할 수 있습니다. 

예시로, 고객의 이탈 예측 점수를 색깔로 강조하여 중요하고 볼만한 정보를 쉽게 전달할 수 있습니다. 예를 들어, 이탈 가능성이 높은 고객을 빨간색으로 표시하면 곧바로 주의를 기울일 수 있게 됩니다.

## 디스플레이 유틸리티의 핵심 개념

### 데이터 포맷팅
디스플레이 유틸리티에서 가장 기본이 되는 개념은 데이터를 사용자가 쉽게 볼 수 있도록 가공하는 것입니다. 여기에는 날짜 형식 변환, 금액을 통화 형식으로 변환하는 등의 작업이 포함됩니다.

```python
import pandas as pd

# 예시 데이터
data = {'고객': ['A', 'B', 'C'],
        '예측 점수': [0.8, 0.2, 0.5]}

df = pd.DataFrame(data)

# 예측 점수에 따라 색상 적용
df['점수 상태'] = df['예측 점수'].apply(lambda x: '위험' if x > 0.7 else '안전')

print(df)
```

위의 코드에서는 고객의 예측 점수를 기반으로 '위험'과 '안전' 상태로 분류합니다. 이렇게 분류된 데이터는 그에 따라 색깔 등을 통해 대시보드에서 표시할 수 있습니다.

### 조건부 포맷팅
조건부 포맷팅은 사용자에게 중요한 데이터를 강조하는 데 유용합니다. 이 방법을 통해 예측 점수에 따라 색상을 변경할 수 있습니다.

```python
import seaborn as sns

def highlight_rows(row):
    return ['background-color: yellow' if row['점수 상태'] == '위험' else '' for _ in row]

# 스타일 적용
styled_df = df.style.apply(highlight_rows, axis=1)
```

**Seaborn**과 같은 라이브러리를 사용하면, 조건부 포맷팅을 통해 데이터의 시각적 강조를 쉽게 할 수 있습니다.

### 웹 페이지에 적합한 포맷팅
위에서 언급한 기능들을 활용하여 대시보드에도 적용할 수 있습니다.

```python
import streamlit as st

# 대시보드에 데이터 표시
st.title('디스플레이 유틸리티 예제')
st.write(styled_df)
```

위 코드를 통해 Streamlit 대시보드에 조건부 포맷팅이 적용된 데이터를 쉽게 표시할 수 있습니다. Streamlit의 **`st.write()`** 함수는 데이터프레임에 대해 다양한 포맷팅을 지원합니다.

## 디스플레이 유틸리티 내부 구현

디스플레이 유틸리티의 작동 방식을 이해하기 위해 시퀀스 다이어그램을 사용해봅시다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 디스플레이 유틸리티
    사용자->>대시보드: 데이터 요청
    대시보드->>디스플레이 유틸리티: 데이터 형식 지정 요청
    디스플레이 유틸리티-->>대시보드: 포맷팅된 데이터 반환
    대시보드-->>사용자: 결과 표시
```

위 다이어그램은 디스플레이 유틸리티가 데이터를 대시보드에 표시하기 전에 어떻게 처리하는지를 보여줍니다.

### 내부 코드 구현

디스플레이 유틸리티의 내부는 다양한 형식 지정 및 조건부 포맷팅을 통해 구성됩니다. 각 단계에서 데이터를 보다 직관적으로 보이도록 만드는 다양한 함수들을 활용합니다.

```python
def format_currency(value):
    return "${:,.2f}".format(value)

formatted_value = format_currency(1500)
print(formatted_value)  # 출력: $1,500.00
```

위 함수는 금액 데이터를 통화 형식으로 변환합니다. 이러한 형식을 통해 사용자가 데이터를 쉽게 이해할 수 있게 됩니다.

## 결론

이번 장에서 우리는 디스플레이 유틸리티를 활용하여 데이터를 보다 사용자 친화적으로 변환하고 강조하는 방법을 배웠습니다. 이렇게 변환된 데이터를 통해 사용자는 더욱 직관적으로 정보를 받아들일 수 있습니다. 다음 장에서는 [필터링 기능](04_필터링_기능.md)을 통해 대시보드 상에서 데이터를 효율적으로 필터링하는 방법을 알아보겠습니다. 이를 통해 우리는 사용자에게 더 개인화된 데이터 뷰를 제공합니다.
---
# Chapter 4: 필터링 기능

[이전 장: 디스플레이 유틸리티](03_디스플레이_유틸리티.md)에서는 다양한 유틸리티를 통해 데이터를 쉽게 이해할 수 있도록 돕는 방법에 대해 알아보았습니다. 이번 장에서는 대시보드에서 사용자에게 필요한 정보만 선택적으로 보여줄 수 있는 필터링 기능을 소개하겠습니다.

## 동기

고객 데이터를 통해 인사이트를 얻고자 할 때, 모든 데이터를 한 번에 살펴보는 것은 어렵고 시간이 많이 소요될 수 있습니다. 이러한 문제를 해결하기 위해 우리는 필터링 기능을 사용할 수 있습니다. 필터링 기능을 통해 사용자는 자신이 원하는 특정 조건에 맞는 데이터만을 선별적으로 볼 수 있습니다. 예를 들어, 특정 연령대의 고객만을 대상으로 이탈 가능성을 분석하고자 할 때 유용합니다.

## 필터링 기능의 핵심 개념

### 필터링의 기본 원리
필터링 기능은 사용자로 하여금 자신의 요구에 맞는 데이터를 선택할 수 있도록 합니다. 보통 필터링은 특정 조건을 설정하고 데이터 중 해당 조건에 일치하는 항목만을 추출하는 방식으로 이루어집니다.

```python
import pandas as pd

# 데이터 예시
data = {'고객': ['A', 'B', 'C'],
        '나이': [25, 30, 22],
        '이탈 가능성': [0.1, 0.4, 0.8]}

df = pd.DataFrame(data)

# 나이가 25세 이상인 고객 데이터 필터링
filtered_data = df[df['나이'] >= 25]
print(filtered_data)
```

위 코드에서는 '나이'가 25세 이상인 고객들만 필터링하여 표시합니다. 이 기능은 다양한 조건을 통해 데이터를 세분화하고 분석하는데 매우 유용합니다.

### 코드 활용 및 예시

사용자가 필요로 하는 데이터만을 선택할 수 있는 필터를 구성하는 방법은 다음과 같습니다.

```python
import streamlit as st

# 스트림릿 슬라이더를 통한 나이 기준 필터링 설정
age_filter = st.slider('필터링 나이', 0, 100, 25)

# 설정된 나이 기준에 따른 데이터 필터링
filtered_data = df[df['나이'] >= age_filter]
st.write(filtered_data)
```

이 코드는 Streamlit 슬라이더를 사용하여 사용자가 나이 기준을 설정하고, 그에 맞춰 데이터를 필터링합니다. 이로 인해 대시보드 사용자가 실시간으로 필터링 조건을 변경할 수 있습니다.

## 내부 구현 방식을 통한 이해

필터링 기능이 어떻게 내부에서 작동하는지를 이해하기 위해 시퀀스 다이어그램을 참고합니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 필터링 모듈
    사용자->>대시보드: 필터 조건 설정
    대시보드->>필터링 모듈: 조건 전달
    필터링 모듈-->>대시보드: 필터링된 데이터 반환
    대시보드-->>사용자: 결과 데이터 표시
```

위의 다이어그램은 사용자가 설정한 조건에 따라 데이터가 필터링되고 그 결과가 대시보드에 표시되는 과정을 설명합니다.

### 내부 코드 구현

필터링 기능은 조건을 기반으로 데이터를 선별하는 다양한 알고리즘과 함수를 사용할 수 있습니다. 다음은 pandas 라이브러리를 사용하는 기본적인 방법입니다.

```python
def filter_data(data_frame, condition):
    return data_frame.query(condition)

# 예시: 이탈 가능성이 0.3 이상인 데이터를 필터링
condition = "이탈 가능성 > 0.3"
filtered_result = filter_data(df, condition)
print(filtered_result)
```

위 함수는 pandas의 **`query()`** 메서드를 사용하여 조건에 맞는 데이터를 추출합니다. 이러한 방법을 통해 데이터를 자유롭게 필터링할 수 있습니다.

## 결론

이번 장에서는 대시보드에서 필터링 기능을 통해 사용자가 원하는 특정 조건의 데이터를 선별적으로 확인하는 방법에 대해 배웠습니다. 이런 기능을 사용하면 더 개인화된 데이터 분석이 가능해집니다. 다음 장에서는 [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)를 통해 데이터를 로드하고 준비하는 방법에 대해 더 알아보겠습니다.
---
# Chapter 5: 데이터 전처리 및 로드

[이전 장: 필터링 기능](04_필터링_기능.md)에서는 대시보드를 통해 원하는 데이터를 필터링하는 방법을 배웠습니다. 이번 장에서는 머신러닝 모델을 위한 중요한 단계인 **데이터 전처리 및 로드**에 대해 알아보겠습니다.

## 동기

데이터 전처리는 머신러닝 모델의 성공적인 학습을 위해 필수적으로 필요합니다. 데이터를 로드하고 사용하기 용이하게 준비하지 않으면 결측값이나 형식 문제로 인해 예측 정확도에 영향을 줄 수 있습니다. 따라서 데이터 전처리를 적절히 수행하는 것은 매우 중요합니다.

### 예시 상황

예시로, 고객 데이터에서 누락된 값이 있는 상황을 고려해 봅시다. 이런 데이터로 모델을 훈련하면 부정확한 결과를 초래할 수 있습니다. 데이터 전처리는 이러한 문제를 해결하기 위해 데이터 형식 변환, 결측값 대체 등의 작업을 포함합니다.

## 데이터 전처리의 핵심 개념

### 데이터 로드

먼저, 데이터를 로딩하는 단계부터 시작해야 합니다. 이 예제에서는 CSV 파일을 읽어옵니다.

```python
import pandas as pd

# 고객 데이터를 CSV에서 읽어오기
data = pd.read_csv('customer_data.csv')
```

**`pandas`**를 사용하여 CSV 파일을 읽어옵니다. 이러면 데이터를 DataFrame 형식으로 쉽게 다룰 수 있습니다.

### 결측값 처리

데이터 중 결측값 또는 누락된 값을 처리해야 합니다. 데이터의 일관성을 확보하는 것이 중요하기 때문입니다.

```python
# 결측값을 평균값으로 대체
data.fillna(data.mean(), inplace=True)
```

위 코드에서는 결측값을 각 열의 평균값으로 대체하여 데이터의 완전성을 확보합니다.

### 범주형 데이터 처리

데이터에 범주형 값을 시계열이나 숫자로 변환하는 것이 중요합니다.

```python
# 범주형 변수를 수치형으로 변환
data['Gender'] = data['Gender'].map({'Male': 0, 'Female': 1})
```

여기서 성별 데이터를 'Male'을 0으로, 'Female'을 1로 변환하여 수치형 변수로 변경합니다.

### 수치형 데이터 정규화

데이터의 스케일링을 통해 모델 훈련 성능을 향상시킬 수 있습니다.

```python
from sklearn.preprocessing import MinMaxScaler

# 스케일러 초기화 및 적용
scaler = MinMaxScaler()
data[['Age', 'Salary']] = scaler.fit_transform(data[['Age', 'Salary']])
```

위 코드에서는 **`MinMaxScaler`**를 사용하여 'Age'와 'Salary' 열을 정규화합니다. 이로 인해 각각의 값이 0과 1 사이로 조정됩니다.

## 데이터 전처리 흐름

이제 전체 데이터를 전처리하는 흐름을 이해할 수 있습니다. 다음 시퀀스 다이어그램은 전처리 과정을 시각적으로 나타냅니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 시스템
    participant 전처리 모듈
    사용자->>시스템: 데이터 로드 요청
    시스템->>전처리 모듈: 데이터 전달
    전처리 모듈-->>시스템: 전처리된 데이터 반환
    시스템-->>사용자: 처리 완료된 데이터 표시
```

이 과정에서는 사용자가 데이터 로드를 요청하면 시스템이 전처리 모듈을 통해 데이터를 준비하고, 완성된 데이터를 반환받아 사용자에게 전달합니다.

### 전처리 코드 내부 구현

데이터 전처리의 실제 코드를 확인해보겠습니다. 데이터 전처리는 체계적인 단계를 통해 수행됩니다.

```python
def preprocess_data(file_path):
    df = pd.read_csv(file_path)
    
    # 결측값 확인 및 대체
    df.fillna(df.mean(), inplace=True)
    
    # 범주형 변수 변환
    df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})
    
    # 수치형 데이터 정규화
    scaler = MinMaxScaler()
    df[['Age', 'Salary']] = scaler.fit_transform(df[['Age', 'Salary']])
    
    return df

processed_data = preprocess_data('customer_data.csv')
```

함수 **`preprocess_data`**는 데이터를 로드하고, 결측값 처리, 범주형 변수 변환, 데이터 정규화를 포함한 모든 전처리 과정을 실행합니다. 결과적으로 모델에 알맞은 형태로 데이터를 변환합니다.

## 결론

이번 장에서는 데이터 전처리와 로드 과정을 통해 데이터의 품질을 높이고 모델 학습에 대비하는 방법을 배웠습니다. 전처리 과정을 잘 이해하면 향후 머신러닝 모델의 성능을 향상시킬 수 있습니다. 다음 장 [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)에서는 준비된 데이터를 사용하여 모델을 학습시키고 예측 성능을 측정하는 방법에 대해 알아보겠습니다.
---
# Chapter 6: 모델 예측 및 성능 측정

[이전 장: 데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)에서는 머신러닝 모델에 데이터를 준비하는 방법을 배웠습니다. 이번 장에서는 이러한 데이터를 사용하여 실제로 모델을 예측하고, 그 성능을 측정하는 방법을 알아보겠습니다.

## 동기

예를 들어, 우리는 고객의 이탈 가능성을 예측하는 모델을 만들려고 합니다. 이를 위해 Random Forest, Gradient Boosting, 그리고 Deep Learning 모델을 사용합니다. 이 예측이 정확하다면 은행은 고객 이탈을 사전에 예방할 수 있습니다. 하지만 예측의 정확도를 어떻게 평가할 수 있을까요? 정확도로만 충분할까요? 이번 장에서는 이러한 질문에 답하기 위해 모델을 예측하고 그 성능을 평가하는 방법을 설명합니다.

## 모델 예측 및 성능 측정의 핵심 개념

### 1. 모델 예측

모델 예측은 준비된 데이터에 기반하여 결과를 예측하는 단계입니다. 이는 예를 들어 고객의 이탈 여부를 예측하는 것과 같습니다.

```python
from sklearn.ensemble import RandomForestClassifier

# 모델 초기화
model = RandomForestClassifier()

# 예측
predictions = model.predict(test_data)
```

위 코드에서는 Random Forest 모델을 통해 데이터를 예측합니다. `test_data`에 대한 결과를 예측하여 그 결과를 `predictions`에 저장합니다.

### 2. 성능 측정

예측의 성능을 평가하는 데 여러 가지 방법이 있습니다. 대표적으로 정확도, 정밀도, 재현율 등이 있습니다.

```python
from sklearn.metrics import accuracy_score

# 정확도 계산
accuracy = accuracy_score(true_labels, predictions)
print(f"정확도: {accuracy}")
```

여기서는 정확도를 사용합니다. **정확도**란 전체 중 맞춘 비율을 의미하며, `true_labels`는 실제 레이블을 나타냅니다.

## 성능 측정의 내부 구현

예측과 성능 측정 과정이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 모델
    participant 성능 측정 모듈
    사용자->>모델: 데이터 입력
    모델-->>사용자: 예측 결과 반환
    사용자->>성능 측정 모듈: 결과와 실제 레이블 전달
    성능 측정 모듈-->>사용자: 성능 평가 지표 반환
```

### 내부 구현 코드

성능 평가 코드는 결과를 비교하여 각 평가 지표를 계산합니다.

```python
def evaluate_model(predictions, actuals):
    accuracy = accuracy_score(actuals, predictions)
    precision = precision_score(actuals, predictions)
    recall = recall_score(actuals, predictions)
    return accuracy, precision, recall

# 평가 실행
acc, prec, rec = evaluate_model(predictions, true_labels)
```

위의 함수는 `predictions`와 `actuals`를 통해 다양한 지표를 반환합니다. 정확도, 정밀도, 재현율을 포함한 결과는 모델의 성능을 종합적으로 평가하는 데 중요한 역할을 합니다.

## 결론

이번 장에서는 모델 예측과 성능 측정 방법에 대해 배웠습니다. 이를 통해 고객의 이탈 가능성을 효과적으로 예측하고, 예측 모델의 성능을 평가하는 방법을 이해할 수 있습니다. 다음 장에서는 [모델 로드 및 관리](07_모델_로드_및_관리.md)에서 이 모델들을 어떻게 저장하고, 재사용하며 관리하는지에 대해 알아보겠습니다.   

---
# Chapter 7: 모델 로드 및 관리

[이전 장: 모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)에서는 은행 고객 이탈 예측 모델의 예측 결과와 성능을 평가하는 방법에 대해 배웠습니다. 이번 장에서는 예측 모델을 저장하고, 추후 필요할 때 다시 불러올 수 있게 관리하는 방법을 알아보겠습니다.

## 동기

모델 학습은 많은 계산 시간과 자원을 필요로 합니다. 따라서 매번 새롭게 모델을 학습시키기보다는 한번 저장해 두고 필요할 때 불러와 사용하는 것이 매우 효율적입니다. 예를 들어, 은행이 매주 고객 이탈을 예측하고자 할 때, 이전에 학습한 모델을 불러와 활용할 수 있습니다. 이 과정에서는 **모델 저장**과 **모델 로드**를 다루어 보겠습니다.

## 모델 로드 및 관리의 핵심 개념

### 1. 모델 저장

모델을 저장하면 나중에도 동일한 모델을 사용하여 예측할 수 있습니다. Scikit-learn에서는 `joblib` 라이브러리를 활용하여 간단히 모델을 저장할 수 있습니다.

```python
import joblib

# 학습된 모델을 저장
joblib.dump(model, 'customer_churn_model.pkl')
```

위 코드는 학습된 모델 객체를 'customer_churn_model.pkl' 파일로 저장합니다. 이렇게 저장한 모델은 언제든지 불러올 수 있습니다.

### 2. 모델 로드

저장한 모델을 불러와 사용하려면 `joblib`의 `load` 함수를 사용합니다.

```python
# 저장된 모델 로드
loaded_model = joblib.load('customer_churn_model.pkl')
```

`loaded_model`은 이제 저장된 모델과 동일한 상태를 가지며, 바로 예측에 사용할 수 있습니다.

## 모델 관리 흐름

모델 저장 및 로드 과정이 어떻게 진행되는지를 이해하기 위해 시퀀스 다이어그램을 이용합니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 모델 관리 시스템
    사용자->>모델 관리 시스템: 모델 저장 요청
    모델 관리 시스템-->>사용자: 저장 완료 확인
    사용자->>모델 관리 시스템: 모델 로드 요청
    모델 관리 시스템-->>사용자: 로드된 모델 반환
```

### 내부 구현 코드

모델 저장 및 로드는 간단한 코드를 통해 이루어집니다. 파일 저장 경로만 정확히 지정해주면, 필요할 때 쉽게 불러와서 사용할 수 있습니다.

```python
def save_model(model, filename):
    # 모델을 파일로 저장
    joblib.dump(model, filename)

def load_model(filename):
    # 파일에서 모델 로드
    return joblib.load(filename)

# 모델 학습 후 저장하기
save_model(model, 'churn_model.pkl')

# 필요할 때 모델 불러오기
loaded_model = load_model('churn_model.pkl')
```

**`save_model`** 함수는 모델을 지정된 파일로 저장하고, **`load_model`** 함수는 해당 파일에서 모델을 불러옵니다. 이러한 기능을 통해 모델을 쉽게 관리하고 이용할 수 있습니다.

## 결론

이번 장에서는 머신러닝 모델을 저장하고 불러오는 방법에 대해 알아보았습니다. 이렇게 하면 학습한 모델을 영구적으로 보관하고, 필요할 때 빠르게 재사용할 수 있습니다. 다음 장에서는 [고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)을 통해 은행 고객 이탈 분석과 관련된 데이터를 어떻게 생성하는지 살펴보겠습니다. 이 데이터는 더 나은 예측을 위한 중요한 자료가 됩니다.
---
# Chapter 8: 고객 이탈 분석 데이터 생성

[이전 장: 모델 로드 및 관리](07_모델_로드_및_관리.md)에서는 학습된 머신러닝 모델을 저장하고 관리하는 방법을 배웠습니다. 이번 장에서는 모델 예측 결과를 바탕으로 고객 이탈 분석 데이터를 생성하는 방법에 대해 다루겠습니다. 이 데이터는 고객의 이탈 원인을 이해하고 이를 해결하는 데 중요한 자료로 활용됩니다.

## 동기

은행에서는 고객의 이탈을 사전에 예방하고 이를 줄이는 것이 매우 중요합니다. 이를 위해 우리는 고객 이탈 가능성을 예측하는 모델을 활용하여 중요한 데이터를 생성할 수 있습니다. 이러한 데이터를 통해 고객이 왜 이탈할 가능성이 있는지를 분석하고, 그에 대한 대책을 마련할 수 있습니다. 예를 들어, 특정 고객이 높은 이탈 가능성을 가지고 있다면 그 원인을 분석하고, 고객 유지 전략을 세울 수 있습니다.

## 주요 개념

### 1. 위험도별 데이터 생성

모델 예측 결과를 기반으로 고객을 위험도에 따라 분류하고, 각 위험도에 따른 데이터를 생성합니다. 이는 고객 맞춤형 솔루션을 제안하는 데 유용합니다.

```python
import pandas as pd

# 예측 점수 데이터 예제
data = {'고객': ['A', 'B', 'C'],
        '이탈 가능성': [0.8, 0.2, 0.5]}

df = pd.DataFrame(data)

# 위험도별 분류
df['위험도'] = df['이탈 가능성'].apply(lambda x: '높음' if x > 0.7 else '낮음')
print(df)
```

위 코드에서는 고객의 이탈 가능성을 기준으로 '높음', '낮음'으로 분류합니다. 이를 통해 어떤 고객이 현재 이탈 위험이 높은지를 파악할 수 있습니다.

### 2. 분석 데이터 생성

고객의 이탈 위험도가 높은 그룹에 대해서는 더욱 심층적인 분석이 필요합니다. 이를 위해 추가적인 분석 데이터를 생성할 수 있습니다.

```python
# 위험도가 높은 고객 필터링
high_risk_customers = df[df['위험도'] == '높음']

# 심층 분석 데이터 생성 (예시)
detailed_analysis = high_risk_customers.assign(해결_방안='고객 서비스 강화')
print(detailed_analysis)
```

위 코드에서는 위험도가 높은 고객을 필터링하고, 이들에게 추가적인 해결 방안을 제안합니다. 이는 구체적인 고객 대응 전략을 만드는데 도움을 줍니다.

## 내부 구현 이해

고객 이탈 분석 데이터 생성 과정은 다음과 같이 이루어집니다. 시퀀스 다이어그램을 통해 내부 흐름을 이해할 수 있습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 분석 모듈
    participant 데이터 생성 모듈
    사용자->>분석 모듈: 고객 이탈 예측 결과 전달
    분석 모듈->>데이터 생성 모듈: 위험도별 데이터 요청
    데이터 생성 모듈-->>분석 모듈: 분석 데이터 반환
    분석 모듈-->>사용자: 분석 완료된 데이터 제공
```

### 구현 코드

아래의 함수 예시는 고객 이탈 예측 결과를 토대로 분석 데이터를 생성합니다.

```python
def generate_churn_analysis(predictions):
    # 고객 데이터 프레임 생성
    df = pd.DataFrame(predictions, columns=['고객', '이탈 가능성'])
    
    # 위험 단계 계산
    df['위험도'] = df['이탈 가능성'].apply(lambda x: '높음' if x > 0.7 else '낮음')
    
    # 심층 분석 제안
    df['추천 조치'] = df['위험도'].apply(
        lambda x: '고객 재방문을 유도하는 마케팅 제공' if x == '높음' else ' '
    )
    
    return df

# 예제 예측 데이터
predictions = [('A', 0.8), ('B', 0.2), ('C', 0.5)]

# 데이터 생성 실행
analysis_results = generate_churn_analysis(predictions)
print(analysis_results)
```

이 함수는 고객의 예측 데이터를 받아 위험도를 계산하고, 추천 조치를 추가합니다. 이를 통해 보다 구체적인 고객 유지 전략을 수립할 수 있습니다.

## 결론

이번 장에서는 고객 이탈 분석 데이터를 생성하는 방법에 대해 배웠습니다. 이를 통해 우리는 고객의 이탈 가능성을 예측하고, 그에 따른 대응 방안을 구체적으로 마련할 수 있습니다. 다음 장인 [나이별 데이터 분석](09_나이별_데이터_분석.md)에서는 나이별로 고객 데이터를 분석하여 더 세분화된 인사이트를 얻는 방법을 알아보겠습니다.   

이 장에서 배운 내용을 바탕으로 실제 데이터를 적용하여 고객 유지 전략을 더욱 강화해보세요!

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 9: 나이별 데이터 분석`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:57:21,474 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:57:36,415 - INFO - RESPONSE: # Chapter 9: 나이별 데이터 분석

[이전 장: 고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)에서는 예측된 고객 이탈 가능성을 활용하여 분석 데이터를 생성하는 방법을 배웠습니다. 이번 장에서는 고객 연령대별 데이터를 분석하여, 더 깊이 있는 인사이트를 얻는 방법을 소개하겠습니다.

## 동기

은행은 다양한 고객층을 상대로 금융 서비스를 제공합니다. 이 때 고객의 나이대는 매우 중요한 요소가 됩니다. 왜냐하면 각 나이대별로 금융 상품 이용 패턴이나 선호도가 다를 수 있기 때문입니다. 예를 들어, 젊은 층은 대출 상품 보다는 투자를 더 선호할 수 있습니다. 따라서 나이별 데이터 분석을 통해 고객 맞춤형 서비스를 제공할 수 있습니다.

## 주요 개념

### 1. 나이대 구분 및 분석 준비

먼저 고객 데이터를 나이대 별로 구분하고 분석하기 위한 준비 작업을 수행합니다.

```python
import pandas as pd

# 고객 데이터 예제
data = {'고객': ['A', 'B', 'C', 'D'],
        '나이': [25, 55, 35, 42],
        '신용점수': [720, 680, 640, 745]}

df = pd.DataFrame(data)

# 10대 구간으로 나누기
bins = [18, 30, 40, 50, 60]
labels = ['18-30', '31-40', '41-50', '51-60']
df['나이대'] = pd.cut(df['나이'], bins=bins, labels=labels)
print(df)
```

위 코드에서는 고객들의 나이를 몇 개의 구간으로 나누어, 그에 따라 나이대를 라벨링합니다. 여기서 사용된 `pd.cut` 메서드는 데이터를 구간별로 나누는 데 유용합니다.

### 2. 나이대별 데이터 분석

라벨링된 나이대를 기준으로 각 그룹의 평균 신용점수를 계산하여 분석에 활용합니다.

```python
# 나이대별 평균 신용점수 계산
age_group_avg_credit = df.groupby('나이대')['신용점수'].mean()
print(age_group_avg_credit)
```

위 코드는 나이대별로 그룹화한 후, 각 그룹의 평균 신용점수를 계산합니다. 이를 통해 나이대별 신용점수가 어떻게 다른지 알 수 있습니다.

## 나이대별 분석의 내부 구현

나이대별 데이터를 분석하는 과정은 아래와 같이 다이어그램으로 이해할 수 있습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 데이터 모듈
    participant 분석 모듈
    사용자->>데이터 모듈: 데이터 로드 요청
    데이터 모듈-->>사용자: 데이터 제공
    사용자->>분석 모듈: 나이대별 구분 및 평균 계산 요청
    분석 모듈-->>사용자: 나이대별 분석 결과 제공
```

### 내부 구현 코드

나이대 분석의 내부 구현 코드는 데이터의 구간 나누기와 평균 계산을 포함합니다.

```python
def analyze_age_groups(data_frame):
    # 나이대 정의
    bins = [18, 30, 40, 50, 60]
    labels = ['18-30', '31-40', '41-50', '51-60']
    
    # 나이대 추가
    data_frame['나이대'] = pd.cut(data_frame['나이'], bins=bins, labels=labels)
    
    # 나이대별 평균 신용점수
    return data_frame.groupby('나이대')['신용점수'].mean()

# 함수 호출 예시
customer_data = pd.DataFrame({'고객': ['A', 'B', 'C'], '나이': [24, 36, 48], '신용점수': [690, 710, 680]})
result = analyze_age_groups(customer_data)
print(result)
```

위 함수는 입력된 고객 데이터 프레임에 대해 나이대를 나누고, 각 나이대별 평균 신용점수를 반환합니다. 이를 사용하여 고객의 특성을 더 명확하게 분석할 수 있습니다.

## 결론

이번 장에서는 고객 데이터를 나이대별로 분석하여, 연령대에 따른 금융 행동 패턴을 이해하는 방법을 배웠습니다. 이를 통해 더 세밀한 고객 서비스 전략을 수립할 수 있습니다. 다음 장에서는 [고객 이탈 원인과 해결 방안](10_고객_이탈_원인과_해결_방안.md)을 탐색하여, 고객을 유지할 수 있는 다양한 방법을 살펴보겠습니다.

이제 나이대별 분석을 통해 더 개인화된 은행 서비스를 제공해보세요!
2025-06-29 20:57:36,426 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN10-2nd-1Team` about the concept: "고객 이탈 원인과 해결 방안". This is Chapter 10.

Concept Details (Note: Provided in Korean):
- Name: 고객 이탈 원인과 해결 방안
- Description:
고객 이탈 원인을 분석하고 Groq API를 통해 해결 방안을 도출하여 조직의 전략 수립에 기여합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)
2. [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)
3. [디스플레이 유틸리티](03_디스플레이_유틸리티.md)
4. [필터링 기능](04_필터링_기능.md)
5. [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)
6. [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)
7. [모델 로드 및 관리](07_모델_로드_및_관리.md)
8. [고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)
9. [나이별 데이터 분석](09_나이별_데이터_분석.md)
10. [고객 이탈 원인과 해결 방안](10_고객_이탈_원인과_해결_방안.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 은행 고객 이탈 예측 시스템

은행 고객 이탈 예측 시스템은 고객 데이터에 기반하여 이탈 가능성을 분석하고 예측하는 대시보드입니다. 이 시스템은 특히 은행이 고객의 이탈을 미리 예측할 수 있도록 도와주어, 적절한 대응 전략을 세울 수 있게 합니다. 

## 동기

은행은 고객 이탈을 줄이는 것이 매우 중요합니다. 고객이 은행을 떠나기 전, 이를 예측할 수 있다면 추가적인 대응조치를 통해 고객 유지율을 높일 수 있습니다. 예를 들어, 한 고객이 최근 거래가 줄어들고 대출 상환에 문제가 있는 경우 이를 빠르게 인지하고 대책을 세우는 것이 가능해집니다.

## 핵심 개념 설명

이 시스템은 여러 단계로 나뉘어 고객의 이탈 가능성을 예측합니다:

1. **데이터 수집**: 고객의 나이, 거래 내역, 고객 만족도 등 다양한 데이터를 수집합니다.
2. **모델 학습**: 수집된 데이터를 사용하여 머신 러닝 모델을 학습시킵니다.
3. **이탈 예측**: 학습된 모델을 통해 고객의 이탈 가능성을 예측합니다.

### Streamlit을 이용한 대시보드

Streamlit은 쉽게 대시보드를 구성할 수 있게 해주는 파이썬 라이브러리입니다. 코드를 한 줄 한 줄 변경하면서, 바로 변경된 부분을 확인할 수 있어 빠르게 대시보드를 개발할 수 있습니다.

```python
import streamlit as st

# 간단한 대시보드 제목 설정
st.title('은행 고객 이탈 예측 대시보드')
```

이 코드는 대시보드의 기본 제목을 설정합니다. **`streamlit`**은 파이썬 코드로 웹 애플리케이션을 쉽게 만들도록 도와줍니다.

## 이탈 예측 시스템의 내부 구현

### 주요 단계 설명

1. **데이터 로드**: 고객 데이터를 읽어옵니다.
2. **예측 실행**: 모델을 사용하여 이탈 위험을 계산합니다.
3. **결과 시각화**: 대시보드에 예측 결과를 표현합니다.

이 과정은 다음의 시퀀스 다이어그램으로 이해할 수 있습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 모델
    사용자->>대시보드: 데이터 입력
    대시보드->>모델: 예측 요청
    모델-->>대시보드: 예측 결과
    대시보드-->>사용자: 결과 시각화
```

### 데이터 로드

고객 데이터를 로드하는 과정을 살펴보겠습니다.

```python
import pandas as pd

# CSV 파일에서 고객 데이터 로드
data = pd.read_csv('customer_data.csv')
```

이 코드는 고객 데이터를 저장한 CSV 파일을 읽어옵니다. **pandas** 라이브러리를 사용하면 데이터를 다루는 과정이 매우 간단해집니다.

### 예측 실행

모델을 이용하여 이탈 가능성을 예측합니다.

```python
# 머신러닝 모델을 불러와서 예측 수행
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(train_X, train_y)

# 예측하기
predictions = model.predict(test_X)
```

위 예제에서는 **RandomForestClassifier**를 사용하여 모델을 학습하고 예측합니다. 간단한 관계를 통해 예측을 수행하며, 이 결과는 대시보드에서 시각화됩니다.

## 결론

이 장에서는 은행 고객 이탈 예측 시스템의 기본 개념과 구현 과정을 간단하게 살펴보았습니다. 다음 장에서는 [데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)을 통해 얻어진 결과를 어떻게 구성하고 표현할 수 있는지에 대한 내용을 알아보겠습니다. 이 시스템을 활용하여 은행이 고객 이탈을 효과적으로 관리할 수 있게 됩니다.
---
# Chapter 2: 데이터 시각화 및 대시보드 구성

[이전 장: 은행 고객 이탈 예측 시스템](01_은행_고객_이탈_예측_시스템.md)에서는 고객 이탈을 예측하는 시스템의 기본 개념과 구현 방법을 소개했습니다. 이번 장에서는 그 결과를 더욱 효과적으로 전달하기 위해 데이터 시각화와 대시보드 구성을 다루어보겠습니다.

## 동기

데이터 시각화는 복잡한 데이터를 이해하기 쉽게 만들어줍니다. 예를 들어, 수많은 숫자 데이터에서 패턴이나 추세를 식별하기 어렵지만, 이를 그래프로 나타내면 한눈에 이해하기가 쉬워집니다. 이처럼 손쉽게 데이터에서 인사이트를 얻는 방식으로, 대시보드는 사용자와 데이터를 연결하는 중요한 역할을 합니다.

## Streamlit을 사용한 시각화 및 대시보드 생성

Streamlit을 사용하면 복잡한 대시보드를 간단한 코드로 쉽게 개발할 수 있습니다. 데이터 시각화를 사용하여 어떠한 정보가 중요한지 사용자에게 명확히 전달할 수 있습니다.

### 기본적인 대시보드 구성

Streamlit의 간단한 코드를 통해 기본적인 대시보드를 구현하는 방법을 살펴봅시다.

```python
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt

# 데이터를 로드
data = pd.read_csv('customer_data.csv')

# 데이터의 일부를 시각화
st.title('데이터 시각화 예제')
st.write("고객 데이터 미리보기:")
st.write(data.head())

# 플롯 생성
st.line_chart(data['Age'])
```

위 코드는 Streamlit을 통해 고객 데이터의 일부를 화면에 표시하고, 'Age' 컬럼을 선 그래프로 시각화합니다. **`st.line_chart`** 는 데이터 시각화를 매우 신속하게 수행할 수 있도록 도와줍니다.

### 대시보드에 추가할 다른 요소

대시보드를 더욱 풍부하게 하기 위해 다양한 그래프와 인터랙티브한 원소들을 추가할 수 있습니다.

```python
# 히스토그램 생성
fig, ax = plt.subplots()
ax.hist(data['Age'], bins=20)

# Streamlit에 Matplotlib 플롯 표시
st.pyplot(fig)
```

위 예제에서는 **Matplotlib**을 사용하여 'Age' 컬럼에 대한 히스토그램을 생성하고, 이를 Streamlit 대시보드에 표시합니다. 이러한 플롯은 데이터의 분포를 시각적으로 파악하는데 유용합니다.

## 내부 구현 상세 설명

대시보드의 작동 방식을 이해하기 위해 간단한 시퀀스 다이어그램을 살펴봅시다.

```mermaid
sequenceDiagram
    participant 사용자
    participant 웹페이지
    participant 스트림릿
    사용자->>웹페이지: 접속 요청
    웹페이지->>스트림릿: 데이터 요청
    스트림릿-->>웹페이지: 시각화 데이터
    웹페이지-->>사용자: 데이터 및 시각화 표시
```

이 과정은 사용자가 웹페이지에 접속하여 데이터를 요청하면, 스트림릿이 적절한 시각화 데이터를 준비하고 이를 사용자에게 전달하는 흐름으로 구성됩니다.

## 결론

이 장에서는 Streamlit을 사용한 데이터 시각화 및 대시보드 구성 방법을 살펴보았습니다. 대시보드는 데이터 해석을 용이하게 해주며, 사용자가 원하는 정보를 효과적으로 전달합니다. 다음 장에서는 [디스플레이 유틸리티](03_디스플레이_유틸리티.md)를 통해 대시보드를 보다 다채롭게 구성하는 방법을 배워보겠습니다. 대시보드의 유익한 시각화 요소들을 더해, 앞으로의 분석이 더욱 직관적으로 이루어질 것입니다.
---
# Chapter 3: 디스플레이 유틸리티

[이전 장: 데이터 시각화 및 대시보드 구성](02_데이터_시각화_및_대시보드_구성.md)에서는 대시보드를 통해 고객 이탈 데이터를 효과적으로 시각화하는 방법을 배웠습니다. 이번 장에서는 대시보드를 보다 직관적이고 사용자 친화적으로 만드는 데에 필요한 **디스플레이 유틸리티**를 소개하겠습니다.

## 동기

우리가 고객 이탈 예측 결과를 분석할 때, 단순히 숫자나 그래프만 보이면 직관적으로 이해하기 힘들 수 있습니다. 이런 데이터를 더 쉽게 이해하고 활용하기 위해, UI에 표현하는 방식에 다양한 유틸리티를 추가할 수 있습니다. 

예시로, 고객의 이탈 예측 점수를 색깔로 강조하여 중요하고 볼만한 정보를 쉽게 전달할 수 있습니다. 예를 들어, 이탈 가능성이 높은 고객을 빨간색으로 표시하면 곧바로 주의를 기울일 수 있게 됩니다.

## 디스플레이 유틸리티의 핵심 개념

### 데이터 포맷팅
디스플레이 유틸리티에서 가장 기본이 되는 개념은 데이터를 사용자가 쉽게 볼 수 있도록 가공하는 것입니다. 여기에는 날짜 형식 변환, 금액을 통화 형식으로 변환하는 등의 작업이 포함됩니다.

```python
import pandas as pd

# 예시 데이터
data = {'고객': ['A', 'B', 'C'],
        '예측 점수': [0.8, 0.2, 0.5]}

df = pd.DataFrame(data)

# 예측 점수에 따라 색상 적용
df['점수 상태'] = df['예측 점수'].apply(lambda x: '위험' if x > 0.7 else '안전')

print(df)
```

위의 코드에서는 고객의 예측 점수를 기반으로 '위험'과 '안전' 상태로 분류합니다. 이렇게 분류된 데이터는 그에 따라 색깔 등을 통해 대시보드에서 표시할 수 있습니다.

### 조건부 포맷팅
조건부 포맷팅은 사용자에게 중요한 데이터를 강조하는 데 유용합니다. 이 방법을 통해 예측 점수에 따라 색상을 변경할 수 있습니다.

```python
import seaborn as sns

def highlight_rows(row):
    return ['background-color: yellow' if row['점수 상태'] == '위험' else '' for _ in row]

# 스타일 적용
styled_df = df.style.apply(highlight_rows, axis=1)
```

**Seaborn**과 같은 라이브러리를 사용하면, 조건부 포맷팅을 통해 데이터의 시각적 강조를 쉽게 할 수 있습니다.

### 웹 페이지에 적합한 포맷팅
위에서 언급한 기능들을 활용하여 대시보드에도 적용할 수 있습니다.

```python
import streamlit as st

# 대시보드에 데이터 표시
st.title('디스플레이 유틸리티 예제')
st.write(styled_df)
```

위 코드를 통해 Streamlit 대시보드에 조건부 포맷팅이 적용된 데이터를 쉽게 표시할 수 있습니다. Streamlit의 **`st.write()`** 함수는 데이터프레임에 대해 다양한 포맷팅을 지원합니다.

## 디스플레이 유틸리티 내부 구현

디스플레이 유틸리티의 작동 방식을 이해하기 위해 시퀀스 다이어그램을 사용해봅시다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 디스플레이 유틸리티
    사용자->>대시보드: 데이터 요청
    대시보드->>디스플레이 유틸리티: 데이터 형식 지정 요청
    디스플레이 유틸리티-->>대시보드: 포맷팅된 데이터 반환
    대시보드-->>사용자: 결과 표시
```

위 다이어그램은 디스플레이 유틸리티가 데이터를 대시보드에 표시하기 전에 어떻게 처리하는지를 보여줍니다.

### 내부 코드 구현

디스플레이 유틸리티의 내부는 다양한 형식 지정 및 조건부 포맷팅을 통해 구성됩니다. 각 단계에서 데이터를 보다 직관적으로 보이도록 만드는 다양한 함수들을 활용합니다.

```python
def format_currency(value):
    return "${:,.2f}".format(value)

formatted_value = format_currency(1500)
print(formatted_value)  # 출력: $1,500.00
```

위 함수는 금액 데이터를 통화 형식으로 변환합니다. 이러한 형식을 통해 사용자가 데이터를 쉽게 이해할 수 있게 됩니다.

## 결론

이번 장에서 우리는 디스플레이 유틸리티를 활용하여 데이터를 보다 사용자 친화적으로 변환하고 강조하는 방법을 배웠습니다. 이렇게 변환된 데이터를 통해 사용자는 더욱 직관적으로 정보를 받아들일 수 있습니다. 다음 장에서는 [필터링 기능](04_필터링_기능.md)을 통해 대시보드 상에서 데이터를 효율적으로 필터링하는 방법을 알아보겠습니다. 이를 통해 우리는 사용자에게 더 개인화된 데이터 뷰를 제공합니다.
---
# Chapter 4: 필터링 기능

[이전 장: 디스플레이 유틸리티](03_디스플레이_유틸리티.md)에서는 다양한 유틸리티를 통해 데이터를 쉽게 이해할 수 있도록 돕는 방법에 대해 알아보았습니다. 이번 장에서는 대시보드에서 사용자에게 필요한 정보만 선택적으로 보여줄 수 있는 필터링 기능을 소개하겠습니다.

## 동기

고객 데이터를 통해 인사이트를 얻고자 할 때, 모든 데이터를 한 번에 살펴보는 것은 어렵고 시간이 많이 소요될 수 있습니다. 이러한 문제를 해결하기 위해 우리는 필터링 기능을 사용할 수 있습니다. 필터링 기능을 통해 사용자는 자신이 원하는 특정 조건에 맞는 데이터만을 선별적으로 볼 수 있습니다. 예를 들어, 특정 연령대의 고객만을 대상으로 이탈 가능성을 분석하고자 할 때 유용합니다.

## 필터링 기능의 핵심 개념

### 필터링의 기본 원리
필터링 기능은 사용자로 하여금 자신의 요구에 맞는 데이터를 선택할 수 있도록 합니다. 보통 필터링은 특정 조건을 설정하고 데이터 중 해당 조건에 일치하는 항목만을 추출하는 방식으로 이루어집니다.

```python
import pandas as pd

# 데이터 예시
data = {'고객': ['A', 'B', 'C'],
        '나이': [25, 30, 22],
        '이탈 가능성': [0.1, 0.4, 0.8]}

df = pd.DataFrame(data)

# 나이가 25세 이상인 고객 데이터 필터링
filtered_data = df[df['나이'] >= 25]
print(filtered_data)
```

위 코드에서는 '나이'가 25세 이상인 고객들만 필터링하여 표시합니다. 이 기능은 다양한 조건을 통해 데이터를 세분화하고 분석하는데 매우 유용합니다.

### 코드 활용 및 예시

사용자가 필요로 하는 데이터만을 선택할 수 있는 필터를 구성하는 방법은 다음과 같습니다.

```python
import streamlit as st

# 스트림릿 슬라이더를 통한 나이 기준 필터링 설정
age_filter = st.slider('필터링 나이', 0, 100, 25)

# 설정된 나이 기준에 따른 데이터 필터링
filtered_data = df[df['나이'] >= age_filter]
st.write(filtered_data)
```

이 코드는 Streamlit 슬라이더를 사용하여 사용자가 나이 기준을 설정하고, 그에 맞춰 데이터를 필터링합니다. 이로 인해 대시보드 사용자가 실시간으로 필터링 조건을 변경할 수 있습니다.

## 내부 구현 방식을 통한 이해

필터링 기능이 어떻게 내부에서 작동하는지를 이해하기 위해 시퀀스 다이어그램을 참고합니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 대시보드
    participant 필터링 모듈
    사용자->>대시보드: 필터 조건 설정
    대시보드->>필터링 모듈: 조건 전달
    필터링 모듈-->>대시보드: 필터링된 데이터 반환
    대시보드-->>사용자: 결과 데이터 표시
```

위의 다이어그램은 사용자가 설정한 조건에 따라 데이터가 필터링되고 그 결과가 대시보드에 표시되는 과정을 설명합니다.

### 내부 코드 구현

필터링 기능은 조건을 기반으로 데이터를 선별하는 다양한 알고리즘과 함수를 사용할 수 있습니다. 다음은 pandas 라이브러리를 사용하는 기본적인 방법입니다.

```python
def filter_data(data_frame, condition):
    return data_frame.query(condition)

# 예시: 이탈 가능성이 0.3 이상인 데이터를 필터링
condition = "이탈 가능성 > 0.3"
filtered_result = filter_data(df, condition)
print(filtered_result)
```

위 함수는 pandas의 **`query()`** 메서드를 사용하여 조건에 맞는 데이터를 추출합니다. 이러한 방법을 통해 데이터를 자유롭게 필터링할 수 있습니다.

## 결론

이번 장에서는 대시보드에서 필터링 기능을 통해 사용자가 원하는 특정 조건의 데이터를 선별적으로 확인하는 방법에 대해 배웠습니다. 이런 기능을 사용하면 더 개인화된 데이터 분석이 가능해집니다. 다음 장에서는 [데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)를 통해 데이터를 로드하고 준비하는 방법에 대해 더 알아보겠습니다.
---
# Chapter 5: 데이터 전처리 및 로드

[이전 장: 필터링 기능](04_필터링_기능.md)에서는 대시보드를 통해 원하는 데이터를 필터링하는 방법을 배웠습니다. 이번 장에서는 머신러닝 모델을 위한 중요한 단계인 **데이터 전처리 및 로드**에 대해 알아보겠습니다.

## 동기

데이터 전처리는 머신러닝 모델의 성공적인 학습을 위해 필수적으로 필요합니다. 데이터를 로드하고 사용하기 용이하게 준비하지 않으면 결측값이나 형식 문제로 인해 예측 정확도에 영향을 줄 수 있습니다. 따라서 데이터 전처리를 적절히 수행하는 것은 매우 중요합니다.

### 예시 상황

예시로, 고객 데이터에서 누락된 값이 있는 상황을 고려해 봅시다. 이런 데이터로 모델을 훈련하면 부정확한 결과를 초래할 수 있습니다. 데이터 전처리는 이러한 문제를 해결하기 위해 데이터 형식 변환, 결측값 대체 등의 작업을 포함합니다.

## 데이터 전처리의 핵심 개념

### 데이터 로드

먼저, 데이터를 로딩하는 단계부터 시작해야 합니다. 이 예제에서는 CSV 파일을 읽어옵니다.

```python
import pandas as pd

# 고객 데이터를 CSV에서 읽어오기
data = pd.read_csv('customer_data.csv')
```

**`pandas`**를 사용하여 CSV 파일을 읽어옵니다. 이러면 데이터를 DataFrame 형식으로 쉽게 다룰 수 있습니다.

### 결측값 처리

데이터 중 결측값 또는 누락된 값을 처리해야 합니다. 데이터의 일관성을 확보하는 것이 중요하기 때문입니다.

```python
# 결측값을 평균값으로 대체
data.fillna(data.mean(), inplace=True)
```

위 코드에서는 결측값을 각 열의 평균값으로 대체하여 데이터의 완전성을 확보합니다.

### 범주형 데이터 처리

데이터에 범주형 값을 시계열이나 숫자로 변환하는 것이 중요합니다.

```python
# 범주형 변수를 수치형으로 변환
data['Gender'] = data['Gender'].map({'Male': 0, 'Female': 1})
```

여기서 성별 데이터를 'Male'을 0으로, 'Female'을 1로 변환하여 수치형 변수로 변경합니다.

### 수치형 데이터 정규화

데이터의 스케일링을 통해 모델 훈련 성능을 향상시킬 수 있습니다.

```python
from sklearn.preprocessing import MinMaxScaler

# 스케일러 초기화 및 적용
scaler = MinMaxScaler()
data[['Age', 'Salary']] = scaler.fit_transform(data[['Age', 'Salary']])
```

위 코드에서는 **`MinMaxScaler`**를 사용하여 'Age'와 'Salary' 열을 정규화합니다. 이로 인해 각각의 값이 0과 1 사이로 조정됩니다.

## 데이터 전처리 흐름

이제 전체 데이터를 전처리하는 흐름을 이해할 수 있습니다. 다음 시퀀스 다이어그램은 전처리 과정을 시각적으로 나타냅니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 시스템
    participant 전처리 모듈
    사용자->>시스템: 데이터 로드 요청
    시스템->>전처리 모듈: 데이터 전달
    전처리 모듈-->>시스템: 전처리된 데이터 반환
    시스템-->>사용자: 처리 완료된 데이터 표시
```

이 과정에서는 사용자가 데이터 로드를 요청하면 시스템이 전처리 모듈을 통해 데이터를 준비하고, 완성된 데이터를 반환받아 사용자에게 전달합니다.

### 전처리 코드 내부 구현

데이터 전처리의 실제 코드를 확인해보겠습니다. 데이터 전처리는 체계적인 단계를 통해 수행됩니다.

```python
def preprocess_data(file_path):
    df = pd.read_csv(file_path)
    
    # 결측값 확인 및 대체
    df.fillna(df.mean(), inplace=True)
    
    # 범주형 변수 변환
    df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})
    
    # 수치형 데이터 정규화
    scaler = MinMaxScaler()
    df[['Age', 'Salary']] = scaler.fit_transform(df[['Age', 'Salary']])
    
    return df

processed_data = preprocess_data('customer_data.csv')
```

함수 **`preprocess_data`**는 데이터를 로드하고, 결측값 처리, 범주형 변수 변환, 데이터 정규화를 포함한 모든 전처리 과정을 실행합니다. 결과적으로 모델에 알맞은 형태로 데이터를 변환합니다.

## 결론

이번 장에서는 데이터 전처리와 로드 과정을 통해 데이터의 품질을 높이고 모델 학습에 대비하는 방법을 배웠습니다. 전처리 과정을 잘 이해하면 향후 머신러닝 모델의 성능을 향상시킬 수 있습니다. 다음 장 [모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)에서는 준비된 데이터를 사용하여 모델을 학습시키고 예측 성능을 측정하는 방법에 대해 알아보겠습니다.
---
# Chapter 6: 모델 예측 및 성능 측정

[이전 장: 데이터 전처리 및 로드](05_데이터_전처리_및_로드.md)에서는 머신러닝 모델에 데이터를 준비하는 방법을 배웠습니다. 이번 장에서는 이러한 데이터를 사용하여 실제로 모델을 예측하고, 그 성능을 측정하는 방법을 알아보겠습니다.

## 동기

예를 들어, 우리는 고객의 이탈 가능성을 예측하는 모델을 만들려고 합니다. 이를 위해 Random Forest, Gradient Boosting, 그리고 Deep Learning 모델을 사용합니다. 이 예측이 정확하다면 은행은 고객 이탈을 사전에 예방할 수 있습니다. 하지만 예측의 정확도를 어떻게 평가할 수 있을까요? 정확도로만 충분할까요? 이번 장에서는 이러한 질문에 답하기 위해 모델을 예측하고 그 성능을 평가하는 방법을 설명합니다.

## 모델 예측 및 성능 측정의 핵심 개념

### 1. 모델 예측

모델 예측은 준비된 데이터에 기반하여 결과를 예측하는 단계입니다. 이는 예를 들어 고객의 이탈 여부를 예측하는 것과 같습니다.

```python
from sklearn.ensemble import RandomForestClassifier

# 모델 초기화
model = RandomForestClassifier()

# 예측
predictions = model.predict(test_data)
```

위 코드에서는 Random Forest 모델을 통해 데이터를 예측합니다. `test_data`에 대한 결과를 예측하여 그 결과를 `predictions`에 저장합니다.

### 2. 성능 측정

예측의 성능을 평가하는 데 여러 가지 방법이 있습니다. 대표적으로 정확도, 정밀도, 재현율 등이 있습니다.

```python
from sklearn.metrics import accuracy_score

# 정확도 계산
accuracy = accuracy_score(true_labels, predictions)
print(f"정확도: {accuracy}")
```

여기서는 정확도를 사용합니다. **정확도**란 전체 중 맞춘 비율을 의미하며, `true_labels`는 실제 레이블을 나타냅니다.

## 성능 측정의 내부 구현

예측과 성능 측정 과정이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 모델
    participant 성능 측정 모듈
    사용자->>모델: 데이터 입력
    모델-->>사용자: 예측 결과 반환
    사용자->>성능 측정 모듈: 결과와 실제 레이블 전달
    성능 측정 모듈-->>사용자: 성능 평가 지표 반환
```

### 내부 구현 코드

성능 평가 코드는 결과를 비교하여 각 평가 지표를 계산합니다.

```python
def evaluate_model(predictions, actuals):
    accuracy = accuracy_score(actuals, predictions)
    precision = precision_score(actuals, predictions)
    recall = recall_score(actuals, predictions)
    return accuracy, precision, recall

# 평가 실행
acc, prec, rec = evaluate_model(predictions, true_labels)
```

위의 함수는 `predictions`와 `actuals`를 통해 다양한 지표를 반환합니다. 정확도, 정밀도, 재현율을 포함한 결과는 모델의 성능을 종합적으로 평가하는 데 중요한 역할을 합니다.

## 결론

이번 장에서는 모델 예측과 성능 측정 방법에 대해 배웠습니다. 이를 통해 고객의 이탈 가능성을 효과적으로 예측하고, 예측 모델의 성능을 평가하는 방법을 이해할 수 있습니다. 다음 장에서는 [모델 로드 및 관리](07_모델_로드_및_관리.md)에서 이 모델들을 어떻게 저장하고, 재사용하며 관리하는지에 대해 알아보겠습니다.   

---
# Chapter 7: 모델 로드 및 관리

[이전 장: 모델 예측 및 성능 측정](06_모델_예측_및_성능_측정.md)에서는 은행 고객 이탈 예측 모델의 예측 결과와 성능을 평가하는 방법에 대해 배웠습니다. 이번 장에서는 예측 모델을 저장하고, 추후 필요할 때 다시 불러올 수 있게 관리하는 방법을 알아보겠습니다.

## 동기

모델 학습은 많은 계산 시간과 자원을 필요로 합니다. 따라서 매번 새롭게 모델을 학습시키기보다는 한번 저장해 두고 필요할 때 불러와 사용하는 것이 매우 효율적입니다. 예를 들어, 은행이 매주 고객 이탈을 예측하고자 할 때, 이전에 학습한 모델을 불러와 활용할 수 있습니다. 이 과정에서는 **모델 저장**과 **모델 로드**를 다루어 보겠습니다.

## 모델 로드 및 관리의 핵심 개념

### 1. 모델 저장

모델을 저장하면 나중에도 동일한 모델을 사용하여 예측할 수 있습니다. Scikit-learn에서는 `joblib` 라이브러리를 활용하여 간단히 모델을 저장할 수 있습니다.

```python
import joblib

# 학습된 모델을 저장
joblib.dump(model, 'customer_churn_model.pkl')
```

위 코드는 학습된 모델 객체를 'customer_churn_model.pkl' 파일로 저장합니다. 이렇게 저장한 모델은 언제든지 불러올 수 있습니다.

### 2. 모델 로드

저장한 모델을 불러와 사용하려면 `joblib`의 `load` 함수를 사용합니다.

```python
# 저장된 모델 로드
loaded_model = joblib.load('customer_churn_model.pkl')
```

`loaded_model`은 이제 저장된 모델과 동일한 상태를 가지며, 바로 예측에 사용할 수 있습니다.

## 모델 관리 흐름

모델 저장 및 로드 과정이 어떻게 진행되는지를 이해하기 위해 시퀀스 다이어그램을 이용합니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 모델 관리 시스템
    사용자->>모델 관리 시스템: 모델 저장 요청
    모델 관리 시스템-->>사용자: 저장 완료 확인
    사용자->>모델 관리 시스템: 모델 로드 요청
    모델 관리 시스템-->>사용자: 로드된 모델 반환
```

### 내부 구현 코드

모델 저장 및 로드는 간단한 코드를 통해 이루어집니다. 파일 저장 경로만 정확히 지정해주면, 필요할 때 쉽게 불러와서 사용할 수 있습니다.

```python
def save_model(model, filename):
    # 모델을 파일로 저장
    joblib.dump(model, filename)

def load_model(filename):
    # 파일에서 모델 로드
    return joblib.load(filename)

# 모델 학습 후 저장하기
save_model(model, 'churn_model.pkl')

# 필요할 때 모델 불러오기
loaded_model = load_model('churn_model.pkl')
```

**`save_model`** 함수는 모델을 지정된 파일로 저장하고, **`load_model`** 함수는 해당 파일에서 모델을 불러옵니다. 이러한 기능을 통해 모델을 쉽게 관리하고 이용할 수 있습니다.

## 결론

이번 장에서는 머신러닝 모델을 저장하고 불러오는 방법에 대해 알아보았습니다. 이렇게 하면 학습한 모델을 영구적으로 보관하고, 필요할 때 빠르게 재사용할 수 있습니다. 다음 장에서는 [고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)을 통해 은행 고객 이탈 분석과 관련된 데이터를 어떻게 생성하는지 살펴보겠습니다. 이 데이터는 더 나은 예측을 위한 중요한 자료가 됩니다.
---
# Chapter 8: 고객 이탈 분석 데이터 생성

[이전 장: 모델 로드 및 관리](07_모델_로드_및_관리.md)에서는 학습된 머신러닝 모델을 저장하고 관리하는 방법을 배웠습니다. 이번 장에서는 모델 예측 결과를 바탕으로 고객 이탈 분석 데이터를 생성하는 방법에 대해 다루겠습니다. 이 데이터는 고객의 이탈 원인을 이해하고 이를 해결하는 데 중요한 자료로 활용됩니다.

## 동기

은행에서는 고객의 이탈을 사전에 예방하고 이를 줄이는 것이 매우 중요합니다. 이를 위해 우리는 고객 이탈 가능성을 예측하는 모델을 활용하여 중요한 데이터를 생성할 수 있습니다. 이러한 데이터를 통해 고객이 왜 이탈할 가능성이 있는지를 분석하고, 그에 대한 대책을 마련할 수 있습니다. 예를 들어, 특정 고객이 높은 이탈 가능성을 가지고 있다면 그 원인을 분석하고, 고객 유지 전략을 세울 수 있습니다.

## 주요 개념

### 1. 위험도별 데이터 생성

모델 예측 결과를 기반으로 고객을 위험도에 따라 분류하고, 각 위험도에 따른 데이터를 생성합니다. 이는 고객 맞춤형 솔루션을 제안하는 데 유용합니다.

```python
import pandas as pd

# 예측 점수 데이터 예제
data = {'고객': ['A', 'B', 'C'],
        '이탈 가능성': [0.8, 0.2, 0.5]}

df = pd.DataFrame(data)

# 위험도별 분류
df['위험도'] = df['이탈 가능성'].apply(lambda x: '높음' if x > 0.7 else '낮음')
print(df)
```

위 코드에서는 고객의 이탈 가능성을 기준으로 '높음', '낮음'으로 분류합니다. 이를 통해 어떤 고객이 현재 이탈 위험이 높은지를 파악할 수 있습니다.

### 2. 분석 데이터 생성

고객의 이탈 위험도가 높은 그룹에 대해서는 더욱 심층적인 분석이 필요합니다. 이를 위해 추가적인 분석 데이터를 생성할 수 있습니다.

```python
# 위험도가 높은 고객 필터링
high_risk_customers = df[df['위험도'] == '높음']

# 심층 분석 데이터 생성 (예시)
detailed_analysis = high_risk_customers.assign(해결_방안='고객 서비스 강화')
print(detailed_analysis)
```

위 코드에서는 위험도가 높은 고객을 필터링하고, 이들에게 추가적인 해결 방안을 제안합니다. 이는 구체적인 고객 대응 전략을 만드는데 도움을 줍니다.

## 내부 구현 이해

고객 이탈 분석 데이터 생성 과정은 다음과 같이 이루어집니다. 시퀀스 다이어그램을 통해 내부 흐름을 이해할 수 있습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 분석 모듈
    participant 데이터 생성 모듈
    사용자->>분석 모듈: 고객 이탈 예측 결과 전달
    분석 모듈->>데이터 생성 모듈: 위험도별 데이터 요청
    데이터 생성 모듈-->>분석 모듈: 분석 데이터 반환
    분석 모듈-->>사용자: 분석 완료된 데이터 제공
```

### 구현 코드

아래의 함수 예시는 고객 이탈 예측 결과를 토대로 분석 데이터를 생성합니다.

```python
def generate_churn_analysis(predictions):
    # 고객 데이터 프레임 생성
    df = pd.DataFrame(predictions, columns=['고객', '이탈 가능성'])
    
    # 위험 단계 계산
    df['위험도'] = df['이탈 가능성'].apply(lambda x: '높음' if x > 0.7 else '낮음')
    
    # 심층 분석 제안
    df['추천 조치'] = df['위험도'].apply(
        lambda x: '고객 재방문을 유도하는 마케팅 제공' if x == '높음' else ' '
    )
    
    return df

# 예제 예측 데이터
predictions = [('A', 0.8), ('B', 0.2), ('C', 0.5)]

# 데이터 생성 실행
analysis_results = generate_churn_analysis(predictions)
print(analysis_results)
```

이 함수는 고객의 예측 데이터를 받아 위험도를 계산하고, 추천 조치를 추가합니다. 이를 통해 보다 구체적인 고객 유지 전략을 수립할 수 있습니다.

## 결론

이번 장에서는 고객 이탈 분석 데이터를 생성하는 방법에 대해 배웠습니다. 이를 통해 우리는 고객의 이탈 가능성을 예측하고, 그에 따른 대응 방안을 구체적으로 마련할 수 있습니다. 다음 장인 [나이별 데이터 분석](09_나이별_데이터_분석.md)에서는 나이별로 고객 데이터를 분석하여 더 세분화된 인사이트를 얻는 방법을 알아보겠습니다.   

이 장에서 배운 내용을 바탕으로 실제 데이터를 적용하여 고객 유지 전략을 더욱 강화해보세요!
---
# Chapter 9: 나이별 데이터 분석

[이전 장: 고객 이탈 분석 데이터 생성](08_고객_이탈_분석_데이터_생성.md)에서는 예측된 고객 이탈 가능성을 활용하여 분석 데이터를 생성하는 방법을 배웠습니다. 이번 장에서는 고객 연령대별 데이터를 분석하여, 더 깊이 있는 인사이트를 얻는 방법을 소개하겠습니다.

## 동기

은행은 다양한 고객층을 상대로 금융 서비스를 제공합니다. 이 때 고객의 나이대는 매우 중요한 요소가 됩니다. 왜냐하면 각 나이대별로 금융 상품 이용 패턴이나 선호도가 다를 수 있기 때문입니다. 예를 들어, 젊은 층은 대출 상품 보다는 투자를 더 선호할 수 있습니다. 따라서 나이별 데이터 분석을 통해 고객 맞춤형 서비스를 제공할 수 있습니다.

## 주요 개념

### 1. 나이대 구분 및 분석 준비

먼저 고객 데이터를 나이대 별로 구분하고 분석하기 위한 준비 작업을 수행합니다.

```python
import pandas as pd

# 고객 데이터 예제
data = {'고객': ['A', 'B', 'C', 'D'],
        '나이': [25, 55, 35, 42],
        '신용점수': [720, 680, 640, 745]}

df = pd.DataFrame(data)

# 10대 구간으로 나누기
bins = [18, 30, 40, 50, 60]
labels = ['18-30', '31-40', '41-50', '51-60']
df['나이대'] = pd.cut(df['나이'], bins=bins, labels=labels)
print(df)
```

위 코드에서는 고객들의 나이를 몇 개의 구간으로 나누어, 그에 따라 나이대를 라벨링합니다. 여기서 사용된 `pd.cut` 메서드는 데이터를 구간별로 나누는 데 유용합니다.

### 2. 나이대별 데이터 분석

라벨링된 나이대를 기준으로 각 그룹의 평균 신용점수를 계산하여 분석에 활용합니다.

```python
# 나이대별 평균 신용점수 계산
age_group_avg_credit = df.groupby('나이대')['신용점수'].mean()
print(age_group_avg_credit)
```

위 코드는 나이대별로 그룹화한 후, 각 그룹의 평균 신용점수를 계산합니다. 이를 통해 나이대별 신용점수가 어떻게 다른지 알 수 있습니다.

## 나이대별 분석의 내부 구현

나이대별 데이터를 분석하는 과정은 아래와 같이 다이어그램으로 이해할 수 있습니다:

```mermaid
sequenceDiagram
    participant 사용자
    participant 데이터 모듈
    participant 분석 모듈
    사용자->>데이터 모듈: 데이터 로드 요청
    데이터 모듈-->>사용자: 데이터 제공
    사용자->>분석 모듈: 나이대별 구분 및 평균 계산 요청
    분석 모듈-->>사용자: 나이대별 분석 결과 제공
```

### 내부 구현 코드

나이대 분석의 내부 구현 코드는 데이터의 구간 나누기와 평균 계산을 포함합니다.

```python
def analyze_age_groups(data_frame):
    # 나이대 정의
    bins = [18, 30, 40, 50, 60]
    labels = ['18-30', '31-40', '41-50', '51-60']
    
    # 나이대 추가
    data_frame['나이대'] = pd.cut(data_frame['나이'], bins=bins, labels=labels)
    
    # 나이대별 평균 신용점수
    return data_frame.groupby('나이대')['신용점수'].mean()

# 함수 호출 예시
customer_data = pd.DataFrame({'고객': ['A', 'B', 'C'], '나이': [24, 36, 48], '신용점수': [690, 710, 680]})
result = analyze_age_groups(customer_data)
print(result)
```

위 함수는 입력된 고객 데이터 프레임에 대해 나이대를 나누고, 각 나이대별 평균 신용점수를 반환합니다. 이를 사용하여 고객의 특성을 더 명확하게 분석할 수 있습니다.

## 결론

이번 장에서는 고객 데이터를 나이대별로 분석하여, 연령대에 따른 금융 행동 패턴을 이해하는 방법을 배웠습니다. 이를 통해 더 세밀한 고객 서비스 전략을 수립할 수 있습니다. 다음 장에서는 [고객 이탈 원인과 해결 방안](10_고객_이탈_원인과_해결_방안.md)을 탐색하여, 고객을 유지할 수 있는 다양한 방법을 살펴보겠습니다.

이제 나이대별 분석을 통해 더 개인화된 은행 서비스를 제공해보세요!

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 10: 고객 이탈 원인과 해결 방안`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 20:57:36,624 - INFO - Using OpenAI model: gpt-4o
2025-06-29 20:57:53,098 - INFO - RESPONSE: # 10장: 고객 이탈 원인과 해결 방안

[이전 장: 나이별 데이터 분석](09_나이별_데이터_분석.md)에서는 고객 데이터를 나이대별로 분석하여, 연령대에 따른 금융 행동 패턴을 이해하였습니다. 이번 장에서는 고객 이탈이 발생하는 원인을 분석하고 이를 해결할 수 있는 방안을 도출하는 방법을 알아보도록 하겠습니다.

## 동기

거래를 멈추고 이탈하는 고객들은 은행에는 큰 손실로 이어질 수 있습니다. 따라서 고객들이 왜 이탈하는지 그 원인을 이해하는 것이 중요합니다. 예를 들어, 고객이 대출 상품에 불만이 있다면 그 제품의 약점을 보완하여 이탈을 방지할 수 있습니다.

고객 이탈의 분석을 통해 은행은 어떤 고객 그룹이 이탈할 가능성이 높은지, 그들이 어떤 불만을 가지고 있는지를 이해할 수 있습니다. 이러한 분석을 통해 적절한 조치를 취해 고객의 만족도를 높이고, 이탈을 줄일 수 있습니다.

## 고객 이탈 원인 분석의 핵심 개념

### 1. 고객 피드백 수집 및 분석

고객 피드백은 이탈 원인을 분명하게 알려주는 중요한 데이터입니다. 이를 통해 고객 불만사항을 이해할 수 있습니다.

```python
import pandas as pd

# 예시 피드백 데이터
feedback_data = {'고객': ['A', 'B', 'C'],
                 '불만사항': ['서비스 느림', '낮은 이자', '고객 지원 불만']}

feedback_df = pd.DataFrame(feedback_data)
print(feedback_df)
```

위 코드에서는 간단한 피드백 데이터를 DataFrame으로 구성하였습니다. 이를 통해 고객들이 불만을 갖고 있는 구체적인 부분을 파악할 수 있습니다.

### 2. 이탈 원인 추출

고객 피드백을 토대로 이런 불만이 이탈로 이어지는 주요 원인을 설명할 수 있습니다.

```python
# 이탈 관련된 불만사항을 필터
related_feedback = feedback_df[feedback_df['불만사항'].str.contains('불만')]
print(related_feedback)
```

위 코드에서는 '불만'이라는 키워드를 기반으로 이탈과 관련된 피드백을 필터링합니다. 이를 통해 보다 이탈에 직접적인 영향을 줄 수 있는 피드백을 중심으로 분석할 수 있습니다.

## 고객 이탈 해결 방안 도출

고객 피드백을 통해 추출된 원인들을 해결할 수 있는 방안을 도출해야 합니다.

### 1. 문제 해결을 위한 행동 계획

고객이 제시한 불만사항을 해결하기 위한 방안을 구체적으로 설정합니다.

```python
# 불만사항에 따른 해결 방안 제안
feedback_df['해결 방안'] = feedback_df['불만사항'].apply(lambda x: '서비스 개선' if '서비스' in x else '신규 혜택 제공')
print(feedback_df)
```

위 코드에서는 특정 불만에 맞춘 해결 방안을 함께 제시합니다. 이는 은행이 시행할 수 있는 구체적인 조치를 제공함으로써, 고객의 불만을 해소할 수 있는 방안을 모색합니다.

## 내부 구현의 이해

고객 이탈 원인 분석 및 해결 방안 도출의 프로세스를 이해하기 쉽게 시퀀스 다이어그램으로 나타내겠습니다:

```mermaid
sequenceDiagram
    participant 은행
    participant 피드백 모듈
    participant 분석 모듈
    participant 해결 방안 모듈
    은행->>피드백 모듈: 고객 피드백 수집 요청
    피드백 모듈-->>은행: 피드백 데이터 제공
    은행->>분석 모듈: 이탈 원인 분석 요청
    분석 모듈-->>해결 방안 모듈: 원인 분석 결과 제공
    해결 방안 모듈-->>은행: 해결 방안 정보 전달
```

### 내부 코드 구현

고객 이탈 원인을 분석하고 해결 방안을 수립하는 전 과정은 다음과 같이 코드로 구현할 수 있습니다.

```python
def analyze_and_suggest_feedback(feedback):
    df = pd.DataFrame(feedback, columns=['고객', '불만사항'])
    # 관련 피드백 찾아내기
    related_feedback = df[df['불만사항'].str.contains('불만')]
    
    # 해결 방안 제안
    related_feedback['해결 방안'] = related_feedback['불만사항'].apply(
        lambda x: '서비스 향상' if '서비스' in x else '맞춤 혜택 제공'
    )
    return related_feedback

# 피드백 데이터 샘플
customer_feedback = [('A', '서비스 느림'), ('B', '낮은 이자'), ('C', '고객 지원 불만')]

# 함수 실행
suggestions = analyze_and_suggest_feedback(customer_feedback)
print(suggestions)
```

위 함수는 고객 피드백을 분석하고, 이탈 방지를 위한 해결 방안을 도출합니다. 각 피드백에 대해 적절한 조치를 제안함으로써, 고객과의 관계를 개선할 수 있습니다.

## 결론

이번 장에서는 고객 이탈의 원인을 분석하고 해결 방안을 구체적으로 수립하는 방법을 배웠습니다. 이를 통해 이탈 가능성이 높은 고객의 불만사항을 해소하고, 더 나은 은행 서비스를 제공할 수 있게 됩니다. 다음 장에서는 분석한 데이터를 활용하여 고객 중심의 전략을 구체적으로 수립하는 방법을 다룰 것입니다. 

다음 장으로 계속 학습하세요!

[다음 장: 은행 고객 이탈 예측 시스템 전략 수립](11_은행_고객_이탈_예측_시스템_전략_수립.md)
2025-06-29 21:01:18,462 - INFO - PROMPT: 
Analyze the following codebase for the project 'SKN_ToyProject'.

Available files (total 21):
- 0 # README.md
- 1 # backend/Curriculum/__init__.py
- 2 # backend/Curriculum/admin.py
- 3 # backend/Curriculum/apps.py
- 4 # backend/Curriculum/migrations/0001_initial.py
- 5 # backend/Curriculum/migrations/0002_initial.py
- 6 # backend/Curriculum/migrations/0003_curriculumquizhistory.py
- 7 # backend/Curriculum/migrations/0004_curriculumquizhistory_curriculumquizhistory_avg_score.py
- 8 # backend/Curriculum/migrations/__init__.py
- 9 # backend/Curriculum/models.py
- 10 # backend/Curriculum/urls.py
- 11 # backend/Curriculum/views.py
- 12 # backend/Project/__init__.py
- 13 # backend/Project/admin.py
- 14 # backend/Project/apps.py
- 15 # backend/Project/migrations/0001_initial.py
- 16 # backend/Project/migrations/0002_initial.py
- 17 # backend/Project/migrations/__init__.py
- 18 # backend/Project/models.py
- 19 # backend/Project/serializers.py
- 20 # backend/Project/urls.py

Full context of all files:
--- File Index 0: README.md ---
venv 생성 후 진입
```
py -3.13 -m venv .venv

.\.venv\Scripts\activate
```
---
라이브러리 설치
``` 
pip install django mysqlclient

pip install sshtunnel
```
---

http://127.0.0.1:8000/admin/ 의 슈퍼계정 하나 만들기.
```
python manage.py createsuperuser
```
admin, admin@gmail.com, admin1234 입력

---
Django 서버 실행.
```
cd .\backend\
python manage.py runserver
```
---
http://127.0.0.1:8000/admin/ 접속해보기
아까 만든 admin, admin1234 입력하면
현재 AWS 서버에 올라가 있는 DB의 Table들을 확인 가능
![image](https://github.com/user-attachments/assets/e02d1273-dceb-46ca-aee3-aa1285371e10)

---


--- File Index 1: backend/Curriculum/__init__.py ---


--- File Index 2: backend/Curriculum/admin.py ---
from django.contrib import admin

from .models import Curriculum

@admin.register(Curriculum)
class CurriculumAdmin(admin.ModelAdmin):
    list_display = (
        'curriculum_id', 'user_id', 'curriculum_type', 'curriculum_name', 'curriculum_prompt1', 'curriculum_prompt2',
        'curriculum_period', 'curriculum_content', 'curriculum_keyword'
    )
    # search_fields = ('curriculum_name', 'curriculum_prompt1', 'curriculum_prompt2')
    # list_filter = ('curriculum_period', 'user_id')
    ordering = ('-curriculum_id',)


from .models import CurriculumSection

@admin.register(CurriculumSection)
class CurriculumSectionAdmin(admin.ModelAdmin):
    list_display = (
        'curriculumsection_id', 'curriculum_id', 'curriculumsection_title', 'curriculumsection_order', 'curriculumsection_video_url'
    )
    # search_fields = ('curriculumsection_title')
    # list_filter = ('curriculum_id')
    ordering = ('-curriculum_id','-curriculumsection_id')


from .models import CurriculumSubSection

@admin.register(CurriculumSubSection)
class CurriculumSubSectionAdmin(admin.ModelAdmin):
    list_display = (
        'curriculumsubsection_id', 'curriculumsection_id', 'curriculumsubsection_title', 'curriculumsubsection_order',
        'curriculumsubsection_content'
    )
    # search_fields = ('curriculumsubsection_title')
    # list_filter = ('curriculumsection_id')
    ordering = ('-curriculumsection_id','-curriculumsubsection_id')


from .models import CurriculumSectionQuiz

@admin.register(CurriculumSectionQuiz)
class CurriculumSectionQuizAdmin(admin.ModelAdmin):
    list_display = (
        'curriculumsectionquiz_id', 'curriculumsection_id', 'curriculumsectionquiz_type', 'curriculumsectionquiz_question',
        'curriculumsectionquiz_data'
    )
    # search_fields = ('curriculumsectionquiz_question')
    # list_filter = ('curriculumsection_id', 'curriculumsectionquiz_type')
    ordering = ('-curriculumsection_id','-curriculumsectionquiz_id')


from .models import CurriculumUser

@admin.register(CurriculumUser)
class CurriculumUserAdmin(admin.ModelAdmin):
    list_display = ('curriculumuser_id', 'curriculum_id', 'user_id', 'curriculumsection_id', 'curriculumuser_is_completed', 'curriculumuser_start_dt', 'curriculumuser_end_dt')
    list_filter = ('curriculum_id', 'user_id')


from .models import Techstack

@admin.register(Techstack)
class TechstackAdmin(admin.ModelAdmin):
    list_display = ('techstack_id', 'techstack_name', 'techstack_desc')
    search_fields = ('techstack_name',)

from .models import CurriculumTechstack

@admin.register(CurriculumTechstack)
class CurriculumTechstackAdmin(admin.ModelAdmin):
    list_display = ('curriculumtechstack_id', 'curriculum_id', 'techstack_id')
    list_filter = ('curriculum_id', 'techstack_id')

from .models import CurriculumQuizHistory

@admin.register(CurriculumQuizHistory)
class CurriculumQuizHistoryAdmin(admin.ModelAdmin):
    list_display = ('curriculumquizhistory_id', 'curriculum_id', 'user_id', "curriculumquizhistory_total_score", "curriculumquizhistory_avg_score", "curriculumquizhistory_history", "curriculumquizhistory_submit_dt")
    list_filter = ('curriculum_id', 'user_id')


--- File Index 3: backend/Curriculum/apps.py ---
from django.apps import AppConfig


class CurriculumConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'Curriculum'


--- File Index 4: backend/Curriculum/migrations/0001_initial.py ---
# Generated by Django 5.1.6 on 2025-04-01 11:14

import django.utils.timezone
import pgvector.django.vector
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
    ]

    operations = [
        migrations.CreateModel(
            name='Curriculum',
            fields=[
                ('curriculum_id', models.AutoField(primary_key=True, serialize=False)),
                ('curriculum_type', models.CharField(blank=True, max_length=20, null=True)),
                ('curriculum_name', models.TextField()),
                ('curriculum_prompt1', models.TextField(blank=True, null=True)),
                ('curriculum_prompt2', models.TextField(blank=True, null=True)),
                ('curriculum_period', models.TextField(blank=True, null=True)),
                ('curriculum_content', models.TextField()),
                ('curriculum_keyword', models.TextField(blank=True, null=True)),
                ('curriculum_emb', pgvector.django.vector.VectorField(default=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], dimensions=1536)),
            ],
        ),
        migrations.CreateModel(
            name='CurriculumSection',
            fields=[
                ('curriculumsection_id', models.AutoField(primary_key=True, serialize=False)),
                ('curriculumsection_title', models.TextField()),
                ('curriculumsection_order', models.PositiveIntegerField()),
                ('curriculumsection_video_url', models.TextField()),
            ],
        ),
        migrations.CreateModel(
            name='CurriculumSectionQuiz',
            fields=[
                ('curriculumsectionquiz_id', models.AutoField(primary_key=True, serialize=False)),
                ('curriculumsectionquiz_type', models.CharField(max_length=20)),
                ('curriculumsectionquiz_question', models.TextField()),
                ('curriculumsectionquiz_data', models.JSONField(blank=True, null=True)),
            ],
        ),
        migrations.CreateModel(
            name='CurriculumSubSection',
            fields=[
                ('curriculumsubsection_id', models.AutoField(primary_key=True, serialize=False)),
                ('curriculumsubsection_title', models.TextField()),
                ('curriculumsubsection_order', models.PositiveIntegerField()),
                ('curriculumsubsection_content', models.TextField(blank=True, null=True)),
            ],
        ),
        migrations.CreateModel(
            name='CurriculumTechstack',
            fields=[
                ('curriculumtechstack_id', models.AutoField(primary_key=True, serialize=False)),
            ],
        ),
        migrations.CreateModel(
            name='CurriculumUser',
            fields=[
                ('curriculumuser_id', models.AutoField(primary_key=True, serialize=False)),
                ('curriculumuser_is_completed', models.BooleanField(default=False)),
                ('curriculumuser_start_dt', models.DateTimeField(default=django.utils.timezone.now)),
                ('curriculumuser_end_dt', models.DateTimeField(blank=True, null=True)),
            ],
        ),
        migrations.CreateModel(
            name='Techstack',
            fields=[
                ('techstack_id', models.AutoField(primary_key=True, serialize=False)),
                ('techstack_name', models.CharField(max_length=50)),
                ('techstack_desc', models.TextField(blank=True, null=True)),
            ],
        ),
    ]


--- File Index 5: backend/Curriculum/migrations/0002_initial.py ---
# Generated by Django 5.1.6 on 2025-04-01 11:14

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('Curriculum', '0001_initial'),
        ('User', '0001_initial'),
    ]

    operations = [
        migrations.AddField(
            model_name='curriculum',
            name='user_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='User.user'),
        ),
        migrations.AddField(
            model_name='curriculumsection',
            name='curriculum_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='Curriculum.curriculum'),
        ),
        migrations.AddField(
            model_name='curriculumsectionquiz',
            name='curriculumsection_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='Curriculum.curriculumsection'),
        ),
        migrations.AddField(
            model_name='curriculumsubsection',
            name='curriculumsection_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='Curriculum.curriculumsection'),
        ),
        migrations.AddField(
            model_name='curriculumtechstack',
            name='curriculum_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='Curriculum.curriculum'),
        ),
        migrations.AddField(
            model_name='curriculumuser',
            name='curriculum_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='Curriculum.curriculum'),
        ),
        migrations.AddField(
            model_name='curriculumuser',
            name='curriculumsection_id',
            field=models.ForeignKey(blank=True, default=None, null=True, on_delete=django.db.models.deletion.SET_NULL, to='Curriculum.curriculumsection'),
        ),
        migrations.AddField(
            model_name='curriculumuser',
            name='user_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='User.user'),
        ),
        migrations.AddField(
            model_name='curriculumtechstack',
            name='techstack_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='Curriculum.techstack'),
        ),
    ]


--- File Index 6: backend/Curriculum/migrations/0003_curriculumquizhistory.py ---
# Generated by Django 5.1.6 on 2025-04-15 09:51

import django.db.models.deletion
import django.utils.timezone
from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('Curriculum', '0002_initial'),
        ('User', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='CurriculumQuizHistory',
            fields=[
                ('curriculumquizhistory_id', models.AutoField(primary_key=True, serialize=False)),
                ('curriculumquizhistory_total_score', models.PositiveIntegerField(default=0)),
                ('curriculumquizhistory_history', models.JSONField(blank=True, null=True)),
                ('curriculumquizhistory_submit_dt', models.DateTimeField(default=django.utils.timezone.now)),
                ('curriculum_id', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='Curriculum.curriculum')),
                ('user_id', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='User.user')),
            ],
        ),
    ]


--- File Index 7: backend/Curriculum/migrations/0004_curriculumquizhistory_curriculumquizhistory_avg_score.py ---
# Generated by Django 5.1.6 on 2025-04-15 10:33

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('Curriculum', '0003_curriculumquizhistory'),
    ]

    operations = [
        migrations.AddField(
            model_name='curriculumquizhistory',
            name='curriculumquizhistory_avg_score',
            field=models.FloatField(default=0.0),
        ),
    ]


--- File Index 8: backend/Curriculum/migrations/__init__.py ---


--- File Index 9: backend/Curriculum/models.py ---
from django.db import models
from django.utils import timezone
from pgvector.django import VectorField


class Curriculum(models.Model):
    curriculum_id = models.AutoField(primary_key=True)
    user_id = models.ForeignKey("User.User", on_delete=models.CASCADE)  # 유저와 연결
    curriculum_type = models.CharField(max_length=20, null=True, blank=True)   # "standard" or "ai" or "dummy"
    curriculum_name = models.TextField()
    curriculum_prompt1 = models.TextField(null=True, blank=True)  # "어떤 주제를 학습하고 싶은지 구체적으로 알려주세요." 입력
    curriculum_prompt2 = models.TextField(null=True, blank=True)  # "당신의 수준을 알려주세요." 입력
    curriculum_period = models.TextField(null=True, blank=True)  # 학습 기간
    curriculum_content = models.TextField()  # 출력 결과 및 커리큘럼 저장
    curriculum_keyword = models.TextField(null=True, blank=True)    # 커리큘럼 키워드
    curriculum_emb = VectorField(dimensions=1536, default=[0.0]*1536)

    def __str__(self):
        return f"{self.curriculum_id} - {self.curriculum_type} - {self.curriculum_name}"


class CurriculumSection(models.Model):
    curriculumsection_id = models.AutoField(primary_key=True)
    curriculum_id = models.ForeignKey(Curriculum, on_delete=models.CASCADE)
    curriculumsection_title = models.TextField()  # 대제목
    curriculumsection_order = models.PositiveIntegerField()  # 대제목 순서
    curriculumsection_video_url = models.TextField()

    def __str__(self):
        return f"{self.curriculumsection_id} - {self.curriculum_id.curriculum_name} - {self.curriculumsection_order} - {self.curriculumsection_title}"


class CurriculumSubSection(models.Model):
    curriculumsubsection_id = models.AutoField(primary_key=True)
    curriculumsection_id = models.ForeignKey(CurriculumSection, on_delete=models.CASCADE)
    curriculumsubsection_title = models.TextField()  # 소제목
    curriculumsubsection_order = models.PositiveIntegerField()  # 소제목 순서
    curriculumsubsection_content = models.TextField(null=True, blank=True)  # 소제목에 대한 설명

    def __str__(self):
        return f"{self.curriculumsection_id.curriculum_id.curriculum_name} - {self.curriculumsection_id.curriculumsection_title} - {self.curriculumsubsection_order} - {self.curriculumsubsection_title}"


class CurriculumSectionQuiz(models.Model):
    curriculumsectionquiz_id = models.AutoField(primary_key=True)
    curriculumsection_id = models.ForeignKey(CurriculumSection, on_delete=models.CASCADE)
    curriculumsectionquiz_type = models.CharField(max_length=20)
    curriculumsectionquiz_question = models.TextField()
    curriculumsectionquiz_data = models.JSONField(null=True, blank=True)

    def __str__(self):
        return f"{self.curriculumsection_id.curriculum_id.curriculum_name} - {self.curriculumsectionquiz_type} - {self.curriculumsectionquiz_question} - {self.curriculumsectionquiz_data}"


class CurriculumUser(models.Model):
    curriculumuser_id = models.AutoField(primary_key=True)
    curriculum_id = models.ForeignKey(Curriculum, on_delete=models.CASCADE)
    user_id = models.ForeignKey("User.User", on_delete=models.CASCADE)
    curriculumsection_id = models.ForeignKey(CurriculumSection, on_delete=models.SET_NULL, null=True, blank=True, default=None)
    curriculumuser_is_completed = models.BooleanField(default=False)
    curriculumuser_start_dt = models.DateTimeField(default=timezone.now)
    curriculumuser_end_dt = models.DateTimeField(null=True, blank=True)

    def __str__(self):
        return f"{self.curriculum_id.curriculum_name} - {self.user_id.user_nickname} - {self.curriculumuser_is_completed}"
    
    def save(self, *args, **kwargs):
        # 완료되지 않은 상태에서만 첫 번째 섹션 자동 설정
        if self.curriculumsection_id is None and not self.curriculumuser_is_completed:
            first_section = CurriculumSection.objects.filter(curriculum_id=self.curriculum_id).order_by('curriculumsection_order').first()
            if first_section:
                self.curriculumsection_id = first_section
        super().save(*args, **kwargs)


class Techstack(models.Model):
    techstack_id = models.AutoField(primary_key=True)
    techstack_name = models.CharField(max_length=50)
    techstack_desc = models.TextField(null=True, blank=True)

    def __str__(self):
        return f"{self.techstack_id} - {self.techstack_name}"


class CurriculumTechstack(models.Model):
    curriculumtechstack_id = models.AutoField(primary_key=True)
    curriculum_id = models.ForeignKey(Curriculum, on_delete=models.CASCADE)
    techstack_id = models.ForeignKey(Techstack, on_delete=models.CASCADE)

    def __str__(self):
        return f"{self.curriculumtechstack_id}"


class CurriculumQuizHistory(models.Model):
    curriculumquizhistory_id = models.AutoField(primary_key=True)
    curriculum_id = models.ForeignKey("Curriculum.Curriculum", on_delete=models.CASCADE)
    user_id = models.ForeignKey("User.User", on_delete=models.CASCADE)
    curriculumquizhistory_total_score = models.PositiveIntegerField(default=0)
    curriculumquizhistory_avg_score = models.FloatField(default=0.0)  # 평균 점수 필드 추가
    curriculumquizhistory_history = models.JSONField(null=True, blank=True)
    curriculumquizhistory_submit_dt = models.DateTimeField(default=timezone.now)

    def __str__(self):
        return f"{self.curriculum_id} - {self.user_id} - {self.curriculumquizhistory_submit_dt}"


--- File Index 10: backend/Curriculum/urls.py ---
from django.urls import path
from .views import (
    submit_answers, get_curriculum_by_id, get_search_curriculum, get_users_curriculum, 
    get_random_curriculum, add_curriculum, delete_curriculum, customize_curriculum,
    is_user_have_curriculum, complete_curriculum, recommend, get_query_result, 
    get_curriculum_quiz, add_quiz_history, get_quiz_history, 
    get_adaptive_quiz, analyze_quiz_report, ai_assistant
)

urlpatterns = [
    ###########################################################################################
    # 커리큘럼,퀴즈를 조회하는 url
    ###########################################################################################
    path("get_curriculum_by_id/", get_curriculum_by_id, name="get_curriculum_by_id"),
    path("get_users_curriculum/", get_users_curriculum, name="get_users_curriculum"),
    path("get_search_curriculum/", get_search_curriculum, name="get_search_curriculum"),
    path('get_random_curriculum/', get_random_curriculum, name='get_random_curriculum'),
    path('get_curriculum_quiz/', get_curriculum_quiz, name='get_curriculum_quiz'),
    path('is_user_have_curriculum/', is_user_have_curriculum, name='is_user_have_curriculum'),

    ###########################################################################################
    # 커리큘럼을 추가/삭제하는 url
    ###########################################################################################
    path('add_curriculum/', add_curriculum, name='add_curriculum'),
    path('delete_curriculum/', delete_curriculum, name='delete_curriculum'),
    path('customize_curriculum/', customize_curriculum, name='customize_curriculum'),

    ###########################################################################################
    # 커리큘럼의 퀴즈에 관련된 url
    ###########################################################################################
    path('submit_answers/', submit_answers, name='submit_answers'),
    path('complete_curriculum/', complete_curriculum, name='complete_curriculum'),
    path('add_quiz_history/', add_quiz_history, name='add_quiz_history'),
    path('get_adaptive_quiz/', get_adaptive_quiz, name='get_adaptive_quiz'),

    ###########################################################################################
    # RAG/Rerank/Agent/LLM 기능을 사용하는 url
    ###########################################################################################
    path('recommend/', recommend, name='recommend'),
    path('get_query_result/', get_query_result, name='get_query_result'),
    path('get_quiz_history/', get_quiz_history, name='get_quiz_history'),
    path('analyze_quiz_report/', analyze_quiz_report, name='analyze_quiz_report'),
    path('query/', ai_assistant, name='process_natural_query'),
    path('ai-assistant/', ai_assistant, name='ai_assistant'),
]


--- File Index 11: backend/Curriculum/views.py ---
###########################################################################################
# Django 관련 import
###########################################################################################
from django.shortcuts import render, get_object_or_404
from django.utils import timezone
from django.http import JsonResponse
from django.db.models import Q, Prefetch
from django.views.decorators.csrf import csrf_exempt
from django.core.paginator import Paginator, EmptyPage, PageNotAnInteger
from django.db import connection
from django.conf import settings

###########################################################################################
# model 관련 import
###########################################################################################
from .models import Curriculum, CurriculumSection, CurriculumSubSection, CurriculumSectionQuiz, CurriculumUser, CurriculumTechstack, Techstack, CurriculumQuizHistory
from User.models import User
from User.decorators import login_required_json

###########################################################################################
# rest_framework 관련 import
###########################################################################################
from rest_framework.decorators import api_view
from rest_framework.response import Response
from rest_framework import status

###########################################################################################
# 파이썬 라이브러리 import
###########################################################################################
import os
import random
import json
from groq import Groq
from google import genai
from google.genai import types

###########################################################################################
# 직접 만든 모듈 import
###########################################################################################
from utils.curriculum_utils import call_groq_api, generate_curriculum_prompt, create_curriculum_from_data
from utils.similarity import get_high_similarity_reranked
from utils.ai_agent import query_db
from utils.db_utils import (
    get_user_curriculum,
    get_user_sections,
    get_user_curriculum_status,
    get_user_info,
    get_user_projects,
    get_user_quiz_history,
    get_quiz_history_detail,
    analyze_quiz_history
)
from utils.query_utils import process_natural_query
from utils.ai_agent_utils import process_ai_assistant_query


# Groq API Key를 settings에서 가져옴
GROQ_API_KEY = settings.GROQ_API_KEY


###########################################################################################
# 커리큘럼,퀴즈를 조회하는 API
###########################################################################################

# curriculum_id를 받아 해당 커리큘럼 정보를 반환하는 API
@api_view(['GET'])
def get_curriculum_by_id(request):
    curriculum_id = request.GET.get("curriculum_id")  # 검색할 커리큘럼 ID
    curriculum_type = request.GET.get("curriculum_type", "standard")  # 기본값은 "standard"
    
    if not curriculum_id:
        return JsonResponse({"error": "curriculum_id를 입력해주세요."}, json_dumps_params={"ensure_ascii": False}, status=400)

    # curriculum_type이 유효한 값인지 확인
    if curriculum_type not in ["standard", "dummy"]:
        return JsonResponse({"error": "curriculum_type은 'standard' 또는 'dummy'여야 합니다."}, json_dumps_params={"ensure_ascii": False}, status=400)

    # 커리큘럼 조회 (관련 데이터 미리 로드)
    curriculum = get_object_or_404(
        Curriculum.objects.filter(curriculum_type=curriculum_type).select_related('user_id').prefetch_related(
            Prefetch('curriculumsection_set', 
                    queryset=CurriculumSection.objects.order_by('curriculumsection_order').prefetch_related(
                        Prefetch('curriculumsubsection_set', 
                                queryset=CurriculumSubSection.objects.order_by('curriculumsubsection_order')),
                        'curriculumsectionquiz_set'
                    ))
        ), 
        pk=curriculum_id
    )

    curriculum_sections = []
    for section in curriculum.curriculumsection_set.all():
        subsections_list = [{
            "curriculumsubsection_id": subsection.curriculumsubsection_id,
            "curriculumsubsection_order": subsection.curriculumsubsection_order,
            "curriculumsubsection_title": subsection.curriculumsubsection_title,
            "curriculumsubsection_content": subsection.curriculumsubsection_content,
        } for subsection in section.curriculumsubsection_set.all()]

        quizzes_list = [{
            "curriculumsectionquiz_id": quiz.curriculumsectionquiz_id,
            "curriculumsectionquiz_type": quiz.curriculumsectionquiz_type,
            "curriculumsectionquiz_question": quiz.curriculumsectionquiz_question,
            "curriculumsectionquiz_data": quiz.curriculumsectionquiz_data,
        } for quiz in section.curriculumsectionquiz_set.all()]
        
        curriculum_sections.append({
            "curriculumsection_id": section.curriculumsection_id,
            "curriculumsection_order": section.curriculumsection_order,
            "curriculumsection_title": section.curriculumsection_title,
            "curriculumsection_video_url": section.curriculumsection_video_url,
            "subsections": subsections_list,
            "quizzes": quizzes_list
        })

    # 결과 JSON 형태로 변환
    result = {
        "curriculum_id": curriculum.curriculum_id,
        "curriculum_type": curriculum.curriculum_type,
        "curriculum_name": curriculum.curriculum_name,
        "user_nickname": curriculum.user_id.user_nickname,
        "curriculum_prompt1": curriculum.curriculum_prompt1,
        "curriculum_prompt2": curriculum.curriculum_prompt2,
        "curriculum_preiod": curriculum.curriculum_period,
        "curriculum_keyword": curriculum.curriculum_keyword,
        "curriculum_content": curriculum.curriculum_content,
        "sections": curriculum_sections
    }

    return JsonResponse(result, json_dumps_params={"ensure_ascii": False})


# user_id, 검색분류, 검색어 를 받아 해당 커리큘럼 정보를 반환하는 API
@api_view(['GET'])
@login_required_json
def get_users_curriculum(request, user):
    user_id = user.user_id
    search_type = request.GET.get("type")  # 검색 분류 ('title' 또는 'techstack')
    query = request.GET.get("query", "")  # 검색어 (빈 문자열 기본값 설정)
    curriculum_type = request.GET.get("curriculum_type", "standard")  # 기본값은 "standard"
    
    # 필수 값 확인 (user_id는 필수, 검색어는 없어도 됨)
    if not user_id:
        return JsonResponse({"error": "user_id를 입력하세요."}, status=400, json_dumps_params={"ensure_ascii": False})
    
    # curriculum_type이 유효한 값인지 확인
    if curriculum_type not in ["standard", "dummy"]:
        return JsonResponse({"error": "curriculum_type은 'standard' 또는 'dummy'여야 합니다."}, json_dumps_params={"ensure_ascii": False}, status=400)
    
    # 기본 쿼리셋에 관련 데이터 미리 로드
    curriculum = Curriculum.objects.filter(user_id=user_id, curriculum_type=curriculum_type).select_related('user_id').prefetch_related(
        'curriculumtechstack_set__techstack_id',
        Prefetch('curriculumsection_set', 
                queryset=CurriculumSection.objects.order_by('curriculumsection_order').prefetch_related(
                    Prefetch('curriculumsubsection_set', 
                            queryset=CurriculumSubSection.objects.order_by('curriculumsubsection_order')),
                    'curriculumsectionquiz_set'
                ))
    )
    
    if not search_type:
        curriculums = curriculum.distinct()

        if query:
            curriculums = curriculums.filter(
                Q(curriculum_name__icontains=query) |  # 제목에서 검색
                Q(user_id__user_nickname__icontains=query) |  # 작성자에서 검색
                Q(curriculumtechstack__techstack_id__techstack_name__icontains=query)  # 기술 스택에서 검색
            )

    # 검색 분류에 따라 필터링 (검색어가 비어있다면 전체 반환)
    elif search_type == "title":
        curriculums = curriculum
        if query:
            curriculums = curriculums.filter(curriculum_name__icontains=query)

    elif search_type == "techstack":
        curriculums = curriculum
        if query:
            curriculums = curriculums.filter(
                curriculum_id__in=CurriculumTechstack.objects.filter(
                    techstack_id__in=Techstack.objects.filter(techstack_name__icontains=query)
                ).values_list("curriculum_id", flat=True)
            )
    else:
        return JsonResponse({"error": "검색 분류가 올바르지 않습니다."}, json_dumps_params={"ensure_ascii": False}, status=400)

    # 결과 JSON 형태로 변환
    results = []
    for curriculum in curriculums:
        curriculum_sections = []
        for section in curriculum.curriculumsection_set.all():
            subsections_list = [{
                "curriculumsubsection_id": subsection.curriculumsubsection_id,
                "curriculumsubsection_order": subsection.curriculumsubsection_order,
                "curriculumsubsection_title": subsection.curriculumsubsection_title,
                "curriculumsubsection_content": subsection.curriculumsubsection_content,
            } for subsection in section.curriculumsubsection_set.all()]

            quizzes_list = [{
                "curriculumsectionquiz_id": quiz.curriculumsectionquiz_id,
                "curriculumsectionquiz_type": quiz.curriculumsectionquiz_type,
                "curriculumsectionquiz_question": quiz.curriculumsectionquiz_question,
                "curriculumsectionquiz_data": quiz.curriculumsectionquiz_data,
            } for quiz in section.curriculumsectionquiz_set.all()]
            
            curriculum_sections.append({
                "curriculumsection_id": section.curriculumsection_id,
                "curriculumsection_order": section.curriculumsection_order,
                "curriculumsection_title": section.curriculumsection_title,
                "subsections": subsections_list,
                "quizzes": quizzes_list
            })

        techstack_names = [ts.techstack_id.techstack_name for ts in curriculum.curriculumtechstack_set.all()]

        results.append({
            "curriculum_id": curriculum.curriculum_id,
            "curriculum_type": curriculum.curriculum_type,
            "curriculum_name": curriculum.curriculum_name,
            "user_nickname": curriculum.user_id.user_nickname,
            "curriculum_keyword": curriculum.curriculum_keyword,
            "curriculum_content": curriculum.curriculum_content,
            "techstack_names": techstack_names,
            "sections": curriculum_sections  # 섹션 및 서브섹션 포함
        })

    return JsonResponse({"results": results}, json_dumps_params={"ensure_ascii": False}, safe=False)


# 검색분류, 검색어를 받아 전체 커리큘럼을 검색하는 API
@api_view(['GET'])
def get_search_curriculum(request):
    query = request.GET.get("query", "")  # 검색어 (빈 문자열 기본값 설정)
    curriculum_type = request.GET.get("curriculum_type", "standard")  # 기본값은 "standard"

    # curriculum_type이 유효한 값인지 확인
    if curriculum_type not in ["standard", "dummy"]:
        return JsonResponse({"error": "curriculum_type은 'standard' 또는 'dummy'여야 합니다."}, json_dumps_params={"ensure_ascii": False}, status=400)

    # 기본 쿼리셋에 관련 데이터 미리 로드
    curriculums = Curriculum.objects.filter(curriculum_type=curriculum_type).select_related('user_id').prefetch_related(
        'curriculumtechstack_set__techstack_id',
        Prefetch('curriculumsection_set', 
                queryset=CurriculumSection.objects.order_by('curriculumsection_order').prefetch_related(
                    Prefetch('curriculumsubsection_set', 
                            queryset=CurriculumSubSection.objects.order_by('curriculumsubsection_order')),
                    'curriculumsectionquiz_set'
                ))
    )

    curriculums = Curriculum.objects.filter(curriculum_type=curriculum_type).distinct()

    if query:
        curriculums = curriculums.filter(
            Q(curriculum_name__icontains=query) |  # 제목에서 검색
            Q(user_id__user_nickname__icontains=query) |  # 작성자에서 검색
            Q(curriculumtechstack__techstack_id__techstack_name__icontains=query)  # 기술 스택에서 검색
        )

    # curriculum_id를 내림차순으로 정렬
    curriculums = curriculums.order_by('-curriculum_id')

    # 페이지네이션 추가
    paginator = Paginator(curriculums, 10)  # 페이지당 10개
    page = request.GET.get('page', 1)

    # 요청된 페이지가 마지막 페이지보다 큰 경우 빈 결과 반환
    if int(page) > paginator.num_pages:
        return JsonResponse({"results": []}, json_dumps_params={"ensure_ascii": False}, safe=False)

    try:
        curriculums = paginator.page(page)
    except PageNotAnInteger:
        # 페이지 번호가 정수가 아닌 경우 첫 번째 페이지 표시
        curriculums = paginator.page(1)
    except EmptyPage:
        # 빈 페이지인 경우 빈 결과 반환
        return JsonResponse({"results": []}, json_dumps_params={"ensure_ascii": False}, safe=False)

    # 결과 JSON 형태로 변환
    results = []
    for curriculum in curriculums:
        curriculum_sections = []
        for section in curriculum.curriculumsection_set.all():
            # subsections_list = [{
            #     "curriculumsubsection_id": subsection.curriculumsubsection_id,
            #     "curriculumsubsection_order": subsection.curriculumsubsection_order,
            #     "curriculumsubsection_title": subsection.curriculumsubsection_title,
            #     "curriculumsubsection_content": subsection.curriculumsubsection_content,
            # } for subsection in section.curriculumsubsection_set.all()]

            # quizzes_list = [{
            #     "curriculumsectionquiz_id": quiz.curriculumsectionquiz_id,
            #     "curriculumsectionquiz_type": quiz.curriculumsectionquiz_type,
            #     "curriculumsectionquiz_question": quiz.curriculumsectionquiz_question,
            #     "curriculumsectionquiz_data": quiz.curriculumsectionquiz_data,
            # } for quiz in section.curriculumsectionquiz_set.all()]
            
            curriculum_sections.append({
                "curriculumsection_id": section.curriculumsection_id,
                "curriculumsection_order": section.curriculumsection_order,
                "curriculumsection_title": section.curriculumsection_title,
                # "subsections": subsections_list,
                # "quizzes": quizzes_list
            })

        # techstack_names = [ ts.techstack_id.techstack_name for ts in curriculum.curriculumtechstack_set.all() ]
        
        results.append({
            "curriculum_id": curriculum.curriculum_id,
            "curriculum_type": curriculum.curriculum_type,
            "curriculum_name": curriculum.curriculum_name,
            "user_nickname": curriculum.user_id.user_nickname,
            "curriculum_keyword": curriculum.curriculum_keyword,
            "curriculum_content": curriculum.curriculum_content,
            # "techstack_names": techstack_names,  # 기술 스택 목록 추가
            "sections": curriculum_sections  # 섹션 및 서브섹션 추가
        })

    return JsonResponse({"results": results}, json_dumps_params={"ensure_ascii": False}, safe=False)


# 랜덤으로 최대 4개의 커리큘럼을 반환하는 API
@api_view(['GET'])
def get_random_curriculum(request):
    curriculum_type = request.GET.get("curriculum_type", "standard")  # 기본값은 "standard"

    # curriculum_type이 유효한 값인지 확인
    if curriculum_type not in ["standard", "dummy"]:
        return JsonResponse({"error": "curriculum_type은 'standard' 또는 'dummy'여야 합니다."}, json_dumps_params={"ensure_ascii": False}, status=400)

    total_curriculums = Curriculum.objects.filter(curriculum_type=curriculum_type).count()
    
    sample_size = min(total_curriculums, 4)

    # 최적화된 쿼리를 위해 모든 커리큘럼 ID 가져오기
    all_curriculum_ids = list(Curriculum.objects.filter(curriculum_type=curriculum_type).values_list('curriculum_id', flat=True))
    
    # 랜덤 ID 선택
    if sample_size < total_curriculums:
        random_ids = random.sample(all_curriculum_ids, sample_size)
    else:
        random_ids = all_curriculum_ids
    
    # 선택된 ID로 한 번에 최적화된 쿼리 실행
    random_curriculums = Curriculum.objects.filter(curriculum_id__in=random_ids, curriculum_type=curriculum_type).select_related('user_id').prefetch_related(
        'curriculumtechstack_set__techstack_id',
        Prefetch('curriculumsection_set', 
                queryset=CurriculumSection.objects.order_by('curriculumsection_order').prefetch_related(
                    Prefetch('curriculumsubsection_set', 
                            queryset=CurriculumSubSection.objects.order_by('curriculumsubsection_order')),
                    'curriculumsectionquiz_set'
                ))
    )

    curriculum_data = []
    
    for curriculum in random_curriculums:
        curriculum_sections = []
        for section in curriculum.curriculumsection_set.all():
            subsections_list = [{
                "curriculumsubsection_id": subsection.curriculumsubsection_id,
                "curriculumsubsection_order": subsection.curriculumsubsection_order,
                "curriculumsubsection_title": subsection.curriculumsubsection_title,
                "curriculumsubsection_content": subsection.curriculumsubsection_content,
            } for subsection in section.curriculumsubsection_set.all()]

            # quizzes_list = [{
            #     "curriculumsectionquiz_id": quiz.curriculumsectionquiz_id,
            #     "curriculumsectionquiz_type": quiz.curriculumsectionquiz_type,
            #     "curriculumsectionquiz_question": quiz.curriculumsectionquiz_question,
            #     "curriculumsectionquiz_data": quiz.curriculumsectionquiz_data,
            # } for quiz in section.curriculumsectionquiz_set.all()]
            
            curriculum_sections.append({
                "curriculumsection_id": section.curriculumsection_id,
                "curriculumsection_order": section.curriculumsection_order,
                "curriculumsection_title": section.curriculumsection_title,
                "subsections": subsections_list,
                # "quizzes": quizzes_list
            })
        
        techstack_names = [ts.techstack_id.techstack_name for ts in curriculum.curriculumtechstack_set.all()]
        
        curriculum_data.append({
            "curriculum_id": curriculum.curriculum_id,
            "curriculum_type": curriculum.curriculum_type,
            "curriculum_name": curriculum.curriculum_name,
            "curriculum_prompt1": curriculum.curriculum_prompt1,
            "curriculum_prompt2": curriculum.curriculum_prompt2,
            "curriculum_keyword": curriculum.curriculum_keyword,
            "curriculum_content": curriculum.curriculum_content,
            "techstack_names": techstack_names,
            "sections": curriculum_sections
        })

    return JsonResponse(curriculum_data, json_dumps_params={"ensure_ascii": False}, safe=False)


@api_view(['GET'])
@login_required_json
def get_curriculum_quiz(request, user):
    """
    커리큘럼의 전체 섹션에 대한 랜덤 퀴즈를 가져오는 API
    
    URL 파라미터:
    - curriculum_id: 커리큘럼 ID
    
    반환:
    - 섹션별 랜덤 퀴즈 목록
    """
    try:
        curriculum_id = request.GET.get('curriculum_id')
        user_id = user.user_id
        
        if not curriculum_id:
            return JsonResponse({"error": "curriculum_id is required"}, status=400)
        
        # 커리큘럼 존재 여부 확인
        try:
            curriculum = Curriculum.objects.get(curriculum_id=curriculum_id)
        except Curriculum.DoesNotExist:
            return JsonResponse({"error": "Curriculum not found"}, status=404)
        
        # 현재 요청에 user_id 파라미터 추가
        request._request.GET = request._request.GET.copy()
        request._request.GET['user_id'] = str(user_id)
        
        quiz_num_data = get_adaptive_quiz(request._request)

        # get_quiz_section_results의 결과가 JsonResponse 형태이므로, content를 파싱함
        try:
            section_results_data = json.loads(quiz_num_data.content.decode("utf-8"))
        except Exception as e:
            return JsonResponse({
                "error": "섹션별 출제 계획을 가져오는데 실패했습니다: " + str(e)
            }, status=500, json_dumps_params={"ensure_ascii": False})
        
        # get_quiz_section_results에서 에러가 발생한 경우 그대로 반환
        if "error" in section_results_data:
            return JsonResponse(section_results_data, status=400, json_dumps_params={"ensure_ascii": False})

        # 섹션별 출제 계획을 딕셔너리로 변환
        section_question_plan = section_results_data.get("section_question_plan", [])
        quiz_counts = {}
        for section_plan in section_question_plan:
            section_id = str(section_plan.get("section_id"))
            num_questions = section_plan.get("num_questions", 0)
            quiz_counts[section_id] = num_questions

        # 섹션별 퀴즈 가져오기
        sections = CurriculumSection.objects.filter(curriculum_id=curriculum_id).order_by('curriculumsection_order')
        
        result = {
            "curriculum_id": curriculum_id,
            "curriculum_name": curriculum.curriculum_name,
            "sections": []
        }
        
        for section in sections:
            section_id = section.curriculumsection_id
            section_str_id = str(section_id)
            
            # 해당 섹션의 퀴즈 개수 설정 (기본값: 0)
            quiz_count = int(quiz_counts.get(section_str_id, 0))
            
            if quiz_count > 0:
                # 섹션에 대한 퀴즈를 랜덤하게 가져오기 - order_by('?')로 랜덤 정렬
                quizzes = CurriculumSectionQuiz.objects.filter(
                    curriculumsection_id=section_id
                ).order_by('?')[:quiz_count]  # 랜덤으로 정렬 후 요청된 수만큼만 가져오기
                
                section_data = {
                    "section_id": section_id,
                    "section_title": section.curriculumsection_title,
                    "quizzes": []
                }
                
                for quiz in quizzes:
                    quiz_data = {
                        "quiz_id": quiz.curriculumsectionquiz_id,
                        "quiz_type": quiz.curriculumsectionquiz_type,
                        "quiz_question": quiz.curriculumsectionquiz_question,
                        "quiz_data": quiz.curriculumsectionquiz_data
                    }
                    section_data["quizzes"].append(quiz_data)
                
                result["sections"].append(section_data)
        
        # 섹션별 출제 계획과 실제 출제된 문제 수를 같이 반환
        result["section_question_plan"] = section_question_plan
        
        return JsonResponse(result, json_dumps_params={"ensure_ascii": False})
    
    except Exception as e:
        return JsonResponse({"error": str(e)}, status=500, json_dumps_params={"ensure_ascii": False})


# user_id를 받아 해당 유저가 커리큘럼을 저장했는지 확인하는 API
@api_view(['GET'])
@login_required_json
def is_user_have_curriculum(request, user):
    user_id = user.user_id
    if request.method == 'GET':
        curriculum_id = request.query_params.get('curriculum_id')

        if not curriculum_id:
            return Response({"error": "curriculum_id is required"}, status=status.HTTP_400_BAD_REQUEST)
        
        try:
            # 해당 유저가 특정 커리큘럼을 보유하고 있는지 확인
            try:
                curriculum_user = CurriculumUser.objects.get(user_id=user_id, curriculum_id=curriculum_id)
                return Response({
                    "is_user_have_curriculum": True,
                    "curriculumuser_id": curriculum_user.curriculumuser_id,
                    "curriculumsection_id": curriculum_user.curriculumsection_id.curriculumsection_id,
                    "curriculumuser_is_completed": curriculum_user.curriculumuser_is_completed
                }, status=status.HTTP_200_OK)
            except CurriculumUser.DoesNotExist:
                return Response({"is_user_have_curriculum": False}, status=status.HTTP_200_OK)
            
        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


###########################################################################################
# 커리큘럼을 추가/삭제하는 API
###########################################################################################

# add_curriculum 함수 리팩토링
@api_view(['POST'])
@login_required_json
def add_curriculum(request, user):
    user_id = user.user_id
    if request.method == 'POST':
        data = request.data
        
        # standard 커리큘럼 생성 전용 계정
        if user_id == 1:
            curriculum_data = data
        else:
            # 필수 필드 확인
            required_fields = ["curriculum_prompt1", "curriculum_prompt2", "curriculum_period"]
            if not all(field in data for field in required_fields):
                return Response({"error": "모든 필수 필드를 입력해주세요."}, status=status.HTTP_400_BAD_REQUEST)

            # 프롬프트 생성
            prompt = generate_curriculum_prompt({
                'curriculum_prompt1': data['curriculum_prompt1'],
                'curriculum_prompt2': data['curriculum_prompt2'],
                'curriculum_period': data['curriculum_period']
            }, prompt_type="new")
            
            # Groq API 호출
            try:
                curriculum_data = call_groq_api(prompt)
            except Exception as e:
                return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        # 커리큘럼 생성
        try:
            curriculum_type = "dummy" if user_id == 1 else "ai"
            new_curriculum = create_curriculum_from_data(
                curriculum_data=curriculum_data,
                user=user,
                curriculum_type=curriculum_type,
                extra_data=data if curriculum_type == "ai" else None
            )
        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        return Response({
            "message": "커리큘럼이 추가되었습니다.", 
            "curriculum_id": new_curriculum.curriculum_id
        }, status=status.HTTP_201_CREATED)


# 커리큘럼 삭제 API
@api_view(['POST'])
def delete_curriculum(request):
    if request.method == 'POST':
        data = request.data  # JSON 데이터는 request.data로 자동 파싱
        curriculum_id = data.get("curriculum_id")

        if not curriculum_id:
            return Response({"error": "curriculum_id를 입력해주세요."}, status=status.HTTP_400_BAD_REQUEST)

        # 해당 커리큘럼 삭제
        try:
            curriculum = Curriculum.objects.get(pk=curriculum_id)
            curriculum.delete()
            return Response({"message": f"커리큘럼 {curriculum_id}이(가) 삭제되었습니다."}, status=status.HTTP_200_OK)
        except Curriculum.DoesNotExist:
            return Response({"error": "커리큘럼을 찾을 수 없습니다."}, status=status.HTTP_404_NOT_FOUND)


# customize_curriculum 함수 리팩토링
@api_view(['GET', 'POST'])
@login_required_json
def customize_curriculum(request, user):
    """
    커리큘럼 번호와 사용자의 요구 쿼리를 받아 커리큘럼 result를 불러오고, 이를 LLM을 사용하여 쿼리에 맞게 커스텀하는 API
    """
    if request.method == 'GET':
        curriculum_id = request.GET.get("curriculum_id")
        user_query = request.GET.get("query")
    else:
        data = request.data
        curriculum_id = data.get("curriculum_id")
        user_query = data.get("query")

    # 필수 파라미터 검증
    if not curriculum_id or not user_query:
        return Response({
            "error": "curriculum_id와 query를 모두 입력해주세요."
        }, status=status.HTTP_400_BAD_REQUEST)

    # 커리큘럼 데이터 가져오기
    curriculum = get_object_or_404(Curriculum, pk=curriculum_id)
    
    # 프롬프트 생성
    prompt = generate_curriculum_prompt({
        'original_curriculum': curriculum.curriculum_content,
        'user_query': user_query
    }, prompt_type="customize")
    
    # Groq API 호출
    try:
        curriculum_data = call_groq_api(prompt)
    except Exception as e:
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    # 커리큘럼 생성
    try:
        new_curriculum = create_curriculum_from_data(
            curriculum_data=curriculum_data,
            user=user,
            curriculum_type="ai",
            extra_data=None
        )
    except Exception as e:
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    return Response({
        "message": "커리큘럼이 커스터마이징되었습니다.", 
        "curriculum_id": new_curriculum.curriculum_id
    }, status=status.HTTP_201_CREATED)


###########################################################################################
# 커리큘럼의 퀴즈에 관련된 API
###########################################################################################

@csrf_exempt
@api_view(['POST'])
def submit_answers(request):
    data = request.data
    section_index = data.get('sectionIndex')
    answers = data.get('answers')
    print(data)
    if section_index is None or answers is None:
        return JsonResponse({"error": "sectionIndex와 answers를 모두 포함해야 합니다."}, status=400, json_dumps_params={"ensure_ascii": False})

    # Ensure answers is a list of dictionaries
    if isinstance(answers, dict):
        answers = [{"question_id": k, "answer": v} for k, v in answers.items()]

    results = {}
    scores = {}
    feedbacks = {}
    user_answers = {}

    for answer in answers:
        if not isinstance(answer, dict):
            continue

        question_id = answer.get('question_id')
        user_answer = answer.get('answer')

        if not question_id or user_answer is None:
            continue
        
        # 사용자 답변 저장
        user_answers[question_id] = user_answer
        
        try:
            quiz = CurriculumSectionQuiz.objects.get(pk=question_id)
        except CurriculumSectionQuiz.DoesNotExist:
            continue
        
        # JSONField에서 정답 추출
        quiz_data = quiz.curriculumsectionquiz_data or {}
        correct_answer = quiz_data.get('answer', '')
        
        if quiz.curriculumsectionquiz_type == '객관식':
            print(f"정답: {correct_answer}, 사용자 답: {user_answer}")
            is_correct = user_answer == correct_answer
            results[question_id] = is_correct
            scores[question_id] = 100 if is_correct else 0
        elif quiz.curriculumsectionquiz_type == '주관식':
            try:
                client = Groq(api_key=GROQ_API_KEY)
                chat_completion = client.chat.completions.create(
                    messages=[
                        {
                            "role": "user",
                            "content": f"""다음 주관식 답안을 채점하시오.
                            피드백에 답안에 대한 힌트를 제시하시오.
                            점수는 100점이 만점으로 채점하시오.
                            사용자가 제출한 답안이 실제 정답과 일치하지 않더라도, 문제의 내용에 맞는 답안을 제출했다면 답안을 무시하고 높은 점수를 부여하시오.
                            만일 답안이 부적절하다고 판단되면, 0점을 부여하시오.
                            점수는 반드시 숫자로만 작성하시오.
                            반드시 피드백을 한글로 작성하시오.
                            문제: {quiz.curriculumsectionquiz_question},
                            답안: {user_answer},
                            정답: {correct_answer}
                            출력 형식: '점수: [점수(int)] 피드백: [피드백]'"""
                        }
                    ],
                    model="gemma2-9b-it",
                )
                grading_result = chat_completion.choices[0].message.content
                print(f"Groq API response: {grading_result}")  # 추가된 로그
                score_line = grading_result.split("점수:")[1].split("피드백:")[0].strip()
                feedback = grading_result.split("피드백:")[1].strip()
                score = int(score_line)
                # 점수가 80점 이상이면 정답으로 간주
                is_correct = score >= 80
                results[question_id] = is_correct
                scores[question_id] = score
                feedbacks[question_id] = feedback  # 피드백을 question_id를 키로 하여 저장
                print(f"주관식 문제 ID {question_id} 채점 결과: {score}점, 정답 여부: {is_correct}")
            except Exception as e:
                print("Groq API 호출 오류:", str(e))
                return JsonResponse({"error": f"Groq API 호출 오류: {str(e)}"}, status=500, json_dumps_params={"ensure_ascii": False})

    # 모든 문제의 정답 여부를 확인하여 전체 통과 여부 결정
    all_correct = all(results.values()) if results else False

    response_data = {
        "message": "정답이 성공적으로 제출되었습니다.",
        "sectionIndex": section_index,
        "results": results,
        "scores": scores,
        "all_correct": all_correct,
        "feedbacks": feedbacks,  # 모든 피드백 반환
        "user_answers": user_answers  # 사용자 답변 추가
    }

    return JsonResponse(response_data, status=200, json_dumps_params={"ensure_ascii": False})


# 커리큘럼을 완료 처리하는 API
@csrf_exempt
@api_view(['POST'])
@login_required_json
def complete_curriculum(request, user):
    curriculum_id = request.data.get('curriculum_id')
    user_id = user.user_id
    
    if not curriculum_id:
        return Response(
            {"error": "curriculum_id is required"}, 
            status=status.HTTP_400_BAD_REQUEST
        )
    
    # Get the current CurriculumUser record
    curriculum_user = get_object_or_404(
        CurriculumUser, 
        curriculum_id=curriculum_id, 
        user_id=user_id
    )
    
    # Mark the curriculum as completed regardless of current section
    curriculum_user.curriculumuser_is_completed = True
    curriculum_user.curriculumuser_end_dt = timezone.now()
    curriculum_user.save()
    
    return Response({
        "status": "success",
        "message": "Curriculum marked as completed",
        "data": {
            "curriculum_name": curriculum_user.curriculum_id.curriculum_name,
            "is_completed": True,
            "completion_date": curriculum_user.curriculumuser_end_dt
        }
    }, status=status.HTTP_200_OK)


@csrf_exempt
@login_required_json
@api_view(['POST'])
def add_quiz_history(request, user):
    if request.method == 'POST':
        try:
            data = request.data
            # 필요한 데이터 추출
            curriculum_id = data.get('curriculum_id')
            user_id = user.user_id  # 현재 로그인된 사용자 ID 사용

            # results, scores, feedbacks 데이터 추출
            results = data.get('results', {})
            scores = data.get('scores', {})
            user_answers = data.get('user_answers', {})
            feedbacks = data.get('feedbacks', {})

            # 총점, 평균 계산
            total_score = sum(scores.values()) if scores else 0
            avg_score = round(total_score / len(scores), 2) if len(scores) > 0 else 0.0

            # 이력 데이터 구조화
            history_data = {
                "historys": []
            }
            
            # 섹션별 통계를 추적하기 위한 딕셔너리
            section_stats = {}
            
            # 각 퀴즈에 대한 결과 기록
            for quiz_id in results.keys():
                quiz = CurriculumSectionQuiz.objects.get(curriculumsectionquiz_id=int(quiz_id))
                section_id = quiz.curriculumsection_id.curriculumsection_id
                section_title = quiz.curriculumsection_id.curriculumsection_title
                question = quiz.curriculumsectionquiz_question
                # 섹션 통계 초기화 (아직 없는 경우)
                if section_id not in section_stats:
                    section_stats[section_id] = {
                        "total_questions": 0,
                        "correct_answers": 0,
                        "total_score": 0
                    }
                
                # 섹션 통계 업데이트
                section_stats[section_id]["total_questions"] += 1
                
                if results.get(quiz_id, False):
                    section_stats[section_id]["correct_answers"] += 1
                
                section_stats[section_id]["total_score"] += scores.get(quiz_id, 0)

                quiz_history = {
                    "curriculumsectionquiz_id": int(quiz_id),
                    "curriculumsection_id": section_id,
                    "curriculumsection_title": section_title,
                    "question": question,
                    "user_answers": user_answers.get(quiz_id, ""),
                    "score": scores.get(quiz_id, 0),
                    "is_correct": results.get(quiz_id, False),
                    "feedback": feedbacks.get(quiz_id, "")
                }
                history_data["historys"].append(quiz_history)
            
            # 섹션별 평균 점수 계산 및 추가
            section_results = []
            for section_id, stats in section_stats.items():
                avg_section_score = round(stats["total_score"] / stats["total_questions"], 2) if stats["total_questions"] > 0 else 0
                
                section_result = {
                    "section_id": section_id,
                    "section_num_questions": stats["total_questions"],
                    "section_correct_answers": stats["correct_answers"],
                    "section_avg_score": avg_section_score
                }
                section_results.append(section_result)
            print("section_results:", section_results)
            # 히스토리 데이터에 섹션별 결과 추가
            history_data["section_results"] = section_results

            # 모델 인스턴스 생성 및 저장
            curriculum = Curriculum.objects.get(curriculum_id=curriculum_id)
            user = User.objects.get(user_id=user_id)

            quiz_history = CurriculumQuizHistory(
                curriculum_id=curriculum,
                user_id=user,
                curriculumquizhistory_total_score=total_score,
                curriculumquizhistory_avg_score=avg_score,
                curriculumquizhistory_history=history_data,
                curriculumquizhistory_submit_dt=timezone.now()
            )
            quiz_history.save()

            return JsonResponse({
                'success': True,
                'message': '퀴즈 결과가 성공적으로 저장되었습니다.',
                'quiz_history_id': quiz_history.curriculumquizhistory_id
            })
            
        except Exception as e:
            return JsonResponse({
                'success': False,
                'message': f'퀴즈 결과 저장 중 오류가 발생했습니다: {str(e)}'
            }, status=400)
    
    return JsonResponse({
        'success': False,
        'message': '잘못된 요청 방식입니다. POST 요청이 필요합니다.'
    }, status=405)


###########################################################################################
# RAG/Rerank/Agent/LLM 기능을 사용하는 API
###########################################################################################

# 커리큘럼으로 커리큘럼을 추천하는 API
@api_view(['GET'])
def recommend(request):
    input_type = request.GET.get("input_type")
    output_type = request.GET.get("output_type")
    only_dummy = request.GET.get("only_dummy", False)

    if input_type not in ["curriculum", "project"] or output_type not in ["curriculum", "project"]:
        return JsonResponse({"error": "Invalid input_type or output_type. Allowed values are 'curriculum' or 'project'."}, status=400)

    input_id = request.GET.get('input_id')
    top_k_sim = request.GET.get('top_k_sim')
    top_k_rerank = request.GET.get('top_k_rerank')

    try:
        input_id = int(input_id)
        top_k_sim = int(top_k_sim)
        top_k_rerank = int(top_k_rerank)
    except ValueError:
        return JsonResponse({"error": "Invalid input for input_id or top_k_sim or top_k_rerank"}, status=400)
    
    similar_curriculums_reranked = get_high_similarity_reranked(
        input_type=input_type,
        output_type=output_type,
        input_id=input_id,
        top_k_sim=top_k_sim,
        top_k_rerank=top_k_rerank,
        only_dummy=only_dummy
    )

    # 결과 반환
    result = [{"target_id": item["sim_id"], "cosine_similarity": item["similarity"]} for item in similar_curriculums_reranked]
    
    return JsonResponse({"input_type": input_type, "output_type": output_type, "similarity": result})


@api_view(['GET'])
def get_query_result(request):
    question = request.GET.get("question")
    result = query_db(question)
    return JsonResponse({"result": result}, json_dumps_params={"ensure_ascii": False})


###########################################################################################
# 퀴즈 히스토리 조회 API
###########################################################################################

@api_view(['GET'])
@login_required_json
def get_quiz_history(request, user):
    """
    특정 사용자의 퀴즈 히스토리를 조회하는 API
    
    Parameters:
    - curriculum_id (optional): 특정 커리큘럼의 퀴즈 히스토리만 조회
    """
    user_id = user.user_id  # 현재 로그인된 사용자 ID 사용
    
    try:
        # 기본 쿼리셋 생성
        quiz_histories = CurriculumQuizHistory.objects.filter(
            user_id=user_id
        ).select_related(
            'curriculum_id'
        ).order_by('-curriculumquizhistory_submit_dt')

        # 특정 커리큘럼에 대한 필터링
        curriculum_id = request.GET.get('curriculum_id')
        if curriculum_id:
            try:
                curriculum_id = int(curriculum_id)
                quiz_histories = quiz_histories.filter(curriculum_id=curriculum_id)
            except ValueError:
                return JsonResponse({
                    "error": "커리큘럼 ID는 숫자여야 합니다."
                }, status=400, json_dumps_params={"ensure_ascii": False})

        # 결과 데이터 구성
        results = []
        for history in quiz_histories:
            results.append({
                "quiz_history_id": history.curriculumquizhistory_id,
                "curriculum_id": history.curriculum_id.curriculum_id,
                "curriculum_name": history.curriculum_id.curriculum_name,
                "total_score": history.curriculumquizhistory_total_score,
                "avg_score": history.curriculumquizhistory_avg_score,
                "history_data": history.curriculumquizhistory_history,
                "submit_date": history.curriculumquizhistory_submit_dt.strftime("%Y-%m-%d %H:%M:%S")
            })

        return JsonResponse({
            "results": results
        }, json_dumps_params={"ensure_ascii": False})
        
    except Exception as e:
        return JsonResponse({
            "error": f"퀴즈 히스토리 조회 중 오류가 발생했습니다: {str(e)}"
        }, status=500, json_dumps_params={"ensure_ascii": False})


###########################################################################################
# GPT-4가 자연어 쿼리를 처리하는 API
###########################################################################################

@api_view(['POST'])
def ai_assistant(request):
    """
    AI 에이전트 엔드포인트 - 자연어 쿼리를 통해 db_utils.py의 함수를 호출합니다.
    """
    try:
        # 요청 데이터 파싱
        data = request.data
        print(f"요청 데이터: {data}")
        
        user_id = data.get('user_id')
        query = data.get('query')
        
        print(f"파싱된 데이터 - user_id: {user_id} ({type(user_id)}), query: {query}")
        
        if not user_id or not query:
            return Response({"error": "user_id와 query는 필수 항목입니다."}, status=400)
        
        # user_id가 정수형인지 확인하고 변환
        try:
            user_id = int(user_id)
        except (ValueError, TypeError):
            return Response({"error": "user_id는 정수여야 합니다."}, status=400)
        
        # 유틸리티 함수 호출
        print(f"process_ai_assistant_query 호출: user_id={user_id}, query={query}")
        result = process_ai_assistant_query(user_id, query)
        
        # 에러 처리
        if "error" in result:
            print(f"에러 응답: {result['error']}")
            return Response(result, status=400)
        
        print(f"성공 응답 - 키: {list(result.keys())}")
        return Response(result)
            
    except Exception as e:
        print(f"예외 발생: {str(e)}")
        import traceback
        traceback.print_exc()
        return Response({"error": str(e)}, status=500)


###########################################################################################
# 히스토리 기반 문제 출제 API
###########################################################################################
def _get_section_score(history_qs):
    """
    history_qs: 최신 2개 CurriculumQuizHistory QuerySet
    반환: (section_question_plan, selected_questions)
    """
    # 1) 섹션별 누적 total/ correct 합산
    merged = {}
    for hist in history_qs:
        data = hist
        for sec in data["history_data"]["section_results"]:
            sid = sec["section_id"]
            total = sec.get("section_num_questions", 0)
            corr  = sec.get("section_correct_answers", 0)
            merged.setdefault(sid, {"total": 0, "correct": 0})
            merged[sid]["total"]   += total
            merged[sid]["correct"] += corr

    # 2) 정답률 기반 문제 수 산정
    section_question_plan = []
    for sid, vals in merged.items():
        total   = vals["total"] or 1
        correct = vals["correct"]
        acc = correct / total

        if acc < 0.25:
            n = 4
        elif acc < 0.5:
            n = 3
        elif acc < 0.75:
            n = 2
        else:
            n = 1

        section_question_plan.append({
            "section_id": sid,
            "accuracy_percent": round(acc * 100, 2),
            "num_questions": n
        })

    return section_question_plan

@api_view(['GET'])
def get_adaptive_quiz(request):
    """
    사용자 최신 2개 히스토리를 기반으로,
    섹션별 누적 정답률 → 문제 수 산정 → 랜덤 문제 추출
    """
    history_response = get_quiz_history(request._request)

    # get_quiz_history의 결과가 JsonResponse 형태이므로, content를 파싱함.
    try:
        history_data = json.loads(history_response.content.decode("utf-8"))
    except Exception as e:
        return JsonResponse({
            "error": "퀴즈 히스토리 데이터를 파싱하는데 실패했습니다."
        }, status=500, json_dumps_params={"ensure_ascii": False})

    # get_quiz_history에서 에러가 발생한 경우 그대로 반환
    if "error" in history_data:
        return JsonResponse(history_data, status=400, json_dumps_params={"ensure_ascii": False})

    quiz_histories = history_data.get("results", [])

    # 히스토리가 없는 경우, 모든 섹션에 기본 문제 수(2개)를 설정하여 반환
    if not quiz_histories:
        # 현재 커리큘럼의 모든 섹션 정보 가져오기
        sections = CurriculumSection.objects.filter(curriculum_id=request.GET.get('curriculum_id'))

        # 각 섹션에 대해 기본값(2문제) 설정
        section_question_plan = []
        for section in sections:
            section_question_plan.append({
                "section_id": section.curriculumsection_id,
                "accuracy_percent": 0,  # 기록 없음
                "num_questions": 2  # 기본값
            })

        return JsonResponse({
            "section_question_plan": section_question_plan
        }, json_dumps_params={"ensure_ascii": False})

    # 가장 최근 2개의 히스토리 데이터만 사용
    recent_histories = quiz_histories[:2]

    plan = _get_section_score(recent_histories)

    return JsonResponse({
        "section_question_plan": plan,
    }, json_dumps_params={"ensure_ascii": False})

###########################################################################################
# 퀴즈 분석 및 레포트 생성 API
###########################################################################################

@api_view(['GET'])
@login_required_json
def analyze_quiz_report(request, user):
    """
    특정 퀴즈 히스토리에 대한 상세 분석 및 학습 계획을 생성하는 API
    
    Parameters:
    - quiz_history_id (required): 분석할 퀴즈 히스토리 ID
    """
    quiz_history_id = request.GET.get('quiz_history_id')
    
    if not quiz_history_id:
        return JsonResponse({
            "error": "quiz_history_id는 필수 파라미터입니다."
        }, status=400, json_dumps_params={"ensure_ascii": False})
    
    try:
        # 퀴즈 히스토리 상세 정보 조회
        history_data = get_quiz_history_detail(quiz_history_id)

        if not history_data:
            return JsonResponse({
                "error": "해당 퀴즈 히스토리가 존재하지 않습니다."
            }, status=404, json_dumps_params={"ensure_ascii": False})
        
        # 권한 확인 - 자신의 퀴즈 히스토리만 볼 수 있음
        if history_data.get('user_id') != user.user_id:
            return JsonResponse({
                "error": "이 퀴즈 히스토리에 접근할 권한이 없습니다."
            }, status=403, json_dumps_params={"ensure_ascii": False})
        
        # 퀴즈 히스토리 분석
        analysis_result = analyze_quiz_history(history_data)
        
        return JsonResponse({
            "quiz_history": {
                "id": history_data.get('curriculumquizhistory_id'),
                "curriculum_id": history_data.get('curriculum_id'),
                "curriculum_name": history_data.get('curriculum_name'),
                "user_nickname": history_data.get('user_nickname'),
                "total_score": history_data.get('curriculumquizhistory_total_score'),
                "avg_score": history_data.get('curriculumquizhistory_avg_score'),
                "submit_date": history_data.get('curriculumquizhistory_submit_dt')
            },
            "analysis": {
                "section_scores": analysis_result.get('section_scores', []),
                "best_sections": analysis_result.get('best_sections', []),
                "worst_sections": analysis_result.get('worst_sections', []),
                "wrong_answers": analysis_result.get('wrong_answers', []),
                "strength_analysis": analysis_result.get('strength_analysis', ''),
                "weakness_analysis": analysis_result.get('weakness_analysis', ''),
                "wrong_answer_analysis": analysis_result.get('wrong_answer_analysis', ''),
                "study_plan": analysis_result.get('study_plan', '')
            }
        }, json_dumps_params={"ensure_ascii": False})
    
    except Exception as e:
        return JsonResponse({
            "error": f"분석 중 오류가 발생했습니다: {str(e)}"
        }, status=500, json_dumps_params={"ensure_ascii": False})



--- File Index 12: backend/Project/__init__.py ---


--- File Index 13: backend/Project/admin.py ---
from django.contrib import admin


from .models import Project

@admin.register(Project)
class ProjectAdmin(admin.ModelAdmin):
    list_display = ('project_id', 'user_id', 'project_name','project_start_date', 'project_end_date', 
                    'project_member_num', "project_join_address", "project_content", 'project_keyword')
    search_fields = ('project_name',)


--- File Index 14: backend/Project/apps.py ---
from django.apps import AppConfig


class ProjectConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'Project'


--- File Index 15: backend/Project/migrations/0001_initial.py ---
# Generated by Django 5.1.6 on 2025-04-01 11:14

import pgvector.django.vector
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
    ]

    operations = [
        migrations.CreateModel(
            name='Project',
            fields=[
                ('project_id', models.AutoField(primary_key=True, serialize=False)),
                ('project_name', models.CharField(max_length=50)),
                ('project_start_date', models.DateTimeField()),
                ('project_end_date', models.DateTimeField()),
                ('project_member_num', models.IntegerField()),
                ('project_join_address', models.TextField(blank=True, null=True)),
                ('project_content', models.TextField(blank=True, null=True)),
                ('project_keyword', models.TextField(blank=True, null=True)),
                ('project_emb', pgvector.django.vector.VectorField(default=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], dimensions=1536)),
            ],
        ),
    ]


--- File Index 16: backend/Project/migrations/0002_initial.py ---
# Generated by Django 5.1.6 on 2025-04-01 11:14

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('Project', '0001_initial'),
        ('User', '0001_initial'),
    ]

    operations = [
        migrations.AddField(
            model_name='project',
            name='user_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='User.user'),
        ),
    ]


--- File Index 17: backend/Project/migrations/__init__.py ---


--- File Index 18: backend/Project/models.py ---
from django.db import models
from pgvector.django import VectorField

class Project(models.Model):
    project_id = models.AutoField(primary_key=True)
    user_id = models.ForeignKey('User.User', on_delete=models.CASCADE)
    project_name = models.CharField(max_length=50)
    project_start_date = models.DateTimeField()
    project_end_date = models.DateTimeField()
    project_member_num = models.IntegerField()
    project_join_address= models.TextField(null=True, blank=True)
    project_content = models.TextField(null=True, blank=True)
    project_keyword = models.TextField(null=True, blank=True)
    project_emb = VectorField(dimensions=1536, default=[0.0]*1536)

    def __str__(self):
        return f"{self.project_id} - {self.project_name}"


--- File Index 19: backend/Project/serializers.py ---
from rest_framework import serializers
from .models import Project
from User.models import User

class ProjectSerializer(serializers.ModelSerializer):
    # user_nickname을 추가
    user_nickname = serializers.SerializerMethodField()

    class Meta:
        model = Project
        fields = '__all__'  # user_id는를 통해 조회한 user_nickname도 json에 같이 담아서 보냄.
    
    def get_user_nickname(self, obj):
        # user_id는 User 모델과 연결되어 있다고 가정
        user = obj.user_id
        return user.user_nickname


--- File Index 20: backend/Project/urls.py ---
from django.urls import path
from . import views
from .views import add_project, get_random_project, CreateProjectUsingLLM, CreateProject, create_project, get_project_by_id, get_search_project, apply_to_project

urlpatterns = [
    ###########################################################################################
    # 프로젝트를 조회하는 url
    ###########################################################################################
    path('get_project_by_id/', get_project_by_id, name='get_project_by_id'),
    path('get_search_project/', get_search_project, name='get_search_project'),
    path('get_random_project/', get_random_project, name='get_random_project'),
    path('<int:project_id>/team/', views.team_member_list, name='team_member_list'),
    
    ###########################################################################################
    # 프로젝트를 추가/삭제하는 url
    ###########################################################################################
    path('add_project/', add_project, name='add_project'),
    path('create_project/<int:project_id>/', CreateProject.as_view(), name='create_project'),
    path('create_project/', create_project, name='create_project'),
    path('apply_to_project/', apply_to_project, name='apply_to_project'),
    
    ###########################################################################################
    # RAG/Rerank/Agent/LLM 기능을 사용하는 url
    ###########################################################################################
    path('create-project-using-llm/<int:curriculum_id>/', CreateProjectUsingLLM.as_view(), name='create-project-using-llm'),

]




Based on the provided codebase, identify the key abstractions that are central to understanding this project. 
These abstractions should represent the core components, modules, or concepts.

Desired output format is a YAML list of objects, where each object has:
- 'name': A concise name for the abstraction (in korean).
- 'description': A brief explanation of what this abstraction represents and its role (in korean).
- 'file_indices': A list of integer file indices that are most relevant to this abstraction. Choose from the file list above.

Return at most 10 key abstractions.

Example for a different project (simple web server):
```yaml
- name: "HTTP 요청 핸들러 (HTTP Request Handler)"
  description: "수신 HTTP 요청을 처리하고 적절한 응답을 생성하는 구성 요소입니다. (Component that processes incoming HTTP requests and generates appropriate responses.)"
  file_indices: [0, 2]
- name: "라우팅 설정 (Routing Configuration)"
  description: "URL 경로를 특정 요청 핸들러 함수에 매핑하는 규칙을 정의합니다. (Defines rules for mapping URL paths to specific request handler functions.)"
  file_indices: [1]
```

Your response should be only the YAML list, enclosed in triple backticks (```yaml ... ```).
Ensure the output is valid YAML.

2025-06-29 21:01:18,727 - INFO - Using OpenAI model: gpt-4o
2025-06-29 21:01:27,455 - INFO - RESPONSE: ```yaml
- name: "커리큘럼 모델 (Curriculum Model)"
  description: "교육 커리큘럼을 정의하고 관리하는 주요 데이터 구조입니다. 사용자 아이디와 관련된 다양한 정보, 예를 들어 커리큘럼 타입, 이름, 키워드 등을 포함합니다."
  file_indices: [9, 4, 5]

- name: "프로젝트 모델 (Project Model)"
  description: "사용자의 프로젝트에 대한 정보를 저장하고 관리하는 데 사용되는 데이터 구조입니다. 프로젝트 이름, 시작 및 종료 날짜, 팀원 수 등을 관리합니다."
  file_indices: [18, 15, 16]

- name: "관리 인터페이스 (Admin Interface)"
  description: "관리자에게 다양한 모델 객체를 관리할 수 있는 인터페이스를 제공하여 데이터의 시각화와 조작을 용이하게 합니다."
  file_indices: [2, 13]

- name: "커리큘럼 뷰 (Curriculum Views)"
  description: "커리큘럼 관련 데이터를 조회, 추가, 삭제하거나 맞춤화된 커리큘럼을 생성하는 API 엔드포인트를 제공합니다."
  file_indices: [11]

- name: "프로젝트 뷰 (Project Views)"
  description: "프로젝트 관련 데이터를 조회하고, 새로운 프로젝트를 추가하거나 수정하는 API 엔드포인트를 제공합니다."
  file_indices: [20]

- name: "퀴즈 히스토리 및 분석 (Quiz History and Analysis)"
  description: "사용자가 완료한 퀴즈의 이력을 저장하고 분석하여 각 섹션의 성과를 평가하고 결과를 제공합니다."
  file_indices: [9, 11, 6, 7]

- name: "기술 스택 관리 (Tech Stack Management)"
  description: "각 커리큘럼에 필요한 기술 스택 정보를 저장하고 관리합니다."
  file_indices: [9]

- name: "사용자 및 커리큘럼 관계 (User and Curriculum Relationship)"
  description: "사용자와 커리큘럼 간의 관계를 관리하여, 사용자가 어떤 커리큘럼을 완료했는지 기록합니다."
  file_indices: [9, 5]

- name: "GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)"
  description: "사용자의 자연어 쿼리를 처리하고, 데이터베이스와 상호작용하며 다양한 커리큘럼 및 프로젝트 관련 데이터를 제공합니다."
  file_indices: [11]

- name: "추천 시스템 (Recommendation System)"
  description: "특정 커리큘럼이나 프로젝트의 유사 항목을 추천하여 사용자에게 더 나은 경험을 제공합니다."
  file_indices: [11]
```
2025-06-29 21:01:27,837 - INFO - PROMPT: 
Based on the following abstractions and relevant code snippets from the project `SKN_ToyProject`:

List of Abstraction Indices and Names (Names might be in Korean):
0 # 커리큘럼 모델 (Curriculum Model)
1 # 프로젝트 모델 (Project Model)
2 # 관리 인터페이스 (Admin Interface)
3 # 커리큘럼 뷰 (Curriculum Views)
4 # 프로젝트 뷰 (Project Views)
5 # 퀴즈 히스토리 및 분석 (Quiz History and Analysis)
6 # 기술 스택 관리 (Tech Stack Management)
7 # 사용자 및 커리큘럼 관계 (User and Curriculum Relationship)
8 # GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)
9 # 추천 시스템 (Recommendation System)

Context (Abstractions, Descriptions, Code):
Identified Abstractions:
- Index 0: 커리큘럼 모델 (Curriculum Model) (Relevant file indices: [9, 4, 5])
  Description: 교육 커리큘럼을 정의하고 관리하는 주요 데이터 구조입니다. 사용자 아이디와 관련된 다양한 정보, 예를 들어 커리큘럼 타입, 이름, 키워드 등을 포함합니다.
- Index 1: 프로젝트 모델 (Project Model) (Relevant file indices: [18, 15, 16])
  Description: 사용자의 프로젝트에 대한 정보를 저장하고 관리하는 데 사용되는 데이터 구조입니다. 프로젝트 이름, 시작 및 종료 날짜, 팀원 수 등을 관리합니다.
- Index 2: 관리 인터페이스 (Admin Interface) (Relevant file indices: [2, 13])
  Description: 관리자에게 다양한 모델 객체를 관리할 수 있는 인터페이스를 제공하여 데이터의 시각화와 조작을 용이하게 합니다.
- Index 3: 커리큘럼 뷰 (Curriculum Views) (Relevant file indices: [11])
  Description: 커리큘럼 관련 데이터를 조회, 추가, 삭제하거나 맞춤화된 커리큘럼을 생성하는 API 엔드포인트를 제공합니다.
- Index 4: 프로젝트 뷰 (Project Views) (Relevant file indices: [20])
  Description: 프로젝트 관련 데이터를 조회하고, 새로운 프로젝트를 추가하거나 수정하는 API 엔드포인트를 제공합니다.
- Index 5: 퀴즈 히스토리 및 분석 (Quiz History and Analysis) (Relevant file indices: [9, 11, 6, 7])
  Description: 사용자가 완료한 퀴즈의 이력을 저장하고 분석하여 각 섹션의 성과를 평가하고 결과를 제공합니다.
- Index 6: 기술 스택 관리 (Tech Stack Management) (Relevant file indices: [9])
  Description: 각 커리큘럼에 필요한 기술 스택 정보를 저장하고 관리합니다.
- Index 7: 사용자 및 커리큘럼 관계 (User and Curriculum Relationship) (Relevant file indices: [9, 5])
  Description: 사용자와 커리큘럼 간의 관계를 관리하여, 사용자가 어떤 커리큘럼을 완료했는지 기록합니다.
- Index 8: GPT 기반 AI 어시스턴트 (GPT-based AI Assistant) (Relevant file indices: [11])
  Description: 사용자의 자연어 쿼리를 처리하고, 데이터베이스와 상호작용하며 다양한 커리큘럼 및 프로젝트 관련 데이터를 제공합니다.
- Index 9: 추천 시스템 (Recommendation System) (Relevant file indices: [11])
  Description: 특정 커리큘럼이나 프로젝트의 유사 항목을 추천하여 사용자에게 더 나은 경험을 제공합니다.

Relevant File Snippets (Referenced by Index and Path):
--- File: 2 # backend/Curriculum/admin.py ---
from django.contrib import admin

from .models import Curriculum

@admin.register(Curriculum)
class CurriculumAdmin(admin.ModelAdmin):
    list_display = (
        'curriculum_id', 'user_id', 'curriculum_type', 'curriculum_name', 'curriculum_prompt1', 'curriculum_prompt2',
        'curriculum_period', 'curriculum_content', 'curriculum_keyword'
    )
    # search_fields = ('curriculum_name', 'curriculum_prompt1', 'curriculum_prompt2')
    # list_filter = ('curriculum_period', 'user_id')
    ordering = ('-curriculum_id',)


from .models import CurriculumSection

@admin.register(CurriculumSection)
class CurriculumSectionAdmin(admin.ModelAdmin):
    list_display = (
        'curriculumsection_id', 'curriculum_id', 'curriculumsection_title', 'curriculumsection_order', 'curriculumsection_video_url'
    )
    # search_fields = ('curriculumsection_title')
    # list_filter = ('curriculum_id')
    ordering = ('-curriculum_id','-curriculumsection_id')


from .models import CurriculumSubSection

@admin.register(CurriculumSubSection)
class CurriculumSubSectionAdmin(admin.ModelAdmin):
    list_display = (
        'curriculumsubsection_id', 'curriculumsection_id', 'curriculumsubsection_title', 'curriculumsubsection_order',
        'curriculumsubsection_content'
    )
    # search_fields = ('curriculumsubsection_title')
    # list_filter = ('curriculumsection_id')
    ordering = ('-curriculumsection_id','-curriculumsubsection_id')


from .models import CurriculumSectionQuiz

@admin.register(CurriculumSectionQuiz)
class CurriculumSectionQuizAdmin(admin.ModelAdmin):
    list_display = (
        'curriculumsectionquiz_id', 'curriculumsection_id', 'curriculumsectionquiz_type', 'curriculumsectionquiz_question',
        'curriculumsectionquiz_data'
    )
    # search_fields = ('curriculumsectionquiz_question')
    # list_filter = ('curriculumsection_id', 'curriculumsectionquiz_type')
    ordering = ('-curriculumsection_id','-curriculumsectionquiz_id')


from .models import CurriculumUser

@admin.register(CurriculumUser)
class CurriculumUserAdmin(admin.ModelAdmin):
    list_display = ('curriculumuser_id', 'curriculum_id', 'user_id', 'curriculumsection_id', 'curriculumuser_is_completed', 'curriculumuser_start_dt', 'curriculumuser_end_dt')
    list_filter = ('curriculum_id', 'user_id')


from .models import Techstack

@admin.register(Techstack)
class TechstackAdmin(admin.ModelAdmin):
    list_display = ('techstack_id', 'techstack_name', 'techstack_desc')
    search_fields = ('techstack_name',)

from .models import CurriculumTechstack

@admin.register(CurriculumTechstack)
class CurriculumTechstackAdmin(admin.ModelAdmin):
    list_display = ('curriculumtechstack_id', 'curriculum_id', 'techstack_id')
    list_filter = ('curriculum_id', 'techstack_id')

from .models import CurriculumQuizHistory

@admin.register(CurriculumQuizHistory)
class CurriculumQuizHistoryAdmin(admin.ModelAdmin):
    list_display = ('curriculumquizhistory_id', 'curriculum_id', 'user_id', "curriculumquizhistory_total_score", "curriculumquizhistory_avg_score", "curriculumquizhistory_history", "curriculumquizhistory_submit_dt")
    list_filter = ('curriculum_id', 'user_id')


--- File: 4 # backend/Curriculum/migrations/0001_initial.py ---
# Generated by Django 5.1.6 on 2025-04-01 11:14

import django.utils.timezone
import pgvector.django.vector
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
    ]

    operations = [
        migrations.CreateModel(
            name='Curriculum',
            fields=[
                ('curriculum_id', models.AutoField(primary_key=True, serialize=False)),
                ('curriculum_type', models.CharField(blank=True, max_length=20, null=True)),
                ('curriculum_name', models.TextField()),
                ('curriculum_prompt1', models.TextField(blank=True, null=True)),
                ('curriculum_prompt2', models.TextField(blank=True, null=True)),
                ('curriculum_period', models.TextField(blank=True, null=True)),
                ('curriculum_content', models.TextField()),
                ('curriculum_keyword', models.TextField(blank=True, null=True)),
                ('curriculum_emb', pgvector.django.vector.VectorField(default=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], dimensions=1536)),
            ],
        ),
        migrations.CreateModel(
            name='CurriculumSection',
            fields=[
                ('curriculumsection_id', models.AutoField(primary_key=True, serialize=False)),
                ('curriculumsection_title', models.TextField()),
                ('curriculumsection_order', models.PositiveIntegerField()),
                ('curriculumsection_video_url', models.TextField()),
            ],
        ),
        migrations.CreateModel(
            name='CurriculumSectionQuiz',
            fields=[
                ('curriculumsectionquiz_id', models.AutoField(primary_key=True, serialize=False)),
                ('curriculumsectionquiz_type', models.CharField(max_length=20)),
                ('curriculumsectionquiz_question', models.TextField()),
                ('curriculumsectionquiz_data', models.JSONField(blank=True, null=True)),
            ],
        ),
        migrations.CreateModel(
            name='CurriculumSubSection',
            fields=[
                ('curriculumsubsection_id', models.AutoField(primary_key=True, serialize=False)),
                ('curriculumsubsection_title', models.TextField()),
                ('curriculumsubsection_order', models.PositiveIntegerField()),
                ('curriculumsubsection_content', models.TextField(blank=True, null=True)),
            ],
        ),
        migrations.CreateModel(
            name='CurriculumTechstack',
            fields=[
                ('curriculumtechstack_id', models.AutoField(primary_key=True, serialize=False)),
            ],
        ),
        migrations.CreateModel(
            name='CurriculumUser',
            fields=[
                ('curriculumuser_id', models.AutoField(primary_key=True, serialize=False)),
                ('curriculumuser_is_completed', models.BooleanField(default=False)),
                ('curriculumuser_start_dt', models.DateTimeField(default=django.utils.timezone.now)),
                ('curriculumuser_end_dt', models.DateTimeField(blank=True, null=True)),
            ],
        ),
        migrations.CreateModel(
            name='Techstack',
            fields=[
                ('techstack_id', models.AutoField(primary_key=True, serialize=False)),
                ('techstack_name', models.CharField(max_length=50)),
                ('techstack_desc', models.TextField(blank=True, null=True)),
            ],
        ),
    ]


--- File: 5 # backend/Curriculum/migrations/0002_initial.py ---
# Generated by Django 5.1.6 on 2025-04-01 11:14

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('Curriculum', '0001_initial'),
        ('User', '0001_initial'),
    ]

    operations = [
        migrations.AddField(
            model_name='curriculum',
            name='user_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='User.user'),
        ),
        migrations.AddField(
            model_name='curriculumsection',
            name='curriculum_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='Curriculum.curriculum'),
        ),
        migrations.AddField(
            model_name='curriculumsectionquiz',
            name='curriculumsection_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='Curriculum.curriculumsection'),
        ),
        migrations.AddField(
            model_name='curriculumsubsection',
            name='curriculumsection_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='Curriculum.curriculumsection'),
        ),
        migrations.AddField(
            model_name='curriculumtechstack',
            name='curriculum_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='Curriculum.curriculum'),
        ),
        migrations.AddField(
            model_name='curriculumuser',
            name='curriculum_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='Curriculum.curriculum'),
        ),
        migrations.AddField(
            model_name='curriculumuser',
            name='curriculumsection_id',
            field=models.ForeignKey(blank=True, default=None, null=True, on_delete=django.db.models.deletion.SET_NULL, to='Curriculum.curriculumsection'),
        ),
        migrations.AddField(
            model_name='curriculumuser',
            name='user_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='User.user'),
        ),
        migrations.AddField(
            model_name='curriculumtechstack',
            name='techstack_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='Curriculum.techstack'),
        ),
    ]


--- File: 6 # backend/Curriculum/migrations/0003_curriculumquizhistory.py ---
# Generated by Django 5.1.6 on 2025-04-15 09:51

import django.db.models.deletion
import django.utils.timezone
from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('Curriculum', '0002_initial'),
        ('User', '0001_initial'),
    ]

    operations = [
        migrations.CreateModel(
            name='CurriculumQuizHistory',
            fields=[
                ('curriculumquizhistory_id', models.AutoField(primary_key=True, serialize=False)),
                ('curriculumquizhistory_total_score', models.PositiveIntegerField(default=0)),
                ('curriculumquizhistory_history', models.JSONField(blank=True, null=True)),
                ('curriculumquizhistory_submit_dt', models.DateTimeField(default=django.utils.timezone.now)),
                ('curriculum_id', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='Curriculum.curriculum')),
                ('user_id', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='User.user')),
            ],
        ),
    ]


--- File: 7 # backend/Curriculum/migrations/0004_curriculumquizhistory_curriculumquizhistory_avg_score.py ---
# Generated by Django 5.1.6 on 2025-04-15 10:33

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('Curriculum', '0003_curriculumquizhistory'),
    ]

    operations = [
        migrations.AddField(
            model_name='curriculumquizhistory',
            name='curriculumquizhistory_avg_score',
            field=models.FloatField(default=0.0),
        ),
    ]


--- File: 9 # backend/Curriculum/models.py ---
from django.db import models
from django.utils import timezone
from pgvector.django import VectorField


class Curriculum(models.Model):
    curriculum_id = models.AutoField(primary_key=True)
    user_id = models.ForeignKey("User.User", on_delete=models.CASCADE)  # 유저와 연결
    curriculum_type = models.CharField(max_length=20, null=True, blank=True)   # "standard" or "ai" or "dummy"
    curriculum_name = models.TextField()
    curriculum_prompt1 = models.TextField(null=True, blank=True)  # "어떤 주제를 학습하고 싶은지 구체적으로 알려주세요." 입력
    curriculum_prompt2 = models.TextField(null=True, blank=True)  # "당신의 수준을 알려주세요." 입력
    curriculum_period = models.TextField(null=True, blank=True)  # 학습 기간
    curriculum_content = models.TextField()  # 출력 결과 및 커리큘럼 저장
    curriculum_keyword = models.TextField(null=True, blank=True)    # 커리큘럼 키워드
    curriculum_emb = VectorField(dimensions=1536, default=[0.0]*1536)

    def __str__(self):
        return f"{self.curriculum_id} - {self.curriculum_type} - {self.curriculum_name}"


class CurriculumSection(models.Model):
    curriculumsection_id = models.AutoField(primary_key=True)
    curriculum_id = models.ForeignKey(Curriculum, on_delete=models.CASCADE)
    curriculumsection_title = models.TextField()  # 대제목
    curriculumsection_order = models.PositiveIntegerField()  # 대제목 순서
    curriculumsection_video_url = models.TextField()

    def __str__(self):
        return f"{self.curriculumsection_id} - {self.curriculum_id.curriculum_name} - {self.curriculumsection_order} - {self.curriculumsection_title}"


class CurriculumSubSection(models.Model):
    curriculumsubsection_id = models.AutoField(primary_key=True)
    curriculumsection_id = models.ForeignKey(CurriculumSection, on_delete=models.CASCADE)
    curriculumsubsection_title = models.TextField()  # 소제목
    curriculumsubsection_order = models.PositiveIntegerField()  # 소제목 순서
    curriculumsubsection_content = models.TextField(null=True, blank=True)  # 소제목에 대한 설명

    def __str__(self):
        return f"{self.curriculumsection_id.curriculum_id.curriculum_name} - {self.curriculumsection_id.curriculumsection_title} - {self.curriculumsubsection_order} - {self.curriculumsubsection_title}"


class CurriculumSectionQuiz(models.Model):
    curriculumsectionquiz_id = models.AutoField(primary_key=True)
    curriculumsection_id = models.ForeignKey(CurriculumSection, on_delete=models.CASCADE)
    curriculumsectionquiz_type = models.CharField(max_length=20)
    curriculumsectionquiz_question = models.TextField()
    curriculumsectionquiz_data = models.JSONField(null=True, blank=True)

    def __str__(self):
        return f"{self.curriculumsection_id.curriculum_id.curriculum_name} - {self.curriculumsectionquiz_type} - {self.curriculumsectionquiz_question} - {self.curriculumsectionquiz_data}"


class CurriculumUser(models.Model):
    curriculumuser_id = models.AutoField(primary_key=True)
    curriculum_id = models.ForeignKey(Curriculum, on_delete=models.CASCADE)
    user_id = models.ForeignKey("User.User", on_delete=models.CASCADE)
    curriculumsection_id = models.ForeignKey(CurriculumSection, on_delete=models.SET_NULL, null=True, blank=True, default=None)
    curriculumuser_is_completed = models.BooleanField(default=False)
    curriculumuser_start_dt = models.DateTimeField(default=timezone.now)
    curriculumuser_end_dt = models.DateTimeField(null=True, blank=True)

    def __str__(self):
        return f"{self.curriculum_id.curriculum_name} - {self.user_id.user_nickname} - {self.curriculumuser_is_completed}"
    
    def save(self, *args, **kwargs):
        # 완료되지 않은 상태에서만 첫 번째 섹션 자동 설정
        if self.curriculumsection_id is None and not self.curriculumuser_is_completed:
            first_section = CurriculumSection.objects.filter(curriculum_id=self.curriculum_id).order_by('curriculumsection_order').first()
            if first_section:
                self.curriculumsection_id = first_section
        super().save(*args, **kwargs)


class Techstack(models.Model):
    techstack_id = models.AutoField(primary_key=True)
    techstack_name = models.CharField(max_length=50)
    techstack_desc = models.TextField(null=True, blank=True)

    def __str__(self):
        return f"{self.techstack_id} - {self.techstack_name}"


class CurriculumTechstack(models.Model):
    curriculumtechstack_id = models.AutoField(primary_key=True)
    curriculum_id = models.ForeignKey(Curriculum, on_delete=models.CASCADE)
    techstack_id = models.ForeignKey(Techstack, on_delete=models.CASCADE)

    def __str__(self):
        return f"{self.curriculumtechstack_id}"


class CurriculumQuizHistory(models.Model):
    curriculumquizhistory_id = models.AutoField(primary_key=True)
    curriculum_id = models.ForeignKey("Curriculum.Curriculum", on_delete=models.CASCADE)
    user_id = models.ForeignKey("User.User", on_delete=models.CASCADE)
    curriculumquizhistory_total_score = models.PositiveIntegerField(default=0)
    curriculumquizhistory_avg_score = models.FloatField(default=0.0)  # 평균 점수 필드 추가
    curriculumquizhistory_history = models.JSONField(null=True, blank=True)
    curriculumquizhistory_submit_dt = models.DateTimeField(default=timezone.now)

    def __str__(self):
        return f"{self.curriculum_id} - {self.user_id} - {self.curriculumquizhistory_submit_dt}"


--- File: 11 # backend/Curriculum/views.py ---
###########################################################################################
# Django 관련 import
###########################################################################################
from django.shortcuts import render, get_object_or_404
from django.utils import timezone
from django.http import JsonResponse
from django.db.models import Q, Prefetch
from django.views.decorators.csrf import csrf_exempt
from django.core.paginator import Paginator, EmptyPage, PageNotAnInteger
from django.db import connection
from django.conf import settings

###########################################################################################
# model 관련 import
###########################################################################################
from .models import Curriculum, CurriculumSection, CurriculumSubSection, CurriculumSectionQuiz, CurriculumUser, CurriculumTechstack, Techstack, CurriculumQuizHistory
from User.models import User
from User.decorators import login_required_json

###########################################################################################
# rest_framework 관련 import
###########################################################################################
from rest_framework.decorators import api_view
from rest_framework.response import Response
from rest_framework import status

###########################################################################################
# 파이썬 라이브러리 import
###########################################################################################
import os
import random
import json
from groq import Groq
from google import genai
from google.genai import types

###########################################################################################
# 직접 만든 모듈 import
###########################################################################################
from utils.curriculum_utils import call_groq_api, generate_curriculum_prompt, create_curriculum_from_data
from utils.similarity import get_high_similarity_reranked
from utils.ai_agent import query_db
from utils.db_utils import (
    get_user_curriculum,
    get_user_sections,
    get_user_curriculum_status,
    get_user_info,
    get_user_projects,
    get_user_quiz_history,
    get_quiz_history_detail,
    analyze_quiz_history
)
from utils.query_utils import process_natural_query
from utils.ai_agent_utils import process_ai_assistant_query


# Groq API Key를 settings에서 가져옴
GROQ_API_KEY = settings.GROQ_API_KEY


###########################################################################################
# 커리큘럼,퀴즈를 조회하는 API
###########################################################################################

# curriculum_id를 받아 해당 커리큘럼 정보를 반환하는 API
@api_view(['GET'])
def get_curriculum_by_id(request):
    curriculum_id = request.GET.get("curriculum_id")  # 검색할 커리큘럼 ID
    curriculum_type = request.GET.get("curriculum_type", "standard")  # 기본값은 "standard"
    
    if not curriculum_id:
        return JsonResponse({"error": "curriculum_id를 입력해주세요."}, json_dumps_params={"ensure_ascii": False}, status=400)

    # curriculum_type이 유효한 값인지 확인
    if curriculum_type not in ["standard", "dummy"]:
        return JsonResponse({"error": "curriculum_type은 'standard' 또는 'dummy'여야 합니다."}, json_dumps_params={"ensure_ascii": False}, status=400)

    # 커리큘럼 조회 (관련 데이터 미리 로드)
    curriculum = get_object_or_404(
        Curriculum.objects.filter(curriculum_type=curriculum_type).select_related('user_id').prefetch_related(
            Prefetch('curriculumsection_set', 
                    queryset=CurriculumSection.objects.order_by('curriculumsection_order').prefetch_related(
                        Prefetch('curriculumsubsection_set', 
                                queryset=CurriculumSubSection.objects.order_by('curriculumsubsection_order')),
                        'curriculumsectionquiz_set'
                    ))
        ), 
        pk=curriculum_id
    )

    curriculum_sections = []
    for section in curriculum.curriculumsection_set.all():
        subsections_list = [{
            "curriculumsubsection_id": subsection.curriculumsubsection_id,
            "curriculumsubsection_order": subsection.curriculumsubsection_order,
            "curriculumsubsection_title": subsection.curriculumsubsection_title,
            "curriculumsubsection_content": subsection.curriculumsubsection_content,
        } for subsection in section.curriculumsubsection_set.all()]

        quizzes_list = [{
            "curriculumsectionquiz_id": quiz.curriculumsectionquiz_id,
            "curriculumsectionquiz_type": quiz.curriculumsectionquiz_type,
            "curriculumsectionquiz_question": quiz.curriculumsectionquiz_question,
            "curriculumsectionquiz_data": quiz.curriculumsectionquiz_data,
        } for quiz in section.curriculumsectionquiz_set.all()]
        
        curriculum_sections.append({
            "curriculumsection_id": section.curriculumsection_id,
            "curriculumsection_order": section.curriculumsection_order,
            "curriculumsection_title": section.curriculumsection_title,
            "curriculumsection_video_url": section.curriculumsection_video_url,
            "subsections": subsections_list,
            "quizzes": quizzes_list
        })

    # 결과 JSON 형태로 변환
    result = {
        "curriculum_id": curriculum.curriculum_id,
        "curriculum_type": curriculum.curriculum_type,
        "curriculum_name": curriculum.curriculum_name,
        "user_nickname": curriculum.user_id.user_nickname,
        "curriculum_prompt1": curriculum.curriculum_prompt1,
        "curriculum_prompt2": curriculum.curriculum_prompt2,
        "curriculum_preiod": curriculum.curriculum_period,
        "curriculum_keyword": curriculum.curriculum_keyword,
        "curriculum_content": curriculum.curriculum_content,
        "sections": curriculum_sections
    }

    return JsonResponse(result, json_dumps_params={"ensure_ascii": False})


# user_id, 검색분류, 검색어 를 받아 해당 커리큘럼 정보를 반환하는 API
@api_view(['GET'])
@login_required_json
def get_users_curriculum(request, user):
    user_id = user.user_id
    search_type = request.GET.get("type")  # 검색 분류 ('title' 또는 'techstack')
    query = request.GET.get("query", "")  # 검색어 (빈 문자열 기본값 설정)
    curriculum_type = request.GET.get("curriculum_type", "standard")  # 기본값은 "standard"
    
    # 필수 값 확인 (user_id는 필수, 검색어는 없어도 됨)
    if not user_id:
        return JsonResponse({"error": "user_id를 입력하세요."}, status=400, json_dumps_params={"ensure_ascii": False})
    
    # curriculum_type이 유효한 값인지 확인
    if curriculum_type not in ["standard", "dummy"]:
        return JsonResponse({"error": "curriculum_type은 'standard' 또는 'dummy'여야 합니다."}, json_dumps_params={"ensure_ascii": False}, status=400)
    
    # 기본 쿼리셋에 관련 데이터 미리 로드
    curriculum = Curriculum.objects.filter(user_id=user_id, curriculum_type=curriculum_type).select_related('user_id').prefetch_related(
        'curriculumtechstack_set__techstack_id',
        Prefetch('curriculumsection_set', 
                queryset=CurriculumSection.objects.order_by('curriculumsection_order').prefetch_related(
                    Prefetch('curriculumsubsection_set', 
                            queryset=CurriculumSubSection.objects.order_by('curriculumsubsection_order')),
                    'curriculumsectionquiz_set'
                ))
    )
    
    if not search_type:
        curriculums = curriculum.distinct()

        if query:
            curriculums = curriculums.filter(
                Q(curriculum_name__icontains=query) |  # 제목에서 검색
                Q(user_id__user_nickname__icontains=query) |  # 작성자에서 검색
                Q(curriculumtechstack__techstack_id__techstack_name__icontains=query)  # 기술 스택에서 검색
            )

    # 검색 분류에 따라 필터링 (검색어가 비어있다면 전체 반환)
    elif search_type == "title":
        curriculums = curriculum
        if query:
            curriculums = curriculums.filter(curriculum_name__icontains=query)

    elif search_type == "techstack":
        curriculums = curriculum
        if query:
            curriculums = curriculums.filter(
                curriculum_id__in=CurriculumTechstack.objects.filter(
                    techstack_id__in=Techstack.objects.filter(techstack_name__icontains=query)
                ).values_list("curriculum_id", flat=True)
            )
    else:
        return JsonResponse({"error": "검색 분류가 올바르지 않습니다."}, json_dumps_params={"ensure_ascii": False}, status=400)

    # 결과 JSON 형태로 변환
    results = []
    for curriculum in curriculums:
        curriculum_sections = []
        for section in curriculum.curriculumsection_set.all():
            subsections_list = [{
                "curriculumsubsection_id": subsection.curriculumsubsection_id,
                "curriculumsubsection_order": subsection.curriculumsubsection_order,
                "curriculumsubsection_title": subsection.curriculumsubsection_title,
                "curriculumsubsection_content": subsection.curriculumsubsection_content,
            } for subsection in section.curriculumsubsection_set.all()]

            quizzes_list = [{
                "curriculumsectionquiz_id": quiz.curriculumsectionquiz_id,
                "curriculumsectionquiz_type": quiz.curriculumsectionquiz_type,
                "curriculumsectionquiz_question": quiz.curriculumsectionquiz_question,
                "curriculumsectionquiz_data": quiz.curriculumsectionquiz_data,
            } for quiz in section.curriculumsectionquiz_set.all()]
            
            curriculum_sections.append({
                "curriculumsection_id": section.curriculumsection_id,
                "curriculumsection_order": section.curriculumsection_order,
                "curriculumsection_title": section.curriculumsection_title,
                "subsections": subsections_list,
                "quizzes": quizzes_list
            })

        techstack_names = [ts.techstack_id.techstack_name for ts in curriculum.curriculumtechstack_set.all()]

        results.append({
            "curriculum_id": curriculum.curriculum_id,
            "curriculum_type": curriculum.curriculum_type,
            "curriculum_name": curriculum.curriculum_name,
            "user_nickname": curriculum.user_id.user_nickname,
            "curriculum_keyword": curriculum.curriculum_keyword,
            "curriculum_content": curriculum.curriculum_content,
            "techstack_names": techstack_names,
            "sections": curriculum_sections  # 섹션 및 서브섹션 포함
        })

    return JsonResponse({"results": results}, json_dumps_params={"ensure_ascii": False}, safe=False)


# 검색분류, 검색어를 받아 전체 커리큘럼을 검색하는 API
@api_view(['GET'])
def get_search_curriculum(request):
    query = request.GET.get("query", "")  # 검색어 (빈 문자열 기본값 설정)
    curriculum_type = request.GET.get("curriculum_type", "standard")  # 기본값은 "standard"

    # curriculum_type이 유효한 값인지 확인
    if curriculum_type not in ["standard", "dummy"]:
        return JsonResponse({"error": "curriculum_type은 'standard' 또는 'dummy'여야 합니다."}, json_dumps_params={"ensure_ascii": False}, status=400)

    # 기본 쿼리셋에 관련 데이터 미리 로드
    curriculums = Curriculum.objects.filter(curriculum_type=curriculum_type).select_related('user_id').prefetch_related(
        'curriculumtechstack_set__techstack_id',
        Prefetch('curriculumsection_set', 
                queryset=CurriculumSection.objects.order_by('curriculumsection_order').prefetch_related(
                    Prefetch('curriculumsubsection_set', 
                            queryset=CurriculumSubSection.objects.order_by('curriculumsubsection_order')),
                    'curriculumsectionquiz_set'
                ))
    )

    curriculums = Curriculum.objects.filter(curriculum_type=curriculum_type).distinct()

    if query:
        curriculums = curriculums.filter(
            Q(curriculum_name__icontains=query) |  # 제목에서 검색
            Q(user_id__user_nickname__icontains=query) |  # 작성자에서 검색
            Q(curriculumtechstack__techstack_id__techstack_name__icontains=query)  # 기술 스택에서 검색
        )

    # curriculum_id를 내림차순으로 정렬
    curriculums = curriculums.order_by('-curriculum_id')

    # 페이지네이션 추가
    paginator = Paginator(curriculums, 10)  # 페이지당 10개
    page = request.GET.get('page', 1)

    # 요청된 페이지가 마지막 페이지보다 큰 경우 빈 결과 반환
    if int(page) > paginator.num_pages:
        return JsonResponse({"results": []}, json_dumps_params={"ensure_ascii": False}, safe=False)

    try:
        curriculums = paginator.page(page)
    except PageNotAnInteger:
        # 페이지 번호가 정수가 아닌 경우 첫 번째 페이지 표시
        curriculums = paginator.page(1)
    except EmptyPage:
        # 빈 페이지인 경우 빈 결과 반환
        return JsonResponse({"results": []}, json_dumps_params={"ensure_ascii": False}, safe=False)

    # 결과 JSON 형태로 변환
    results = []
    for curriculum in curriculums:
        curriculum_sections = []
        for section in curriculum.curriculumsection_set.all():
            # subsections_list = [{
            #     "curriculumsubsection_id": subsection.curriculumsubsection_id,
            #     "curriculumsubsection_order": subsection.curriculumsubsection_order,
            #     "curriculumsubsection_title": subsection.curriculumsubsection_title,
            #     "curriculumsubsection_content": subsection.curriculumsubsection_content,
            # } for subsection in section.curriculumsubsection_set.all()]

            # quizzes_list = [{
            #     "curriculumsectionquiz_id": quiz.curriculumsectionquiz_id,
            #     "curriculumsectionquiz_type": quiz.curriculumsectionquiz_type,
            #     "curriculumsectionquiz_question": quiz.curriculumsectionquiz_question,
            #     "curriculumsectionquiz_data": quiz.curriculumsectionquiz_data,
            # } for quiz in section.curriculumsectionquiz_set.all()]
            
            curriculum_sections.append({
                "curriculumsection_id": section.curriculumsection_id,
                "curriculumsection_order": section.curriculumsection_order,
                "curriculumsection_title": section.curriculumsection_title,
                # "subsections": subsections_list,
                # "quizzes": quizzes_list
            })

        # techstack_names = [ ts.techstack_id.techstack_name for ts in curriculum.curriculumtechstack_set.all() ]
        
        results.append({
            "curriculum_id": curriculum.curriculum_id,
            "curriculum_type": curriculum.curriculum_type,
            "curriculum_name": curriculum.curriculum_name,
            "user_nickname": curriculum.user_id.user_nickname,
            "curriculum_keyword": curriculum.curriculum_keyword,
            "curriculum_content": curriculum.curriculum_content,
            # "techstack_names": techstack_names,  # 기술 스택 목록 추가
            "sections": curriculum_sections  # 섹션 및 서브섹션 추가
        })

    return JsonResponse({"results": results}, json_dumps_params={"ensure_ascii": False}, safe=False)


# 랜덤으로 최대 4개의 커리큘럼을 반환하는 API
@api_view(['GET'])
def get_random_curriculum(request):
    curriculum_type = request.GET.get("curriculum_type", "standard")  # 기본값은 "standard"

    # curriculum_type이 유효한 값인지 확인
    if curriculum_type not in ["standard", "dummy"]:
        return JsonResponse({"error": "curriculum_type은 'standard' 또는 'dummy'여야 합니다."}, json_dumps_params={"ensure_ascii": False}, status=400)

    total_curriculums = Curriculum.objects.filter(curriculum_type=curriculum_type).count()
    
    sample_size = min(total_curriculums, 4)

    # 최적화된 쿼리를 위해 모든 커리큘럼 ID 가져오기
    all_curriculum_ids = list(Curriculum.objects.filter(curriculum_type=curriculum_type).values_list('curriculum_id', flat=True))
    
    # 랜덤 ID 선택
    if sample_size < total_curriculums:
        random_ids = random.sample(all_curriculum_ids, sample_size)
    else:
        random_ids = all_curriculum_ids
    
    # 선택된 ID로 한 번에 최적화된 쿼리 실행
    random_curriculums = Curriculum.objects.filter(curriculum_id__in=random_ids, curriculum_type=curriculum_type).select_related('user_id').prefetch_related(
        'curriculumtechstack_set__techstack_id',
        Prefetch('curriculumsection_set', 
                queryset=CurriculumSection.objects.order_by('curriculumsection_order').prefetch_related(
                    Prefetch('curriculumsubsection_set', 
                            queryset=CurriculumSubSection.objects.order_by('curriculumsubsection_order')),
                    'curriculumsectionquiz_set'
                ))
    )

    curriculum_data = []
    
    for curriculum in random_curriculums:
        curriculum_sections = []
        for section in curriculum.curriculumsection_set.all():
            subsections_list = [{
                "curriculumsubsection_id": subsection.curriculumsubsection_id,
                "curriculumsubsection_order": subsection.curriculumsubsection_order,
                "curriculumsubsection_title": subsection.curriculumsubsection_title,
                "curriculumsubsection_content": subsection.curriculumsubsection_content,
            } for subsection in section.curriculumsubsection_set.all()]

            # quizzes_list = [{
            #     "curriculumsectionquiz_id": quiz.curriculumsectionquiz_id,
            #     "curriculumsectionquiz_type": quiz.curriculumsectionquiz_type,
            #     "curriculumsectionquiz_question": quiz.curriculumsectionquiz_question,
            #     "curriculumsectionquiz_data": quiz.curriculumsectionquiz_data,
            # } for quiz in section.curriculumsectionquiz_set.all()]
            
            curriculum_sections.append({
                "curriculumsection_id": section.curriculumsection_id,
                "curriculumsection_order": section.curriculumsection_order,
                "curriculumsection_title": section.curriculumsection_title,
                "subsections": subsections_list,
                # "quizzes": quizzes_list
            })
        
        techstack_names = [ts.techstack_id.techstack_name for ts in curriculum.curriculumtechstack_set.all()]
        
        curriculum_data.append({
            "curriculum_id": curriculum.curriculum_id,
            "curriculum_type": curriculum.curriculum_type,
            "curriculum_name": curriculum.curriculum_name,
            "curriculum_prompt1": curriculum.curriculum_prompt1,
            "curriculum_prompt2": curriculum.curriculum_prompt2,
            "curriculum_keyword": curriculum.curriculum_keyword,
            "curriculum_content": curriculum.curriculum_content,
            "techstack_names": techstack_names,
            "sections": curriculum_sections
        })

    return JsonResponse(curriculum_data, json_dumps_params={"ensure_ascii": False}, safe=False)


@api_view(['GET'])
@login_required_json
def get_curriculum_quiz(request, user):
    """
    커리큘럼의 전체 섹션에 대한 랜덤 퀴즈를 가져오는 API
    
    URL 파라미터:
    - curriculum_id: 커리큘럼 ID
    
    반환:
    - 섹션별 랜덤 퀴즈 목록
    """
    try:
        curriculum_id = request.GET.get('curriculum_id')
        user_id = user.user_id
        
        if not curriculum_id:
            return JsonResponse({"error": "curriculum_id is required"}, status=400)
        
        # 커리큘럼 존재 여부 확인
        try:
            curriculum = Curriculum.objects.get(curriculum_id=curriculum_id)
        except Curriculum.DoesNotExist:
            return JsonResponse({"error": "Curriculum not found"}, status=404)
        
        # 현재 요청에 user_id 파라미터 추가
        request._request.GET = request._request.GET.copy()
        request._request.GET['user_id'] = str(user_id)
        
        quiz_num_data = get_adaptive_quiz(request._request)

        # get_quiz_section_results의 결과가 JsonResponse 형태이므로, content를 파싱함
        try:
            section_results_data = json.loads(quiz_num_data.content.decode("utf-8"))
        except Exception as e:
            return JsonResponse({
                "error": "섹션별 출제 계획을 가져오는데 실패했습니다: " + str(e)
            }, status=500, json_dumps_params={"ensure_ascii": False})
        
        # get_quiz_section_results에서 에러가 발생한 경우 그대로 반환
        if "error" in section_results_data:
            return JsonResponse(section_results_data, status=400, json_dumps_params={"ensure_ascii": False})

        # 섹션별 출제 계획을 딕셔너리로 변환
        section_question_plan = section_results_data.get("section_question_plan", [])
        quiz_counts = {}
        for section_plan in section_question_plan:
            section_id = str(section_plan.get("section_id"))
            num_questions = section_plan.get("num_questions", 0)
            quiz_counts[section_id] = num_questions

        # 섹션별 퀴즈 가져오기
        sections = CurriculumSection.objects.filter(curriculum_id=curriculum_id).order_by('curriculumsection_order')
        
        result = {
            "curriculum_id": curriculum_id,
            "curriculum_name": curriculum.curriculum_name,
            "sections": []
        }
        
        for section in sections:
            section_id = section.curriculumsection_id
            section_str_id = str(section_id)
            
            # 해당 섹션의 퀴즈 개수 설정 (기본값: 0)
            quiz_count = int(quiz_counts.get(section_str_id, 0))
            
            if quiz_count > 0:
                # 섹션에 대한 퀴즈를 랜덤하게 가져오기 - order_by('?')로 랜덤 정렬
                quizzes = CurriculumSectionQuiz.objects.filter(
                    curriculumsection_id=section_id
                ).order_by('?')[:quiz_count]  # 랜덤으로 정렬 후 요청된 수만큼만 가져오기
                
                section_data = {
                    "section_id": section_id,
                    "section_title": section.curriculumsection_title,
                    "quizzes": []
                }
                
                for quiz in quizzes:
                    quiz_data = {
                        "quiz_id": quiz.curriculumsectionquiz_id,
                        "quiz_type": quiz.curriculumsectionquiz_type,
                        "quiz_question": quiz.curriculumsectionquiz_question,
                        "quiz_data": quiz.curriculumsectionquiz_data
                    }
                    section_data["quizzes"].append(quiz_data)
                
                result["sections"].append(section_data)
        
        # 섹션별 출제 계획과 실제 출제된 문제 수를 같이 반환
        result["section_question_plan"] = section_question_plan
        
        return JsonResponse(result, json_dumps_params={"ensure_ascii": False})
    
    except Exception as e:
        return JsonResponse({"error": str(e)}, status=500, json_dumps_params={"ensure_ascii": False})


# user_id를 받아 해당 유저가 커리큘럼을 저장했는지 확인하는 API
@api_view(['GET'])
@login_required_json
def is_user_have_curriculum(request, user):
    user_id = user.user_id
    if request.method == 'GET':
        curriculum_id = request.query_params.get('curriculum_id')

        if not curriculum_id:
            return Response({"error": "curriculum_id is required"}, status=status.HTTP_400_BAD_REQUEST)
        
        try:
            # 해당 유저가 특정 커리큘럼을 보유하고 있는지 확인
            try:
                curriculum_user = CurriculumUser.objects.get(user_id=user_id, curriculum_id=curriculum_id)
                return Response({
                    "is_user_have_curriculum": True,
                    "curriculumuser_id": curriculum_user.curriculumuser_id,
                    "curriculumsection_id": curriculum_user.curriculumsection_id.curriculumsection_id,
                    "curriculumuser_is_completed": curriculum_user.curriculumuser_is_completed
                }, status=status.HTTP_200_OK)
            except CurriculumUser.DoesNotExist:
                return Response({"is_user_have_curriculum": False}, status=status.HTTP_200_OK)
            
        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


###########################################################################################
# 커리큘럼을 추가/삭제하는 API
###########################################################################################

# add_curriculum 함수 리팩토링
@api_view(['POST'])
@login_required_json
def add_curriculum(request, user):
    user_id = user.user_id
    if request.method == 'POST':
        data = request.data
        
        # standard 커리큘럼 생성 전용 계정
        if user_id == 1:
            curriculum_data = data
        else:
            # 필수 필드 확인
            required_fields = ["curriculum_prompt1", "curriculum_prompt2", "curriculum_period"]
            if not all(field in data for field in required_fields):
                return Response({"error": "모든 필수 필드를 입력해주세요."}, status=status.HTTP_400_BAD_REQUEST)

            # 프롬프트 생성
            prompt = generate_curriculum_prompt({
                'curriculum_prompt1': data['curriculum_prompt1'],
                'curriculum_prompt2': data['curriculum_prompt2'],
                'curriculum_period': data['curriculum_period']
            }, prompt_type="new")
            
            # Groq API 호출
            try:
                curriculum_data = call_groq_api(prompt)
            except Exception as e:
                return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        # 커리큘럼 생성
        try:
            curriculum_type = "dummy" if user_id == 1 else "ai"
            new_curriculum = create_curriculum_from_data(
                curriculum_data=curriculum_data,
                user=user,
                curriculum_type=curriculum_type,
                extra_data=data if curriculum_type == "ai" else None
            )
        except Exception as e:
            return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        return Response({
            "message": "커리큘럼이 추가되었습니다.", 
            "curriculum_id": new_curriculum.curriculum_id
        }, status=status.HTTP_201_CREATED)


# 커리큘럼 삭제 API
@api_view(['POST'])
def delete_curriculum(request):
    if request.method == 'POST':
        data = request.data  # JSON 데이터는 request.data로 자동 파싱
        curriculum_id = data.get("curriculum_id")

        if not curriculum_id:
            return Response({"error": "curriculum_id를 입력해주세요."}, status=status.HTTP_400_BAD_REQUEST)

        # 해당 커리큘럼 삭제
        try:
            curriculum = Curriculum.objects.get(pk=curriculum_id)
            curriculum.delete()
            return Response({"message": f"커리큘럼 {curriculum_id}이(가) 삭제되었습니다."}, status=status.HTTP_200_OK)
        except Curriculum.DoesNotExist:
            return Response({"error": "커리큘럼을 찾을 수 없습니다."}, status=status.HTTP_404_NOT_FOUND)


# customize_curriculum 함수 리팩토링
@api_view(['GET', 'POST'])
@login_required_json
def customize_curriculum(request, user):
    """
    커리큘럼 번호와 사용자의 요구 쿼리를 받아 커리큘럼 result를 불러오고, 이를 LLM을 사용하여 쿼리에 맞게 커스텀하는 API
    """
    if request.method == 'GET':
        curriculum_id = request.GET.get("curriculum_id")
        user_query = request.GET.get("query")
    else:
        data = request.data
        curriculum_id = data.get("curriculum_id")
        user_query = data.get("query")

    # 필수 파라미터 검증
    if not curriculum_id or not user_query:
        return Response({
            "error": "curriculum_id와 query를 모두 입력해주세요."
        }, status=status.HTTP_400_BAD_REQUEST)

    # 커리큘럼 데이터 가져오기
    curriculum = get_object_or_404(Curriculum, pk=curriculum_id)
    
    # 프롬프트 생성
    prompt = generate_curriculum_prompt({
        'original_curriculum': curriculum.curriculum_content,
        'user_query': user_query
    }, prompt_type="customize")
    
    # Groq API 호출
    try:
        curriculum_data = call_groq_api(prompt)
    except Exception as e:
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    # 커리큘럼 생성
    try:
        new_curriculum = create_curriculum_from_data(
            curriculum_data=curriculum_data,
            user=user,
            curriculum_type="ai",
            extra_data=None
        )
    except Exception as e:
        return Response({"error": str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    return Response({
        "message": "커리큘럼이 커스터마이징되었습니다.", 
        "curriculum_id": new_curriculum.curriculum_id
    }, status=status.HTTP_201_CREATED)


###########################################################################################
# 커리큘럼의 퀴즈에 관련된 API
###########################################################################################

@csrf_exempt
@api_view(['POST'])
def submit_answers(request):
    data = request.data
    section_index = data.get('sectionIndex')
    answers = data.get('answers')
    print(data)
    if section_index is None or answers is None:
        return JsonResponse({"error": "sectionIndex와 answers를 모두 포함해야 합니다."}, status=400, json_dumps_params={"ensure_ascii": False})

    # Ensure answers is a list of dictionaries
    if isinstance(answers, dict):
        answers = [{"question_id": k, "answer": v} for k, v in answers.items()]

    results = {}
    scores = {}
    feedbacks = {}
    user_answers = {}

    for answer in answers:
        if not isinstance(answer, dict):
            continue

        question_id = answer.get('question_id')
        user_answer = answer.get('answer')

        if not question_id or user_answer is None:
            continue
        
        # 사용자 답변 저장
        user_answers[question_id] = user_answer
        
        try:
            quiz = CurriculumSectionQuiz.objects.get(pk=question_id)
        except CurriculumSectionQuiz.DoesNotExist:
            continue
        
        # JSONField에서 정답 추출
        quiz_data = quiz.curriculumsectionquiz_data or {}
        correct_answer = quiz_data.get('answer', '')
        
        if quiz.curriculumsectionquiz_type == '객관식':
            print(f"정답: {correct_answer}, 사용자 답: {user_answer}")
            is_correct = user_answer == correct_answer
            results[question_id] = is_correct
            scores[question_id] = 100 if is_correct else 0
        elif quiz.curriculumsectionquiz_type == '주관식':
            try:
                client = Groq(api_key=GROQ_API_KEY)
                chat_completion = client.chat.completions.create(
                    messages=[
                        {
                            "role": "user",
                            "content": f"""다음 주관식 답안을 채점하시오.
                            피드백에 답안에 대한 힌트를 제시하시오.
                            점수는 100점이 만점으로 채점하시오.
                            사용자가 제출한 답안이 실제 정답과 일치하지 않더라도, 문제의 내용에 맞는 답안을 제출했다면 답안을 무시하고 높은 점수를 부여하시오.
                            만일 답안이 부적절하다고 판단되면, 0점을 부여하시오.
                            점수는 반드시 숫자로만 작성하시오.
                            반드시 피드백을 한글로 작성하시오.
                            문제: {quiz.curriculumsectionquiz_question},
                            답안: {user_answer},
                            정답: {correct_answer}
                            출력 형식: '점수: [점수(int)] 피드백: [피드백]'"""
                        }
                    ],
                    model="gemma2-9b-it",
                )
                grading_result = chat_completion.choices[0].message.content
                print(f"Groq API response: {grading_result}")  # 추가된 로그
                score_line = grading_result.split("점수:")[1].split("피드백:")[0].strip()
                feedback = grading_result.split("피드백:")[1].strip()
                score = int(score_line)
                # 점수가 80점 이상이면 정답으로 간주
                is_correct = score >= 80
                results[question_id] = is_correct
                scores[question_id] = score
                feedbacks[question_id] = feedback  # 피드백을 question_id를 키로 하여 저장
                print(f"주관식 문제 ID {question_id} 채점 결과: {score}점, 정답 여부: {is_correct}")
            except Exception as e:
                print("Groq API 호출 오류:", str(e))
                return JsonResponse({"error": f"Groq API 호출 오류: {str(e)}"}, status=500, json_dumps_params={"ensure_ascii": False})

    # 모든 문제의 정답 여부를 확인하여 전체 통과 여부 결정
    all_correct = all(results.values()) if results else False

    response_data = {
        "message": "정답이 성공적으로 제출되었습니다.",
        "sectionIndex": section_index,
        "results": results,
        "scores": scores,
        "all_correct": all_correct,
        "feedbacks": feedbacks,  # 모든 피드백 반환
        "user_answers": user_answers  # 사용자 답변 추가
    }

    return JsonResponse(response_data, status=200, json_dumps_params={"ensure_ascii": False})


# 커리큘럼을 완료 처리하는 API
@csrf_exempt
@api_view(['POST'])
@login_required_json
def complete_curriculum(request, user):
    curriculum_id = request.data.get('curriculum_id')
    user_id = user.user_id
    
    if not curriculum_id:
        return Response(
            {"error": "curriculum_id is required"}, 
            status=status.HTTP_400_BAD_REQUEST
        )
    
    # Get the current CurriculumUser record
    curriculum_user = get_object_or_404(
        CurriculumUser, 
        curriculum_id=curriculum_id, 
        user_id=user_id
    )
    
    # Mark the curriculum as completed regardless of current section
    curriculum_user.curriculumuser_is_completed = True
    curriculum_user.curriculumuser_end_dt = timezone.now()
    curriculum_user.save()
    
    return Response({
        "status": "success",
        "message": "Curriculum marked as completed",
        "data": {
            "curriculum_name": curriculum_user.curriculum_id.curriculum_name,
            "is_completed": True,
            "completion_date": curriculum_user.curriculumuser_end_dt
        }
    }, status=status.HTTP_200_OK)


@csrf_exempt
@login_required_json
@api_view(['POST'])
def add_quiz_history(request, user):
    if request.method == 'POST':
        try:
            data = request.data
            # 필요한 데이터 추출
            curriculum_id = data.get('curriculum_id')
            user_id = user.user_id  # 현재 로그인된 사용자 ID 사용

            # results, scores, feedbacks 데이터 추출
            results = data.get('results', {})
            scores = data.get('scores', {})
            user_answers = data.get('user_answers', {})
            feedbacks = data.get('feedbacks', {})

            # 총점, 평균 계산
            total_score = sum(scores.values()) if scores else 0
            avg_score = round(total_score / len(scores), 2) if len(scores) > 0 else 0.0

            # 이력 데이터 구조화
            history_data = {
                "historys": []
            }
            
            # 섹션별 통계를 추적하기 위한 딕셔너리
            section_stats = {}
            
            # 각 퀴즈에 대한 결과 기록
            for quiz_id in results.keys():
                quiz = CurriculumSectionQuiz.objects.get(curriculumsectionquiz_id=int(quiz_id))
                section_id = quiz.curriculumsection_id.curriculumsection_id
                section_title = quiz.curriculumsection_id.curriculumsection_title
                question = quiz.curriculumsectionquiz_question
                # 섹션 통계 초기화 (아직 없는 경우)
                if section_id not in section_stats:
                    section_stats[section_id] = {
                        "total_questions": 0,
                        "correct_answers": 0,
                        "total_score": 0
                    }
                
                # 섹션 통계 업데이트
                section_stats[section_id]["total_questions"] += 1
                
                if results.get(quiz_id, False):
                    section_stats[section_id]["correct_answers"] += 1
                
                section_stats[section_id]["total_score"] += scores.get(quiz_id, 0)

                quiz_history = {
                    "curriculumsectionquiz_id": int(quiz_id),
                    "curriculumsection_id": section_id,
                    "curriculumsection_title": section_title,
                    "question": question,
                    "user_answers": user_answers.get(quiz_id, ""),
                    "score": scores.get(quiz_id, 0),
                    "is_correct": results.get(quiz_id, False),
                    "feedback": feedbacks.get(quiz_id, "")
                }
                history_data["historys"].append(quiz_history)
            
            # 섹션별 평균 점수 계산 및 추가
            section_results = []
            for section_id, stats in section_stats.items():
                avg_section_score = round(stats["total_score"] / stats["total_questions"], 2) if stats["total_questions"] > 0 else 0
                
                section_result = {
                    "section_id": section_id,
                    "section_num_questions": stats["total_questions"],
                    "section_correct_answers": stats["correct_answers"],
                    "section_avg_score": avg_section_score
                }
                section_results.append(section_result)
            print("section_results:", section_results)
            # 히스토리 데이터에 섹션별 결과 추가
            history_data["section_results"] = section_results

            # 모델 인스턴스 생성 및 저장
            curriculum = Curriculum.objects.get(curriculum_id=curriculum_id)
            user = User.objects.get(user_id=user_id)

            quiz_history = CurriculumQuizHistory(
                curriculum_id=curriculum,
                user_id=user,
                curriculumquizhistory_total_score=total_score,
                curriculumquizhistory_avg_score=avg_score,
                curriculumquizhistory_history=history_data,
                curriculumquizhistory_submit_dt=timezone.now()
            )
            quiz_history.save()

            return JsonResponse({
                'success': True,
                'message': '퀴즈 결과가 성공적으로 저장되었습니다.',
                'quiz_history_id': quiz_history.curriculumquizhistory_id
            })
            
        except Exception as e:
            return JsonResponse({
                'success': False,
                'message': f'퀴즈 결과 저장 중 오류가 발생했습니다: {str(e)}'
            }, status=400)
    
    return JsonResponse({
        'success': False,
        'message': '잘못된 요청 방식입니다. POST 요청이 필요합니다.'
    }, status=405)


###########################################################################################
# RAG/Rerank/Agent/LLM 기능을 사용하는 API
###########################################################################################

# 커리큘럼으로 커리큘럼을 추천하는 API
@api_view(['GET'])
def recommend(request):
    input_type = request.GET.get("input_type")
    output_type = request.GET.get("output_type")
    only_dummy = request.GET.get("only_dummy", False)

    if input_type not in ["curriculum", "project"] or output_type not in ["curriculum", "project"]:
        return JsonResponse({"error": "Invalid input_type or output_type. Allowed values are 'curriculum' or 'project'."}, status=400)

    input_id = request.GET.get('input_id')
    top_k_sim = request.GET.get('top_k_sim')
    top_k_rerank = request.GET.get('top_k_rerank')

    try:
        input_id = int(input_id)
        top_k_sim = int(top_k_sim)
        top_k_rerank = int(top_k_rerank)
    except ValueError:
        return JsonResponse({"error": "Invalid input for input_id or top_k_sim or top_k_rerank"}, status=400)
    
    similar_curriculums_reranked = get_high_similarity_reranked(
        input_type=input_type,
        output_type=output_type,
        input_id=input_id,
        top_k_sim=top_k_sim,
        top_k_rerank=top_k_rerank,
        only_dummy=only_dummy
    )

    # 결과 반환
    result = [{"target_id": item["sim_id"], "cosine_similarity": item["similarity"]} for item in similar_curriculums_reranked]
    
    return JsonResponse({"input_type": input_type, "output_type": output_type, "similarity": result})


@api_view(['GET'])
def get_query_result(request):
    question = request.GET.get("question")
    result = query_db(question)
    return JsonResponse({"result": result}, json_dumps_params={"ensure_ascii": False})


###########################################################################################
# 퀴즈 히스토리 조회 API
###########################################################################################

@api_view(['GET'])
@login_required_json
def get_quiz_history(request, user):
    """
    특정 사용자의 퀴즈 히스토리를 조회하는 API
    
    Parameters:
    - curriculum_id (optional): 특정 커리큘럼의 퀴즈 히스토리만 조회
    """
    user_id = user.user_id  # 현재 로그인된 사용자 ID 사용
    
    try:
        # 기본 쿼리셋 생성
        quiz_histories = CurriculumQuizHistory.objects.filter(
            user_id=user_id
        ).select_related(
            'curriculum_id'
        ).order_by('-curriculumquizhistory_submit_dt')

        # 특정 커리큘럼에 대한 필터링
        curriculum_id = request.GET.get('curriculum_id')
        if curriculum_id:
            try:
                curriculum_id = int(curriculum_id)
                quiz_histories = quiz_histories.filter(curriculum_id=curriculum_id)
            except ValueError:
                return JsonResponse({
                    "error": "커리큘럼 ID는 숫자여야 합니다."
                }, status=400, json_dumps_params={"ensure_ascii": False})

        # 결과 데이터 구성
        results = []
        for history in quiz_histories:
            results.append({
                "quiz_history_id": history.curriculumquizhistory_id,
                "curriculum_id": history.curriculum_id.curriculum_id,
                "curriculum_name": history.curriculum_id.curriculum_name,
                "total_score": history.curriculumquizhistory_total_score,
                "avg_score": history.curriculumquizhistory_avg_score,
                "history_data": history.curriculumquizhistory_history,
                "submit_date": history.curriculumquizhistory_submit_dt.strftime("%Y-%m-%d %H:%M:%S")
            })

        return JsonResponse({
            "results": results
        }, json_dumps_params={"ensure_ascii": False})
        
    except Exception as e:
        return JsonResponse({
            "error": f"퀴즈 히스토리 조회 중 오류가 발생했습니다: {str(e)}"
        }, status=500, json_dumps_params={"ensure_ascii": False})


###########################################################################################
# GPT-4가 자연어 쿼리를 처리하는 API
###########################################################################################

@api_view(['POST'])
def ai_assistant(request):
    """
    AI 에이전트 엔드포인트 - 자연어 쿼리를 통해 db_utils.py의 함수를 호출합니다.
    """
    try:
        # 요청 데이터 파싱
        data = request.data
        print(f"요청 데이터: {data}")
        
        user_id = data.get('user_id')
        query = data.get('query')
        
        print(f"파싱된 데이터 - user_id: {user_id} ({type(user_id)}), query: {query}")
        
        if not user_id or not query:
            return Response({"error": "user_id와 query는 필수 항목입니다."}, status=400)
        
        # user_id가 정수형인지 확인하고 변환
        try:
            user_id = int(user_id)
        except (ValueError, TypeError):
            return Response({"error": "user_id는 정수여야 합니다."}, status=400)
        
        # 유틸리티 함수 호출
        print(f"process_ai_assistant_query 호출: user_id={user_id}, query={query}")
        result = process_ai_assistant_query(user_id, query)
        
        # 에러 처리
        if "error" in result:
            print(f"에러 응답: {result['error']}")
            return Response(result, status=400)
        
        print(f"성공 응답 - 키: {list(result.keys())}")
        return Response(result)
            
    except Exception as e:
        print(f"예외 발생: {str(e)}")
        import traceback
        traceback.print_exc()
        return Response({"error": str(e)}, status=500)


###########################################################################################
# 히스토리 기반 문제 출제 API
###########################################################################################
def _get_section_score(history_qs):
    """
    history_qs: 최신 2개 CurriculumQuizHistory QuerySet
    반환: (section_question_plan, selected_questions)
    """
    # 1) 섹션별 누적 total/ correct 합산
    merged = {}
    for hist in history_qs:
        data = hist
        for sec in data["history_data"]["section_results"]:
            sid = sec["section_id"]
            total = sec.get("section_num_questions", 0)
            corr  = sec.get("section_correct_answers", 0)
            merged.setdefault(sid, {"total": 0, "correct": 0})
            merged[sid]["total"]   += total
            merged[sid]["correct"] += corr

    # 2) 정답률 기반 문제 수 산정
    section_question_plan = []
    for sid, vals in merged.items():
        total   = vals["total"] or 1
        correct = vals["correct"]
        acc = correct / total

        if acc < 0.25:
            n = 4
        elif acc < 0.5:
            n = 3
        elif acc < 0.75:
            n = 2
        else:
            n = 1

        section_question_plan.append({
            "section_id": sid,
            "accuracy_percent": round(acc * 100, 2),
            "num_questions": n
        })

    return section_question_plan

@api_view(['GET'])
def get_adaptive_quiz(request):
    """
    사용자 최신 2개 히스토리를 기반으로,
    섹션별 누적 정답률 → 문제 수 산정 → 랜덤 문제 추출
    """
    history_response = get_quiz_history(request._request)

    # get_quiz_history의 결과가 JsonResponse 형태이므로, content를 파싱함.
    try:
        history_data = json.loads(history_response.content.decode("utf-8"))
    except Exception as e:
        return JsonResponse({
            "error": "퀴즈 히스토리 데이터를 파싱하는데 실패했습니다."
        }, status=500, json_dumps_params={"ensure_ascii": False})

    # get_quiz_history에서 에러가 발생한 경우 그대로 반환
    if "error" in history_data:
        return JsonResponse(history_data, status=400, json_dumps_params={"ensure_ascii": False})

    quiz_histories = history_data.get("results", [])

    # 히스토리가 없는 경우, 모든 섹션에 기본 문제 수(2개)를 설정하여 반환
    if not quiz_histories:
        # 현재 커리큘럼의 모든 섹션 정보 가져오기
        sections = CurriculumSection.objects.filter(curriculum_id=request.GET.get('curriculum_id'))

        # 각 섹션에 대해 기본값(2문제) 설정
        section_question_plan = []
        for section in sections:
            section_question_plan.append({
                "section_id": section.curriculumsection_id,
                "accuracy_percent": 0,  # 기록 없음
                "num_questions": 2  # 기본값
            })

        return JsonResponse({
            "section_question_plan": section_question_plan
        }, json_dumps_params={"ensure_ascii": False})

    # 가장 최근 2개의 히스토리 데이터만 사용
    recent_histories = quiz_histories[:2]

    plan = _get_section_score(recent_histories)

    return JsonResponse({
        "section_question_plan": plan,
    }, json_dumps_params={"ensure_ascii": False})

###########################################################################################
# 퀴즈 분석 및 레포트 생성 API
###########################################################################################

@api_view(['GET'])
@login_required_json
def analyze_quiz_report(request, user):
    """
    특정 퀴즈 히스토리에 대한 상세 분석 및 학습 계획을 생성하는 API
    
    Parameters:
    - quiz_history_id (required): 분석할 퀴즈 히스토리 ID
    """
    quiz_history_id = request.GET.get('quiz_history_id')
    
    if not quiz_history_id:
        return JsonResponse({
            "error": "quiz_history_id는 필수 파라미터입니다."
        }, status=400, json_dumps_params={"ensure_ascii": False})
    
    try:
        # 퀴즈 히스토리 상세 정보 조회
        history_data = get_quiz_history_detail(quiz_history_id)

        if not history_data:
            return JsonResponse({
                "error": "해당 퀴즈 히스토리가 존재하지 않습니다."
            }, status=404, json_dumps_params={"ensure_ascii": False})
        
        # 권한 확인 - 자신의 퀴즈 히스토리만 볼 수 있음
        if history_data.get('user_id') != user.user_id:
            return JsonResponse({
                "error": "이 퀴즈 히스토리에 접근할 권한이 없습니다."
            }, status=403, json_dumps_params={"ensure_ascii": False})
        
        # 퀴즈 히스토리 분석
        analysis_result = analyze_quiz_history(history_data)
        
        return JsonResponse({
            "quiz_history": {
                "id": history_data.get('curriculumquizhistory_id'),
                "curriculum_id": history_data.get('curriculum_id'),
                "curriculum_name": history_data.get('curriculum_name'),
                "user_nickname": history_data.get('user_nickname'),
                "total_score": history_data.get('curriculumquizhistory_total_score'),
                "avg_score": history_data.get('curriculumquizhistory_avg_score'),
                "submit_date": history_data.get('curriculumquizhistory_submit_dt')
            },
            "analysis": {
                "section_scores": analysis_result.get('section_scores', []),
                "best_sections": analysis_result.get('best_sections', []),
                "worst_sections": analysis_result.get('worst_sections', []),
                "wrong_answers": analysis_result.get('wrong_answers', []),
                "strength_analysis": analysis_result.get('strength_analysis', ''),
                "weakness_analysis": analysis_result.get('weakness_analysis', ''),
                "wrong_answer_analysis": analysis_result.get('wrong_answer_analysis', ''),
                "study_plan": analysis_result.get('study_plan', '')
            }
        }, json_dumps_params={"ensure_ascii": False})
    
    except Exception as e:
        return JsonResponse({
            "error": f"분석 중 오류가 발생했습니다: {str(e)}"
        }, status=500, json_dumps_params={"ensure_ascii": False})



--- File: 13 # backend/Project/admin.py ---
from django.contrib import admin


from .models import Project

@admin.register(Project)
class ProjectAdmin(admin.ModelAdmin):
    list_display = ('project_id', 'user_id', 'project_name','project_start_date', 'project_end_date', 
                    'project_member_num', "project_join_address", "project_content", 'project_keyword')
    search_fields = ('project_name',)


--- File: 15 # backend/Project/migrations/0001_initial.py ---
# Generated by Django 5.1.6 on 2025-04-01 11:14

import pgvector.django.vector
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
    ]

    operations = [
        migrations.CreateModel(
            name='Project',
            fields=[
                ('project_id', models.AutoField(primary_key=True, serialize=False)),
                ('project_name', models.CharField(max_length=50)),
                ('project_start_date', models.DateTimeField()),
                ('project_end_date', models.DateTimeField()),
                ('project_member_num', models.IntegerField()),
                ('project_join_address', models.TextField(blank=True, null=True)),
                ('project_content', models.TextField(blank=True, null=True)),
                ('project_keyword', models.TextField(blank=True, null=True)),
                ('project_emb', pgvector.django.vector.VectorField(default=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], dimensions=1536)),
            ],
        ),
    ]


--- File: 16 # backend/Project/migrations/0002_initial.py ---
# Generated by Django 5.1.6 on 2025-04-01 11:14

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('Project', '0001_initial'),
        ('User', '0001_initial'),
    ]

    operations = [
        migrations.AddField(
            model_name='project',
            name='user_id',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, to='User.user'),
        ),
    ]


--- File: 18 # backend/Project/models.py ---
from django.db import models
from pgvector.django import VectorField

class Project(models.Model):
    project_id = models.AutoField(primary_key=True)
    user_id = models.ForeignKey('User.User', on_delete=models.CASCADE)
    project_name = models.CharField(max_length=50)
    project_start_date = models.DateTimeField()
    project_end_date = models.DateTimeField()
    project_member_num = models.IntegerField()
    project_join_address= models.TextField(null=True, blank=True)
    project_content = models.TextField(null=True, blank=True)
    project_keyword = models.TextField(null=True, blank=True)
    project_emb = VectorField(dimensions=1536, default=[0.0]*1536)

    def __str__(self):
        return f"{self.project_id} - {self.project_name}"


--- File: 20 # backend/Project/urls.py ---
from django.urls import path
from . import views
from .views import add_project, get_random_project, CreateProjectUsingLLM, CreateProject, create_project, get_project_by_id, get_search_project, apply_to_project

urlpatterns = [
    ###########################################################################################
    # 프로젝트를 조회하는 url
    ###########################################################################################
    path('get_project_by_id/', get_project_by_id, name='get_project_by_id'),
    path('get_search_project/', get_search_project, name='get_search_project'),
    path('get_random_project/', get_random_project, name='get_random_project'),
    path('<int:project_id>/team/', views.team_member_list, name='team_member_list'),
    
    ###########################################################################################
    # 프로젝트를 추가/삭제하는 url
    ###########################################################################################
    path('add_project/', add_project, name='add_project'),
    path('create_project/<int:project_id>/', CreateProject.as_view(), name='create_project'),
    path('create_project/', create_project, name='create_project'),
    path('apply_to_project/', apply_to_project, name='apply_to_project'),
    
    ###########################################################################################
    # RAG/Rerank/Agent/LLM 기능을 사용하는 url
    ###########################################################################################
    path('create-project-using-llm/<int:curriculum_id>/', CreateProjectUsingLLM.as_view(), name='create-project-using-llm'),

]


IMPORTANT: Generate the `summary` and relationship `label` fields in **Korean** language. Do NOT use English for these fields.

Please provide:
1. A high-level `summary` of the project's main purpose and functionality in a few beginner-friendly sentences (in Korean). Use markdown formatting with **bold** and *italic* text to highlight important concepts.
2. A list (`relationships`) describing the key interactions between these abstractions. For each relationship, specify:
    - `from_abstraction`: Index of the source abstraction (e.g., `0 # AbstractionName1`)
    - `to_abstraction`: Index of the target abstraction (e.g., `1 # AbstractionName2`)
    - `label`: A brief label for the interaction **in just a few words** (in Korean) (e.g., "Manages", "Inherits", "Uses").
    Ideally the relationship should be backed by one abstraction calling or passing parameters to another.
    Simplify the relationship and exclude those non-important ones.

IMPORTANT: Make sure EVERY abstraction is involved in at least ONE relationship (either as source or target). Each abstraction index must appear at least once across all relationships.

Format the output as YAML:

```yaml
summary: |
  A brief, simple explanation of the project (in Korean).
  Can span multiple lines with **bold** and *italic* for emphasis.
relationships:
  - from_abstraction: 0 # AbstractionName1
    to_abstraction: 1 # AbstractionName2
    label: "Manages" (in Korean)
  - from_abstraction: 2 # AbstractionName3
    to_abstraction: 0 # AbstractionName1
    label: "Provides config" (in Korean)
  # ... other relationships
```

Now, provide the YAML output:

2025-06-29 21:01:28,014 - INFO - Using OpenAI model: gpt-4o
2025-06-29 21:02:18,640 - INFO - RESPONSE: ```yaml
summary: |
  **SKN_ToyProject**는 사용자가 교육 커리큘럼과 프로젝트를 관리하고 참여할 수 있도록 도와주는 **웹 애플리케이션**입니다. 
  *교육 커리큘럼*은 다양한 강의와 퀴즈를 포함하여 학습을 지원하며, *프로젝트 모델*은 팀 협업을 관리하고 추적할 수 있습니다. 
  **추천 시스템**과 **AI 어시스턴트** 기능을 통해 사용자에게 맞춤형 학습 경험을 제공합니다.

relationships:
  - from_abstraction: 0 # 커리큘럼 모델
    to_abstraction: 3 # 커리큘럼 뷰
    label: "제공" 
  - from_abstraction: 1 # 프로젝트 모델
    to_abstraction: 4 # 프로젝트 뷰
    label: "제공"
  - from_abstraction: 2 # 관리 인터페이스
    to_abstraction: 0 # 커리큘럼 모델
    label: "관리"
  - from_abstraction: 2 # 관리 인터페이스
    to_abstraction: 1 # 프로젝트 모델
    label: "관리"
  - from_abstraction: 3 # 커리큘럼 뷰
    to_abstraction: 0 # 커리큘럼 모델
    label: "조회"
  - from_abstraction: 4 # 프로젝트 뷰
    to_abstraction: 1 # 프로젝트 모델
    label: "조회"
  - from_abstraction: 5 # 퀴즈 히스토리 및 분석
    to_abstraction: 0 # 커리큘럼 모델
    label: "기록"
  - from_abstraction: 7 # 사용자 및 커리큘럼 관계
    to_abstraction: 0 # 커리큘럼 모델
    label: "연관"
  - from_abstraction: 9 # 추천 시스템
    to_abstraction: 8 # GPT 기반 AI 어시스턴트
    label: "사용"
  - from_abstraction: 6 # 기술 스택 관리
    to_abstraction: 0 # 커리큘럼 모델
    label: "정보제공"
```
2025-06-29 21:02:19,018 - INFO - PROMPT: 
Given the following project abstractions and their relationships for the project ```` SKN_ToyProject ````:

Abstractions (Index # Name) (Names might be in Korean):
- 0 # 커리큘럼 모델 (Curriculum Model)
- 1 # 프로젝트 모델 (Project Model)
- 2 # 관리 인터페이스 (Admin Interface)
- 3 # 커리큘럼 뷰 (Curriculum Views)
- 4 # 프로젝트 뷰 (Project Views)
- 5 # 퀴즈 히스토리 및 분석 (Quiz History and Analysis)
- 6 # 기술 스택 관리 (Tech Stack Management)
- 7 # 사용자 및 커리큘럼 관계 (User and Curriculum Relationship)
- 8 # GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)
- 9 # 추천 시스템 (Recommendation System)

Context about relationships and project summary:
Project Summary (Note: Project Summary might be in Korean):
**SKN_ToyProject**는 사용자가 교육 커리큘럼과 프로젝트를 관리하고 참여할 수 있도록 도와주는 **웹 애플리케이션**입니다. 
*교육 커리큘럼*은 다양한 강의와 퀴즈를 포함하여 학습을 지원하며, *프로젝트 모델*은 팀 협업을 관리하고 추적할 수 있습니다. 
**추천 시스템**과 **AI 어시스턴트** 기능을 통해 사용자에게 맞춤형 학습 경험을 제공합니다.


Relationships (Indices refer to abstractions above):
- From 0 (커리큘럼 모델 (Curriculum Model)) to 3 (커리큘럼 뷰 (Curriculum Views)): 제공
- From 1 (프로젝트 모델 (Project Model)) to 4 (프로젝트 뷰 (Project Views)): 제공
- From 2 (관리 인터페이스 (Admin Interface)) to 0 (커리큘럼 모델 (Curriculum Model)): 관리
- From 2 (관리 인터페이스 (Admin Interface)) to 1 (프로젝트 모델 (Project Model)): 관리
- From 3 (커리큘럼 뷰 (Curriculum Views)) to 0 (커리큘럼 모델 (Curriculum Model)): 조회
- From 4 (프로젝트 뷰 (Project Views)) to 1 (프로젝트 모델 (Project Model)): 조회
- From 5 (퀴즈 히스토리 및 분석 (Quiz History and Analysis)) to 0 (커리큘럼 모델 (Curriculum Model)): 기록
- From 7 (사용자 및 커리큘럼 관계 (User and Curriculum Relationship)) to 0 (커리큘럼 모델 (Curriculum Model)): 연관
- From 9 (추천 시스템 (Recommendation System)) to 8 (GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)): 사용
- From 6 (기술 스택 관리 (Tech Stack Management)) to 0 (커리큘럼 모델 (Curriculum Model)): 정보제공


If you are going to make a tutorial for ```` SKN_ToyProject ````, what is the best order to explain these abstractions, from first to last?
Ideally, first explain those that are the most important or foundational, perhaps user-facing concepts or entry points. Then move to more detailed, lower-level implementation details or supporting concepts.

Output the ordered list of abstraction indices, including the name in a comment for clarity. Use the format `idx # AbstractionName`.

```yaml
- 2 # FoundationalConcept
- 0 # CoreClassA
- 1 # CoreClassB (uses CoreClassA)
- ...
```

Now, provide the YAML output:

2025-06-29 21:02:19,193 - INFO - Using OpenAI model: gpt-4o
2025-06-29 21:02:23,252 - ERROR - Error during OpenAI API call: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-LE7UVm78wd0kYoJt4VNGcUvU on tokens per min (TPM): Limit 30000, Used 30000, Requested 755. Please try again in 1.51s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-06-29 21:02:23,253 - ERROR - OpenAI API Error Details: {'error': {'message': 'Rate limit reached for gpt-4o in organization org-LE7UVm78wd0kYoJt4VNGcUvU on tokens per min (TPM): Limit 30000, Used 30000, Requested 755. Please try again in 1.51s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}
2025-06-29 21:02:43,253 - INFO - PROMPT: 
Given the following project abstractions and their relationships for the project ```` SKN_ToyProject ````:

Abstractions (Index # Name) (Names might be in Korean):
- 0 # 커리큘럼 모델 (Curriculum Model)
- 1 # 프로젝트 모델 (Project Model)
- 2 # 관리 인터페이스 (Admin Interface)
- 3 # 커리큘럼 뷰 (Curriculum Views)
- 4 # 프로젝트 뷰 (Project Views)
- 5 # 퀴즈 히스토리 및 분석 (Quiz History and Analysis)
- 6 # 기술 스택 관리 (Tech Stack Management)
- 7 # 사용자 및 커리큘럼 관계 (User and Curriculum Relationship)
- 8 # GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)
- 9 # 추천 시스템 (Recommendation System)

Context about relationships and project summary:
Project Summary (Note: Project Summary might be in Korean):
**SKN_ToyProject**는 사용자가 교육 커리큘럼과 프로젝트를 관리하고 참여할 수 있도록 도와주는 **웹 애플리케이션**입니다. 
*교육 커리큘럼*은 다양한 강의와 퀴즈를 포함하여 학습을 지원하며, *프로젝트 모델*은 팀 협업을 관리하고 추적할 수 있습니다. 
**추천 시스템**과 **AI 어시스턴트** 기능을 통해 사용자에게 맞춤형 학습 경험을 제공합니다.


Relationships (Indices refer to abstractions above):
- From 0 (커리큘럼 모델 (Curriculum Model)) to 3 (커리큘럼 뷰 (Curriculum Views)): 제공
- From 1 (프로젝트 모델 (Project Model)) to 4 (프로젝트 뷰 (Project Views)): 제공
- From 2 (관리 인터페이스 (Admin Interface)) to 0 (커리큘럼 모델 (Curriculum Model)): 관리
- From 2 (관리 인터페이스 (Admin Interface)) to 1 (프로젝트 모델 (Project Model)): 관리
- From 3 (커리큘럼 뷰 (Curriculum Views)) to 0 (커리큘럼 모델 (Curriculum Model)): 조회
- From 4 (프로젝트 뷰 (Project Views)) to 1 (프로젝트 모델 (Project Model)): 조회
- From 5 (퀴즈 히스토리 및 분석 (Quiz History and Analysis)) to 0 (커리큘럼 모델 (Curriculum Model)): 기록
- From 7 (사용자 및 커리큘럼 관계 (User and Curriculum Relationship)) to 0 (커리큘럼 모델 (Curriculum Model)): 연관
- From 9 (추천 시스템 (Recommendation System)) to 8 (GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)): 사용
- From 6 (기술 스택 관리 (Tech Stack Management)) to 0 (커리큘럼 모델 (Curriculum Model)): 정보제공


If you are going to make a tutorial for ```` SKN_ToyProject ````, what is the best order to explain these abstractions, from first to last?
Ideally, first explain those that are the most important or foundational, perhaps user-facing concepts or entry points. Then move to more detailed, lower-level implementation details or supporting concepts.

Output the ordered list of abstraction indices, including the name in a comment for clarity. Use the format `idx # AbstractionName`.

```yaml
- 2 # FoundationalConcept
- 0 # CoreClassA
- 1 # CoreClassB (uses CoreClassA)
- ...
```

Now, provide the YAML output:

2025-06-29 21:02:43,410 - INFO - Using OpenAI model: gpt-4o
2025-06-29 21:02:44,950 - INFO - RESPONSE: ```yaml
- 2 # 관리 인터페이스 (Admin Interface)
- 0 # 커리큘럼 모델 (Curriculum Model)
- 1 # 프로젝트 모델 (Project Model)
- 3 # 커리큘럼 뷰 (Curriculum Views)
- 4 # 프로젝트 뷰 (Project Views)
- 7 # 사용자 및 커리큘럼 관계 (User and Curriculum Relationship)
- 5 # 퀴즈 히스토리 및 분석 (Quiz History and Analysis)
- 8 # GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)
- 9 # 추천 시스템 (Recommendation System)
- 6 # 기술 스택 관리 (Tech Stack Management)
```
2025-06-29 21:02:45,315 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN_ToyProject` about the concept: "관리 인터페이스 (Admin Interface)". This is Chapter 1.

Concept Details (Note: Provided in Korean):
- Name: 관리 인터페이스 (Admin Interface)
- Description:
관리자에게 다양한 모델 객체를 관리할 수 있는 인터페이스를 제공하여 데이터의 시각화와 조작을 용이하게 합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)
2. [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)
3. [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)
4. [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)
5. [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)
6. [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)
7. [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)
8. [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)
9. [추천 시스템 (Recommendation System)](09_추천_시스템__recommendation_system_.md)
10. [기술 스택 관리 (Tech Stack Management)](10_기술_스택_관리__tech_stack_management_.md)

Context from previous chapters (Note: This summary might be in Korean):
This is the first chapter.

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 1: 관리 인터페이스 (Admin Interface)`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 21:02:45,479 - INFO - Using OpenAI model: gpt-4o
2025-06-29 21:02:54,630 - INFO - RESPONSE: # Chapter 1: 관리 인터페이스 (Admin Interface)

`SKN_ToyProject`에 오신 것을 환영합니다! 이 장에서는 관리 인터페이스(Admin Interface)의 개념에 대해 알아보겠습니다. 관리 인터페이스는 데이터를 관리하고 시각화하는 데 매우 중요한 도구입니다. 관리자가 다양한 모델 객체를 효율적으로 다루는 방법을 배울 수 있습니다.

## 관리 인터페이스란 무엇인가요?

관리 인터페이스는 프로젝트 내에서 데이터를 쉽게 시각화하고 조작할 수 있도록 도와주는 도구입니다. 예를 들어, 웹사이트의 관리자 페이지를 생각해보세요. 사용자가 데이터를 입력하면, 관리자는 이 데이터가 어떻게 저장되고, 표현되는지를 이 페이지에서 직접 확인하고 변경할 수 있습니다. 바로 이런 역할을 하는 것이 관리 인터페이스입니다.

## 관리 인터페이스의 주요 개념

### 1. 데이터 시각화
관리 인터페이스는 데이터를 표 형태로 보여줍니다. 이는 사용자가 데이터를 한눈에 이해할 수 있게 도와줍니다.

### 2. 데이터 조작
사용자는 인터페이스를 통해 데이터를 직접 추가, 수정, 삭제할 수 있습니다. 이를 통해 데이터 관리가 훨씬 더 직관적이고 효율적이 됩니다.

## 관리 인터페이스 사용 방법

이제 간단한 예제로 관리 인터페이스를 사용하는 방법을 살펴보겠습니다.

```python
from admin_interface import Admin

# 관리자 인터페이스 초기화
admin = Admin()

# 데이터 추가
admin.add_model('새로운 모델 객체')

# 데이터 목록 보기
print(admin.list_models())  # ['새로운 모델 객체']
```

첫 줄에서 관리 인터페이스를 불러오고, 두 번째 줄에서 관리 인터페이스를 초기화합니다. 그 후, `add_model` 메소드를 통해 데이터를 추가하고, `list_models`를 통해 현재 데이터를 확인할 수 있습니다.

## 관리 인터페이스의 내부 구조

관리 인터페이스가 어떻게 내부적으로 동작하는지 간단히 살펴보겠습니다. 관리 인터페이스가 호출되면, 다음과 같은 단계를 거칩니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant AI as 관리 인터페이스
    participant DB as 데이터베이스

    U->>AI: 데이터 추가 요청
    AI->>DB: 데이터 저장 요청
    DB->>AI: 저장 완료 응답
    AI->>U: 처리 결과 전달
```

`사용자`가 관리 인터페이스를 통해 데이터를 추가하면, `관리 인터페이스`는 이를 `데이터베이스`에 저장하고 결과를 다시 사용자에게 전달합니다.

### 코드를 통한 내부 구조 이해

관리 인터페이스의 내부 구현을 간단한 코드로 살펴보겠습니다.

```python
class Admin:
    def __init__(self):
        self.models = []

    def add_model(self, model_name):
        # 모델 추가
        self.models.append(model_name)

    def list_models(self):
        # 모델 목록 반환
        return self.models
```

`Admin` 클래스는 모델 목록을 관리합니다. `add_model` 메소드는 모델을 추가하고, `list_models` 메소드는 현재 모델 목록을 반환합니다.

## 결론

이 장에서는 관리 인터페이스의 기본 개념과 사용 방법을 배웠습니다. 관리 인터페이스는 프로젝트 내 데이터를 효율적으로 관리하는 데 매우 유용한 도구입니다. 

다음 장에서는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 알아보겠습니다. 기대해주세요!
2025-06-29 21:02:54,643 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN_ToyProject` about the concept: "커리큘럼 모델 (Curriculum Model)". This is Chapter 2.

Concept Details (Note: Provided in Korean):
- Name: 커리큘럼 모델 (Curriculum Model)
- Description:
교육 커리큘럼을 정의하고 관리하는 주요 데이터 구조입니다. 사용자 아이디와 관련된 다양한 정보, 예를 들어 커리큘럼 타입, 이름, 키워드 등을 포함합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)
2. [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)
3. [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)
4. [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)
5. [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)
6. [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)
7. [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)
8. [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)
9. [추천 시스템 (Recommendation System)](09_추천_시스템__recommendation_system_.md)
10. [기술 스택 관리 (Tech Stack Management)](10_기술_스택_관리__tech_stack_management_.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 관리 인터페이스 (Admin Interface)

`SKN_ToyProject`에 오신 것을 환영합니다! 이 장에서는 관리 인터페이스(Admin Interface)의 개념에 대해 알아보겠습니다. 관리 인터페이스는 데이터를 관리하고 시각화하는 데 매우 중요한 도구입니다. 관리자가 다양한 모델 객체를 효율적으로 다루는 방법을 배울 수 있습니다.

## 관리 인터페이스란 무엇인가요?

관리 인터페이스는 프로젝트 내에서 데이터를 쉽게 시각화하고 조작할 수 있도록 도와주는 도구입니다. 예를 들어, 웹사이트의 관리자 페이지를 생각해보세요. 사용자가 데이터를 입력하면, 관리자는 이 데이터가 어떻게 저장되고, 표현되는지를 이 페이지에서 직접 확인하고 변경할 수 있습니다. 바로 이런 역할을 하는 것이 관리 인터페이스입니다.

## 관리 인터페이스의 주요 개념

### 1. 데이터 시각화
관리 인터페이스는 데이터를 표 형태로 보여줍니다. 이는 사용자가 데이터를 한눈에 이해할 수 있게 도와줍니다.

### 2. 데이터 조작
사용자는 인터페이스를 통해 데이터를 직접 추가, 수정, 삭제할 수 있습니다. 이를 통해 데이터 관리가 훨씬 더 직관적이고 효율적이 됩니다.

## 관리 인터페이스 사용 방법

이제 간단한 예제로 관리 인터페이스를 사용하는 방법을 살펴보겠습니다.

```python
from admin_interface import Admin

# 관리자 인터페이스 초기화
admin = Admin()

# 데이터 추가
admin.add_model('새로운 모델 객체')

# 데이터 목록 보기
print(admin.list_models())  # ['새로운 모델 객체']
```

첫 줄에서 관리 인터페이스를 불러오고, 두 번째 줄에서 관리 인터페이스를 초기화합니다. 그 후, `add_model` 메소드를 통해 데이터를 추가하고, `list_models`를 통해 현재 데이터를 확인할 수 있습니다.

## 관리 인터페이스의 내부 구조

관리 인터페이스가 어떻게 내부적으로 동작하는지 간단히 살펴보겠습니다. 관리 인터페이스가 호출되면, 다음과 같은 단계를 거칩니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant AI as 관리 인터페이스
    participant DB as 데이터베이스

    U->>AI: 데이터 추가 요청
    AI->>DB: 데이터 저장 요청
    DB->>AI: 저장 완료 응답
    AI->>U: 처리 결과 전달
```

`사용자`가 관리 인터페이스를 통해 데이터를 추가하면, `관리 인터페이스`는 이를 `데이터베이스`에 저장하고 결과를 다시 사용자에게 전달합니다.

### 코드를 통한 내부 구조 이해

관리 인터페이스의 내부 구현을 간단한 코드로 살펴보겠습니다.

```python
class Admin:
    def __init__(self):
        self.models = []

    def add_model(self, model_name):
        # 모델 추가
        self.models.append(model_name)

    def list_models(self):
        # 모델 목록 반환
        return self.models
```

`Admin` 클래스는 모델 목록을 관리합니다. `add_model` 메소드는 모델을 추가하고, `list_models` 메소드는 현재 모델 목록을 반환합니다.

## 결론

이 장에서는 관리 인터페이스의 기본 개념과 사용 방법을 배웠습니다. 관리 인터페이스는 프로젝트 내 데이터를 효율적으로 관리하는 데 매우 유용한 도구입니다. 

다음 장에서는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 알아보겠습니다. 기대해주세요!

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 2: 커리큘럼 모델 (Curriculum Model)`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 21:02:54,825 - INFO - Using OpenAI model: gpt-4o
2025-06-29 21:03:05,671 - INFO - RESPONSE: # Chapter 2: 커리큘럼 모델 (Curriculum Model)

이전 장에서는 [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)에 대해 알아보았습니다. 이제 우리는 커리큘럼 모델에 대해 설명할 것입니다. 이는 교육 커리큘럼을 정의하고 관리하기 위한 핵심 데이터 구조입니다. 초심자를 위한 설명을 통해 쉽게 따라올 수 있도록 하겠습니다.

## 커리큘럼 모델이란 무엇인가요?

커리큘럼 모델은 교육 콘텐츠를 체계적으로 관리하기 위한 데이터 구조입니다. 이를 통해 우리는 다양한 사용자에 맞춘 교육 경로를 계획하고 조정할 수 있습니다. 대표적인 예로 프로그래밍 학습 플랫폼에서 다양한 난이도별 코스를 제공하는 것을 들 수 있습니다.

### 커리큘럼 모델의 주요 개념

- **사용자 아이디**: 커리큘럼이 특정 사용자에게 할당되었음을 나타냅니다.
- **커리큘럼 타입**: 커리큘럼의 유형(예: 입문, 중급, 고급)을 정의합니다.
- **커리큘럼 이름**: 사용자가 이해하기 쉽고 식별할 수 있도록 지정합니다.
- **키워드**: 커리큘럼의 핵심 주제를 빠르게 파악할 수 있게 도와줍니다.

## 커리큘럼 모델 사용 방법

이제 간단한 커리큘럼 객체를 생성하고 사용하는 방법을 살펴보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        # 사용자 아이디 저장
        self.user_id = user_id
        # 커리큘럼 타입 저장
        self.cur_type = cur_type
        # 커리큘럼 이름 저장
        self.name = name
        # 키워드 저장
        self.keywords = keywords

# 커리큘럼 객체 생성
my_curriculum = CurriculumModel('user123', '입문', '파이썬 기본', ['프로그래밍', '파이썬'])
```

위 코드에서는 `CurriculumModel` 클래스를 정의하고 인스턴스를 생성했습니다. 각 인스턴스는 사용자 아이디, 커리큘럼 타입, 이름, 키워드를 포함합니다. 이와 같은 방식을 통해 다양한 커리큘럼을 효과적으로 관리할 수 있습니다.

## 내부 구현의 이해

커리큘럼 모델이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다. 이는 주로 객체가 생성되어, 데이터를 처리를 하는 과정을 보여줍니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant C as 커리큘럼 모델
    participant DB as 데이터베이스

    U->>C: 새로운 커리큘럼 생성 요청
    C->>DB: 커리큘럼 저장
    DB->>C: 저장 완료 응답
    C->>U: 생성 결과 전달
```

위 시퀀스 다이어그램은 사용자가 커리큘럼을 생성하면 그 요청이 데이터베이스에 저장되는 과정을 보여줍니다.

### 내부 코드 분석

커리큘럼 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        self.user_id = user_id
        self.cur_type = cur_type
        self.name = name
        self.keywords = keywords
    
    def save_to_db(self):
        # 데이터베이스에 커리큘럼 저장
        print(f"커리큘럼 '{self.name}'이 저장되었습니다.")
```

`CurriculumModel` 클래스에는 생성자 외에도 커리큘럼을 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 커리큘럼 모델이 무엇인지, 이를 사용하여 데이터를 어떻게 관리할 수 있는지를 배웠습니다. 이를 통해 다양한 교육 경로를 효율적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 알아보겠습니다. 함께 탐구해 봅시다!
2025-06-29 21:03:05,684 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN_ToyProject` about the concept: "프로젝트 모델 (Project Model)". This is Chapter 3.

Concept Details (Note: Provided in Korean):
- Name: 프로젝트 모델 (Project Model)
- Description:
사용자의 프로젝트에 대한 정보를 저장하고 관리하는 데 사용되는 데이터 구조입니다. 프로젝트 이름, 시작 및 종료 날짜, 팀원 수 등을 관리합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)
2. [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)
3. [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)
4. [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)
5. [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)
6. [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)
7. [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)
8. [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)
9. [추천 시스템 (Recommendation System)](09_추천_시스템__recommendation_system_.md)
10. [기술 스택 관리 (Tech Stack Management)](10_기술_스택_관리__tech_stack_management_.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 관리 인터페이스 (Admin Interface)

`SKN_ToyProject`에 오신 것을 환영합니다! 이 장에서는 관리 인터페이스(Admin Interface)의 개념에 대해 알아보겠습니다. 관리 인터페이스는 데이터를 관리하고 시각화하는 데 매우 중요한 도구입니다. 관리자가 다양한 모델 객체를 효율적으로 다루는 방법을 배울 수 있습니다.

## 관리 인터페이스란 무엇인가요?

관리 인터페이스는 프로젝트 내에서 데이터를 쉽게 시각화하고 조작할 수 있도록 도와주는 도구입니다. 예를 들어, 웹사이트의 관리자 페이지를 생각해보세요. 사용자가 데이터를 입력하면, 관리자는 이 데이터가 어떻게 저장되고, 표현되는지를 이 페이지에서 직접 확인하고 변경할 수 있습니다. 바로 이런 역할을 하는 것이 관리 인터페이스입니다.

## 관리 인터페이스의 주요 개념

### 1. 데이터 시각화
관리 인터페이스는 데이터를 표 형태로 보여줍니다. 이는 사용자가 데이터를 한눈에 이해할 수 있게 도와줍니다.

### 2. 데이터 조작
사용자는 인터페이스를 통해 데이터를 직접 추가, 수정, 삭제할 수 있습니다. 이를 통해 데이터 관리가 훨씬 더 직관적이고 효율적이 됩니다.

## 관리 인터페이스 사용 방법

이제 간단한 예제로 관리 인터페이스를 사용하는 방법을 살펴보겠습니다.

```python
from admin_interface import Admin

# 관리자 인터페이스 초기화
admin = Admin()

# 데이터 추가
admin.add_model('새로운 모델 객체')

# 데이터 목록 보기
print(admin.list_models())  # ['새로운 모델 객체']
```

첫 줄에서 관리 인터페이스를 불러오고, 두 번째 줄에서 관리 인터페이스를 초기화합니다. 그 후, `add_model` 메소드를 통해 데이터를 추가하고, `list_models`를 통해 현재 데이터를 확인할 수 있습니다.

## 관리 인터페이스의 내부 구조

관리 인터페이스가 어떻게 내부적으로 동작하는지 간단히 살펴보겠습니다. 관리 인터페이스가 호출되면, 다음과 같은 단계를 거칩니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant AI as 관리 인터페이스
    participant DB as 데이터베이스

    U->>AI: 데이터 추가 요청
    AI->>DB: 데이터 저장 요청
    DB->>AI: 저장 완료 응답
    AI->>U: 처리 결과 전달
```

`사용자`가 관리 인터페이스를 통해 데이터를 추가하면, `관리 인터페이스`는 이를 `데이터베이스`에 저장하고 결과를 다시 사용자에게 전달합니다.

### 코드를 통한 내부 구조 이해

관리 인터페이스의 내부 구현을 간단한 코드로 살펴보겠습니다.

```python
class Admin:
    def __init__(self):
        self.models = []

    def add_model(self, model_name):
        # 모델 추가
        self.models.append(model_name)

    def list_models(self):
        # 모델 목록 반환
        return self.models
```

`Admin` 클래스는 모델 목록을 관리합니다. `add_model` 메소드는 모델을 추가하고, `list_models` 메소드는 현재 모델 목록을 반환합니다.

## 결론

이 장에서는 관리 인터페이스의 기본 개념과 사용 방법을 배웠습니다. 관리 인터페이스는 프로젝트 내 데이터를 효율적으로 관리하는 데 매우 유용한 도구입니다. 

다음 장에서는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 2: 커리큘럼 모델 (Curriculum Model)

이전 장에서는 [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)에 대해 알아보았습니다. 이제 우리는 커리큘럼 모델에 대해 설명할 것입니다. 이는 교육 커리큘럼을 정의하고 관리하기 위한 핵심 데이터 구조입니다. 초심자를 위한 설명을 통해 쉽게 따라올 수 있도록 하겠습니다.

## 커리큘럼 모델이란 무엇인가요?

커리큘럼 모델은 교육 콘텐츠를 체계적으로 관리하기 위한 데이터 구조입니다. 이를 통해 우리는 다양한 사용자에 맞춘 교육 경로를 계획하고 조정할 수 있습니다. 대표적인 예로 프로그래밍 학습 플랫폼에서 다양한 난이도별 코스를 제공하는 것을 들 수 있습니다.

### 커리큘럼 모델의 주요 개념

- **사용자 아이디**: 커리큘럼이 특정 사용자에게 할당되었음을 나타냅니다.
- **커리큘럼 타입**: 커리큘럼의 유형(예: 입문, 중급, 고급)을 정의합니다.
- **커리큘럼 이름**: 사용자가 이해하기 쉽고 식별할 수 있도록 지정합니다.
- **키워드**: 커리큘럼의 핵심 주제를 빠르게 파악할 수 있게 도와줍니다.

## 커리큘럼 모델 사용 방법

이제 간단한 커리큘럼 객체를 생성하고 사용하는 방법을 살펴보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        # 사용자 아이디 저장
        self.user_id = user_id
        # 커리큘럼 타입 저장
        self.cur_type = cur_type
        # 커리큘럼 이름 저장
        self.name = name
        # 키워드 저장
        self.keywords = keywords

# 커리큘럼 객체 생성
my_curriculum = CurriculumModel('user123', '입문', '파이썬 기본', ['프로그래밍', '파이썬'])
```

위 코드에서는 `CurriculumModel` 클래스를 정의하고 인스턴스를 생성했습니다. 각 인스턴스는 사용자 아이디, 커리큘럼 타입, 이름, 키워드를 포함합니다. 이와 같은 방식을 통해 다양한 커리큘럼을 효과적으로 관리할 수 있습니다.

## 내부 구현의 이해

커리큘럼 모델이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다. 이는 주로 객체가 생성되어, 데이터를 처리를 하는 과정을 보여줍니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant C as 커리큘럼 모델
    participant DB as 데이터베이스

    U->>C: 새로운 커리큘럼 생성 요청
    C->>DB: 커리큘럼 저장
    DB->>C: 저장 완료 응답
    C->>U: 생성 결과 전달
```

위 시퀀스 다이어그램은 사용자가 커리큘럼을 생성하면 그 요청이 데이터베이스에 저장되는 과정을 보여줍니다.

### 내부 코드 분석

커리큘럼 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        self.user_id = user_id
        self.cur_type = cur_type
        self.name = name
        self.keywords = keywords
    
    def save_to_db(self):
        # 데이터베이스에 커리큘럼 저장
        print(f"커리큘럼 '{self.name}'이 저장되었습니다.")
```

`CurriculumModel` 클래스에는 생성자 외에도 커리큘럼을 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 커리큘럼 모델이 무엇인지, 이를 사용하여 데이터를 어떻게 관리할 수 있는지를 배웠습니다. 이를 통해 다양한 교육 경로를 효율적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 알아보겠습니다. 함께 탐구해 봅시다!

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 3: 프로젝트 모델 (Project Model)`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 21:03:05,857 - INFO - Using OpenAI model: gpt-4o
2025-06-29 21:03:15,029 - INFO - RESPONSE: # Chapter 3: 프로젝트 모델 (Project Model)

이전 장에서 우리는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 배웠습니다. 이제 `SKN_ToyProject`에서 사용될 프로젝트 모델에 대해 알아보겠습니다. 이 장에서는 프로젝트 모델이 무엇인지, 그리고 어떻게 사용해야 하는지를 간단하게 설명하겠습니다.

## 프로젝트 모델이란 무엇인가요?

프로젝트 모델은 사용자의 프로젝트에 관한 정보를 체계적으로 저장하고 관리하기 위한 데이터 구조입니다. 이를 통해 프로젝트 이름, 시작 및 종료 날짜, 그리고 팀원 수 등 다양한 정보를 손쉽게 다룰 수 있습니다.

### 핵심 사례

상상해보세요, 팀과 함께 새로운 웹사이트를 만드는 프로젝트를 시작한다고 가정할 때, 이 프로젝트 모델은 다음과 같은 정보를 체계적으로 보관할 수 있어요.

- 프로젝트 이름: "웹사이트 개발"
- 시작 날짜: "2023-06-01"
- 종료 날짜: "2023-12-31"
- 팀원 수: 5명

이렇게 프로젝트 모델을 사용하면 전체 프로젝트 일정을 더욱 명확하게 관리할 수 있습니다.

## 프로젝트 모델 주요 개념

### 1. 프로젝트 이름
프로젝트의 가장 기본적인 식별자 역할을 합니다.

### 2. 시작 및 종료 날짜
프로젝트의 기간을 지정합니다. 이를 통해 일정을 체계적으로 관리할 수 있습니다.

### 3. 팀원 수
프로젝트에 참여하는 인원의 수를 의미합니다.

## 프로젝트 모델 사용 방법

`ProjectModel` 클래스를 사용하여 프로젝트 객체를 생성할 수 있습니다. 다음은 간단한 예제 코드입니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        # 프로젝트 이름 저장
        self.name = name
        # 시작 날짜 저장
        self.start_date = start_date
        # 종료 날짜 저장
        self.end_date = end_date
        # 팀원 수 저장
        self.team_members = team_members

# 프로젝트 객체 생성
my_project = ProjectModel("웹사이트 개발", "2023-06-01", "2023-12-31", 5)
```

위 코드에서는 `ProjectModel` 클래스를 정의하고, 해당 클래스의 인스턴스를 생성했습니다. 각 인스턴스는 프로젝트 이름, 시작 및 종료 날짜, 팀원 수를 저장합니다.

### 프로젝트 모델의 동작 과정

이제 프로젝트 모델의 작동 방식에 대해 간단한 시퀀스 다이어그램을 통해 알아보겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant P as 프로젝트 모델
    participant DB as 데이터베이스

    U->>P: 프로젝트 생성 요청
    P->>DB: 프로젝트 정보 저장
    DB->>P: 저장 완료 응답
    P->>U: 생성 성공 메시지 전달
```

사용자가 프로젝트를 생성하면, 프로젝트 모델은 데이터를 데이터베이스에 저장합니다. 이후, 저장이 완료되면 사용자는 성공 메시지를 받게 됩니다.

## 내부 코드 이해

프로젝트 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        self.name = name
        self.start_date = start_date
        self.end_date = end_date
        self.team_members = team_members
    
    def save_to_db(self):
        # 데이터베이스에 프로젝트 저장
        print(f"프로젝트 '{self.name}'이 저장되었습니다.")
```

`ProjectModel` 클래스에는 생성자 외에도 프로젝트를 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 프로젝트 모델이 무엇이며, 이를 어떻게 사용하는지를 배웠습니다. 프로젝트 모델은 사용자의 프로젝트 정보를 관리하기 위한 강력한 도구입니다. 다음 장에서는 [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)에 대해 알아보겠습니다. 기대해주세요!
2025-06-29 21:03:15,046 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN_ToyProject` about the concept: "커리큘럼 뷰 (Curriculum Views)". This is Chapter 4.

Concept Details (Note: Provided in Korean):
- Name: 커리큘럼 뷰 (Curriculum Views)
- Description:
커리큘럼 관련 데이터를 조회, 추가, 삭제하거나 맞춤화된 커리큘럼을 생성하는 API 엔드포인트를 제공합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)
2. [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)
3. [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)
4. [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)
5. [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)
6. [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)
7. [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)
8. [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)
9. [추천 시스템 (Recommendation System)](09_추천_시스템__recommendation_system_.md)
10. [기술 스택 관리 (Tech Stack Management)](10_기술_스택_관리__tech_stack_management_.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 관리 인터페이스 (Admin Interface)

`SKN_ToyProject`에 오신 것을 환영합니다! 이 장에서는 관리 인터페이스(Admin Interface)의 개념에 대해 알아보겠습니다. 관리 인터페이스는 데이터를 관리하고 시각화하는 데 매우 중요한 도구입니다. 관리자가 다양한 모델 객체를 효율적으로 다루는 방법을 배울 수 있습니다.

## 관리 인터페이스란 무엇인가요?

관리 인터페이스는 프로젝트 내에서 데이터를 쉽게 시각화하고 조작할 수 있도록 도와주는 도구입니다. 예를 들어, 웹사이트의 관리자 페이지를 생각해보세요. 사용자가 데이터를 입력하면, 관리자는 이 데이터가 어떻게 저장되고, 표현되는지를 이 페이지에서 직접 확인하고 변경할 수 있습니다. 바로 이런 역할을 하는 것이 관리 인터페이스입니다.

## 관리 인터페이스의 주요 개념

### 1. 데이터 시각화
관리 인터페이스는 데이터를 표 형태로 보여줍니다. 이는 사용자가 데이터를 한눈에 이해할 수 있게 도와줍니다.

### 2. 데이터 조작
사용자는 인터페이스를 통해 데이터를 직접 추가, 수정, 삭제할 수 있습니다. 이를 통해 데이터 관리가 훨씬 더 직관적이고 효율적이 됩니다.

## 관리 인터페이스 사용 방법

이제 간단한 예제로 관리 인터페이스를 사용하는 방법을 살펴보겠습니다.

```python
from admin_interface import Admin

# 관리자 인터페이스 초기화
admin = Admin()

# 데이터 추가
admin.add_model('새로운 모델 객체')

# 데이터 목록 보기
print(admin.list_models())  # ['새로운 모델 객체']
```

첫 줄에서 관리 인터페이스를 불러오고, 두 번째 줄에서 관리 인터페이스를 초기화합니다. 그 후, `add_model` 메소드를 통해 데이터를 추가하고, `list_models`를 통해 현재 데이터를 확인할 수 있습니다.

## 관리 인터페이스의 내부 구조

관리 인터페이스가 어떻게 내부적으로 동작하는지 간단히 살펴보겠습니다. 관리 인터페이스가 호출되면, 다음과 같은 단계를 거칩니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant AI as 관리 인터페이스
    participant DB as 데이터베이스

    U->>AI: 데이터 추가 요청
    AI->>DB: 데이터 저장 요청
    DB->>AI: 저장 완료 응답
    AI->>U: 처리 결과 전달
```

`사용자`가 관리 인터페이스를 통해 데이터를 추가하면, `관리 인터페이스`는 이를 `데이터베이스`에 저장하고 결과를 다시 사용자에게 전달합니다.

### 코드를 통한 내부 구조 이해

관리 인터페이스의 내부 구현을 간단한 코드로 살펴보겠습니다.

```python
class Admin:
    def __init__(self):
        self.models = []

    def add_model(self, model_name):
        # 모델 추가
        self.models.append(model_name)

    def list_models(self):
        # 모델 목록 반환
        return self.models
```

`Admin` 클래스는 모델 목록을 관리합니다. `add_model` 메소드는 모델을 추가하고, `list_models` 메소드는 현재 모델 목록을 반환합니다.

## 결론

이 장에서는 관리 인터페이스의 기본 개념과 사용 방법을 배웠습니다. 관리 인터페이스는 프로젝트 내 데이터를 효율적으로 관리하는 데 매우 유용한 도구입니다. 

다음 장에서는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 2: 커리큘럼 모델 (Curriculum Model)

이전 장에서는 [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)에 대해 알아보았습니다. 이제 우리는 커리큘럼 모델에 대해 설명할 것입니다. 이는 교육 커리큘럼을 정의하고 관리하기 위한 핵심 데이터 구조입니다. 초심자를 위한 설명을 통해 쉽게 따라올 수 있도록 하겠습니다.

## 커리큘럼 모델이란 무엇인가요?

커리큘럼 모델은 교육 콘텐츠를 체계적으로 관리하기 위한 데이터 구조입니다. 이를 통해 우리는 다양한 사용자에 맞춘 교육 경로를 계획하고 조정할 수 있습니다. 대표적인 예로 프로그래밍 학습 플랫폼에서 다양한 난이도별 코스를 제공하는 것을 들 수 있습니다.

### 커리큘럼 모델의 주요 개념

- **사용자 아이디**: 커리큘럼이 특정 사용자에게 할당되었음을 나타냅니다.
- **커리큘럼 타입**: 커리큘럼의 유형(예: 입문, 중급, 고급)을 정의합니다.
- **커리큘럼 이름**: 사용자가 이해하기 쉽고 식별할 수 있도록 지정합니다.
- **키워드**: 커리큘럼의 핵심 주제를 빠르게 파악할 수 있게 도와줍니다.

## 커리큘럼 모델 사용 방법

이제 간단한 커리큘럼 객체를 생성하고 사용하는 방법을 살펴보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        # 사용자 아이디 저장
        self.user_id = user_id
        # 커리큘럼 타입 저장
        self.cur_type = cur_type
        # 커리큘럼 이름 저장
        self.name = name
        # 키워드 저장
        self.keywords = keywords

# 커리큘럼 객체 생성
my_curriculum = CurriculumModel('user123', '입문', '파이썬 기본', ['프로그래밍', '파이썬'])
```

위 코드에서는 `CurriculumModel` 클래스를 정의하고 인스턴스를 생성했습니다. 각 인스턴스는 사용자 아이디, 커리큘럼 타입, 이름, 키워드를 포함합니다. 이와 같은 방식을 통해 다양한 커리큘럼을 효과적으로 관리할 수 있습니다.

## 내부 구현의 이해

커리큘럼 모델이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다. 이는 주로 객체가 생성되어, 데이터를 처리를 하는 과정을 보여줍니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant C as 커리큘럼 모델
    participant DB as 데이터베이스

    U->>C: 새로운 커리큘럼 생성 요청
    C->>DB: 커리큘럼 저장
    DB->>C: 저장 완료 응답
    C->>U: 생성 결과 전달
```

위 시퀀스 다이어그램은 사용자가 커리큘럼을 생성하면 그 요청이 데이터베이스에 저장되는 과정을 보여줍니다.

### 내부 코드 분석

커리큘럼 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        self.user_id = user_id
        self.cur_type = cur_type
        self.name = name
        self.keywords = keywords
    
    def save_to_db(self):
        # 데이터베이스에 커리큘럼 저장
        print(f"커리큘럼 '{self.name}'이 저장되었습니다.")
```

`CurriculumModel` 클래스에는 생성자 외에도 커리큘럼을 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 커리큘럼 모델이 무엇인지, 이를 사용하여 데이터를 어떻게 관리할 수 있는지를 배웠습니다. 이를 통해 다양한 교육 경로를 효율적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 알아보겠습니다. 함께 탐구해 봅시다!
---
# Chapter 3: 프로젝트 모델 (Project Model)

이전 장에서 우리는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 배웠습니다. 이제 `SKN_ToyProject`에서 사용될 프로젝트 모델에 대해 알아보겠습니다. 이 장에서는 프로젝트 모델이 무엇인지, 그리고 어떻게 사용해야 하는지를 간단하게 설명하겠습니다.

## 프로젝트 모델이란 무엇인가요?

프로젝트 모델은 사용자의 프로젝트에 관한 정보를 체계적으로 저장하고 관리하기 위한 데이터 구조입니다. 이를 통해 프로젝트 이름, 시작 및 종료 날짜, 그리고 팀원 수 등 다양한 정보를 손쉽게 다룰 수 있습니다.

### 핵심 사례

상상해보세요, 팀과 함께 새로운 웹사이트를 만드는 프로젝트를 시작한다고 가정할 때, 이 프로젝트 모델은 다음과 같은 정보를 체계적으로 보관할 수 있어요.

- 프로젝트 이름: "웹사이트 개발"
- 시작 날짜: "2023-06-01"
- 종료 날짜: "2023-12-31"
- 팀원 수: 5명

이렇게 프로젝트 모델을 사용하면 전체 프로젝트 일정을 더욱 명확하게 관리할 수 있습니다.

## 프로젝트 모델 주요 개념

### 1. 프로젝트 이름
프로젝트의 가장 기본적인 식별자 역할을 합니다.

### 2. 시작 및 종료 날짜
프로젝트의 기간을 지정합니다. 이를 통해 일정을 체계적으로 관리할 수 있습니다.

### 3. 팀원 수
프로젝트에 참여하는 인원의 수를 의미합니다.

## 프로젝트 모델 사용 방법

`ProjectModel` 클래스를 사용하여 프로젝트 객체를 생성할 수 있습니다. 다음은 간단한 예제 코드입니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        # 프로젝트 이름 저장
        self.name = name
        # 시작 날짜 저장
        self.start_date = start_date
        # 종료 날짜 저장
        self.end_date = end_date
        # 팀원 수 저장
        self.team_members = team_members

# 프로젝트 객체 생성
my_project = ProjectModel("웹사이트 개발", "2023-06-01", "2023-12-31", 5)
```

위 코드에서는 `ProjectModel` 클래스를 정의하고, 해당 클래스의 인스턴스를 생성했습니다. 각 인스턴스는 프로젝트 이름, 시작 및 종료 날짜, 팀원 수를 저장합니다.

### 프로젝트 모델의 동작 과정

이제 프로젝트 모델의 작동 방식에 대해 간단한 시퀀스 다이어그램을 통해 알아보겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant P as 프로젝트 모델
    participant DB as 데이터베이스

    U->>P: 프로젝트 생성 요청
    P->>DB: 프로젝트 정보 저장
    DB->>P: 저장 완료 응답
    P->>U: 생성 성공 메시지 전달
```

사용자가 프로젝트를 생성하면, 프로젝트 모델은 데이터를 데이터베이스에 저장합니다. 이후, 저장이 완료되면 사용자는 성공 메시지를 받게 됩니다.

## 내부 코드 이해

프로젝트 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        self.name = name
        self.start_date = start_date
        self.end_date = end_date
        self.team_members = team_members
    
    def save_to_db(self):
        # 데이터베이스에 프로젝트 저장
        print(f"프로젝트 '{self.name}'이 저장되었습니다.")
```

`ProjectModel` 클래스에는 생성자 외에도 프로젝트를 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 프로젝트 모델이 무엇이며, 이를 어떻게 사용하는지를 배웠습니다. 프로젝트 모델은 사용자의 프로젝트 정보를 관리하기 위한 강력한 도구입니다. 다음 장에서는 [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)에 대해 알아보겠습니다. 기대해주세요!

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 4: 커리큘럼 뷰 (Curriculum Views)`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 21:03:15,229 - INFO - Using OpenAI model: gpt-4o
2025-06-29 21:03:30,441 - INFO - RESPONSE: # Chapter 4: 커리큘럼 뷰 (Curriculum Views)

이전 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 배워봤습니다. 이번 장에서는 `SKN_ToyProject`에서 커리큘럼 데이터를 어떻게 조회하고, 추가하고, 삭제하며, 맞춤형 커리큘럼을 생성하는지에 대해 알아보겠습니다. 이는 사용자가 다양한 교육 콘텐츠를 손쉽게 관리할 수 있도록 돕는 기능입니다. 초보자도 쉽게 따라갈 수 있도록 최대한 간단하게 설명하겠습니다.

---

## 커리큘럼 뷰란 무엇인가요?

커리큘럼 뷰는 프로젝트 내 여러 커리큘럼과 관련된 작업을 수행할 수 있는 인터페이스를 제공합니다. 예를 들어, 교육 플랫폼에서 새로운 강좌를 추가하거나 기존 강좌를 삭제하는 경우를 생각할 수 있습니다. 이를 통해 사용자들은 자신이 원하는 대로 커리큘럼을 조정할 수 있습니다.

### 커리큘럼 뷰가 해결하는 문제

- **데이터 조회**: 사용자에게 필요한 커리큘럼 정보를 손쉽게 조회할 수 있습니다.
- **데이터 추가**: 새로운 커리큘럼을 추가하여 교육 콘텐츠를 확장할 수 있습니다.
- **데이터 삭제**: 불필요한 커리큘럼을 삭제하여 관리 효율성을 높일 수 있습니다.
- **맞춤형 커리큘럼 생성**: 사용자에게 맞춤형 학습 경로를 제공합니다.

## 커리큘럼 뷰의 주요 기능

### 1. 커리큘럼 조회

아래 코드는 커리큘럼 목록을 조회하는 간단한 예제입니다.

```python
def get_curriculums():
    # 커리큘럼 목록 조회
    return ["커리큘럼1", "커리큘럼2", "커리큘럼3"]

# 커리큘럼 목록 출력
print(get_curriculums())
```

이 코드는 `get_curriculums` 함수를 통해 현재 저장된 커리큘럼들을 출력합니다.

### 2. 커리큘럼 추가

커리큘럼을 추가하는 방법은 다음과 같습니다.

```python
def add_curriculum(name):
    # 새로운 커리큘럼 추가
    print(f"{name} 커리큘럼이 추가되었습니다.")

# 새 커리큘럼 추가
add_curriculum("파이썬 기초")
```

여기서 `add_curriculum` 함수는 새로운 커리큘럼 이름을 받아서 추가 작업을 수행합니다.

### 3. 커리큘럼 삭제

커리큘럼 삭제도 매우 간단하게 이루어집니다.

```python
def delete_curriculum(name):
    # 커리큘럼 삭제
    print(f"{name} 커리큘럼이 삭제되었습니다.")

# 기존 커리큘럼 삭제
delete_curriculum("커리큘럼1")
```

`delete_curriculum` 함수는 지정된 이름의 커리큘럼을 삭제합니다.

### 4. 맞춤형 커리큘럼 생성

사용자 맞춤 커리큘럼을 생성하여 유저 경험을 향상시킬 수 있습니다.

```python
def create_custom_curriculum(user_id, preferences):
    # 사용자 맞춤 커리큘럼 생성
    print(f"사용자 {user_id}를 위한 맞춤형 커리큘럼이 생성되었습니다.")

# 맞춤형 커리큘럼 생성
create_custom_curriculum("user123", ["프로그래밍", "데이터 분석"])
```

이 코드는 사용자 ID와 선호 분야들을 이용해 맞춤형 커리큘럼을 생성합니다.

## 내부 구현 이해

이제 내부적으로 커리큘럼 뷰가 어떻게 동작하는지 간단하게 설명하겠습니다. 각 기능이 어떻게 상호작용하는지 보기 위해 시퀀스 다이어그램을 사용합니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant CV as 커리큘럼 뷰
    participant DB as 데이터베이스

    U->>CV: 커리큘럼 조회 요청
    CV->>DB: 조회 쿼리 전송
    DB->>CV: 응답 반환
    CV->>U: 커리큘럼 목록 전달
```

여기서 사용자가 커리큘럼 뷰로 요청을 하면, 커리큘럼 뷰는 데이터베이스에 쿼리를 날리고, 그 결과를 사용자에게 반환합니다.

### 내부 코드 구현

커리큘럼 뷰의 데이터 흐름은 아래와 같이 구성됩니다.

```python
class CurriculumView:
    def __init__(self):
        self.curriculums = []

    def add(self, name):
        self.curriculums.append(name)
        print(f"커리큘럼 '{name}'이 추가되었습니다.")

    def remove(self, name):
        if name in self.curriculums:
            self.curriculums.remove(name)
            print(f"커리큘럼 '{name}'이 삭제되었습니다.")
        else:
            print("커리큘럼이 존재하지 않습니다.")
```

위 `CurriculumView` 클래스는 커리큘럼 목록을 관리하기 위한 기본적인 기능을 제공합니다. `add`와 `remove` 메소드를 통해 커리큘럼을 추가하고 삭제할 수 있습니다.

---

## 결론

이번 장에서는 커리큘럼 뷰를 통해 어떻게 데이터를 조회하고, 추가하고, 삭제하며 맞춤형 커리큘럼을 생성할 수 있는지를 배웠습니다. 이를 통해 사용자 맞춤형 교육 콘텐츠를 효과적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)에 대해 설명하겠습니다. 기대해주세요!
2025-06-29 21:03:30,456 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN_ToyProject` about the concept: "프로젝트 뷰 (Project Views)". This is Chapter 5.

Concept Details (Note: Provided in Korean):
- Name: 프로젝트 뷰 (Project Views)
- Description:
프로젝트 관련 데이터를 조회하고, 새로운 프로젝트를 추가하거나 수정하는 API 엔드포인트를 제공합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)
2. [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)
3. [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)
4. [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)
5. [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)
6. [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)
7. [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)
8. [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)
9. [추천 시스템 (Recommendation System)](09_추천_시스템__recommendation_system_.md)
10. [기술 스택 관리 (Tech Stack Management)](10_기술_스택_관리__tech_stack_management_.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 관리 인터페이스 (Admin Interface)

`SKN_ToyProject`에 오신 것을 환영합니다! 이 장에서는 관리 인터페이스(Admin Interface)의 개념에 대해 알아보겠습니다. 관리 인터페이스는 데이터를 관리하고 시각화하는 데 매우 중요한 도구입니다. 관리자가 다양한 모델 객체를 효율적으로 다루는 방법을 배울 수 있습니다.

## 관리 인터페이스란 무엇인가요?

관리 인터페이스는 프로젝트 내에서 데이터를 쉽게 시각화하고 조작할 수 있도록 도와주는 도구입니다. 예를 들어, 웹사이트의 관리자 페이지를 생각해보세요. 사용자가 데이터를 입력하면, 관리자는 이 데이터가 어떻게 저장되고, 표현되는지를 이 페이지에서 직접 확인하고 변경할 수 있습니다. 바로 이런 역할을 하는 것이 관리 인터페이스입니다.

## 관리 인터페이스의 주요 개념

### 1. 데이터 시각화
관리 인터페이스는 데이터를 표 형태로 보여줍니다. 이는 사용자가 데이터를 한눈에 이해할 수 있게 도와줍니다.

### 2. 데이터 조작
사용자는 인터페이스를 통해 데이터를 직접 추가, 수정, 삭제할 수 있습니다. 이를 통해 데이터 관리가 훨씬 더 직관적이고 효율적이 됩니다.

## 관리 인터페이스 사용 방법

이제 간단한 예제로 관리 인터페이스를 사용하는 방법을 살펴보겠습니다.

```python
from admin_interface import Admin

# 관리자 인터페이스 초기화
admin = Admin()

# 데이터 추가
admin.add_model('새로운 모델 객체')

# 데이터 목록 보기
print(admin.list_models())  # ['새로운 모델 객체']
```

첫 줄에서 관리 인터페이스를 불러오고, 두 번째 줄에서 관리 인터페이스를 초기화합니다. 그 후, `add_model` 메소드를 통해 데이터를 추가하고, `list_models`를 통해 현재 데이터를 확인할 수 있습니다.

## 관리 인터페이스의 내부 구조

관리 인터페이스가 어떻게 내부적으로 동작하는지 간단히 살펴보겠습니다. 관리 인터페이스가 호출되면, 다음과 같은 단계를 거칩니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant AI as 관리 인터페이스
    participant DB as 데이터베이스

    U->>AI: 데이터 추가 요청
    AI->>DB: 데이터 저장 요청
    DB->>AI: 저장 완료 응답
    AI->>U: 처리 결과 전달
```

`사용자`가 관리 인터페이스를 통해 데이터를 추가하면, `관리 인터페이스`는 이를 `데이터베이스`에 저장하고 결과를 다시 사용자에게 전달합니다.

### 코드를 통한 내부 구조 이해

관리 인터페이스의 내부 구현을 간단한 코드로 살펴보겠습니다.

```python
class Admin:
    def __init__(self):
        self.models = []

    def add_model(self, model_name):
        # 모델 추가
        self.models.append(model_name)

    def list_models(self):
        # 모델 목록 반환
        return self.models
```

`Admin` 클래스는 모델 목록을 관리합니다. `add_model` 메소드는 모델을 추가하고, `list_models` 메소드는 현재 모델 목록을 반환합니다.

## 결론

이 장에서는 관리 인터페이스의 기본 개념과 사용 방법을 배웠습니다. 관리 인터페이스는 프로젝트 내 데이터를 효율적으로 관리하는 데 매우 유용한 도구입니다. 

다음 장에서는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 2: 커리큘럼 모델 (Curriculum Model)

이전 장에서는 [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)에 대해 알아보았습니다. 이제 우리는 커리큘럼 모델에 대해 설명할 것입니다. 이는 교육 커리큘럼을 정의하고 관리하기 위한 핵심 데이터 구조입니다. 초심자를 위한 설명을 통해 쉽게 따라올 수 있도록 하겠습니다.

## 커리큘럼 모델이란 무엇인가요?

커리큘럼 모델은 교육 콘텐츠를 체계적으로 관리하기 위한 데이터 구조입니다. 이를 통해 우리는 다양한 사용자에 맞춘 교육 경로를 계획하고 조정할 수 있습니다. 대표적인 예로 프로그래밍 학습 플랫폼에서 다양한 난이도별 코스를 제공하는 것을 들 수 있습니다.

### 커리큘럼 모델의 주요 개념

- **사용자 아이디**: 커리큘럼이 특정 사용자에게 할당되었음을 나타냅니다.
- **커리큘럼 타입**: 커리큘럼의 유형(예: 입문, 중급, 고급)을 정의합니다.
- **커리큘럼 이름**: 사용자가 이해하기 쉽고 식별할 수 있도록 지정합니다.
- **키워드**: 커리큘럼의 핵심 주제를 빠르게 파악할 수 있게 도와줍니다.

## 커리큘럼 모델 사용 방법

이제 간단한 커리큘럼 객체를 생성하고 사용하는 방법을 살펴보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        # 사용자 아이디 저장
        self.user_id = user_id
        # 커리큘럼 타입 저장
        self.cur_type = cur_type
        # 커리큘럼 이름 저장
        self.name = name
        # 키워드 저장
        self.keywords = keywords

# 커리큘럼 객체 생성
my_curriculum = CurriculumModel('user123', '입문', '파이썬 기본', ['프로그래밍', '파이썬'])
```

위 코드에서는 `CurriculumModel` 클래스를 정의하고 인스턴스를 생성했습니다. 각 인스턴스는 사용자 아이디, 커리큘럼 타입, 이름, 키워드를 포함합니다. 이와 같은 방식을 통해 다양한 커리큘럼을 효과적으로 관리할 수 있습니다.

## 내부 구현의 이해

커리큘럼 모델이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다. 이는 주로 객체가 생성되어, 데이터를 처리를 하는 과정을 보여줍니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant C as 커리큘럼 모델
    participant DB as 데이터베이스

    U->>C: 새로운 커리큘럼 생성 요청
    C->>DB: 커리큘럼 저장
    DB->>C: 저장 완료 응답
    C->>U: 생성 결과 전달
```

위 시퀀스 다이어그램은 사용자가 커리큘럼을 생성하면 그 요청이 데이터베이스에 저장되는 과정을 보여줍니다.

### 내부 코드 분석

커리큘럼 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        self.user_id = user_id
        self.cur_type = cur_type
        self.name = name
        self.keywords = keywords
    
    def save_to_db(self):
        # 데이터베이스에 커리큘럼 저장
        print(f"커리큘럼 '{self.name}'이 저장되었습니다.")
```

`CurriculumModel` 클래스에는 생성자 외에도 커리큘럼을 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 커리큘럼 모델이 무엇인지, 이를 사용하여 데이터를 어떻게 관리할 수 있는지를 배웠습니다. 이를 통해 다양한 교육 경로를 효율적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 알아보겠습니다. 함께 탐구해 봅시다!
---
# Chapter 3: 프로젝트 모델 (Project Model)

이전 장에서 우리는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 배웠습니다. 이제 `SKN_ToyProject`에서 사용될 프로젝트 모델에 대해 알아보겠습니다. 이 장에서는 프로젝트 모델이 무엇인지, 그리고 어떻게 사용해야 하는지를 간단하게 설명하겠습니다.

## 프로젝트 모델이란 무엇인가요?

프로젝트 모델은 사용자의 프로젝트에 관한 정보를 체계적으로 저장하고 관리하기 위한 데이터 구조입니다. 이를 통해 프로젝트 이름, 시작 및 종료 날짜, 그리고 팀원 수 등 다양한 정보를 손쉽게 다룰 수 있습니다.

### 핵심 사례

상상해보세요, 팀과 함께 새로운 웹사이트를 만드는 프로젝트를 시작한다고 가정할 때, 이 프로젝트 모델은 다음과 같은 정보를 체계적으로 보관할 수 있어요.

- 프로젝트 이름: "웹사이트 개발"
- 시작 날짜: "2023-06-01"
- 종료 날짜: "2023-12-31"
- 팀원 수: 5명

이렇게 프로젝트 모델을 사용하면 전체 프로젝트 일정을 더욱 명확하게 관리할 수 있습니다.

## 프로젝트 모델 주요 개념

### 1. 프로젝트 이름
프로젝트의 가장 기본적인 식별자 역할을 합니다.

### 2. 시작 및 종료 날짜
프로젝트의 기간을 지정합니다. 이를 통해 일정을 체계적으로 관리할 수 있습니다.

### 3. 팀원 수
프로젝트에 참여하는 인원의 수를 의미합니다.

## 프로젝트 모델 사용 방법

`ProjectModel` 클래스를 사용하여 프로젝트 객체를 생성할 수 있습니다. 다음은 간단한 예제 코드입니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        # 프로젝트 이름 저장
        self.name = name
        # 시작 날짜 저장
        self.start_date = start_date
        # 종료 날짜 저장
        self.end_date = end_date
        # 팀원 수 저장
        self.team_members = team_members

# 프로젝트 객체 생성
my_project = ProjectModel("웹사이트 개발", "2023-06-01", "2023-12-31", 5)
```

위 코드에서는 `ProjectModel` 클래스를 정의하고, 해당 클래스의 인스턴스를 생성했습니다. 각 인스턴스는 프로젝트 이름, 시작 및 종료 날짜, 팀원 수를 저장합니다.

### 프로젝트 모델의 동작 과정

이제 프로젝트 모델의 작동 방식에 대해 간단한 시퀀스 다이어그램을 통해 알아보겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant P as 프로젝트 모델
    participant DB as 데이터베이스

    U->>P: 프로젝트 생성 요청
    P->>DB: 프로젝트 정보 저장
    DB->>P: 저장 완료 응답
    P->>U: 생성 성공 메시지 전달
```

사용자가 프로젝트를 생성하면, 프로젝트 모델은 데이터를 데이터베이스에 저장합니다. 이후, 저장이 완료되면 사용자는 성공 메시지를 받게 됩니다.

## 내부 코드 이해

프로젝트 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        self.name = name
        self.start_date = start_date
        self.end_date = end_date
        self.team_members = team_members
    
    def save_to_db(self):
        # 데이터베이스에 프로젝트 저장
        print(f"프로젝트 '{self.name}'이 저장되었습니다.")
```

`ProjectModel` 클래스에는 생성자 외에도 프로젝트를 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 프로젝트 모델이 무엇이며, 이를 어떻게 사용하는지를 배웠습니다. 프로젝트 모델은 사용자의 프로젝트 정보를 관리하기 위한 강력한 도구입니다. 다음 장에서는 [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 4: 커리큘럼 뷰 (Curriculum Views)

이전 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 배워봤습니다. 이번 장에서는 `SKN_ToyProject`에서 커리큘럼 데이터를 어떻게 조회하고, 추가하고, 삭제하며, 맞춤형 커리큘럼을 생성하는지에 대해 알아보겠습니다. 이는 사용자가 다양한 교육 콘텐츠를 손쉽게 관리할 수 있도록 돕는 기능입니다. 초보자도 쉽게 따라갈 수 있도록 최대한 간단하게 설명하겠습니다.

---

## 커리큘럼 뷰란 무엇인가요?

커리큘럼 뷰는 프로젝트 내 여러 커리큘럼과 관련된 작업을 수행할 수 있는 인터페이스를 제공합니다. 예를 들어, 교육 플랫폼에서 새로운 강좌를 추가하거나 기존 강좌를 삭제하는 경우를 생각할 수 있습니다. 이를 통해 사용자들은 자신이 원하는 대로 커리큘럼을 조정할 수 있습니다.

### 커리큘럼 뷰가 해결하는 문제

- **데이터 조회**: 사용자에게 필요한 커리큘럼 정보를 손쉽게 조회할 수 있습니다.
- **데이터 추가**: 새로운 커리큘럼을 추가하여 교육 콘텐츠를 확장할 수 있습니다.
- **데이터 삭제**: 불필요한 커리큘럼을 삭제하여 관리 효율성을 높일 수 있습니다.
- **맞춤형 커리큘럼 생성**: 사용자에게 맞춤형 학습 경로를 제공합니다.

## 커리큘럼 뷰의 주요 기능

### 1. 커리큘럼 조회

아래 코드는 커리큘럼 목록을 조회하는 간단한 예제입니다.

```python
def get_curriculums():
    # 커리큘럼 목록 조회
    return ["커리큘럼1", "커리큘럼2", "커리큘럼3"]

# 커리큘럼 목록 출력
print(get_curriculums())
```

이 코드는 `get_curriculums` 함수를 통해 현재 저장된 커리큘럼들을 출력합니다.

### 2. 커리큘럼 추가

커리큘럼을 추가하는 방법은 다음과 같습니다.

```python
def add_curriculum(name):
    # 새로운 커리큘럼 추가
    print(f"{name} 커리큘럼이 추가되었습니다.")

# 새 커리큘럼 추가
add_curriculum("파이썬 기초")
```

여기서 `add_curriculum` 함수는 새로운 커리큘럼 이름을 받아서 추가 작업을 수행합니다.

### 3. 커리큘럼 삭제

커리큘럼 삭제도 매우 간단하게 이루어집니다.

```python
def delete_curriculum(name):
    # 커리큘럼 삭제
    print(f"{name} 커리큘럼이 삭제되었습니다.")

# 기존 커리큘럼 삭제
delete_curriculum("커리큘럼1")
```

`delete_curriculum` 함수는 지정된 이름의 커리큘럼을 삭제합니다.

### 4. 맞춤형 커리큘럼 생성

사용자 맞춤 커리큘럼을 생성하여 유저 경험을 향상시킬 수 있습니다.

```python
def create_custom_curriculum(user_id, preferences):
    # 사용자 맞춤 커리큘럼 생성
    print(f"사용자 {user_id}를 위한 맞춤형 커리큘럼이 생성되었습니다.")

# 맞춤형 커리큘럼 생성
create_custom_curriculum("user123", ["프로그래밍", "데이터 분석"])
```

이 코드는 사용자 ID와 선호 분야들을 이용해 맞춤형 커리큘럼을 생성합니다.

## 내부 구현 이해

이제 내부적으로 커리큘럼 뷰가 어떻게 동작하는지 간단하게 설명하겠습니다. 각 기능이 어떻게 상호작용하는지 보기 위해 시퀀스 다이어그램을 사용합니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant CV as 커리큘럼 뷰
    participant DB as 데이터베이스

    U->>CV: 커리큘럼 조회 요청
    CV->>DB: 조회 쿼리 전송
    DB->>CV: 응답 반환
    CV->>U: 커리큘럼 목록 전달
```

여기서 사용자가 커리큘럼 뷰로 요청을 하면, 커리큘럼 뷰는 데이터베이스에 쿼리를 날리고, 그 결과를 사용자에게 반환합니다.

### 내부 코드 구현

커리큘럼 뷰의 데이터 흐름은 아래와 같이 구성됩니다.

```python
class CurriculumView:
    def __init__(self):
        self.curriculums = []

    def add(self, name):
        self.curriculums.append(name)
        print(f"커리큘럼 '{name}'이 추가되었습니다.")

    def remove(self, name):
        if name in self.curriculums:
            self.curriculums.remove(name)
            print(f"커리큘럼 '{name}'이 삭제되었습니다.")
        else:
            print("커리큘럼이 존재하지 않습니다.")
```

위 `CurriculumView` 클래스는 커리큘럼 목록을 관리하기 위한 기본적인 기능을 제공합니다. `add`와 `remove` 메소드를 통해 커리큘럼을 추가하고 삭제할 수 있습니다.

---

## 결론

이번 장에서는 커리큘럼 뷰를 통해 어떻게 데이터를 조회하고, 추가하고, 삭제하며 맞춤형 커리큘럼을 생성할 수 있는지를 배웠습니다. 이를 통해 사용자 맞춤형 교육 콘텐츠를 효과적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)에 대해 설명하겠습니다. 기대해주세요!

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 5: 프로젝트 뷰 (Project Views)`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 21:03:30,643 - INFO - Using OpenAI model: gpt-4o
2025-06-29 21:03:43,095 - INFO - RESPONSE: # Chapter 5: 프로젝트 뷰 (Project Views)

이전 장에서는 [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)에 대해 배웠습니다. 이번 장에서는 `SKN_ToyProject`에서 `프로젝트 뷰 (Project Views)`에 대해 알아보도록 하겠습니다. 프로젝트 뷰는 프로젝트와 관련된 데이터를 조회하고, 새로운 프로젝트를 추가하거나, 기존 프로젝트를 수정하는 API 엔드포인트를 제공합니다. 이 장에서는 이러한 기능들을 어떻게 활용할 수 있는지를 살펴보겠습니다.

## 프로젝트 뷰란 무엇인가요?

프로젝트 뷰는 사용자가 프로젝트와 관련된 데이터를 효율적으로 관리할 수 있게 해주는 도구입니다. 예를 들어, 팀 프로젝트를 진행하는 동안 관련 정보를 효율적으로 조회하고 필요에 따라 수정할 수 있습니다.

### 프로젝트 뷰의 주요 기능

- **프로젝트 조회**: 기존 프로젝트의 정보를 확인할 수 있습니다.
- **프로젝트 추가**: 새로운 프로젝트를 데이터베이스에 저장할 수 있습니다.
- **프로젝트 수정**: 등록된 프로젝트 정보를 업데이트할 수 있습니다.

## 프로젝트 뷰 사용 방법

이제 간단한 예제를 통해 프로젝트 뷰를 어떻게 사용할 수 있는지 알아보겠습니다.

### 1. 프로젝트 조회하기

프로젝트 데이터를 조회할 수 있는 간단한 코드를 작성해 봅시다.

```python
def get_projects():
    # 프로젝트 목록 조회
    return ["프로젝트 A", "프로젝트 B", "프로젝트 C"]

# 프로젝트 목록 출력
print(get_projects())
```

위 코드에서는 `get_projects` 함수를 통해 등록된 모든 프로젝트를 조회할 수 있습니다. 이 함수는 프로젝트 이름의 리스트를 반환합니다.

### 2. 새로운 프로젝트 추가하기

다음은 새로운 프로젝트를 추가하는 방법입니다.

```python
def add_project(name):
    # 새로운 프로젝트 추가
    print(f"{name} 프로젝트가 추가되었습니다.")

# 프로젝트 추가
add_project("프로젝트 D")
```

이 코드에서 `add_project` 함수는 프로젝트 이름을 받아 새로운 프로젝트를 추가하는 기능을 수행합니다.

### 3. 기존 프로젝트 수정하기

다음으로 프로젝트 정보를 수정하는 방법을 살펴보겠습니다.

```python
def update_project(old_name, new_name):
    # 프로젝트 이름 수정
    print(f"{old_name}가 {new_name}로 변경되었습니다.")

# 프로젝트 수정
update_project("프로젝트 A", "프로젝트 Z")
```

위 코드에서는 `update_project` 함수를 사용하여 기존 프로젝트의 이름을 업데이트할 수 있습니다.

## 내부 구현 이해

프로젝트 뷰의 내부에서 발생하는 상호작용을 간단하게 설명하겠습니다. 프로젝트의 생성, 조회, 수정 과정을 시퀀스 다이어그램을 통해 이해해 봅시다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant PV as 프로젝트 뷰
    participant DB as 데이터베이스

    U->>PV: 프로젝트 조회 요청
    PV->>DB: 조회 쿼리 전송
    DB->>PV: 응답 반환
    PV->>U: 프로젝트 목록 전달

    U->>PV: 프로젝트 추가 요청
    PV->>DB: 새로운 프로젝트 저장
    DB->>PV: 저장 성공 메시지 반환
    PV->>U: 프로젝트 추가 성공 메시지 전달

    U->>PV: 프로젝트 수정 요청
    PV->>DB: 프로젝트 업데이트
    DB->>PV: 업데이트 성공 메시지 반환
    PV->>U: 프로젝트 수정 성공 메시지 전달
```

각 기능은 데이터베이스와 상호작용하여 데이터를 효율적으로 처리합니다.

### 내부 코드 구현

이제 프로젝트 뷰의 내부 구현에 대한 코드를 살펴보겠습니다.

```python
class ProjectView:
    def __init__(self):
        self.projects = []

    def add(self, name):
        self.projects.append(name)
        print(f"프로젝트 '{name}'이 추가되었습니다.")

    def update(self, old_name, new_name):
        if old_name in self.projects:
            self.projects[self.projects.index(old_name)] = new_name
            print(f"프로젝트 '{old_name}'이 '{new_name}'로 변경되었습니다.")
        else:
            print("프로젝트가 존재하지 않습니다.")
```

`ProjectView` 클래스는 프로젝트 목록을 관리하며, `add`와 `update` 메소드를 통해 프로젝트를 추가하고 수정할 수 있는 기능을 제공합니다.

## 결론

이번 장에서는 프로젝트 뷰가 제공하는 기본적인 기능을 이용해 프로젝트 데이터를 조회하고 추가 및 수정하는 방법을 배웠습니다. 이를 통해 사용자는 프로젝트와 관련된 데이터를 효율적으로 관리할 수 있습니다. 다음 장에서는 [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)에 대해 배워보겠습니다. 함께 탐구해봅시다!
2025-06-29 21:03:43,110 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN_ToyProject` about the concept: "사용자 및 커리큘럼 관계 (User and Curriculum Relationship)". This is Chapter 6.

Concept Details (Note: Provided in Korean):
- Name: 사용자 및 커리큘럼 관계 (User and Curriculum Relationship)
- Description:
사용자와 커리큘럼 간의 관계를 관리하여, 사용자가 어떤 커리큘럼을 완료했는지 기록합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)
2. [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)
3. [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)
4. [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)
5. [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)
6. [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)
7. [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)
8. [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)
9. [추천 시스템 (Recommendation System)](09_추천_시스템__recommendation_system_.md)
10. [기술 스택 관리 (Tech Stack Management)](10_기술_스택_관리__tech_stack_management_.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 관리 인터페이스 (Admin Interface)

`SKN_ToyProject`에 오신 것을 환영합니다! 이 장에서는 관리 인터페이스(Admin Interface)의 개념에 대해 알아보겠습니다. 관리 인터페이스는 데이터를 관리하고 시각화하는 데 매우 중요한 도구입니다. 관리자가 다양한 모델 객체를 효율적으로 다루는 방법을 배울 수 있습니다.

## 관리 인터페이스란 무엇인가요?

관리 인터페이스는 프로젝트 내에서 데이터를 쉽게 시각화하고 조작할 수 있도록 도와주는 도구입니다. 예를 들어, 웹사이트의 관리자 페이지를 생각해보세요. 사용자가 데이터를 입력하면, 관리자는 이 데이터가 어떻게 저장되고, 표현되는지를 이 페이지에서 직접 확인하고 변경할 수 있습니다. 바로 이런 역할을 하는 것이 관리 인터페이스입니다.

## 관리 인터페이스의 주요 개념

### 1. 데이터 시각화
관리 인터페이스는 데이터를 표 형태로 보여줍니다. 이는 사용자가 데이터를 한눈에 이해할 수 있게 도와줍니다.

### 2. 데이터 조작
사용자는 인터페이스를 통해 데이터를 직접 추가, 수정, 삭제할 수 있습니다. 이를 통해 데이터 관리가 훨씬 더 직관적이고 효율적이 됩니다.

## 관리 인터페이스 사용 방법

이제 간단한 예제로 관리 인터페이스를 사용하는 방법을 살펴보겠습니다.

```python
from admin_interface import Admin

# 관리자 인터페이스 초기화
admin = Admin()

# 데이터 추가
admin.add_model('새로운 모델 객체')

# 데이터 목록 보기
print(admin.list_models())  # ['새로운 모델 객체']
```

첫 줄에서 관리 인터페이스를 불러오고, 두 번째 줄에서 관리 인터페이스를 초기화합니다. 그 후, `add_model` 메소드를 통해 데이터를 추가하고, `list_models`를 통해 현재 데이터를 확인할 수 있습니다.

## 관리 인터페이스의 내부 구조

관리 인터페이스가 어떻게 내부적으로 동작하는지 간단히 살펴보겠습니다. 관리 인터페이스가 호출되면, 다음과 같은 단계를 거칩니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant AI as 관리 인터페이스
    participant DB as 데이터베이스

    U->>AI: 데이터 추가 요청
    AI->>DB: 데이터 저장 요청
    DB->>AI: 저장 완료 응답
    AI->>U: 처리 결과 전달
```

`사용자`가 관리 인터페이스를 통해 데이터를 추가하면, `관리 인터페이스`는 이를 `데이터베이스`에 저장하고 결과를 다시 사용자에게 전달합니다.

### 코드를 통한 내부 구조 이해

관리 인터페이스의 내부 구현을 간단한 코드로 살펴보겠습니다.

```python
class Admin:
    def __init__(self):
        self.models = []

    def add_model(self, model_name):
        # 모델 추가
        self.models.append(model_name)

    def list_models(self):
        # 모델 목록 반환
        return self.models
```

`Admin` 클래스는 모델 목록을 관리합니다. `add_model` 메소드는 모델을 추가하고, `list_models` 메소드는 현재 모델 목록을 반환합니다.

## 결론

이 장에서는 관리 인터페이스의 기본 개념과 사용 방법을 배웠습니다. 관리 인터페이스는 프로젝트 내 데이터를 효율적으로 관리하는 데 매우 유용한 도구입니다. 

다음 장에서는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 2: 커리큘럼 모델 (Curriculum Model)

이전 장에서는 [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)에 대해 알아보았습니다. 이제 우리는 커리큘럼 모델에 대해 설명할 것입니다. 이는 교육 커리큘럼을 정의하고 관리하기 위한 핵심 데이터 구조입니다. 초심자를 위한 설명을 통해 쉽게 따라올 수 있도록 하겠습니다.

## 커리큘럼 모델이란 무엇인가요?

커리큘럼 모델은 교육 콘텐츠를 체계적으로 관리하기 위한 데이터 구조입니다. 이를 통해 우리는 다양한 사용자에 맞춘 교육 경로를 계획하고 조정할 수 있습니다. 대표적인 예로 프로그래밍 학습 플랫폼에서 다양한 난이도별 코스를 제공하는 것을 들 수 있습니다.

### 커리큘럼 모델의 주요 개념

- **사용자 아이디**: 커리큘럼이 특정 사용자에게 할당되었음을 나타냅니다.
- **커리큘럼 타입**: 커리큘럼의 유형(예: 입문, 중급, 고급)을 정의합니다.
- **커리큘럼 이름**: 사용자가 이해하기 쉽고 식별할 수 있도록 지정합니다.
- **키워드**: 커리큘럼의 핵심 주제를 빠르게 파악할 수 있게 도와줍니다.

## 커리큘럼 모델 사용 방법

이제 간단한 커리큘럼 객체를 생성하고 사용하는 방법을 살펴보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        # 사용자 아이디 저장
        self.user_id = user_id
        # 커리큘럼 타입 저장
        self.cur_type = cur_type
        # 커리큘럼 이름 저장
        self.name = name
        # 키워드 저장
        self.keywords = keywords

# 커리큘럼 객체 생성
my_curriculum = CurriculumModel('user123', '입문', '파이썬 기본', ['프로그래밍', '파이썬'])
```

위 코드에서는 `CurriculumModel` 클래스를 정의하고 인스턴스를 생성했습니다. 각 인스턴스는 사용자 아이디, 커리큘럼 타입, 이름, 키워드를 포함합니다. 이와 같은 방식을 통해 다양한 커리큘럼을 효과적으로 관리할 수 있습니다.

## 내부 구현의 이해

커리큘럼 모델이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다. 이는 주로 객체가 생성되어, 데이터를 처리를 하는 과정을 보여줍니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant C as 커리큘럼 모델
    participant DB as 데이터베이스

    U->>C: 새로운 커리큘럼 생성 요청
    C->>DB: 커리큘럼 저장
    DB->>C: 저장 완료 응답
    C->>U: 생성 결과 전달
```

위 시퀀스 다이어그램은 사용자가 커리큘럼을 생성하면 그 요청이 데이터베이스에 저장되는 과정을 보여줍니다.

### 내부 코드 분석

커리큘럼 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        self.user_id = user_id
        self.cur_type = cur_type
        self.name = name
        self.keywords = keywords
    
    def save_to_db(self):
        # 데이터베이스에 커리큘럼 저장
        print(f"커리큘럼 '{self.name}'이 저장되었습니다.")
```

`CurriculumModel` 클래스에는 생성자 외에도 커리큘럼을 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 커리큘럼 모델이 무엇인지, 이를 사용하여 데이터를 어떻게 관리할 수 있는지를 배웠습니다. 이를 통해 다양한 교육 경로를 효율적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 알아보겠습니다. 함께 탐구해 봅시다!
---
# Chapter 3: 프로젝트 모델 (Project Model)

이전 장에서 우리는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 배웠습니다. 이제 `SKN_ToyProject`에서 사용될 프로젝트 모델에 대해 알아보겠습니다. 이 장에서는 프로젝트 모델이 무엇인지, 그리고 어떻게 사용해야 하는지를 간단하게 설명하겠습니다.

## 프로젝트 모델이란 무엇인가요?

프로젝트 모델은 사용자의 프로젝트에 관한 정보를 체계적으로 저장하고 관리하기 위한 데이터 구조입니다. 이를 통해 프로젝트 이름, 시작 및 종료 날짜, 그리고 팀원 수 등 다양한 정보를 손쉽게 다룰 수 있습니다.

### 핵심 사례

상상해보세요, 팀과 함께 새로운 웹사이트를 만드는 프로젝트를 시작한다고 가정할 때, 이 프로젝트 모델은 다음과 같은 정보를 체계적으로 보관할 수 있어요.

- 프로젝트 이름: "웹사이트 개발"
- 시작 날짜: "2023-06-01"
- 종료 날짜: "2023-12-31"
- 팀원 수: 5명

이렇게 프로젝트 모델을 사용하면 전체 프로젝트 일정을 더욱 명확하게 관리할 수 있습니다.

## 프로젝트 모델 주요 개념

### 1. 프로젝트 이름
프로젝트의 가장 기본적인 식별자 역할을 합니다.

### 2. 시작 및 종료 날짜
프로젝트의 기간을 지정합니다. 이를 통해 일정을 체계적으로 관리할 수 있습니다.

### 3. 팀원 수
프로젝트에 참여하는 인원의 수를 의미합니다.

## 프로젝트 모델 사용 방법

`ProjectModel` 클래스를 사용하여 프로젝트 객체를 생성할 수 있습니다. 다음은 간단한 예제 코드입니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        # 프로젝트 이름 저장
        self.name = name
        # 시작 날짜 저장
        self.start_date = start_date
        # 종료 날짜 저장
        self.end_date = end_date
        # 팀원 수 저장
        self.team_members = team_members

# 프로젝트 객체 생성
my_project = ProjectModel("웹사이트 개발", "2023-06-01", "2023-12-31", 5)
```

위 코드에서는 `ProjectModel` 클래스를 정의하고, 해당 클래스의 인스턴스를 생성했습니다. 각 인스턴스는 프로젝트 이름, 시작 및 종료 날짜, 팀원 수를 저장합니다.

### 프로젝트 모델의 동작 과정

이제 프로젝트 모델의 작동 방식에 대해 간단한 시퀀스 다이어그램을 통해 알아보겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant P as 프로젝트 모델
    participant DB as 데이터베이스

    U->>P: 프로젝트 생성 요청
    P->>DB: 프로젝트 정보 저장
    DB->>P: 저장 완료 응답
    P->>U: 생성 성공 메시지 전달
```

사용자가 프로젝트를 생성하면, 프로젝트 모델은 데이터를 데이터베이스에 저장합니다. 이후, 저장이 완료되면 사용자는 성공 메시지를 받게 됩니다.

## 내부 코드 이해

프로젝트 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        self.name = name
        self.start_date = start_date
        self.end_date = end_date
        self.team_members = team_members
    
    def save_to_db(self):
        # 데이터베이스에 프로젝트 저장
        print(f"프로젝트 '{self.name}'이 저장되었습니다.")
```

`ProjectModel` 클래스에는 생성자 외에도 프로젝트를 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 프로젝트 모델이 무엇이며, 이를 어떻게 사용하는지를 배웠습니다. 프로젝트 모델은 사용자의 프로젝트 정보를 관리하기 위한 강력한 도구입니다. 다음 장에서는 [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 4: 커리큘럼 뷰 (Curriculum Views)

이전 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 배워봤습니다. 이번 장에서는 `SKN_ToyProject`에서 커리큘럼 데이터를 어떻게 조회하고, 추가하고, 삭제하며, 맞춤형 커리큘럼을 생성하는지에 대해 알아보겠습니다. 이는 사용자가 다양한 교육 콘텐츠를 손쉽게 관리할 수 있도록 돕는 기능입니다. 초보자도 쉽게 따라갈 수 있도록 최대한 간단하게 설명하겠습니다.

---

## 커리큘럼 뷰란 무엇인가요?

커리큘럼 뷰는 프로젝트 내 여러 커리큘럼과 관련된 작업을 수행할 수 있는 인터페이스를 제공합니다. 예를 들어, 교육 플랫폼에서 새로운 강좌를 추가하거나 기존 강좌를 삭제하는 경우를 생각할 수 있습니다. 이를 통해 사용자들은 자신이 원하는 대로 커리큘럼을 조정할 수 있습니다.

### 커리큘럼 뷰가 해결하는 문제

- **데이터 조회**: 사용자에게 필요한 커리큘럼 정보를 손쉽게 조회할 수 있습니다.
- **데이터 추가**: 새로운 커리큘럼을 추가하여 교육 콘텐츠를 확장할 수 있습니다.
- **데이터 삭제**: 불필요한 커리큘럼을 삭제하여 관리 효율성을 높일 수 있습니다.
- **맞춤형 커리큘럼 생성**: 사용자에게 맞춤형 학습 경로를 제공합니다.

## 커리큘럼 뷰의 주요 기능

### 1. 커리큘럼 조회

아래 코드는 커리큘럼 목록을 조회하는 간단한 예제입니다.

```python
def get_curriculums():
    # 커리큘럼 목록 조회
    return ["커리큘럼1", "커리큘럼2", "커리큘럼3"]

# 커리큘럼 목록 출력
print(get_curriculums())
```

이 코드는 `get_curriculums` 함수를 통해 현재 저장된 커리큘럼들을 출력합니다.

### 2. 커리큘럼 추가

커리큘럼을 추가하는 방법은 다음과 같습니다.

```python
def add_curriculum(name):
    # 새로운 커리큘럼 추가
    print(f"{name} 커리큘럼이 추가되었습니다.")

# 새 커리큘럼 추가
add_curriculum("파이썬 기초")
```

여기서 `add_curriculum` 함수는 새로운 커리큘럼 이름을 받아서 추가 작업을 수행합니다.

### 3. 커리큘럼 삭제

커리큘럼 삭제도 매우 간단하게 이루어집니다.

```python
def delete_curriculum(name):
    # 커리큘럼 삭제
    print(f"{name} 커리큘럼이 삭제되었습니다.")

# 기존 커리큘럼 삭제
delete_curriculum("커리큘럼1")
```

`delete_curriculum` 함수는 지정된 이름의 커리큘럼을 삭제합니다.

### 4. 맞춤형 커리큘럼 생성

사용자 맞춤 커리큘럼을 생성하여 유저 경험을 향상시킬 수 있습니다.

```python
def create_custom_curriculum(user_id, preferences):
    # 사용자 맞춤 커리큘럼 생성
    print(f"사용자 {user_id}를 위한 맞춤형 커리큘럼이 생성되었습니다.")

# 맞춤형 커리큘럼 생성
create_custom_curriculum("user123", ["프로그래밍", "데이터 분석"])
```

이 코드는 사용자 ID와 선호 분야들을 이용해 맞춤형 커리큘럼을 생성합니다.

## 내부 구현 이해

이제 내부적으로 커리큘럼 뷰가 어떻게 동작하는지 간단하게 설명하겠습니다. 각 기능이 어떻게 상호작용하는지 보기 위해 시퀀스 다이어그램을 사용합니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant CV as 커리큘럼 뷰
    participant DB as 데이터베이스

    U->>CV: 커리큘럼 조회 요청
    CV->>DB: 조회 쿼리 전송
    DB->>CV: 응답 반환
    CV->>U: 커리큘럼 목록 전달
```

여기서 사용자가 커리큘럼 뷰로 요청을 하면, 커리큘럼 뷰는 데이터베이스에 쿼리를 날리고, 그 결과를 사용자에게 반환합니다.

### 내부 코드 구현

커리큘럼 뷰의 데이터 흐름은 아래와 같이 구성됩니다.

```python
class CurriculumView:
    def __init__(self):
        self.curriculums = []

    def add(self, name):
        self.curriculums.append(name)
        print(f"커리큘럼 '{name}'이 추가되었습니다.")

    def remove(self, name):
        if name in self.curriculums:
            self.curriculums.remove(name)
            print(f"커리큘럼 '{name}'이 삭제되었습니다.")
        else:
            print("커리큘럼이 존재하지 않습니다.")
```

위 `CurriculumView` 클래스는 커리큘럼 목록을 관리하기 위한 기본적인 기능을 제공합니다. `add`와 `remove` 메소드를 통해 커리큘럼을 추가하고 삭제할 수 있습니다.

---

## 결론

이번 장에서는 커리큘럼 뷰를 통해 어떻게 데이터를 조회하고, 추가하고, 삭제하며 맞춤형 커리큘럼을 생성할 수 있는지를 배웠습니다. 이를 통해 사용자 맞춤형 교육 콘텐츠를 효과적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)에 대해 설명하겠습니다. 기대해주세요!
---
# Chapter 5: 프로젝트 뷰 (Project Views)

이전 장에서는 [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)에 대해 배웠습니다. 이번 장에서는 `SKN_ToyProject`에서 `프로젝트 뷰 (Project Views)`에 대해 알아보도록 하겠습니다. 프로젝트 뷰는 프로젝트와 관련된 데이터를 조회하고, 새로운 프로젝트를 추가하거나, 기존 프로젝트를 수정하는 API 엔드포인트를 제공합니다. 이 장에서는 이러한 기능들을 어떻게 활용할 수 있는지를 살펴보겠습니다.

## 프로젝트 뷰란 무엇인가요?

프로젝트 뷰는 사용자가 프로젝트와 관련된 데이터를 효율적으로 관리할 수 있게 해주는 도구입니다. 예를 들어, 팀 프로젝트를 진행하는 동안 관련 정보를 효율적으로 조회하고 필요에 따라 수정할 수 있습니다.

### 프로젝트 뷰의 주요 기능

- **프로젝트 조회**: 기존 프로젝트의 정보를 확인할 수 있습니다.
- **프로젝트 추가**: 새로운 프로젝트를 데이터베이스에 저장할 수 있습니다.
- **프로젝트 수정**: 등록된 프로젝트 정보를 업데이트할 수 있습니다.

## 프로젝트 뷰 사용 방법

이제 간단한 예제를 통해 프로젝트 뷰를 어떻게 사용할 수 있는지 알아보겠습니다.

### 1. 프로젝트 조회하기

프로젝트 데이터를 조회할 수 있는 간단한 코드를 작성해 봅시다.

```python
def get_projects():
    # 프로젝트 목록 조회
    return ["프로젝트 A", "프로젝트 B", "프로젝트 C"]

# 프로젝트 목록 출력
print(get_projects())
```

위 코드에서는 `get_projects` 함수를 통해 등록된 모든 프로젝트를 조회할 수 있습니다. 이 함수는 프로젝트 이름의 리스트를 반환합니다.

### 2. 새로운 프로젝트 추가하기

다음은 새로운 프로젝트를 추가하는 방법입니다.

```python
def add_project(name):
    # 새로운 프로젝트 추가
    print(f"{name} 프로젝트가 추가되었습니다.")

# 프로젝트 추가
add_project("프로젝트 D")
```

이 코드에서 `add_project` 함수는 프로젝트 이름을 받아 새로운 프로젝트를 추가하는 기능을 수행합니다.

### 3. 기존 프로젝트 수정하기

다음으로 프로젝트 정보를 수정하는 방법을 살펴보겠습니다.

```python
def update_project(old_name, new_name):
    # 프로젝트 이름 수정
    print(f"{old_name}가 {new_name}로 변경되었습니다.")

# 프로젝트 수정
update_project("프로젝트 A", "프로젝트 Z")
```

위 코드에서는 `update_project` 함수를 사용하여 기존 프로젝트의 이름을 업데이트할 수 있습니다.

## 내부 구현 이해

프로젝트 뷰의 내부에서 발생하는 상호작용을 간단하게 설명하겠습니다. 프로젝트의 생성, 조회, 수정 과정을 시퀀스 다이어그램을 통해 이해해 봅시다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant PV as 프로젝트 뷰
    participant DB as 데이터베이스

    U->>PV: 프로젝트 조회 요청
    PV->>DB: 조회 쿼리 전송
    DB->>PV: 응답 반환
    PV->>U: 프로젝트 목록 전달

    U->>PV: 프로젝트 추가 요청
    PV->>DB: 새로운 프로젝트 저장
    DB->>PV: 저장 성공 메시지 반환
    PV->>U: 프로젝트 추가 성공 메시지 전달

    U->>PV: 프로젝트 수정 요청
    PV->>DB: 프로젝트 업데이트
    DB->>PV: 업데이트 성공 메시지 반환
    PV->>U: 프로젝트 수정 성공 메시지 전달
```

각 기능은 데이터베이스와 상호작용하여 데이터를 효율적으로 처리합니다.

### 내부 코드 구현

이제 프로젝트 뷰의 내부 구현에 대한 코드를 살펴보겠습니다.

```python
class ProjectView:
    def __init__(self):
        self.projects = []

    def add(self, name):
        self.projects.append(name)
        print(f"프로젝트 '{name}'이 추가되었습니다.")

    def update(self, old_name, new_name):
        if old_name in self.projects:
            self.projects[self.projects.index(old_name)] = new_name
            print(f"프로젝트 '{old_name}'이 '{new_name}'로 변경되었습니다.")
        else:
            print("프로젝트가 존재하지 않습니다.")
```

`ProjectView` 클래스는 프로젝트 목록을 관리하며, `add`와 `update` 메소드를 통해 프로젝트를 추가하고 수정할 수 있는 기능을 제공합니다.

## 결론

이번 장에서는 프로젝트 뷰가 제공하는 기본적인 기능을 이용해 프로젝트 데이터를 조회하고 추가 및 수정하는 방법을 배웠습니다. 이를 통해 사용자는 프로젝트와 관련된 데이터를 효율적으로 관리할 수 있습니다. 다음 장에서는 [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)에 대해 배워보겠습니다. 함께 탐구해봅시다!

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 6: 사용자 및 커리큘럼 관계 (User and Curriculum Relationship)`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 21:03:43,292 - INFO - Using OpenAI model: gpt-4o
2025-06-29 21:03:54,737 - INFO - RESPONSE: # Chapter 6: 사용자 및 커리큘럼 관계 (User and Curriculum Relationship)

이전 장에서는 [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)에 대해 배웠습니다. 이제 `SKN_ToyProject`에서 사용자와 커리큘럼 간의 관계를 어떻게 정의하고 관리할 수 있는지에 대해 알아볼 차례입니다. 이는 각 사용자가 커리큘럼을 어떻게 완료했는지를 추적하고 관리할 수 있도록 도와주는 핵심 기능입니다.

## 사용자 및 커리큘럼 관계란 무엇인가요?

사용자 및 커리큘럼 관계는 사용자가 어떤 커리큘럼을 완료했는지를 추적합니다. 예를 들어, 여러분이 온라인 학습 플랫폼에서 여러 강의를 수강할 때, 이 관계를 통해 어떤 강의를 완료했는지 기록하고 확인할 수 있습니다. 이를 통해 여러분은 학습 진척도를 쉽게 관리할 수 있습니다.

### 사용자 및 커리큘럼 관계의 주요 개념

- **사용자 식별자(User ID)**: 각 사용자를 고유하게 식별합니다.
- **커리큘럼 식별자(Curriculum ID)**: 커리큘럼을 고유하게 식별합니다.
- **완료 상태(Completion Status)**: 사용자가 커리큘럼을 완료했는지 여부를 추적합니다.

## 사용자 및 커리큘럼 관계 사용 방법

이제 이 관계를 어떻게 코드로 구현하고 활용할 수 있는지 간단한 예제를 통해 살펴보겠습니다.

### 1. 사용자와 커리큘럼 간의 관계 정의하기

```python
class UserCurriculumRelation:
    def __init__(self, user_id, curriculum_id, completed=False):
        # 사용자 ID 저장
        self.user_id = user_id
        # 커리큘럼 ID 저장
        self.curriculum_id = curriculum_id
        # 완료 상태 저장
        self.completed = completed

# 관계 생성
relation = UserCurriculumRelation("user123", "curriculum456")
```

이 코드에서는 `UserCurriculumRelation` 클래스가 사용자와 커리큘럼 간의 관계를 나타냅니다. 각 관계는 사용자 ID, 커리큘럼 ID, 그리고 완료 상태를 포함합니다.

### 2. 완료 상태 업데이트하기

사용자가 커리큘럼을 완료했을 때, 완료 상태를 업데이트할 수 있습니다.

```python
def mark_complete(relation):
    # 완료 상태 업데이트
    relation.completed = True
    print(f"사용자 {relation.user_id}가 커리큘럼 {relation.curriculum_id}를 완료했습니다.")

# 완료 상태 업데이트 호출
mark_complete(relation)
```

위 함수는 `relation` 객체의 완료 상태를 `True`로 변경하며 완료 메시지를 출력합니다.

## 내부 구현 이해

이제 사용자와 커리큘럼 간의 관계가 어떻게 동작하는지 시퀀스 다이어그램을 통해 설명하겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant UR as 사용자 관계
    participant DB as 데이터베이스

    U->>UR: 커리큘럼 완료 요청
    UR->>DB: 완료 상태 업데이트
    DB->>UR: 업데이트 확인
    UR->>U: 완료 상태 확인 및 전달
```

이 다이어그램에서는 사용자가 커리큘럼을 완료한다고 요청하고, 그 상태가 데이터베이스에 업데이트 되는 과정을 보여줍니다.

### 내부 코드 분석

다음으로 `UserCurriculumRelation` 클래스의 간단한 내부 구현을 살펴보겠습니다.

```python
class UserCurriculumRelation:
    def __init__(self, user_id, curriculum_id, completed=False):
        self.user_id = user_id
        self.curriculum_id = curriculum_id
        self.completed = completed
        
    def save_to_db(self):
        # 완료 상태를 데이터베이스에 저장
        print(f"커리큘럼 '{self.curriculum_id}'의 완료 상태가 저장되었습니다.")
```

`save_to_db` 메소드는 완료 상태를 데이터베이스에 저장하는 기능을 합니다. 이는 사용자의 완벽한 학습 기록을 관리하는 데 필수적입니다.

## 결론

이번 장에서는 사용자와 커리큘럼 간의 관계를 어떻게 정의하고, 완료 상태를 추적할 수 있는지를 배웠습니다. 이는 사용자 학습의 진척도를 파악하는 데 중요한 역할을 합니다. 이후 장에서는 [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)에 대해 알아보겠습니다. 함께 배워봅시다!
2025-06-29 21:03:54,752 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN_ToyProject` about the concept: "퀴즈 히스토리 및 분석 (Quiz History and Analysis)". This is Chapter 7.

Concept Details (Note: Provided in Korean):
- Name: 퀴즈 히스토리 및 분석 (Quiz History and Analysis)
- Description:
사용자가 완료한 퀴즈의 이력을 저장하고 분석하여 각 섹션의 성과를 평가하고 결과를 제공합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)
2. [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)
3. [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)
4. [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)
5. [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)
6. [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)
7. [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)
8. [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)
9. [추천 시스템 (Recommendation System)](09_추천_시스템__recommendation_system_.md)
10. [기술 스택 관리 (Tech Stack Management)](10_기술_스택_관리__tech_stack_management_.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 관리 인터페이스 (Admin Interface)

`SKN_ToyProject`에 오신 것을 환영합니다! 이 장에서는 관리 인터페이스(Admin Interface)의 개념에 대해 알아보겠습니다. 관리 인터페이스는 데이터를 관리하고 시각화하는 데 매우 중요한 도구입니다. 관리자가 다양한 모델 객체를 효율적으로 다루는 방법을 배울 수 있습니다.

## 관리 인터페이스란 무엇인가요?

관리 인터페이스는 프로젝트 내에서 데이터를 쉽게 시각화하고 조작할 수 있도록 도와주는 도구입니다. 예를 들어, 웹사이트의 관리자 페이지를 생각해보세요. 사용자가 데이터를 입력하면, 관리자는 이 데이터가 어떻게 저장되고, 표현되는지를 이 페이지에서 직접 확인하고 변경할 수 있습니다. 바로 이런 역할을 하는 것이 관리 인터페이스입니다.

## 관리 인터페이스의 주요 개념

### 1. 데이터 시각화
관리 인터페이스는 데이터를 표 형태로 보여줍니다. 이는 사용자가 데이터를 한눈에 이해할 수 있게 도와줍니다.

### 2. 데이터 조작
사용자는 인터페이스를 통해 데이터를 직접 추가, 수정, 삭제할 수 있습니다. 이를 통해 데이터 관리가 훨씬 더 직관적이고 효율적이 됩니다.

## 관리 인터페이스 사용 방법

이제 간단한 예제로 관리 인터페이스를 사용하는 방법을 살펴보겠습니다.

```python
from admin_interface import Admin

# 관리자 인터페이스 초기화
admin = Admin()

# 데이터 추가
admin.add_model('새로운 모델 객체')

# 데이터 목록 보기
print(admin.list_models())  # ['새로운 모델 객체']
```

첫 줄에서 관리 인터페이스를 불러오고, 두 번째 줄에서 관리 인터페이스를 초기화합니다. 그 후, `add_model` 메소드를 통해 데이터를 추가하고, `list_models`를 통해 현재 데이터를 확인할 수 있습니다.

## 관리 인터페이스의 내부 구조

관리 인터페이스가 어떻게 내부적으로 동작하는지 간단히 살펴보겠습니다. 관리 인터페이스가 호출되면, 다음과 같은 단계를 거칩니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant AI as 관리 인터페이스
    participant DB as 데이터베이스

    U->>AI: 데이터 추가 요청
    AI->>DB: 데이터 저장 요청
    DB->>AI: 저장 완료 응답
    AI->>U: 처리 결과 전달
```

`사용자`가 관리 인터페이스를 통해 데이터를 추가하면, `관리 인터페이스`는 이를 `데이터베이스`에 저장하고 결과를 다시 사용자에게 전달합니다.

### 코드를 통한 내부 구조 이해

관리 인터페이스의 내부 구현을 간단한 코드로 살펴보겠습니다.

```python
class Admin:
    def __init__(self):
        self.models = []

    def add_model(self, model_name):
        # 모델 추가
        self.models.append(model_name)

    def list_models(self):
        # 모델 목록 반환
        return self.models
```

`Admin` 클래스는 모델 목록을 관리합니다. `add_model` 메소드는 모델을 추가하고, `list_models` 메소드는 현재 모델 목록을 반환합니다.

## 결론

이 장에서는 관리 인터페이스의 기본 개념과 사용 방법을 배웠습니다. 관리 인터페이스는 프로젝트 내 데이터를 효율적으로 관리하는 데 매우 유용한 도구입니다. 

다음 장에서는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 2: 커리큘럼 모델 (Curriculum Model)

이전 장에서는 [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)에 대해 알아보았습니다. 이제 우리는 커리큘럼 모델에 대해 설명할 것입니다. 이는 교육 커리큘럼을 정의하고 관리하기 위한 핵심 데이터 구조입니다. 초심자를 위한 설명을 통해 쉽게 따라올 수 있도록 하겠습니다.

## 커리큘럼 모델이란 무엇인가요?

커리큘럼 모델은 교육 콘텐츠를 체계적으로 관리하기 위한 데이터 구조입니다. 이를 통해 우리는 다양한 사용자에 맞춘 교육 경로를 계획하고 조정할 수 있습니다. 대표적인 예로 프로그래밍 학습 플랫폼에서 다양한 난이도별 코스를 제공하는 것을 들 수 있습니다.

### 커리큘럼 모델의 주요 개념

- **사용자 아이디**: 커리큘럼이 특정 사용자에게 할당되었음을 나타냅니다.
- **커리큘럼 타입**: 커리큘럼의 유형(예: 입문, 중급, 고급)을 정의합니다.
- **커리큘럼 이름**: 사용자가 이해하기 쉽고 식별할 수 있도록 지정합니다.
- **키워드**: 커리큘럼의 핵심 주제를 빠르게 파악할 수 있게 도와줍니다.

## 커리큘럼 모델 사용 방법

이제 간단한 커리큘럼 객체를 생성하고 사용하는 방법을 살펴보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        # 사용자 아이디 저장
        self.user_id = user_id
        # 커리큘럼 타입 저장
        self.cur_type = cur_type
        # 커리큘럼 이름 저장
        self.name = name
        # 키워드 저장
        self.keywords = keywords

# 커리큘럼 객체 생성
my_curriculum = CurriculumModel('user123', '입문', '파이썬 기본', ['프로그래밍', '파이썬'])
```

위 코드에서는 `CurriculumModel` 클래스를 정의하고 인스턴스를 생성했습니다. 각 인스턴스는 사용자 아이디, 커리큘럼 타입, 이름, 키워드를 포함합니다. 이와 같은 방식을 통해 다양한 커리큘럼을 효과적으로 관리할 수 있습니다.

## 내부 구현의 이해

커리큘럼 모델이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다. 이는 주로 객체가 생성되어, 데이터를 처리를 하는 과정을 보여줍니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant C as 커리큘럼 모델
    participant DB as 데이터베이스

    U->>C: 새로운 커리큘럼 생성 요청
    C->>DB: 커리큘럼 저장
    DB->>C: 저장 완료 응답
    C->>U: 생성 결과 전달
```

위 시퀀스 다이어그램은 사용자가 커리큘럼을 생성하면 그 요청이 데이터베이스에 저장되는 과정을 보여줍니다.

### 내부 코드 분석

커리큘럼 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        self.user_id = user_id
        self.cur_type = cur_type
        self.name = name
        self.keywords = keywords
    
    def save_to_db(self):
        # 데이터베이스에 커리큘럼 저장
        print(f"커리큘럼 '{self.name}'이 저장되었습니다.")
```

`CurriculumModel` 클래스에는 생성자 외에도 커리큘럼을 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 커리큘럼 모델이 무엇인지, 이를 사용하여 데이터를 어떻게 관리할 수 있는지를 배웠습니다. 이를 통해 다양한 교육 경로를 효율적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 알아보겠습니다. 함께 탐구해 봅시다!
---
# Chapter 3: 프로젝트 모델 (Project Model)

이전 장에서 우리는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 배웠습니다. 이제 `SKN_ToyProject`에서 사용될 프로젝트 모델에 대해 알아보겠습니다. 이 장에서는 프로젝트 모델이 무엇인지, 그리고 어떻게 사용해야 하는지를 간단하게 설명하겠습니다.

## 프로젝트 모델이란 무엇인가요?

프로젝트 모델은 사용자의 프로젝트에 관한 정보를 체계적으로 저장하고 관리하기 위한 데이터 구조입니다. 이를 통해 프로젝트 이름, 시작 및 종료 날짜, 그리고 팀원 수 등 다양한 정보를 손쉽게 다룰 수 있습니다.

### 핵심 사례

상상해보세요, 팀과 함께 새로운 웹사이트를 만드는 프로젝트를 시작한다고 가정할 때, 이 프로젝트 모델은 다음과 같은 정보를 체계적으로 보관할 수 있어요.

- 프로젝트 이름: "웹사이트 개발"
- 시작 날짜: "2023-06-01"
- 종료 날짜: "2023-12-31"
- 팀원 수: 5명

이렇게 프로젝트 모델을 사용하면 전체 프로젝트 일정을 더욱 명확하게 관리할 수 있습니다.

## 프로젝트 모델 주요 개념

### 1. 프로젝트 이름
프로젝트의 가장 기본적인 식별자 역할을 합니다.

### 2. 시작 및 종료 날짜
프로젝트의 기간을 지정합니다. 이를 통해 일정을 체계적으로 관리할 수 있습니다.

### 3. 팀원 수
프로젝트에 참여하는 인원의 수를 의미합니다.

## 프로젝트 모델 사용 방법

`ProjectModel` 클래스를 사용하여 프로젝트 객체를 생성할 수 있습니다. 다음은 간단한 예제 코드입니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        # 프로젝트 이름 저장
        self.name = name
        # 시작 날짜 저장
        self.start_date = start_date
        # 종료 날짜 저장
        self.end_date = end_date
        # 팀원 수 저장
        self.team_members = team_members

# 프로젝트 객체 생성
my_project = ProjectModel("웹사이트 개발", "2023-06-01", "2023-12-31", 5)
```

위 코드에서는 `ProjectModel` 클래스를 정의하고, 해당 클래스의 인스턴스를 생성했습니다. 각 인스턴스는 프로젝트 이름, 시작 및 종료 날짜, 팀원 수를 저장합니다.

### 프로젝트 모델의 동작 과정

이제 프로젝트 모델의 작동 방식에 대해 간단한 시퀀스 다이어그램을 통해 알아보겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant P as 프로젝트 모델
    participant DB as 데이터베이스

    U->>P: 프로젝트 생성 요청
    P->>DB: 프로젝트 정보 저장
    DB->>P: 저장 완료 응답
    P->>U: 생성 성공 메시지 전달
```

사용자가 프로젝트를 생성하면, 프로젝트 모델은 데이터를 데이터베이스에 저장합니다. 이후, 저장이 완료되면 사용자는 성공 메시지를 받게 됩니다.

## 내부 코드 이해

프로젝트 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        self.name = name
        self.start_date = start_date
        self.end_date = end_date
        self.team_members = team_members
    
    def save_to_db(self):
        # 데이터베이스에 프로젝트 저장
        print(f"프로젝트 '{self.name}'이 저장되었습니다.")
```

`ProjectModel` 클래스에는 생성자 외에도 프로젝트를 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 프로젝트 모델이 무엇이며, 이를 어떻게 사용하는지를 배웠습니다. 프로젝트 모델은 사용자의 프로젝트 정보를 관리하기 위한 강력한 도구입니다. 다음 장에서는 [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 4: 커리큘럼 뷰 (Curriculum Views)

이전 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 배워봤습니다. 이번 장에서는 `SKN_ToyProject`에서 커리큘럼 데이터를 어떻게 조회하고, 추가하고, 삭제하며, 맞춤형 커리큘럼을 생성하는지에 대해 알아보겠습니다. 이는 사용자가 다양한 교육 콘텐츠를 손쉽게 관리할 수 있도록 돕는 기능입니다. 초보자도 쉽게 따라갈 수 있도록 최대한 간단하게 설명하겠습니다.

---

## 커리큘럼 뷰란 무엇인가요?

커리큘럼 뷰는 프로젝트 내 여러 커리큘럼과 관련된 작업을 수행할 수 있는 인터페이스를 제공합니다. 예를 들어, 교육 플랫폼에서 새로운 강좌를 추가하거나 기존 강좌를 삭제하는 경우를 생각할 수 있습니다. 이를 통해 사용자들은 자신이 원하는 대로 커리큘럼을 조정할 수 있습니다.

### 커리큘럼 뷰가 해결하는 문제

- **데이터 조회**: 사용자에게 필요한 커리큘럼 정보를 손쉽게 조회할 수 있습니다.
- **데이터 추가**: 새로운 커리큘럼을 추가하여 교육 콘텐츠를 확장할 수 있습니다.
- **데이터 삭제**: 불필요한 커리큘럼을 삭제하여 관리 효율성을 높일 수 있습니다.
- **맞춤형 커리큘럼 생성**: 사용자에게 맞춤형 학습 경로를 제공합니다.

## 커리큘럼 뷰의 주요 기능

### 1. 커리큘럼 조회

아래 코드는 커리큘럼 목록을 조회하는 간단한 예제입니다.

```python
def get_curriculums():
    # 커리큘럼 목록 조회
    return ["커리큘럼1", "커리큘럼2", "커리큘럼3"]

# 커리큘럼 목록 출력
print(get_curriculums())
```

이 코드는 `get_curriculums` 함수를 통해 현재 저장된 커리큘럼들을 출력합니다.

### 2. 커리큘럼 추가

커리큘럼을 추가하는 방법은 다음과 같습니다.

```python
def add_curriculum(name):
    # 새로운 커리큘럼 추가
    print(f"{name} 커리큘럼이 추가되었습니다.")

# 새 커리큘럼 추가
add_curriculum("파이썬 기초")
```

여기서 `add_curriculum` 함수는 새로운 커리큘럼 이름을 받아서 추가 작업을 수행합니다.

### 3. 커리큘럼 삭제

커리큘럼 삭제도 매우 간단하게 이루어집니다.

```python
def delete_curriculum(name):
    # 커리큘럼 삭제
    print(f"{name} 커리큘럼이 삭제되었습니다.")

# 기존 커리큘럼 삭제
delete_curriculum("커리큘럼1")
```

`delete_curriculum` 함수는 지정된 이름의 커리큘럼을 삭제합니다.

### 4. 맞춤형 커리큘럼 생성

사용자 맞춤 커리큘럼을 생성하여 유저 경험을 향상시킬 수 있습니다.

```python
def create_custom_curriculum(user_id, preferences):
    # 사용자 맞춤 커리큘럼 생성
    print(f"사용자 {user_id}를 위한 맞춤형 커리큘럼이 생성되었습니다.")

# 맞춤형 커리큘럼 생성
create_custom_curriculum("user123", ["프로그래밍", "데이터 분석"])
```

이 코드는 사용자 ID와 선호 분야들을 이용해 맞춤형 커리큘럼을 생성합니다.

## 내부 구현 이해

이제 내부적으로 커리큘럼 뷰가 어떻게 동작하는지 간단하게 설명하겠습니다. 각 기능이 어떻게 상호작용하는지 보기 위해 시퀀스 다이어그램을 사용합니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant CV as 커리큘럼 뷰
    participant DB as 데이터베이스

    U->>CV: 커리큘럼 조회 요청
    CV->>DB: 조회 쿼리 전송
    DB->>CV: 응답 반환
    CV->>U: 커리큘럼 목록 전달
```

여기서 사용자가 커리큘럼 뷰로 요청을 하면, 커리큘럼 뷰는 데이터베이스에 쿼리를 날리고, 그 결과를 사용자에게 반환합니다.

### 내부 코드 구현

커리큘럼 뷰의 데이터 흐름은 아래와 같이 구성됩니다.

```python
class CurriculumView:
    def __init__(self):
        self.curriculums = []

    def add(self, name):
        self.curriculums.append(name)
        print(f"커리큘럼 '{name}'이 추가되었습니다.")

    def remove(self, name):
        if name in self.curriculums:
            self.curriculums.remove(name)
            print(f"커리큘럼 '{name}'이 삭제되었습니다.")
        else:
            print("커리큘럼이 존재하지 않습니다.")
```

위 `CurriculumView` 클래스는 커리큘럼 목록을 관리하기 위한 기본적인 기능을 제공합니다. `add`와 `remove` 메소드를 통해 커리큘럼을 추가하고 삭제할 수 있습니다.

---

## 결론

이번 장에서는 커리큘럼 뷰를 통해 어떻게 데이터를 조회하고, 추가하고, 삭제하며 맞춤형 커리큘럼을 생성할 수 있는지를 배웠습니다. 이를 통해 사용자 맞춤형 교육 콘텐츠를 효과적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)에 대해 설명하겠습니다. 기대해주세요!
---
# Chapter 5: 프로젝트 뷰 (Project Views)

이전 장에서는 [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)에 대해 배웠습니다. 이번 장에서는 `SKN_ToyProject`에서 `프로젝트 뷰 (Project Views)`에 대해 알아보도록 하겠습니다. 프로젝트 뷰는 프로젝트와 관련된 데이터를 조회하고, 새로운 프로젝트를 추가하거나, 기존 프로젝트를 수정하는 API 엔드포인트를 제공합니다. 이 장에서는 이러한 기능들을 어떻게 활용할 수 있는지를 살펴보겠습니다.

## 프로젝트 뷰란 무엇인가요?

프로젝트 뷰는 사용자가 프로젝트와 관련된 데이터를 효율적으로 관리할 수 있게 해주는 도구입니다. 예를 들어, 팀 프로젝트를 진행하는 동안 관련 정보를 효율적으로 조회하고 필요에 따라 수정할 수 있습니다.

### 프로젝트 뷰의 주요 기능

- **프로젝트 조회**: 기존 프로젝트의 정보를 확인할 수 있습니다.
- **프로젝트 추가**: 새로운 프로젝트를 데이터베이스에 저장할 수 있습니다.
- **프로젝트 수정**: 등록된 프로젝트 정보를 업데이트할 수 있습니다.

## 프로젝트 뷰 사용 방법

이제 간단한 예제를 통해 프로젝트 뷰를 어떻게 사용할 수 있는지 알아보겠습니다.

### 1. 프로젝트 조회하기

프로젝트 데이터를 조회할 수 있는 간단한 코드를 작성해 봅시다.

```python
def get_projects():
    # 프로젝트 목록 조회
    return ["프로젝트 A", "프로젝트 B", "프로젝트 C"]

# 프로젝트 목록 출력
print(get_projects())
```

위 코드에서는 `get_projects` 함수를 통해 등록된 모든 프로젝트를 조회할 수 있습니다. 이 함수는 프로젝트 이름의 리스트를 반환합니다.

### 2. 새로운 프로젝트 추가하기

다음은 새로운 프로젝트를 추가하는 방법입니다.

```python
def add_project(name):
    # 새로운 프로젝트 추가
    print(f"{name} 프로젝트가 추가되었습니다.")

# 프로젝트 추가
add_project("프로젝트 D")
```

이 코드에서 `add_project` 함수는 프로젝트 이름을 받아 새로운 프로젝트를 추가하는 기능을 수행합니다.

### 3. 기존 프로젝트 수정하기

다음으로 프로젝트 정보를 수정하는 방법을 살펴보겠습니다.

```python
def update_project(old_name, new_name):
    # 프로젝트 이름 수정
    print(f"{old_name}가 {new_name}로 변경되었습니다.")

# 프로젝트 수정
update_project("프로젝트 A", "프로젝트 Z")
```

위 코드에서는 `update_project` 함수를 사용하여 기존 프로젝트의 이름을 업데이트할 수 있습니다.

## 내부 구현 이해

프로젝트 뷰의 내부에서 발생하는 상호작용을 간단하게 설명하겠습니다. 프로젝트의 생성, 조회, 수정 과정을 시퀀스 다이어그램을 통해 이해해 봅시다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant PV as 프로젝트 뷰
    participant DB as 데이터베이스

    U->>PV: 프로젝트 조회 요청
    PV->>DB: 조회 쿼리 전송
    DB->>PV: 응답 반환
    PV->>U: 프로젝트 목록 전달

    U->>PV: 프로젝트 추가 요청
    PV->>DB: 새로운 프로젝트 저장
    DB->>PV: 저장 성공 메시지 반환
    PV->>U: 프로젝트 추가 성공 메시지 전달

    U->>PV: 프로젝트 수정 요청
    PV->>DB: 프로젝트 업데이트
    DB->>PV: 업데이트 성공 메시지 반환
    PV->>U: 프로젝트 수정 성공 메시지 전달
```

각 기능은 데이터베이스와 상호작용하여 데이터를 효율적으로 처리합니다.

### 내부 코드 구현

이제 프로젝트 뷰의 내부 구현에 대한 코드를 살펴보겠습니다.

```python
class ProjectView:
    def __init__(self):
        self.projects = []

    def add(self, name):
        self.projects.append(name)
        print(f"프로젝트 '{name}'이 추가되었습니다.")

    def update(self, old_name, new_name):
        if old_name in self.projects:
            self.projects[self.projects.index(old_name)] = new_name
            print(f"프로젝트 '{old_name}'이 '{new_name}'로 변경되었습니다.")
        else:
            print("프로젝트가 존재하지 않습니다.")
```

`ProjectView` 클래스는 프로젝트 목록을 관리하며, `add`와 `update` 메소드를 통해 프로젝트를 추가하고 수정할 수 있는 기능을 제공합니다.

## 결론

이번 장에서는 프로젝트 뷰가 제공하는 기본적인 기능을 이용해 프로젝트 데이터를 조회하고 추가 및 수정하는 방법을 배웠습니다. 이를 통해 사용자는 프로젝트와 관련된 데이터를 효율적으로 관리할 수 있습니다. 다음 장에서는 [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)에 대해 배워보겠습니다. 함께 탐구해봅시다!
---
# Chapter 6: 사용자 및 커리큘럼 관계 (User and Curriculum Relationship)

이전 장에서는 [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)에 대해 배웠습니다. 이제 `SKN_ToyProject`에서 사용자와 커리큘럼 간의 관계를 어떻게 정의하고 관리할 수 있는지에 대해 알아볼 차례입니다. 이는 각 사용자가 커리큘럼을 어떻게 완료했는지를 추적하고 관리할 수 있도록 도와주는 핵심 기능입니다.

## 사용자 및 커리큘럼 관계란 무엇인가요?

사용자 및 커리큘럼 관계는 사용자가 어떤 커리큘럼을 완료했는지를 추적합니다. 예를 들어, 여러분이 온라인 학습 플랫폼에서 여러 강의를 수강할 때, 이 관계를 통해 어떤 강의를 완료했는지 기록하고 확인할 수 있습니다. 이를 통해 여러분은 학습 진척도를 쉽게 관리할 수 있습니다.

### 사용자 및 커리큘럼 관계의 주요 개념

- **사용자 식별자(User ID)**: 각 사용자를 고유하게 식별합니다.
- **커리큘럼 식별자(Curriculum ID)**: 커리큘럼을 고유하게 식별합니다.
- **완료 상태(Completion Status)**: 사용자가 커리큘럼을 완료했는지 여부를 추적합니다.

## 사용자 및 커리큘럼 관계 사용 방법

이제 이 관계를 어떻게 코드로 구현하고 활용할 수 있는지 간단한 예제를 통해 살펴보겠습니다.

### 1. 사용자와 커리큘럼 간의 관계 정의하기

```python
class UserCurriculumRelation:
    def __init__(self, user_id, curriculum_id, completed=False):
        # 사용자 ID 저장
        self.user_id = user_id
        # 커리큘럼 ID 저장
        self.curriculum_id = curriculum_id
        # 완료 상태 저장
        self.completed = completed

# 관계 생성
relation = UserCurriculumRelation("user123", "curriculum456")
```

이 코드에서는 `UserCurriculumRelation` 클래스가 사용자와 커리큘럼 간의 관계를 나타냅니다. 각 관계는 사용자 ID, 커리큘럼 ID, 그리고 완료 상태를 포함합니다.

### 2. 완료 상태 업데이트하기

사용자가 커리큘럼을 완료했을 때, 완료 상태를 업데이트할 수 있습니다.

```python
def mark_complete(relation):
    # 완료 상태 업데이트
    relation.completed = True
    print(f"사용자 {relation.user_id}가 커리큘럼 {relation.curriculum_id}를 완료했습니다.")

# 완료 상태 업데이트 호출
mark_complete(relation)
```

위 함수는 `relation` 객체의 완료 상태를 `True`로 변경하며 완료 메시지를 출력합니다.

## 내부 구현 이해

이제 사용자와 커리큘럼 간의 관계가 어떻게 동작하는지 시퀀스 다이어그램을 통해 설명하겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant UR as 사용자 관계
    participant DB as 데이터베이스

    U->>UR: 커리큘럼 완료 요청
    UR->>DB: 완료 상태 업데이트
    DB->>UR: 업데이트 확인
    UR->>U: 완료 상태 확인 및 전달
```

이 다이어그램에서는 사용자가 커리큘럼을 완료한다고 요청하고, 그 상태가 데이터베이스에 업데이트 되는 과정을 보여줍니다.

### 내부 코드 분석

다음으로 `UserCurriculumRelation` 클래스의 간단한 내부 구현을 살펴보겠습니다.

```python
class UserCurriculumRelation:
    def __init__(self, user_id, curriculum_id, completed=False):
        self.user_id = user_id
        self.curriculum_id = curriculum_id
        self.completed = completed
        
    def save_to_db(self):
        # 완료 상태를 데이터베이스에 저장
        print(f"커리큘럼 '{self.curriculum_id}'의 완료 상태가 저장되었습니다.")
```

`save_to_db` 메소드는 완료 상태를 데이터베이스에 저장하는 기능을 합니다. 이는 사용자의 완벽한 학습 기록을 관리하는 데 필수적입니다.

## 결론

이번 장에서는 사용자와 커리큘럼 간의 관계를 어떻게 정의하고, 완료 상태를 추적할 수 있는지를 배웠습니다. 이는 사용자 학습의 진척도를 파악하는 데 중요한 역할을 합니다. 이후 장에서는 [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)에 대해 알아보겠습니다. 함께 배워봅시다!

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 7: 퀴즈 히스토리 및 분석 (Quiz History and Analysis)`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 21:03:54,929 - INFO - Using OpenAI model: gpt-4o
2025-06-29 21:04:07,278 - INFO - RESPONSE: # Chapter 7: 퀴즈 히스토리 및 분석 (Quiz History and Analysis)

이전 장에서는 [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)에 대해 배워보았습니다. 이번 장에서는 사용자 퀴즈 히스토리 및 성과를 분석하는 방법에 대해 알아보겠습니다. 이를 통해 사용자는 자신의 학습 진척도를 파악하고, 더 나은 학습 계획을 세울 수 있습니다.

## 문제 해결을 위한 배경

퀴즈 히스토리 및 분석 기능은 사용자가 완료한 퀴즈의 이력을 저장하고, 이를 바탕으로 성과를 평가하여 개선점을 찾을 수 있도록 돕습니다. 예를 들어, 학생이 여러 과목의 퀴즈를 푸는 동안 어떤 과목이 상대적으로 약한지를 파악할 수 있게 되는 것입니다.

## 퀴즈 히스토리의 주요 개념

### 1. 퀴즈 이력 저장
사용자가 퀴즈를 완료하면, 그 결과가 저장됩니다. 이는 나중에 분석하여 성과를 평가하는 데 사용됩니다.

### 2. 퀴즈 성과 분석
저장된 이력을 바탕으로 사용자가 어떤 퀴즈에 강하고 약한지를 분석할 수 있습니다. 이를 통해 학습 전략을 개선할 수 있습니다.

## 퀴즈 히스토리 및 분석 사용 방법

### 퀴즈 이력 저장하기

사용자가 퀴즈를 완료할 때마다 이력을 저장하는 간단한 예제입니다.

```python
class QuizHistory:
    def __init__(self):
        self.history = []

    def save_result(self, quiz_id, score):
        # 퀴즈 결과 저장
        self.history.append((quiz_id, score))
        print(f"퀴즈 {quiz_id}에 대한 점수가 저장되었습니다: {score}")

# 퀴즈 이력 저장
quiz_history = QuizHistory()
quiz_history.save_result("quiz001", 85)
```

위 코드에서는 `QuizHistory` 클래스를 통해 사용자 퀴즈 점수를 저장할 수 있습니다. `save_result` 메소드는 퀴즈 ID와 점수를 받아서 저장합니다.

### 퀴즈 성과 분석하기

저장된 결과를 기반으로 성과를 분석할 수 있습니다.

```python
def analyze_performance(history):
    # 평균 점수 계산
    total_score = sum(score for _, score in history)
    average_score = total_score / len(history) if history else 0
    print(f"평균 점수: {average_score}")

# 성과 분석
analyze_performance(quiz_history.history)
```

여기서는 퀴즈 이력의 평균 점수를 계산하여 출력합니다. 이를 통해 사용자는 전반적인 성과를 파악할 수 있습니다.

## 내부 구현 이해

퀴즈 히스토리 및 분석이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant QH as 퀴즈 히스토리
    participant DB as 데이터베이스

    U->>QH: 퀴즈 완료 결과 전송
    QH->>DB: 이력 저장
    DB->>QH: 저장 확인
    QH->>U: 저장 완료 메시지
    U->>QH: 성과 분석 요청
    QH->>U: 분석 결과 전송
```

위 다이어그램이 보여주듯이, 사용자가 퀴즈를 완료하면 결과가 저장되고, 그 결과를 바탕으로 성과를 분석해줍니다.

### 내부 코드 분석

`QuizHistory` 클래스의 내부 구현을 좀 더 살펴보겠습니다.

```python
class QuizHistory:
    def __init__(self):
        self.history = []
        
    def save_result(self, quiz_id, score):
        self.history.append((quiz_id, score))

    def analyze_performance(self):
        total_score = sum(score for _, score in self.history)
        average_score = total_score / len(self.history) if self.history else 0
        return average_score
```

이 클래스는 퀴즈 결과를 저장하고, 평균 점수를 계산하여 성과를 단순히 분석하는 메소드를 포함합니다. 이는 학습 진척도를 측정하는 데 도움이 됩니다.

## 결론

이번 장에서는 퀴즈 히스토리 및 분석의 개념과 이를 사용하여 학습 성과를 측정하고 분석하는 방법을 배웠습니다. 이를 통해 사용자는 자신의 학습 약점을 파악하고, 보다 효과적인 학습 계획을 세울 수 있습니다. 다음 장에서는 [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)에 대해 알아보겠습니다. 기대해주세요!
2025-06-29 21:04:07,297 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN_ToyProject` about the concept: "GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)". This is Chapter 8.

Concept Details (Note: Provided in Korean):
- Name: GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)
- Description:
사용자의 자연어 쿼리를 처리하고, 데이터베이스와 상호작용하며 다양한 커리큘럼 및 프로젝트 관련 데이터를 제공합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)
2. [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)
3. [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)
4. [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)
5. [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)
6. [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)
7. [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)
8. [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)
9. [추천 시스템 (Recommendation System)](09_추천_시스템__recommendation_system_.md)
10. [기술 스택 관리 (Tech Stack Management)](10_기술_스택_관리__tech_stack_management_.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 관리 인터페이스 (Admin Interface)

`SKN_ToyProject`에 오신 것을 환영합니다! 이 장에서는 관리 인터페이스(Admin Interface)의 개념에 대해 알아보겠습니다. 관리 인터페이스는 데이터를 관리하고 시각화하는 데 매우 중요한 도구입니다. 관리자가 다양한 모델 객체를 효율적으로 다루는 방법을 배울 수 있습니다.

## 관리 인터페이스란 무엇인가요?

관리 인터페이스는 프로젝트 내에서 데이터를 쉽게 시각화하고 조작할 수 있도록 도와주는 도구입니다. 예를 들어, 웹사이트의 관리자 페이지를 생각해보세요. 사용자가 데이터를 입력하면, 관리자는 이 데이터가 어떻게 저장되고, 표현되는지를 이 페이지에서 직접 확인하고 변경할 수 있습니다. 바로 이런 역할을 하는 것이 관리 인터페이스입니다.

## 관리 인터페이스의 주요 개념

### 1. 데이터 시각화
관리 인터페이스는 데이터를 표 형태로 보여줍니다. 이는 사용자가 데이터를 한눈에 이해할 수 있게 도와줍니다.

### 2. 데이터 조작
사용자는 인터페이스를 통해 데이터를 직접 추가, 수정, 삭제할 수 있습니다. 이를 통해 데이터 관리가 훨씬 더 직관적이고 효율적이 됩니다.

## 관리 인터페이스 사용 방법

이제 간단한 예제로 관리 인터페이스를 사용하는 방법을 살펴보겠습니다.

```python
from admin_interface import Admin

# 관리자 인터페이스 초기화
admin = Admin()

# 데이터 추가
admin.add_model('새로운 모델 객체')

# 데이터 목록 보기
print(admin.list_models())  # ['새로운 모델 객체']
```

첫 줄에서 관리 인터페이스를 불러오고, 두 번째 줄에서 관리 인터페이스를 초기화합니다. 그 후, `add_model` 메소드를 통해 데이터를 추가하고, `list_models`를 통해 현재 데이터를 확인할 수 있습니다.

## 관리 인터페이스의 내부 구조

관리 인터페이스가 어떻게 내부적으로 동작하는지 간단히 살펴보겠습니다. 관리 인터페이스가 호출되면, 다음과 같은 단계를 거칩니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant AI as 관리 인터페이스
    participant DB as 데이터베이스

    U->>AI: 데이터 추가 요청
    AI->>DB: 데이터 저장 요청
    DB->>AI: 저장 완료 응답
    AI->>U: 처리 결과 전달
```

`사용자`가 관리 인터페이스를 통해 데이터를 추가하면, `관리 인터페이스`는 이를 `데이터베이스`에 저장하고 결과를 다시 사용자에게 전달합니다.

### 코드를 통한 내부 구조 이해

관리 인터페이스의 내부 구현을 간단한 코드로 살펴보겠습니다.

```python
class Admin:
    def __init__(self):
        self.models = []

    def add_model(self, model_name):
        # 모델 추가
        self.models.append(model_name)

    def list_models(self):
        # 모델 목록 반환
        return self.models
```

`Admin` 클래스는 모델 목록을 관리합니다. `add_model` 메소드는 모델을 추가하고, `list_models` 메소드는 현재 모델 목록을 반환합니다.

## 결론

이 장에서는 관리 인터페이스의 기본 개념과 사용 방법을 배웠습니다. 관리 인터페이스는 프로젝트 내 데이터를 효율적으로 관리하는 데 매우 유용한 도구입니다. 

다음 장에서는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 2: 커리큘럼 모델 (Curriculum Model)

이전 장에서는 [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)에 대해 알아보았습니다. 이제 우리는 커리큘럼 모델에 대해 설명할 것입니다. 이는 교육 커리큘럼을 정의하고 관리하기 위한 핵심 데이터 구조입니다. 초심자를 위한 설명을 통해 쉽게 따라올 수 있도록 하겠습니다.

## 커리큘럼 모델이란 무엇인가요?

커리큘럼 모델은 교육 콘텐츠를 체계적으로 관리하기 위한 데이터 구조입니다. 이를 통해 우리는 다양한 사용자에 맞춘 교육 경로를 계획하고 조정할 수 있습니다. 대표적인 예로 프로그래밍 학습 플랫폼에서 다양한 난이도별 코스를 제공하는 것을 들 수 있습니다.

### 커리큘럼 모델의 주요 개념

- **사용자 아이디**: 커리큘럼이 특정 사용자에게 할당되었음을 나타냅니다.
- **커리큘럼 타입**: 커리큘럼의 유형(예: 입문, 중급, 고급)을 정의합니다.
- **커리큘럼 이름**: 사용자가 이해하기 쉽고 식별할 수 있도록 지정합니다.
- **키워드**: 커리큘럼의 핵심 주제를 빠르게 파악할 수 있게 도와줍니다.

## 커리큘럼 모델 사용 방법

이제 간단한 커리큘럼 객체를 생성하고 사용하는 방법을 살펴보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        # 사용자 아이디 저장
        self.user_id = user_id
        # 커리큘럼 타입 저장
        self.cur_type = cur_type
        # 커리큘럼 이름 저장
        self.name = name
        # 키워드 저장
        self.keywords = keywords

# 커리큘럼 객체 생성
my_curriculum = CurriculumModel('user123', '입문', '파이썬 기본', ['프로그래밍', '파이썬'])
```

위 코드에서는 `CurriculumModel` 클래스를 정의하고 인스턴스를 생성했습니다. 각 인스턴스는 사용자 아이디, 커리큘럼 타입, 이름, 키워드를 포함합니다. 이와 같은 방식을 통해 다양한 커리큘럼을 효과적으로 관리할 수 있습니다.

## 내부 구현의 이해

커리큘럼 모델이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다. 이는 주로 객체가 생성되어, 데이터를 처리를 하는 과정을 보여줍니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant C as 커리큘럼 모델
    participant DB as 데이터베이스

    U->>C: 새로운 커리큘럼 생성 요청
    C->>DB: 커리큘럼 저장
    DB->>C: 저장 완료 응답
    C->>U: 생성 결과 전달
```

위 시퀀스 다이어그램은 사용자가 커리큘럼을 생성하면 그 요청이 데이터베이스에 저장되는 과정을 보여줍니다.

### 내부 코드 분석

커리큘럼 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        self.user_id = user_id
        self.cur_type = cur_type
        self.name = name
        self.keywords = keywords
    
    def save_to_db(self):
        # 데이터베이스에 커리큘럼 저장
        print(f"커리큘럼 '{self.name}'이 저장되었습니다.")
```

`CurriculumModel` 클래스에는 생성자 외에도 커리큘럼을 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 커리큘럼 모델이 무엇인지, 이를 사용하여 데이터를 어떻게 관리할 수 있는지를 배웠습니다. 이를 통해 다양한 교육 경로를 효율적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 알아보겠습니다. 함께 탐구해 봅시다!
---
# Chapter 3: 프로젝트 모델 (Project Model)

이전 장에서 우리는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 배웠습니다. 이제 `SKN_ToyProject`에서 사용될 프로젝트 모델에 대해 알아보겠습니다. 이 장에서는 프로젝트 모델이 무엇인지, 그리고 어떻게 사용해야 하는지를 간단하게 설명하겠습니다.

## 프로젝트 모델이란 무엇인가요?

프로젝트 모델은 사용자의 프로젝트에 관한 정보를 체계적으로 저장하고 관리하기 위한 데이터 구조입니다. 이를 통해 프로젝트 이름, 시작 및 종료 날짜, 그리고 팀원 수 등 다양한 정보를 손쉽게 다룰 수 있습니다.

### 핵심 사례

상상해보세요, 팀과 함께 새로운 웹사이트를 만드는 프로젝트를 시작한다고 가정할 때, 이 프로젝트 모델은 다음과 같은 정보를 체계적으로 보관할 수 있어요.

- 프로젝트 이름: "웹사이트 개발"
- 시작 날짜: "2023-06-01"
- 종료 날짜: "2023-12-31"
- 팀원 수: 5명

이렇게 프로젝트 모델을 사용하면 전체 프로젝트 일정을 더욱 명확하게 관리할 수 있습니다.

## 프로젝트 모델 주요 개념

### 1. 프로젝트 이름
프로젝트의 가장 기본적인 식별자 역할을 합니다.

### 2. 시작 및 종료 날짜
프로젝트의 기간을 지정합니다. 이를 통해 일정을 체계적으로 관리할 수 있습니다.

### 3. 팀원 수
프로젝트에 참여하는 인원의 수를 의미합니다.

## 프로젝트 모델 사용 방법

`ProjectModel` 클래스를 사용하여 프로젝트 객체를 생성할 수 있습니다. 다음은 간단한 예제 코드입니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        # 프로젝트 이름 저장
        self.name = name
        # 시작 날짜 저장
        self.start_date = start_date
        # 종료 날짜 저장
        self.end_date = end_date
        # 팀원 수 저장
        self.team_members = team_members

# 프로젝트 객체 생성
my_project = ProjectModel("웹사이트 개발", "2023-06-01", "2023-12-31", 5)
```

위 코드에서는 `ProjectModel` 클래스를 정의하고, 해당 클래스의 인스턴스를 생성했습니다. 각 인스턴스는 프로젝트 이름, 시작 및 종료 날짜, 팀원 수를 저장합니다.

### 프로젝트 모델의 동작 과정

이제 프로젝트 모델의 작동 방식에 대해 간단한 시퀀스 다이어그램을 통해 알아보겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant P as 프로젝트 모델
    participant DB as 데이터베이스

    U->>P: 프로젝트 생성 요청
    P->>DB: 프로젝트 정보 저장
    DB->>P: 저장 완료 응답
    P->>U: 생성 성공 메시지 전달
```

사용자가 프로젝트를 생성하면, 프로젝트 모델은 데이터를 데이터베이스에 저장합니다. 이후, 저장이 완료되면 사용자는 성공 메시지를 받게 됩니다.

## 내부 코드 이해

프로젝트 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        self.name = name
        self.start_date = start_date
        self.end_date = end_date
        self.team_members = team_members
    
    def save_to_db(self):
        # 데이터베이스에 프로젝트 저장
        print(f"프로젝트 '{self.name}'이 저장되었습니다.")
```

`ProjectModel` 클래스에는 생성자 외에도 프로젝트를 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 프로젝트 모델이 무엇이며, 이를 어떻게 사용하는지를 배웠습니다. 프로젝트 모델은 사용자의 프로젝트 정보를 관리하기 위한 강력한 도구입니다. 다음 장에서는 [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 4: 커리큘럼 뷰 (Curriculum Views)

이전 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 배워봤습니다. 이번 장에서는 `SKN_ToyProject`에서 커리큘럼 데이터를 어떻게 조회하고, 추가하고, 삭제하며, 맞춤형 커리큘럼을 생성하는지에 대해 알아보겠습니다. 이는 사용자가 다양한 교육 콘텐츠를 손쉽게 관리할 수 있도록 돕는 기능입니다. 초보자도 쉽게 따라갈 수 있도록 최대한 간단하게 설명하겠습니다.

---

## 커리큘럼 뷰란 무엇인가요?

커리큘럼 뷰는 프로젝트 내 여러 커리큘럼과 관련된 작업을 수행할 수 있는 인터페이스를 제공합니다. 예를 들어, 교육 플랫폼에서 새로운 강좌를 추가하거나 기존 강좌를 삭제하는 경우를 생각할 수 있습니다. 이를 통해 사용자들은 자신이 원하는 대로 커리큘럼을 조정할 수 있습니다.

### 커리큘럼 뷰가 해결하는 문제

- **데이터 조회**: 사용자에게 필요한 커리큘럼 정보를 손쉽게 조회할 수 있습니다.
- **데이터 추가**: 새로운 커리큘럼을 추가하여 교육 콘텐츠를 확장할 수 있습니다.
- **데이터 삭제**: 불필요한 커리큘럼을 삭제하여 관리 효율성을 높일 수 있습니다.
- **맞춤형 커리큘럼 생성**: 사용자에게 맞춤형 학습 경로를 제공합니다.

## 커리큘럼 뷰의 주요 기능

### 1. 커리큘럼 조회

아래 코드는 커리큘럼 목록을 조회하는 간단한 예제입니다.

```python
def get_curriculums():
    # 커리큘럼 목록 조회
    return ["커리큘럼1", "커리큘럼2", "커리큘럼3"]

# 커리큘럼 목록 출력
print(get_curriculums())
```

이 코드는 `get_curriculums` 함수를 통해 현재 저장된 커리큘럼들을 출력합니다.

### 2. 커리큘럼 추가

커리큘럼을 추가하는 방법은 다음과 같습니다.

```python
def add_curriculum(name):
    # 새로운 커리큘럼 추가
    print(f"{name} 커리큘럼이 추가되었습니다.")

# 새 커리큘럼 추가
add_curriculum("파이썬 기초")
```

여기서 `add_curriculum` 함수는 새로운 커리큘럼 이름을 받아서 추가 작업을 수행합니다.

### 3. 커리큘럼 삭제

커리큘럼 삭제도 매우 간단하게 이루어집니다.

```python
def delete_curriculum(name):
    # 커리큘럼 삭제
    print(f"{name} 커리큘럼이 삭제되었습니다.")

# 기존 커리큘럼 삭제
delete_curriculum("커리큘럼1")
```

`delete_curriculum` 함수는 지정된 이름의 커리큘럼을 삭제합니다.

### 4. 맞춤형 커리큘럼 생성

사용자 맞춤 커리큘럼을 생성하여 유저 경험을 향상시킬 수 있습니다.

```python
def create_custom_curriculum(user_id, preferences):
    # 사용자 맞춤 커리큘럼 생성
    print(f"사용자 {user_id}를 위한 맞춤형 커리큘럼이 생성되었습니다.")

# 맞춤형 커리큘럼 생성
create_custom_curriculum("user123", ["프로그래밍", "데이터 분석"])
```

이 코드는 사용자 ID와 선호 분야들을 이용해 맞춤형 커리큘럼을 생성합니다.

## 내부 구현 이해

이제 내부적으로 커리큘럼 뷰가 어떻게 동작하는지 간단하게 설명하겠습니다. 각 기능이 어떻게 상호작용하는지 보기 위해 시퀀스 다이어그램을 사용합니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant CV as 커리큘럼 뷰
    participant DB as 데이터베이스

    U->>CV: 커리큘럼 조회 요청
    CV->>DB: 조회 쿼리 전송
    DB->>CV: 응답 반환
    CV->>U: 커리큘럼 목록 전달
```

여기서 사용자가 커리큘럼 뷰로 요청을 하면, 커리큘럼 뷰는 데이터베이스에 쿼리를 날리고, 그 결과를 사용자에게 반환합니다.

### 내부 코드 구현

커리큘럼 뷰의 데이터 흐름은 아래와 같이 구성됩니다.

```python
class CurriculumView:
    def __init__(self):
        self.curriculums = []

    def add(self, name):
        self.curriculums.append(name)
        print(f"커리큘럼 '{name}'이 추가되었습니다.")

    def remove(self, name):
        if name in self.curriculums:
            self.curriculums.remove(name)
            print(f"커리큘럼 '{name}'이 삭제되었습니다.")
        else:
            print("커리큘럼이 존재하지 않습니다.")
```

위 `CurriculumView` 클래스는 커리큘럼 목록을 관리하기 위한 기본적인 기능을 제공합니다. `add`와 `remove` 메소드를 통해 커리큘럼을 추가하고 삭제할 수 있습니다.

---

## 결론

이번 장에서는 커리큘럼 뷰를 통해 어떻게 데이터를 조회하고, 추가하고, 삭제하며 맞춤형 커리큘럼을 생성할 수 있는지를 배웠습니다. 이를 통해 사용자 맞춤형 교육 콘텐츠를 효과적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)에 대해 설명하겠습니다. 기대해주세요!
---
# Chapter 5: 프로젝트 뷰 (Project Views)

이전 장에서는 [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)에 대해 배웠습니다. 이번 장에서는 `SKN_ToyProject`에서 `프로젝트 뷰 (Project Views)`에 대해 알아보도록 하겠습니다. 프로젝트 뷰는 프로젝트와 관련된 데이터를 조회하고, 새로운 프로젝트를 추가하거나, 기존 프로젝트를 수정하는 API 엔드포인트를 제공합니다. 이 장에서는 이러한 기능들을 어떻게 활용할 수 있는지를 살펴보겠습니다.

## 프로젝트 뷰란 무엇인가요?

프로젝트 뷰는 사용자가 프로젝트와 관련된 데이터를 효율적으로 관리할 수 있게 해주는 도구입니다. 예를 들어, 팀 프로젝트를 진행하는 동안 관련 정보를 효율적으로 조회하고 필요에 따라 수정할 수 있습니다.

### 프로젝트 뷰의 주요 기능

- **프로젝트 조회**: 기존 프로젝트의 정보를 확인할 수 있습니다.
- **프로젝트 추가**: 새로운 프로젝트를 데이터베이스에 저장할 수 있습니다.
- **프로젝트 수정**: 등록된 프로젝트 정보를 업데이트할 수 있습니다.

## 프로젝트 뷰 사용 방법

이제 간단한 예제를 통해 프로젝트 뷰를 어떻게 사용할 수 있는지 알아보겠습니다.

### 1. 프로젝트 조회하기

프로젝트 데이터를 조회할 수 있는 간단한 코드를 작성해 봅시다.

```python
def get_projects():
    # 프로젝트 목록 조회
    return ["프로젝트 A", "프로젝트 B", "프로젝트 C"]

# 프로젝트 목록 출력
print(get_projects())
```

위 코드에서는 `get_projects` 함수를 통해 등록된 모든 프로젝트를 조회할 수 있습니다. 이 함수는 프로젝트 이름의 리스트를 반환합니다.

### 2. 새로운 프로젝트 추가하기

다음은 새로운 프로젝트를 추가하는 방법입니다.

```python
def add_project(name):
    # 새로운 프로젝트 추가
    print(f"{name} 프로젝트가 추가되었습니다.")

# 프로젝트 추가
add_project("프로젝트 D")
```

이 코드에서 `add_project` 함수는 프로젝트 이름을 받아 새로운 프로젝트를 추가하는 기능을 수행합니다.

### 3. 기존 프로젝트 수정하기

다음으로 프로젝트 정보를 수정하는 방법을 살펴보겠습니다.

```python
def update_project(old_name, new_name):
    # 프로젝트 이름 수정
    print(f"{old_name}가 {new_name}로 변경되었습니다.")

# 프로젝트 수정
update_project("프로젝트 A", "프로젝트 Z")
```

위 코드에서는 `update_project` 함수를 사용하여 기존 프로젝트의 이름을 업데이트할 수 있습니다.

## 내부 구현 이해

프로젝트 뷰의 내부에서 발생하는 상호작용을 간단하게 설명하겠습니다. 프로젝트의 생성, 조회, 수정 과정을 시퀀스 다이어그램을 통해 이해해 봅시다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant PV as 프로젝트 뷰
    participant DB as 데이터베이스

    U->>PV: 프로젝트 조회 요청
    PV->>DB: 조회 쿼리 전송
    DB->>PV: 응답 반환
    PV->>U: 프로젝트 목록 전달

    U->>PV: 프로젝트 추가 요청
    PV->>DB: 새로운 프로젝트 저장
    DB->>PV: 저장 성공 메시지 반환
    PV->>U: 프로젝트 추가 성공 메시지 전달

    U->>PV: 프로젝트 수정 요청
    PV->>DB: 프로젝트 업데이트
    DB->>PV: 업데이트 성공 메시지 반환
    PV->>U: 프로젝트 수정 성공 메시지 전달
```

각 기능은 데이터베이스와 상호작용하여 데이터를 효율적으로 처리합니다.

### 내부 코드 구현

이제 프로젝트 뷰의 내부 구현에 대한 코드를 살펴보겠습니다.

```python
class ProjectView:
    def __init__(self):
        self.projects = []

    def add(self, name):
        self.projects.append(name)
        print(f"프로젝트 '{name}'이 추가되었습니다.")

    def update(self, old_name, new_name):
        if old_name in self.projects:
            self.projects[self.projects.index(old_name)] = new_name
            print(f"프로젝트 '{old_name}'이 '{new_name}'로 변경되었습니다.")
        else:
            print("프로젝트가 존재하지 않습니다.")
```

`ProjectView` 클래스는 프로젝트 목록을 관리하며, `add`와 `update` 메소드를 통해 프로젝트를 추가하고 수정할 수 있는 기능을 제공합니다.

## 결론

이번 장에서는 프로젝트 뷰가 제공하는 기본적인 기능을 이용해 프로젝트 데이터를 조회하고 추가 및 수정하는 방법을 배웠습니다. 이를 통해 사용자는 프로젝트와 관련된 데이터를 효율적으로 관리할 수 있습니다. 다음 장에서는 [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)에 대해 배워보겠습니다. 함께 탐구해봅시다!
---
# Chapter 6: 사용자 및 커리큘럼 관계 (User and Curriculum Relationship)

이전 장에서는 [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)에 대해 배웠습니다. 이제 `SKN_ToyProject`에서 사용자와 커리큘럼 간의 관계를 어떻게 정의하고 관리할 수 있는지에 대해 알아볼 차례입니다. 이는 각 사용자가 커리큘럼을 어떻게 완료했는지를 추적하고 관리할 수 있도록 도와주는 핵심 기능입니다.

## 사용자 및 커리큘럼 관계란 무엇인가요?

사용자 및 커리큘럼 관계는 사용자가 어떤 커리큘럼을 완료했는지를 추적합니다. 예를 들어, 여러분이 온라인 학습 플랫폼에서 여러 강의를 수강할 때, 이 관계를 통해 어떤 강의를 완료했는지 기록하고 확인할 수 있습니다. 이를 통해 여러분은 학습 진척도를 쉽게 관리할 수 있습니다.

### 사용자 및 커리큘럼 관계의 주요 개념

- **사용자 식별자(User ID)**: 각 사용자를 고유하게 식별합니다.
- **커리큘럼 식별자(Curriculum ID)**: 커리큘럼을 고유하게 식별합니다.
- **완료 상태(Completion Status)**: 사용자가 커리큘럼을 완료했는지 여부를 추적합니다.

## 사용자 및 커리큘럼 관계 사용 방법

이제 이 관계를 어떻게 코드로 구현하고 활용할 수 있는지 간단한 예제를 통해 살펴보겠습니다.

### 1. 사용자와 커리큘럼 간의 관계 정의하기

```python
class UserCurriculumRelation:
    def __init__(self, user_id, curriculum_id, completed=False):
        # 사용자 ID 저장
        self.user_id = user_id
        # 커리큘럼 ID 저장
        self.curriculum_id = curriculum_id
        # 완료 상태 저장
        self.completed = completed

# 관계 생성
relation = UserCurriculumRelation("user123", "curriculum456")
```

이 코드에서는 `UserCurriculumRelation` 클래스가 사용자와 커리큘럼 간의 관계를 나타냅니다. 각 관계는 사용자 ID, 커리큘럼 ID, 그리고 완료 상태를 포함합니다.

### 2. 완료 상태 업데이트하기

사용자가 커리큘럼을 완료했을 때, 완료 상태를 업데이트할 수 있습니다.

```python
def mark_complete(relation):
    # 완료 상태 업데이트
    relation.completed = True
    print(f"사용자 {relation.user_id}가 커리큘럼 {relation.curriculum_id}를 완료했습니다.")

# 완료 상태 업데이트 호출
mark_complete(relation)
```

위 함수는 `relation` 객체의 완료 상태를 `True`로 변경하며 완료 메시지를 출력합니다.

## 내부 구현 이해

이제 사용자와 커리큘럼 간의 관계가 어떻게 동작하는지 시퀀스 다이어그램을 통해 설명하겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant UR as 사용자 관계
    participant DB as 데이터베이스

    U->>UR: 커리큘럼 완료 요청
    UR->>DB: 완료 상태 업데이트
    DB->>UR: 업데이트 확인
    UR->>U: 완료 상태 확인 및 전달
```

이 다이어그램에서는 사용자가 커리큘럼을 완료한다고 요청하고, 그 상태가 데이터베이스에 업데이트 되는 과정을 보여줍니다.

### 내부 코드 분석

다음으로 `UserCurriculumRelation` 클래스의 간단한 내부 구현을 살펴보겠습니다.

```python
class UserCurriculumRelation:
    def __init__(self, user_id, curriculum_id, completed=False):
        self.user_id = user_id
        self.curriculum_id = curriculum_id
        self.completed = completed
        
    def save_to_db(self):
        # 완료 상태를 데이터베이스에 저장
        print(f"커리큘럼 '{self.curriculum_id}'의 완료 상태가 저장되었습니다.")
```

`save_to_db` 메소드는 완료 상태를 데이터베이스에 저장하는 기능을 합니다. 이는 사용자의 완벽한 학습 기록을 관리하는 데 필수적입니다.

## 결론

이번 장에서는 사용자와 커리큘럼 간의 관계를 어떻게 정의하고, 완료 상태를 추적할 수 있는지를 배웠습니다. 이는 사용자 학습의 진척도를 파악하는 데 중요한 역할을 합니다. 이후 장에서는 [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)에 대해 알아보겠습니다. 함께 배워봅시다!
---
# Chapter 7: 퀴즈 히스토리 및 분석 (Quiz History and Analysis)

이전 장에서는 [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)에 대해 배워보았습니다. 이번 장에서는 사용자 퀴즈 히스토리 및 성과를 분석하는 방법에 대해 알아보겠습니다. 이를 통해 사용자는 자신의 학습 진척도를 파악하고, 더 나은 학습 계획을 세울 수 있습니다.

## 문제 해결을 위한 배경

퀴즈 히스토리 및 분석 기능은 사용자가 완료한 퀴즈의 이력을 저장하고, 이를 바탕으로 성과를 평가하여 개선점을 찾을 수 있도록 돕습니다. 예를 들어, 학생이 여러 과목의 퀴즈를 푸는 동안 어떤 과목이 상대적으로 약한지를 파악할 수 있게 되는 것입니다.

## 퀴즈 히스토리의 주요 개념

### 1. 퀴즈 이력 저장
사용자가 퀴즈를 완료하면, 그 결과가 저장됩니다. 이는 나중에 분석하여 성과를 평가하는 데 사용됩니다.

### 2. 퀴즈 성과 분석
저장된 이력을 바탕으로 사용자가 어떤 퀴즈에 강하고 약한지를 분석할 수 있습니다. 이를 통해 학습 전략을 개선할 수 있습니다.

## 퀴즈 히스토리 및 분석 사용 방법

### 퀴즈 이력 저장하기

사용자가 퀴즈를 완료할 때마다 이력을 저장하는 간단한 예제입니다.

```python
class QuizHistory:
    def __init__(self):
        self.history = []

    def save_result(self, quiz_id, score):
        # 퀴즈 결과 저장
        self.history.append((quiz_id, score))
        print(f"퀴즈 {quiz_id}에 대한 점수가 저장되었습니다: {score}")

# 퀴즈 이력 저장
quiz_history = QuizHistory()
quiz_history.save_result("quiz001", 85)
```

위 코드에서는 `QuizHistory` 클래스를 통해 사용자 퀴즈 점수를 저장할 수 있습니다. `save_result` 메소드는 퀴즈 ID와 점수를 받아서 저장합니다.

### 퀴즈 성과 분석하기

저장된 결과를 기반으로 성과를 분석할 수 있습니다.

```python
def analyze_performance(history):
    # 평균 점수 계산
    total_score = sum(score for _, score in history)
    average_score = total_score / len(history) if history else 0
    print(f"평균 점수: {average_score}")

# 성과 분석
analyze_performance(quiz_history.history)
```

여기서는 퀴즈 이력의 평균 점수를 계산하여 출력합니다. 이를 통해 사용자는 전반적인 성과를 파악할 수 있습니다.

## 내부 구현 이해

퀴즈 히스토리 및 분석이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant QH as 퀴즈 히스토리
    participant DB as 데이터베이스

    U->>QH: 퀴즈 완료 결과 전송
    QH->>DB: 이력 저장
    DB->>QH: 저장 확인
    QH->>U: 저장 완료 메시지
    U->>QH: 성과 분석 요청
    QH->>U: 분석 결과 전송
```

위 다이어그램이 보여주듯이, 사용자가 퀴즈를 완료하면 결과가 저장되고, 그 결과를 바탕으로 성과를 분석해줍니다.

### 내부 코드 분석

`QuizHistory` 클래스의 내부 구현을 좀 더 살펴보겠습니다.

```python
class QuizHistory:
    def __init__(self):
        self.history = []
        
    def save_result(self, quiz_id, score):
        self.history.append((quiz_id, score))

    def analyze_performance(self):
        total_score = sum(score for _, score in self.history)
        average_score = total_score / len(self.history) if self.history else 0
        return average_score
```

이 클래스는 퀴즈 결과를 저장하고, 평균 점수를 계산하여 성과를 단순히 분석하는 메소드를 포함합니다. 이는 학습 진척도를 측정하는 데 도움이 됩니다.

## 결론

이번 장에서는 퀴즈 히스토리 및 분석의 개념과 이를 사용하여 학습 성과를 측정하고 분석하는 방법을 배웠습니다. 이를 통해 사용자는 자신의 학습 약점을 파악하고, 보다 효과적인 학습 계획을 세울 수 있습니다. 다음 장에서는 [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)에 대해 알아보겠습니다. 기대해주세요!

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 8: GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 21:04:07,629 - INFO - Using OpenAI model: gpt-4o
2025-06-29 21:04:23,262 - INFO - RESPONSE: # Chapter 8: GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)

이전 장에서는 [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)에 대해 배웠습니다. 이번 장에서는 `GPT 기반 AI 어시스턴트`를 알아보겠습니다. 이 시스템은 사용자의 자연어 쿼리를 처리하여 데이터베이스와 상호작용하며 다양한 커리큘럼 및 프로젝트 관련 데이터를 제공하는 매우 강력한 도구입니다.

## 문제 해결을 위한 배경

여러 교육 플랫폼에서 우리는 사용자가 특정 정보를 검색하거나 문의할 때 즉각적인 답변을 제공하는 것이 점점 더 중요해지고 있습니다. 예를 들어, 사용자가 "다음 주에 예정된 퀴즈가 무엇인가요?" 라고 물을 때, AI 어시스턴트는 관련 정보를 신속하게 제공할 수 있습니다.

### 주요 기능

- **자연어 처리 (NLP)**: 사용자의 쿼리를 이해하고 해석합니다.
- **데이터베이스 인터페이스**: 사용자 질문에 기반하여 필요한 데이터를 조회합니다.
- **응답 생성**: 분석된 데이터를 바탕으로 사용자가 이해하기 쉬운 응답을 생성합니다.

## GPT 기반 AI 어시스턴트 사용 방법

이제 GPT 기반 AI 어시스턴트가 어떻게 작동하는지 간단한 예제를 통해 알아보겠습니다.

### 1. 사용자 쿼리 이해하기

먼저 사용자의 자연어 쿼리를 AI가 처리하는 방법을 살펴봅니다.

```python
def process_query(query):
    # 입력된 자연어 쿼리 처리
    print(f"쿼리 처리 중: {query}")

# 예시 쿼리 처리
process_query("다음 주 퀴즈 일정은?")
```

이 코드에서는 `process_query` 함수가 사용자의 쿼리를 입력받아 처리 과정을 시작합니다.

### 2. 데이터베이스와 상호작용하기

처리된 쿼리를 바탕으로 데이터베이스에서 필요한 정보를 가져옵니다.

```python
def fetch_data_from_db(query_params):
    # 데이터베이스에서 관련 데이터를 가져옴
    print(f"데이터베이스에서 {query_params} 관련 데이터 조회")

# 쿼리 파라미터로 데이터 조회
fetch_data_from_db("퀴즈 일정")
```

여기서는 `fetch_data_from_db` 함수가 데이터베이스에서 사용자 요청에 맞는 데이터를 조회합니다.

### 3. 응답 생성하기

조회된 데이터를 바탕으로 사용자에게 적절한 응답을 제공합니다.

```python
def generate_response(data):
    # 사용자에게 전달할 응답 생성
    print(f"응답 생성: {data} 관련 정보입니다.")

# 데이터 기반 응답 생성
generate_response("다음 주 퀴즈 일정")
```

`generate_response` 함수는 얻어진 데이터를 바탕으로 사용자가 이해할 수 있는 응답을 생성하는 역할을 합니다.

## 내부 구현 이해

GPT 기반 AI 어시스턴트의 내부 과정은 다음 시퀀스 다이어그램을 통해 설명됩니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant AI as AI 어시스턴트
    participant NLP as 자연어 처리
    participant DB as 데이터베이스
    participant R as 응답 생성

    U->>AI: 자연어 쿼리 전송
    AI->>NLP: 쿼리 처리 요청
    NLP->>AI: 처리된 쿼리 반환
    AI->>DB: 데이터베이스 조회
    DB->>AI: 조회 결과 반환
    AI->>R: 응답 생성 요청
    R->>AI: 생성된 응답 반환
    AI->>U: 최종 응답 전달
```

이 다이어그램에서 사용자가 쿼리를 입력하면 AI 어시스턴트는 이를 이해하고 적절한 데이터를 조회하여 사용자에게 응답을 제공합니다.

### 내부 코드 분석

이제 GPT 기반 AI 어시스턴트의 핵심 코드를 살펴보겠습니다.

```python
class GPTAssistant:
    def __init__(self):
        self.database = {}

    def process_query(self, query):
        # 가상의 쿼리 처리
        print(f"쿼리 처리 중: {query}")
        return query

    def fetch_data(self, params):
        # 가상의 데이터 조회
        data = f"{params} 관련 데이터"
        return data

    def generate_response(self, data):
        # 응답 생성 및 반환
        response = f"응답: {data}"
        return response
```

위 `GPTAssistant` 클래스는 쿼리 처리, 데이터 조회 및 응답 생성을 담당하는 메소드를 가지고 있습니다. 이 클래스를 통해 사용자의 복잡한 요청을 이해하고 적절히 처리할 수 있습니다.

## 결론

이번 장에서는 GPT 기반 AI 어시스턴트의 기능과 이를 활용하여 사용자의 자연어 쿼리에 응답하는 방법을 배웠습니다. 이 시스템은 효율적인 정보 제공 및 사용자 경험 향상을 목표로 합니다. 다음 장에서는 [추천 시스템 (Recommendation System)](09_추천_시스템__recommendation_system_.md)에 대해 알아보겠습니다. 기대해주세요!
2025-06-29 21:04:23,279 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN_ToyProject` about the concept: "추천 시스템 (Recommendation System)". This is Chapter 9.

Concept Details (Note: Provided in Korean):
- Name: 추천 시스템 (Recommendation System)
- Description:
특정 커리큘럼이나 프로젝트의 유사 항목을 추천하여 사용자에게 더 나은 경험을 제공합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)
2. [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)
3. [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)
4. [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)
5. [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)
6. [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)
7. [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)
8. [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)
9. [추천 시스템 (Recommendation System)](09_추천_시스템__recommendation_system_.md)
10. [기술 스택 관리 (Tech Stack Management)](10_기술_스택_관리__tech_stack_management_.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 관리 인터페이스 (Admin Interface)

`SKN_ToyProject`에 오신 것을 환영합니다! 이 장에서는 관리 인터페이스(Admin Interface)의 개념에 대해 알아보겠습니다. 관리 인터페이스는 데이터를 관리하고 시각화하는 데 매우 중요한 도구입니다. 관리자가 다양한 모델 객체를 효율적으로 다루는 방법을 배울 수 있습니다.

## 관리 인터페이스란 무엇인가요?

관리 인터페이스는 프로젝트 내에서 데이터를 쉽게 시각화하고 조작할 수 있도록 도와주는 도구입니다. 예를 들어, 웹사이트의 관리자 페이지를 생각해보세요. 사용자가 데이터를 입력하면, 관리자는 이 데이터가 어떻게 저장되고, 표현되는지를 이 페이지에서 직접 확인하고 변경할 수 있습니다. 바로 이런 역할을 하는 것이 관리 인터페이스입니다.

## 관리 인터페이스의 주요 개념

### 1. 데이터 시각화
관리 인터페이스는 데이터를 표 형태로 보여줍니다. 이는 사용자가 데이터를 한눈에 이해할 수 있게 도와줍니다.

### 2. 데이터 조작
사용자는 인터페이스를 통해 데이터를 직접 추가, 수정, 삭제할 수 있습니다. 이를 통해 데이터 관리가 훨씬 더 직관적이고 효율적이 됩니다.

## 관리 인터페이스 사용 방법

이제 간단한 예제로 관리 인터페이스를 사용하는 방법을 살펴보겠습니다.

```python
from admin_interface import Admin

# 관리자 인터페이스 초기화
admin = Admin()

# 데이터 추가
admin.add_model('새로운 모델 객체')

# 데이터 목록 보기
print(admin.list_models())  # ['새로운 모델 객체']
```

첫 줄에서 관리 인터페이스를 불러오고, 두 번째 줄에서 관리 인터페이스를 초기화합니다. 그 후, `add_model` 메소드를 통해 데이터를 추가하고, `list_models`를 통해 현재 데이터를 확인할 수 있습니다.

## 관리 인터페이스의 내부 구조

관리 인터페이스가 어떻게 내부적으로 동작하는지 간단히 살펴보겠습니다. 관리 인터페이스가 호출되면, 다음과 같은 단계를 거칩니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant AI as 관리 인터페이스
    participant DB as 데이터베이스

    U->>AI: 데이터 추가 요청
    AI->>DB: 데이터 저장 요청
    DB->>AI: 저장 완료 응답
    AI->>U: 처리 결과 전달
```

`사용자`가 관리 인터페이스를 통해 데이터를 추가하면, `관리 인터페이스`는 이를 `데이터베이스`에 저장하고 결과를 다시 사용자에게 전달합니다.

### 코드를 통한 내부 구조 이해

관리 인터페이스의 내부 구현을 간단한 코드로 살펴보겠습니다.

```python
class Admin:
    def __init__(self):
        self.models = []

    def add_model(self, model_name):
        # 모델 추가
        self.models.append(model_name)

    def list_models(self):
        # 모델 목록 반환
        return self.models
```

`Admin` 클래스는 모델 목록을 관리합니다. `add_model` 메소드는 모델을 추가하고, `list_models` 메소드는 현재 모델 목록을 반환합니다.

## 결론

이 장에서는 관리 인터페이스의 기본 개념과 사용 방법을 배웠습니다. 관리 인터페이스는 프로젝트 내 데이터를 효율적으로 관리하는 데 매우 유용한 도구입니다. 

다음 장에서는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 2: 커리큘럼 모델 (Curriculum Model)

이전 장에서는 [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)에 대해 알아보았습니다. 이제 우리는 커리큘럼 모델에 대해 설명할 것입니다. 이는 교육 커리큘럼을 정의하고 관리하기 위한 핵심 데이터 구조입니다. 초심자를 위한 설명을 통해 쉽게 따라올 수 있도록 하겠습니다.

## 커리큘럼 모델이란 무엇인가요?

커리큘럼 모델은 교육 콘텐츠를 체계적으로 관리하기 위한 데이터 구조입니다. 이를 통해 우리는 다양한 사용자에 맞춘 교육 경로를 계획하고 조정할 수 있습니다. 대표적인 예로 프로그래밍 학습 플랫폼에서 다양한 난이도별 코스를 제공하는 것을 들 수 있습니다.

### 커리큘럼 모델의 주요 개념

- **사용자 아이디**: 커리큘럼이 특정 사용자에게 할당되었음을 나타냅니다.
- **커리큘럼 타입**: 커리큘럼의 유형(예: 입문, 중급, 고급)을 정의합니다.
- **커리큘럼 이름**: 사용자가 이해하기 쉽고 식별할 수 있도록 지정합니다.
- **키워드**: 커리큘럼의 핵심 주제를 빠르게 파악할 수 있게 도와줍니다.

## 커리큘럼 모델 사용 방법

이제 간단한 커리큘럼 객체를 생성하고 사용하는 방법을 살펴보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        # 사용자 아이디 저장
        self.user_id = user_id
        # 커리큘럼 타입 저장
        self.cur_type = cur_type
        # 커리큘럼 이름 저장
        self.name = name
        # 키워드 저장
        self.keywords = keywords

# 커리큘럼 객체 생성
my_curriculum = CurriculumModel('user123', '입문', '파이썬 기본', ['프로그래밍', '파이썬'])
```

위 코드에서는 `CurriculumModel` 클래스를 정의하고 인스턴스를 생성했습니다. 각 인스턴스는 사용자 아이디, 커리큘럼 타입, 이름, 키워드를 포함합니다. 이와 같은 방식을 통해 다양한 커리큘럼을 효과적으로 관리할 수 있습니다.

## 내부 구현의 이해

커리큘럼 모델이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다. 이는 주로 객체가 생성되어, 데이터를 처리를 하는 과정을 보여줍니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant C as 커리큘럼 모델
    participant DB as 데이터베이스

    U->>C: 새로운 커리큘럼 생성 요청
    C->>DB: 커리큘럼 저장
    DB->>C: 저장 완료 응답
    C->>U: 생성 결과 전달
```

위 시퀀스 다이어그램은 사용자가 커리큘럼을 생성하면 그 요청이 데이터베이스에 저장되는 과정을 보여줍니다.

### 내부 코드 분석

커리큘럼 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        self.user_id = user_id
        self.cur_type = cur_type
        self.name = name
        self.keywords = keywords
    
    def save_to_db(self):
        # 데이터베이스에 커리큘럼 저장
        print(f"커리큘럼 '{self.name}'이 저장되었습니다.")
```

`CurriculumModel` 클래스에는 생성자 외에도 커리큘럼을 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 커리큘럼 모델이 무엇인지, 이를 사용하여 데이터를 어떻게 관리할 수 있는지를 배웠습니다. 이를 통해 다양한 교육 경로를 효율적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 알아보겠습니다. 함께 탐구해 봅시다!
---
# Chapter 3: 프로젝트 모델 (Project Model)

이전 장에서 우리는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 배웠습니다. 이제 `SKN_ToyProject`에서 사용될 프로젝트 모델에 대해 알아보겠습니다. 이 장에서는 프로젝트 모델이 무엇인지, 그리고 어떻게 사용해야 하는지를 간단하게 설명하겠습니다.

## 프로젝트 모델이란 무엇인가요?

프로젝트 모델은 사용자의 프로젝트에 관한 정보를 체계적으로 저장하고 관리하기 위한 데이터 구조입니다. 이를 통해 프로젝트 이름, 시작 및 종료 날짜, 그리고 팀원 수 등 다양한 정보를 손쉽게 다룰 수 있습니다.

### 핵심 사례

상상해보세요, 팀과 함께 새로운 웹사이트를 만드는 프로젝트를 시작한다고 가정할 때, 이 프로젝트 모델은 다음과 같은 정보를 체계적으로 보관할 수 있어요.

- 프로젝트 이름: "웹사이트 개발"
- 시작 날짜: "2023-06-01"
- 종료 날짜: "2023-12-31"
- 팀원 수: 5명

이렇게 프로젝트 모델을 사용하면 전체 프로젝트 일정을 더욱 명확하게 관리할 수 있습니다.

## 프로젝트 모델 주요 개념

### 1. 프로젝트 이름
프로젝트의 가장 기본적인 식별자 역할을 합니다.

### 2. 시작 및 종료 날짜
프로젝트의 기간을 지정합니다. 이를 통해 일정을 체계적으로 관리할 수 있습니다.

### 3. 팀원 수
프로젝트에 참여하는 인원의 수를 의미합니다.

## 프로젝트 모델 사용 방법

`ProjectModel` 클래스를 사용하여 프로젝트 객체를 생성할 수 있습니다. 다음은 간단한 예제 코드입니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        # 프로젝트 이름 저장
        self.name = name
        # 시작 날짜 저장
        self.start_date = start_date
        # 종료 날짜 저장
        self.end_date = end_date
        # 팀원 수 저장
        self.team_members = team_members

# 프로젝트 객체 생성
my_project = ProjectModel("웹사이트 개발", "2023-06-01", "2023-12-31", 5)
```

위 코드에서는 `ProjectModel` 클래스를 정의하고, 해당 클래스의 인스턴스를 생성했습니다. 각 인스턴스는 프로젝트 이름, 시작 및 종료 날짜, 팀원 수를 저장합니다.

### 프로젝트 모델의 동작 과정

이제 프로젝트 모델의 작동 방식에 대해 간단한 시퀀스 다이어그램을 통해 알아보겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant P as 프로젝트 모델
    participant DB as 데이터베이스

    U->>P: 프로젝트 생성 요청
    P->>DB: 프로젝트 정보 저장
    DB->>P: 저장 완료 응답
    P->>U: 생성 성공 메시지 전달
```

사용자가 프로젝트를 생성하면, 프로젝트 모델은 데이터를 데이터베이스에 저장합니다. 이후, 저장이 완료되면 사용자는 성공 메시지를 받게 됩니다.

## 내부 코드 이해

프로젝트 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        self.name = name
        self.start_date = start_date
        self.end_date = end_date
        self.team_members = team_members
    
    def save_to_db(self):
        # 데이터베이스에 프로젝트 저장
        print(f"프로젝트 '{self.name}'이 저장되었습니다.")
```

`ProjectModel` 클래스에는 생성자 외에도 프로젝트를 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 프로젝트 모델이 무엇이며, 이를 어떻게 사용하는지를 배웠습니다. 프로젝트 모델은 사용자의 프로젝트 정보를 관리하기 위한 강력한 도구입니다. 다음 장에서는 [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 4: 커리큘럼 뷰 (Curriculum Views)

이전 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 배워봤습니다. 이번 장에서는 `SKN_ToyProject`에서 커리큘럼 데이터를 어떻게 조회하고, 추가하고, 삭제하며, 맞춤형 커리큘럼을 생성하는지에 대해 알아보겠습니다. 이는 사용자가 다양한 교육 콘텐츠를 손쉽게 관리할 수 있도록 돕는 기능입니다. 초보자도 쉽게 따라갈 수 있도록 최대한 간단하게 설명하겠습니다.

---

## 커리큘럼 뷰란 무엇인가요?

커리큘럼 뷰는 프로젝트 내 여러 커리큘럼과 관련된 작업을 수행할 수 있는 인터페이스를 제공합니다. 예를 들어, 교육 플랫폼에서 새로운 강좌를 추가하거나 기존 강좌를 삭제하는 경우를 생각할 수 있습니다. 이를 통해 사용자들은 자신이 원하는 대로 커리큘럼을 조정할 수 있습니다.

### 커리큘럼 뷰가 해결하는 문제

- **데이터 조회**: 사용자에게 필요한 커리큘럼 정보를 손쉽게 조회할 수 있습니다.
- **데이터 추가**: 새로운 커리큘럼을 추가하여 교육 콘텐츠를 확장할 수 있습니다.
- **데이터 삭제**: 불필요한 커리큘럼을 삭제하여 관리 효율성을 높일 수 있습니다.
- **맞춤형 커리큘럼 생성**: 사용자에게 맞춤형 학습 경로를 제공합니다.

## 커리큘럼 뷰의 주요 기능

### 1. 커리큘럼 조회

아래 코드는 커리큘럼 목록을 조회하는 간단한 예제입니다.

```python
def get_curriculums():
    # 커리큘럼 목록 조회
    return ["커리큘럼1", "커리큘럼2", "커리큘럼3"]

# 커리큘럼 목록 출력
print(get_curriculums())
```

이 코드는 `get_curriculums` 함수를 통해 현재 저장된 커리큘럼들을 출력합니다.

### 2. 커리큘럼 추가

커리큘럼을 추가하는 방법은 다음과 같습니다.

```python
def add_curriculum(name):
    # 새로운 커리큘럼 추가
    print(f"{name} 커리큘럼이 추가되었습니다.")

# 새 커리큘럼 추가
add_curriculum("파이썬 기초")
```

여기서 `add_curriculum` 함수는 새로운 커리큘럼 이름을 받아서 추가 작업을 수행합니다.

### 3. 커리큘럼 삭제

커리큘럼 삭제도 매우 간단하게 이루어집니다.

```python
def delete_curriculum(name):
    # 커리큘럼 삭제
    print(f"{name} 커리큘럼이 삭제되었습니다.")

# 기존 커리큘럼 삭제
delete_curriculum("커리큘럼1")
```

`delete_curriculum` 함수는 지정된 이름의 커리큘럼을 삭제합니다.

### 4. 맞춤형 커리큘럼 생성

사용자 맞춤 커리큘럼을 생성하여 유저 경험을 향상시킬 수 있습니다.

```python
def create_custom_curriculum(user_id, preferences):
    # 사용자 맞춤 커리큘럼 생성
    print(f"사용자 {user_id}를 위한 맞춤형 커리큘럼이 생성되었습니다.")

# 맞춤형 커리큘럼 생성
create_custom_curriculum("user123", ["프로그래밍", "데이터 분석"])
```

이 코드는 사용자 ID와 선호 분야들을 이용해 맞춤형 커리큘럼을 생성합니다.

## 내부 구현 이해

이제 내부적으로 커리큘럼 뷰가 어떻게 동작하는지 간단하게 설명하겠습니다. 각 기능이 어떻게 상호작용하는지 보기 위해 시퀀스 다이어그램을 사용합니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant CV as 커리큘럼 뷰
    participant DB as 데이터베이스

    U->>CV: 커리큘럼 조회 요청
    CV->>DB: 조회 쿼리 전송
    DB->>CV: 응답 반환
    CV->>U: 커리큘럼 목록 전달
```

여기서 사용자가 커리큘럼 뷰로 요청을 하면, 커리큘럼 뷰는 데이터베이스에 쿼리를 날리고, 그 결과를 사용자에게 반환합니다.

### 내부 코드 구현

커리큘럼 뷰의 데이터 흐름은 아래와 같이 구성됩니다.

```python
class CurriculumView:
    def __init__(self):
        self.curriculums = []

    def add(self, name):
        self.curriculums.append(name)
        print(f"커리큘럼 '{name}'이 추가되었습니다.")

    def remove(self, name):
        if name in self.curriculums:
            self.curriculums.remove(name)
            print(f"커리큘럼 '{name}'이 삭제되었습니다.")
        else:
            print("커리큘럼이 존재하지 않습니다.")
```

위 `CurriculumView` 클래스는 커리큘럼 목록을 관리하기 위한 기본적인 기능을 제공합니다. `add`와 `remove` 메소드를 통해 커리큘럼을 추가하고 삭제할 수 있습니다.

---

## 결론

이번 장에서는 커리큘럼 뷰를 통해 어떻게 데이터를 조회하고, 추가하고, 삭제하며 맞춤형 커리큘럼을 생성할 수 있는지를 배웠습니다. 이를 통해 사용자 맞춤형 교육 콘텐츠를 효과적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)에 대해 설명하겠습니다. 기대해주세요!
---
# Chapter 5: 프로젝트 뷰 (Project Views)

이전 장에서는 [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)에 대해 배웠습니다. 이번 장에서는 `SKN_ToyProject`에서 `프로젝트 뷰 (Project Views)`에 대해 알아보도록 하겠습니다. 프로젝트 뷰는 프로젝트와 관련된 데이터를 조회하고, 새로운 프로젝트를 추가하거나, 기존 프로젝트를 수정하는 API 엔드포인트를 제공합니다. 이 장에서는 이러한 기능들을 어떻게 활용할 수 있는지를 살펴보겠습니다.

## 프로젝트 뷰란 무엇인가요?

프로젝트 뷰는 사용자가 프로젝트와 관련된 데이터를 효율적으로 관리할 수 있게 해주는 도구입니다. 예를 들어, 팀 프로젝트를 진행하는 동안 관련 정보를 효율적으로 조회하고 필요에 따라 수정할 수 있습니다.

### 프로젝트 뷰의 주요 기능

- **프로젝트 조회**: 기존 프로젝트의 정보를 확인할 수 있습니다.
- **프로젝트 추가**: 새로운 프로젝트를 데이터베이스에 저장할 수 있습니다.
- **프로젝트 수정**: 등록된 프로젝트 정보를 업데이트할 수 있습니다.

## 프로젝트 뷰 사용 방법

이제 간단한 예제를 통해 프로젝트 뷰를 어떻게 사용할 수 있는지 알아보겠습니다.

### 1. 프로젝트 조회하기

프로젝트 데이터를 조회할 수 있는 간단한 코드를 작성해 봅시다.

```python
def get_projects():
    # 프로젝트 목록 조회
    return ["프로젝트 A", "프로젝트 B", "프로젝트 C"]

# 프로젝트 목록 출력
print(get_projects())
```

위 코드에서는 `get_projects` 함수를 통해 등록된 모든 프로젝트를 조회할 수 있습니다. 이 함수는 프로젝트 이름의 리스트를 반환합니다.

### 2. 새로운 프로젝트 추가하기

다음은 새로운 프로젝트를 추가하는 방법입니다.

```python
def add_project(name):
    # 새로운 프로젝트 추가
    print(f"{name} 프로젝트가 추가되었습니다.")

# 프로젝트 추가
add_project("프로젝트 D")
```

이 코드에서 `add_project` 함수는 프로젝트 이름을 받아 새로운 프로젝트를 추가하는 기능을 수행합니다.

### 3. 기존 프로젝트 수정하기

다음으로 프로젝트 정보를 수정하는 방법을 살펴보겠습니다.

```python
def update_project(old_name, new_name):
    # 프로젝트 이름 수정
    print(f"{old_name}가 {new_name}로 변경되었습니다.")

# 프로젝트 수정
update_project("프로젝트 A", "프로젝트 Z")
```

위 코드에서는 `update_project` 함수를 사용하여 기존 프로젝트의 이름을 업데이트할 수 있습니다.

## 내부 구현 이해

프로젝트 뷰의 내부에서 발생하는 상호작용을 간단하게 설명하겠습니다. 프로젝트의 생성, 조회, 수정 과정을 시퀀스 다이어그램을 통해 이해해 봅시다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant PV as 프로젝트 뷰
    participant DB as 데이터베이스

    U->>PV: 프로젝트 조회 요청
    PV->>DB: 조회 쿼리 전송
    DB->>PV: 응답 반환
    PV->>U: 프로젝트 목록 전달

    U->>PV: 프로젝트 추가 요청
    PV->>DB: 새로운 프로젝트 저장
    DB->>PV: 저장 성공 메시지 반환
    PV->>U: 프로젝트 추가 성공 메시지 전달

    U->>PV: 프로젝트 수정 요청
    PV->>DB: 프로젝트 업데이트
    DB->>PV: 업데이트 성공 메시지 반환
    PV->>U: 프로젝트 수정 성공 메시지 전달
```

각 기능은 데이터베이스와 상호작용하여 데이터를 효율적으로 처리합니다.

### 내부 코드 구현

이제 프로젝트 뷰의 내부 구현에 대한 코드를 살펴보겠습니다.

```python
class ProjectView:
    def __init__(self):
        self.projects = []

    def add(self, name):
        self.projects.append(name)
        print(f"프로젝트 '{name}'이 추가되었습니다.")

    def update(self, old_name, new_name):
        if old_name in self.projects:
            self.projects[self.projects.index(old_name)] = new_name
            print(f"프로젝트 '{old_name}'이 '{new_name}'로 변경되었습니다.")
        else:
            print("프로젝트가 존재하지 않습니다.")
```

`ProjectView` 클래스는 프로젝트 목록을 관리하며, `add`와 `update` 메소드를 통해 프로젝트를 추가하고 수정할 수 있는 기능을 제공합니다.

## 결론

이번 장에서는 프로젝트 뷰가 제공하는 기본적인 기능을 이용해 프로젝트 데이터를 조회하고 추가 및 수정하는 방법을 배웠습니다. 이를 통해 사용자는 프로젝트와 관련된 데이터를 효율적으로 관리할 수 있습니다. 다음 장에서는 [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)에 대해 배워보겠습니다. 함께 탐구해봅시다!
---
# Chapter 6: 사용자 및 커리큘럼 관계 (User and Curriculum Relationship)

이전 장에서는 [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)에 대해 배웠습니다. 이제 `SKN_ToyProject`에서 사용자와 커리큘럼 간의 관계를 어떻게 정의하고 관리할 수 있는지에 대해 알아볼 차례입니다. 이는 각 사용자가 커리큘럼을 어떻게 완료했는지를 추적하고 관리할 수 있도록 도와주는 핵심 기능입니다.

## 사용자 및 커리큘럼 관계란 무엇인가요?

사용자 및 커리큘럼 관계는 사용자가 어떤 커리큘럼을 완료했는지를 추적합니다. 예를 들어, 여러분이 온라인 학습 플랫폼에서 여러 강의를 수강할 때, 이 관계를 통해 어떤 강의를 완료했는지 기록하고 확인할 수 있습니다. 이를 통해 여러분은 학습 진척도를 쉽게 관리할 수 있습니다.

### 사용자 및 커리큘럼 관계의 주요 개념

- **사용자 식별자(User ID)**: 각 사용자를 고유하게 식별합니다.
- **커리큘럼 식별자(Curriculum ID)**: 커리큘럼을 고유하게 식별합니다.
- **완료 상태(Completion Status)**: 사용자가 커리큘럼을 완료했는지 여부를 추적합니다.

## 사용자 및 커리큘럼 관계 사용 방법

이제 이 관계를 어떻게 코드로 구현하고 활용할 수 있는지 간단한 예제를 통해 살펴보겠습니다.

### 1. 사용자와 커리큘럼 간의 관계 정의하기

```python
class UserCurriculumRelation:
    def __init__(self, user_id, curriculum_id, completed=False):
        # 사용자 ID 저장
        self.user_id = user_id
        # 커리큘럼 ID 저장
        self.curriculum_id = curriculum_id
        # 완료 상태 저장
        self.completed = completed

# 관계 생성
relation = UserCurriculumRelation("user123", "curriculum456")
```

이 코드에서는 `UserCurriculumRelation` 클래스가 사용자와 커리큘럼 간의 관계를 나타냅니다. 각 관계는 사용자 ID, 커리큘럼 ID, 그리고 완료 상태를 포함합니다.

### 2. 완료 상태 업데이트하기

사용자가 커리큘럼을 완료했을 때, 완료 상태를 업데이트할 수 있습니다.

```python
def mark_complete(relation):
    # 완료 상태 업데이트
    relation.completed = True
    print(f"사용자 {relation.user_id}가 커리큘럼 {relation.curriculum_id}를 완료했습니다.")

# 완료 상태 업데이트 호출
mark_complete(relation)
```

위 함수는 `relation` 객체의 완료 상태를 `True`로 변경하며 완료 메시지를 출력합니다.

## 내부 구현 이해

이제 사용자와 커리큘럼 간의 관계가 어떻게 동작하는지 시퀀스 다이어그램을 통해 설명하겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant UR as 사용자 관계
    participant DB as 데이터베이스

    U->>UR: 커리큘럼 완료 요청
    UR->>DB: 완료 상태 업데이트
    DB->>UR: 업데이트 확인
    UR->>U: 완료 상태 확인 및 전달
```

이 다이어그램에서는 사용자가 커리큘럼을 완료한다고 요청하고, 그 상태가 데이터베이스에 업데이트 되는 과정을 보여줍니다.

### 내부 코드 분석

다음으로 `UserCurriculumRelation` 클래스의 간단한 내부 구현을 살펴보겠습니다.

```python
class UserCurriculumRelation:
    def __init__(self, user_id, curriculum_id, completed=False):
        self.user_id = user_id
        self.curriculum_id = curriculum_id
        self.completed = completed
        
    def save_to_db(self):
        # 완료 상태를 데이터베이스에 저장
        print(f"커리큘럼 '{self.curriculum_id}'의 완료 상태가 저장되었습니다.")
```

`save_to_db` 메소드는 완료 상태를 데이터베이스에 저장하는 기능을 합니다. 이는 사용자의 완벽한 학습 기록을 관리하는 데 필수적입니다.

## 결론

이번 장에서는 사용자와 커리큘럼 간의 관계를 어떻게 정의하고, 완료 상태를 추적할 수 있는지를 배웠습니다. 이는 사용자 학습의 진척도를 파악하는 데 중요한 역할을 합니다. 이후 장에서는 [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)에 대해 알아보겠습니다. 함께 배워봅시다!
---
# Chapter 7: 퀴즈 히스토리 및 분석 (Quiz History and Analysis)

이전 장에서는 [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)에 대해 배워보았습니다. 이번 장에서는 사용자 퀴즈 히스토리 및 성과를 분석하는 방법에 대해 알아보겠습니다. 이를 통해 사용자는 자신의 학습 진척도를 파악하고, 더 나은 학습 계획을 세울 수 있습니다.

## 문제 해결을 위한 배경

퀴즈 히스토리 및 분석 기능은 사용자가 완료한 퀴즈의 이력을 저장하고, 이를 바탕으로 성과를 평가하여 개선점을 찾을 수 있도록 돕습니다. 예를 들어, 학생이 여러 과목의 퀴즈를 푸는 동안 어떤 과목이 상대적으로 약한지를 파악할 수 있게 되는 것입니다.

## 퀴즈 히스토리의 주요 개념

### 1. 퀴즈 이력 저장
사용자가 퀴즈를 완료하면, 그 결과가 저장됩니다. 이는 나중에 분석하여 성과를 평가하는 데 사용됩니다.

### 2. 퀴즈 성과 분석
저장된 이력을 바탕으로 사용자가 어떤 퀴즈에 강하고 약한지를 분석할 수 있습니다. 이를 통해 학습 전략을 개선할 수 있습니다.

## 퀴즈 히스토리 및 분석 사용 방법

### 퀴즈 이력 저장하기

사용자가 퀴즈를 완료할 때마다 이력을 저장하는 간단한 예제입니다.

```python
class QuizHistory:
    def __init__(self):
        self.history = []

    def save_result(self, quiz_id, score):
        # 퀴즈 결과 저장
        self.history.append((quiz_id, score))
        print(f"퀴즈 {quiz_id}에 대한 점수가 저장되었습니다: {score}")

# 퀴즈 이력 저장
quiz_history = QuizHistory()
quiz_history.save_result("quiz001", 85)
```

위 코드에서는 `QuizHistory` 클래스를 통해 사용자 퀴즈 점수를 저장할 수 있습니다. `save_result` 메소드는 퀴즈 ID와 점수를 받아서 저장합니다.

### 퀴즈 성과 분석하기

저장된 결과를 기반으로 성과를 분석할 수 있습니다.

```python
def analyze_performance(history):
    # 평균 점수 계산
    total_score = sum(score for _, score in history)
    average_score = total_score / len(history) if history else 0
    print(f"평균 점수: {average_score}")

# 성과 분석
analyze_performance(quiz_history.history)
```

여기서는 퀴즈 이력의 평균 점수를 계산하여 출력합니다. 이를 통해 사용자는 전반적인 성과를 파악할 수 있습니다.

## 내부 구현 이해

퀴즈 히스토리 및 분석이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant QH as 퀴즈 히스토리
    participant DB as 데이터베이스

    U->>QH: 퀴즈 완료 결과 전송
    QH->>DB: 이력 저장
    DB->>QH: 저장 확인
    QH->>U: 저장 완료 메시지
    U->>QH: 성과 분석 요청
    QH->>U: 분석 결과 전송
```

위 다이어그램이 보여주듯이, 사용자가 퀴즈를 완료하면 결과가 저장되고, 그 결과를 바탕으로 성과를 분석해줍니다.

### 내부 코드 분석

`QuizHistory` 클래스의 내부 구현을 좀 더 살펴보겠습니다.

```python
class QuizHistory:
    def __init__(self):
        self.history = []
        
    def save_result(self, quiz_id, score):
        self.history.append((quiz_id, score))

    def analyze_performance(self):
        total_score = sum(score for _, score in self.history)
        average_score = total_score / len(self.history) if self.history else 0
        return average_score
```

이 클래스는 퀴즈 결과를 저장하고, 평균 점수를 계산하여 성과를 단순히 분석하는 메소드를 포함합니다. 이는 학습 진척도를 측정하는 데 도움이 됩니다.

## 결론

이번 장에서는 퀴즈 히스토리 및 분석의 개념과 이를 사용하여 학습 성과를 측정하고 분석하는 방법을 배웠습니다. 이를 통해 사용자는 자신의 학습 약점을 파악하고, 보다 효과적인 학습 계획을 세울 수 있습니다. 다음 장에서는 [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 8: GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)

이전 장에서는 [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)에 대해 배웠습니다. 이번 장에서는 `GPT 기반 AI 어시스턴트`를 알아보겠습니다. 이 시스템은 사용자의 자연어 쿼리를 처리하여 데이터베이스와 상호작용하며 다양한 커리큘럼 및 프로젝트 관련 데이터를 제공하는 매우 강력한 도구입니다.

## 문제 해결을 위한 배경

여러 교육 플랫폼에서 우리는 사용자가 특정 정보를 검색하거나 문의할 때 즉각적인 답변을 제공하는 것이 점점 더 중요해지고 있습니다. 예를 들어, 사용자가 "다음 주에 예정된 퀴즈가 무엇인가요?" 라고 물을 때, AI 어시스턴트는 관련 정보를 신속하게 제공할 수 있습니다.

### 주요 기능

- **자연어 처리 (NLP)**: 사용자의 쿼리를 이해하고 해석합니다.
- **데이터베이스 인터페이스**: 사용자 질문에 기반하여 필요한 데이터를 조회합니다.
- **응답 생성**: 분석된 데이터를 바탕으로 사용자가 이해하기 쉬운 응답을 생성합니다.

## GPT 기반 AI 어시스턴트 사용 방법

이제 GPT 기반 AI 어시스턴트가 어떻게 작동하는지 간단한 예제를 통해 알아보겠습니다.

### 1. 사용자 쿼리 이해하기

먼저 사용자의 자연어 쿼리를 AI가 처리하는 방법을 살펴봅니다.

```python
def process_query(query):
    # 입력된 자연어 쿼리 처리
    print(f"쿼리 처리 중: {query}")

# 예시 쿼리 처리
process_query("다음 주 퀴즈 일정은?")
```

이 코드에서는 `process_query` 함수가 사용자의 쿼리를 입력받아 처리 과정을 시작합니다.

### 2. 데이터베이스와 상호작용하기

처리된 쿼리를 바탕으로 데이터베이스에서 필요한 정보를 가져옵니다.

```python
def fetch_data_from_db(query_params):
    # 데이터베이스에서 관련 데이터를 가져옴
    print(f"데이터베이스에서 {query_params} 관련 데이터 조회")

# 쿼리 파라미터로 데이터 조회
fetch_data_from_db("퀴즈 일정")
```

여기서는 `fetch_data_from_db` 함수가 데이터베이스에서 사용자 요청에 맞는 데이터를 조회합니다.

### 3. 응답 생성하기

조회된 데이터를 바탕으로 사용자에게 적절한 응답을 제공합니다.

```python
def generate_response(data):
    # 사용자에게 전달할 응답 생성
    print(f"응답 생성: {data} 관련 정보입니다.")

# 데이터 기반 응답 생성
generate_response("다음 주 퀴즈 일정")
```

`generate_response` 함수는 얻어진 데이터를 바탕으로 사용자가 이해할 수 있는 응답을 생성하는 역할을 합니다.

## 내부 구현 이해

GPT 기반 AI 어시스턴트의 내부 과정은 다음 시퀀스 다이어그램을 통해 설명됩니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant AI as AI 어시스턴트
    participant NLP as 자연어 처리
    participant DB as 데이터베이스
    participant R as 응답 생성

    U->>AI: 자연어 쿼리 전송
    AI->>NLP: 쿼리 처리 요청
    NLP->>AI: 처리된 쿼리 반환
    AI->>DB: 데이터베이스 조회
    DB->>AI: 조회 결과 반환
    AI->>R: 응답 생성 요청
    R->>AI: 생성된 응답 반환
    AI->>U: 최종 응답 전달
```

이 다이어그램에서 사용자가 쿼리를 입력하면 AI 어시스턴트는 이를 이해하고 적절한 데이터를 조회하여 사용자에게 응답을 제공합니다.

### 내부 코드 분석

이제 GPT 기반 AI 어시스턴트의 핵심 코드를 살펴보겠습니다.

```python
class GPTAssistant:
    def __init__(self):
        self.database = {}

    def process_query(self, query):
        # 가상의 쿼리 처리
        print(f"쿼리 처리 중: {query}")
        return query

    def fetch_data(self, params):
        # 가상의 데이터 조회
        data = f"{params} 관련 데이터"
        return data

    def generate_response(self, data):
        # 응답 생성 및 반환
        response = f"응답: {data}"
        return response
```

위 `GPTAssistant` 클래스는 쿼리 처리, 데이터 조회 및 응답 생성을 담당하는 메소드를 가지고 있습니다. 이 클래스를 통해 사용자의 복잡한 요청을 이해하고 적절히 처리할 수 있습니다.

## 결론

이번 장에서는 GPT 기반 AI 어시스턴트의 기능과 이를 활용하여 사용자의 자연어 쿼리에 응답하는 방법을 배웠습니다. 이 시스템은 효율적인 정보 제공 및 사용자 경험 향상을 목표로 합니다. 다음 장에서는 [추천 시스템 (Recommendation System)](09_추천_시스템__recommendation_system_.md)에 대해 알아보겠습니다. 기대해주세요!

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 9: 추천 시스템 (Recommendation System)`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 21:04:23,534 - INFO - Using OpenAI model: gpt-4o
2025-06-29 21:04:32,831 - INFO - RESPONSE: # Chapter 9: 추천 시스템 (Recommendation System)

이전 장에서는 [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)에 대해 이야기를 나눴습니다. 이제 `추천 시스템`에 대해 알아보겠습니다. 추천 시스템은 사용자가 더 나은 경험을 할 수 있도록 관련 커리큘럼이나 프로젝트를 제안하는 기술입니다.

## 문제를 해결하기 위한 배경

추천 시스템은 사용자가 필요로 하는 정보를 제공하여 궁극적으로 사용자 경험을 개선하는 데 도움을 줍니다. 예를 들어, 온라인 교육 플랫폼에서 학습자가 특정 과목을 매우 좋아한다면, 이와 유사한 다른 과목을 추천받아 학습을 지속할 수 있습니다.

### 추천 시스템의 주요 기능

- **유사 항목 추천**: 사용자의 이전 선택을 기반으로 유사한 콘텐츠를 추천합니다.
- **개인화된 학습 경로**: 사용자의 학습 기록과 선호도를 분석하여 학습 경로를 맞춤화합니다.

## 추천 시스템 사용 방법

### 1. 추천 리스트 생성하기

아래 예제는 사용자의 이전 학습 활동을 기반으로 추천 리스트를 생성하는 방법을 보여줍니다.

```python
def generate_recommendations(user_history):
    # 간단한 추천 목록 생성
    recommendations = ["과목 A", "과목 B", "과목 C"]
    return recommendations

# 사용자의 추천 리스트 생성
user_history = ["과목 X", "과목 Y"]
print(generate_recommendations(user_history))
```

이 코드는 `generate_recommendations` 함수를 통해 사용자의 학습 이력을 기반으로 추천 과목을 반환합니다.

## 내부 구현 이해

이제 추천 시스템이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant RS as 추천 시스템
    participant DB as 데이터베이스
    participant RE as 추천 엔진

    U->>RS: 추천 요청 전송
    RS->>DB: 사용자 데이터 조회
    DB->>RS: 사용자 데이터 반환
    RS->>RE: 추천 생성 요청
    RE->>RS: 추천 리스트 반환
    RS->>U: 추천 결과 전달
```

이 다이어그램에서 사용자는 추천 요청을 하고, 시스템은 사용자 데이터를 분석하여 맞춤형 추천 결과를 제공합니다.

### 내부 코드 분석

추천 시스템의 내부 동작을 좀 더 깊이 알아보겠습니다.

```python
class RecommendationSystem:
    def __init__(self):
        self.database = {}

    def get_user_data(self, user_id):
        # 사용자 데이터를 데이터베이스에서 가져오기
        return self.database.get(user_id, [])

    def generate_recommendations(self, user_data):
        # 추천 항목 생성
        recommendations = ["과목 A", "과목 B", "과목 C"]
        return recommendations

# 인스턴스 생성 및 추천 실행
rec_sys = RecommendationSystem()
user_data = rec_sys.get_user_data("user123")
print(rec_sys.generate_recommendations(user_data))
```

위 `RecommendationSystem` 클래스는 사용자 데이터를 관리하고, 추천 목록을 생성하는 메소드를 포함합니다. 이 간단한 예제를 통해 추천 시스템이 어떻게 작동하는지를 알 수 있습니다.

## 결론

이번 장에서는 추천 시스템의 기본 개념과 이를 사용하여 개별 사용자에게 맞춤형 콘텐츠를 제공하는 방법을 배웠습니다. 이 시스템은 더 나은 사용자 경험을 제공하는 데 매우 유용합니다. 다음 장에서는 [기술 스택 관리 (Tech Stack Management)](10_기술_스택_관리__tech_stack_management_.md)에 대해 배워보겠습니다. 기대해주세요!
2025-06-29 21:04:32,846 - INFO - PROMPT: 
IMPORTANT: Write this ENTIRE tutorial chapter in **Korean**. Some input context (like concept name, description, chapter list, previous summary) might already be in Korean, but you MUST translate ALL other generated content including explanations, examples, technical terms, and potentially code comments into Korean. DO NOT use English anywhere except in code syntax, required proper nouns, or when specified. The entire output MUST be in Korean.

Write a very beginner-friendly tutorial chapter (in Markdown format) for the project `SKN_ToyProject` about the concept: "기술 스택 관리 (Tech Stack Management)". This is Chapter 10.

Concept Details (Note: Provided in Korean):
- Name: 기술 스택 관리 (Tech Stack Management)
- Description:
각 커리큘럼에 필요한 기술 스택 정보를 저장하고 관리합니다.

Complete Tutorial Structure (Note: Chapter names might be in Korean):
1. [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)
2. [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)
3. [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)
4. [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)
5. [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)
6. [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)
7. [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)
8. [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)
9. [추천 시스템 (Recommendation System)](09_추천_시스템__recommendation_system_.md)
10. [기술 스택 관리 (Tech Stack Management)](10_기술_스택_관리__tech_stack_management_.md)

Context from previous chapters (Note: This summary might be in Korean):
# Chapter 1: 관리 인터페이스 (Admin Interface)

`SKN_ToyProject`에 오신 것을 환영합니다! 이 장에서는 관리 인터페이스(Admin Interface)의 개념에 대해 알아보겠습니다. 관리 인터페이스는 데이터를 관리하고 시각화하는 데 매우 중요한 도구입니다. 관리자가 다양한 모델 객체를 효율적으로 다루는 방법을 배울 수 있습니다.

## 관리 인터페이스란 무엇인가요?

관리 인터페이스는 프로젝트 내에서 데이터를 쉽게 시각화하고 조작할 수 있도록 도와주는 도구입니다. 예를 들어, 웹사이트의 관리자 페이지를 생각해보세요. 사용자가 데이터를 입력하면, 관리자는 이 데이터가 어떻게 저장되고, 표현되는지를 이 페이지에서 직접 확인하고 변경할 수 있습니다. 바로 이런 역할을 하는 것이 관리 인터페이스입니다.

## 관리 인터페이스의 주요 개념

### 1. 데이터 시각화
관리 인터페이스는 데이터를 표 형태로 보여줍니다. 이는 사용자가 데이터를 한눈에 이해할 수 있게 도와줍니다.

### 2. 데이터 조작
사용자는 인터페이스를 통해 데이터를 직접 추가, 수정, 삭제할 수 있습니다. 이를 통해 데이터 관리가 훨씬 더 직관적이고 효율적이 됩니다.

## 관리 인터페이스 사용 방법

이제 간단한 예제로 관리 인터페이스를 사용하는 방법을 살펴보겠습니다.

```python
from admin_interface import Admin

# 관리자 인터페이스 초기화
admin = Admin()

# 데이터 추가
admin.add_model('새로운 모델 객체')

# 데이터 목록 보기
print(admin.list_models())  # ['새로운 모델 객체']
```

첫 줄에서 관리 인터페이스를 불러오고, 두 번째 줄에서 관리 인터페이스를 초기화합니다. 그 후, `add_model` 메소드를 통해 데이터를 추가하고, `list_models`를 통해 현재 데이터를 확인할 수 있습니다.

## 관리 인터페이스의 내부 구조

관리 인터페이스가 어떻게 내부적으로 동작하는지 간단히 살펴보겠습니다. 관리 인터페이스가 호출되면, 다음과 같은 단계를 거칩니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant AI as 관리 인터페이스
    participant DB as 데이터베이스

    U->>AI: 데이터 추가 요청
    AI->>DB: 데이터 저장 요청
    DB->>AI: 저장 완료 응답
    AI->>U: 처리 결과 전달
```

`사용자`가 관리 인터페이스를 통해 데이터를 추가하면, `관리 인터페이스`는 이를 `데이터베이스`에 저장하고 결과를 다시 사용자에게 전달합니다.

### 코드를 통한 내부 구조 이해

관리 인터페이스의 내부 구현을 간단한 코드로 살펴보겠습니다.

```python
class Admin:
    def __init__(self):
        self.models = []

    def add_model(self, model_name):
        # 모델 추가
        self.models.append(model_name)

    def list_models(self):
        # 모델 목록 반환
        return self.models
```

`Admin` 클래스는 모델 목록을 관리합니다. `add_model` 메소드는 모델을 추가하고, `list_models` 메소드는 현재 모델 목록을 반환합니다.

## 결론

이 장에서는 관리 인터페이스의 기본 개념과 사용 방법을 배웠습니다. 관리 인터페이스는 프로젝트 내 데이터를 효율적으로 관리하는 데 매우 유용한 도구입니다. 

다음 장에서는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 2: 커리큘럼 모델 (Curriculum Model)

이전 장에서는 [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)에 대해 알아보았습니다. 이제 우리는 커리큘럼 모델에 대해 설명할 것입니다. 이는 교육 커리큘럼을 정의하고 관리하기 위한 핵심 데이터 구조입니다. 초심자를 위한 설명을 통해 쉽게 따라올 수 있도록 하겠습니다.

## 커리큘럼 모델이란 무엇인가요?

커리큘럼 모델은 교육 콘텐츠를 체계적으로 관리하기 위한 데이터 구조입니다. 이를 통해 우리는 다양한 사용자에 맞춘 교육 경로를 계획하고 조정할 수 있습니다. 대표적인 예로 프로그래밍 학습 플랫폼에서 다양한 난이도별 코스를 제공하는 것을 들 수 있습니다.

### 커리큘럼 모델의 주요 개념

- **사용자 아이디**: 커리큘럼이 특정 사용자에게 할당되었음을 나타냅니다.
- **커리큘럼 타입**: 커리큘럼의 유형(예: 입문, 중급, 고급)을 정의합니다.
- **커리큘럼 이름**: 사용자가 이해하기 쉽고 식별할 수 있도록 지정합니다.
- **키워드**: 커리큘럼의 핵심 주제를 빠르게 파악할 수 있게 도와줍니다.

## 커리큘럼 모델 사용 방법

이제 간단한 커리큘럼 객체를 생성하고 사용하는 방법을 살펴보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        # 사용자 아이디 저장
        self.user_id = user_id
        # 커리큘럼 타입 저장
        self.cur_type = cur_type
        # 커리큘럼 이름 저장
        self.name = name
        # 키워드 저장
        self.keywords = keywords

# 커리큘럼 객체 생성
my_curriculum = CurriculumModel('user123', '입문', '파이썬 기본', ['프로그래밍', '파이썬'])
```

위 코드에서는 `CurriculumModel` 클래스를 정의하고 인스턴스를 생성했습니다. 각 인스턴스는 사용자 아이디, 커리큘럼 타입, 이름, 키워드를 포함합니다. 이와 같은 방식을 통해 다양한 커리큘럼을 효과적으로 관리할 수 있습니다.

## 내부 구현의 이해

커리큘럼 모델이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다. 이는 주로 객체가 생성되어, 데이터를 처리를 하는 과정을 보여줍니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant C as 커리큘럼 모델
    participant DB as 데이터베이스

    U->>C: 새로운 커리큘럼 생성 요청
    C->>DB: 커리큘럼 저장
    DB->>C: 저장 완료 응답
    C->>U: 생성 결과 전달
```

위 시퀀스 다이어그램은 사용자가 커리큘럼을 생성하면 그 요청이 데이터베이스에 저장되는 과정을 보여줍니다.

### 내부 코드 분석

커리큘럼 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class CurriculumModel:
    def __init__(self, user_id, cur_type, name, keywords):
        self.user_id = user_id
        self.cur_type = cur_type
        self.name = name
        self.keywords = keywords
    
    def save_to_db(self):
        # 데이터베이스에 커리큘럼 저장
        print(f"커리큘럼 '{self.name}'이 저장되었습니다.")
```

`CurriculumModel` 클래스에는 생성자 외에도 커리큘럼을 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 커리큘럼 모델이 무엇인지, 이를 사용하여 데이터를 어떻게 관리할 수 있는지를 배웠습니다. 이를 통해 다양한 교육 경로를 효율적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 알아보겠습니다. 함께 탐구해 봅시다!
---
# Chapter 3: 프로젝트 모델 (Project Model)

이전 장에서 우리는 [커리큘럼 모델 (Curriculum Model)](02_커리큘럼_모델__curriculum_model_.md)에 대해 배웠습니다. 이제 `SKN_ToyProject`에서 사용될 프로젝트 모델에 대해 알아보겠습니다. 이 장에서는 프로젝트 모델이 무엇인지, 그리고 어떻게 사용해야 하는지를 간단하게 설명하겠습니다.

## 프로젝트 모델이란 무엇인가요?

프로젝트 모델은 사용자의 프로젝트에 관한 정보를 체계적으로 저장하고 관리하기 위한 데이터 구조입니다. 이를 통해 프로젝트 이름, 시작 및 종료 날짜, 그리고 팀원 수 등 다양한 정보를 손쉽게 다룰 수 있습니다.

### 핵심 사례

상상해보세요, 팀과 함께 새로운 웹사이트를 만드는 프로젝트를 시작한다고 가정할 때, 이 프로젝트 모델은 다음과 같은 정보를 체계적으로 보관할 수 있어요.

- 프로젝트 이름: "웹사이트 개발"
- 시작 날짜: "2023-06-01"
- 종료 날짜: "2023-12-31"
- 팀원 수: 5명

이렇게 프로젝트 모델을 사용하면 전체 프로젝트 일정을 더욱 명확하게 관리할 수 있습니다.

## 프로젝트 모델 주요 개념

### 1. 프로젝트 이름
프로젝트의 가장 기본적인 식별자 역할을 합니다.

### 2. 시작 및 종료 날짜
프로젝트의 기간을 지정합니다. 이를 통해 일정을 체계적으로 관리할 수 있습니다.

### 3. 팀원 수
프로젝트에 참여하는 인원의 수를 의미합니다.

## 프로젝트 모델 사용 방법

`ProjectModel` 클래스를 사용하여 프로젝트 객체를 생성할 수 있습니다. 다음은 간단한 예제 코드입니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        # 프로젝트 이름 저장
        self.name = name
        # 시작 날짜 저장
        self.start_date = start_date
        # 종료 날짜 저장
        self.end_date = end_date
        # 팀원 수 저장
        self.team_members = team_members

# 프로젝트 객체 생성
my_project = ProjectModel("웹사이트 개발", "2023-06-01", "2023-12-31", 5)
```

위 코드에서는 `ProjectModel` 클래스를 정의하고, 해당 클래스의 인스턴스를 생성했습니다. 각 인스턴스는 프로젝트 이름, 시작 및 종료 날짜, 팀원 수를 저장합니다.

### 프로젝트 모델의 동작 과정

이제 프로젝트 모델의 작동 방식에 대해 간단한 시퀀스 다이어그램을 통해 알아보겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant P as 프로젝트 모델
    participant DB as 데이터베이스

    U->>P: 프로젝트 생성 요청
    P->>DB: 프로젝트 정보 저장
    DB->>P: 저장 완료 응답
    P->>U: 생성 성공 메시지 전달
```

사용자가 프로젝트를 생성하면, 프로젝트 모델은 데이터를 데이터베이스에 저장합니다. 이후, 저장이 완료되면 사용자는 성공 메시지를 받게 됩니다.

## 내부 코드 이해

프로젝트 모델의 내부 구조를 좀 더 깊이 이해하기 위해 코드를 분해해 보겠습니다.

```python
class ProjectModel:
    def __init__(self, name, start_date, end_date, team_members):
        self.name = name
        self.start_date = start_date
        self.end_date = end_date
        self.team_members = team_members
    
    def save_to_db(self):
        # 데이터베이스에 프로젝트 저장
        print(f"프로젝트 '{self.name}'이 저장되었습니다.")
```

`ProjectModel` 클래스에는 생성자 외에도 프로젝트를 데이터베이스에 저장하는 `save_to_db` 메소드가 있습니다. 이는 실제 구현에 따라 데이터를 영구적으로 저장할 수 있도록 설계되었습니다.

## 결론

이번 장에서는 프로젝트 모델이 무엇이며, 이를 어떻게 사용하는지를 배웠습니다. 프로젝트 모델은 사용자의 프로젝트 정보를 관리하기 위한 강력한 도구입니다. 다음 장에서는 [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 4: 커리큘럼 뷰 (Curriculum Views)

이전 장에서는 [프로젝트 모델 (Project Model)](03_프로젝트_모델__project_model_.md)에 대해 배워봤습니다. 이번 장에서는 `SKN_ToyProject`에서 커리큘럼 데이터를 어떻게 조회하고, 추가하고, 삭제하며, 맞춤형 커리큘럼을 생성하는지에 대해 알아보겠습니다. 이는 사용자가 다양한 교육 콘텐츠를 손쉽게 관리할 수 있도록 돕는 기능입니다. 초보자도 쉽게 따라갈 수 있도록 최대한 간단하게 설명하겠습니다.

---

## 커리큘럼 뷰란 무엇인가요?

커리큘럼 뷰는 프로젝트 내 여러 커리큘럼과 관련된 작업을 수행할 수 있는 인터페이스를 제공합니다. 예를 들어, 교육 플랫폼에서 새로운 강좌를 추가하거나 기존 강좌를 삭제하는 경우를 생각할 수 있습니다. 이를 통해 사용자들은 자신이 원하는 대로 커리큘럼을 조정할 수 있습니다.

### 커리큘럼 뷰가 해결하는 문제

- **데이터 조회**: 사용자에게 필요한 커리큘럼 정보를 손쉽게 조회할 수 있습니다.
- **데이터 추가**: 새로운 커리큘럼을 추가하여 교육 콘텐츠를 확장할 수 있습니다.
- **데이터 삭제**: 불필요한 커리큘럼을 삭제하여 관리 효율성을 높일 수 있습니다.
- **맞춤형 커리큘럼 생성**: 사용자에게 맞춤형 학습 경로를 제공합니다.

## 커리큘럼 뷰의 주요 기능

### 1. 커리큘럼 조회

아래 코드는 커리큘럼 목록을 조회하는 간단한 예제입니다.

```python
def get_curriculums():
    # 커리큘럼 목록 조회
    return ["커리큘럼1", "커리큘럼2", "커리큘럼3"]

# 커리큘럼 목록 출력
print(get_curriculums())
```

이 코드는 `get_curriculums` 함수를 통해 현재 저장된 커리큘럼들을 출력합니다.

### 2. 커리큘럼 추가

커리큘럼을 추가하는 방법은 다음과 같습니다.

```python
def add_curriculum(name):
    # 새로운 커리큘럼 추가
    print(f"{name} 커리큘럼이 추가되었습니다.")

# 새 커리큘럼 추가
add_curriculum("파이썬 기초")
```

여기서 `add_curriculum` 함수는 새로운 커리큘럼 이름을 받아서 추가 작업을 수행합니다.

### 3. 커리큘럼 삭제

커리큘럼 삭제도 매우 간단하게 이루어집니다.

```python
def delete_curriculum(name):
    # 커리큘럼 삭제
    print(f"{name} 커리큘럼이 삭제되었습니다.")

# 기존 커리큘럼 삭제
delete_curriculum("커리큘럼1")
```

`delete_curriculum` 함수는 지정된 이름의 커리큘럼을 삭제합니다.

### 4. 맞춤형 커리큘럼 생성

사용자 맞춤 커리큘럼을 생성하여 유저 경험을 향상시킬 수 있습니다.

```python
def create_custom_curriculum(user_id, preferences):
    # 사용자 맞춤 커리큘럼 생성
    print(f"사용자 {user_id}를 위한 맞춤형 커리큘럼이 생성되었습니다.")

# 맞춤형 커리큘럼 생성
create_custom_curriculum("user123", ["프로그래밍", "데이터 분석"])
```

이 코드는 사용자 ID와 선호 분야들을 이용해 맞춤형 커리큘럼을 생성합니다.

## 내부 구현 이해

이제 내부적으로 커리큘럼 뷰가 어떻게 동작하는지 간단하게 설명하겠습니다. 각 기능이 어떻게 상호작용하는지 보기 위해 시퀀스 다이어그램을 사용합니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant CV as 커리큘럼 뷰
    participant DB as 데이터베이스

    U->>CV: 커리큘럼 조회 요청
    CV->>DB: 조회 쿼리 전송
    DB->>CV: 응답 반환
    CV->>U: 커리큘럼 목록 전달
```

여기서 사용자가 커리큘럼 뷰로 요청을 하면, 커리큘럼 뷰는 데이터베이스에 쿼리를 날리고, 그 결과를 사용자에게 반환합니다.

### 내부 코드 구현

커리큘럼 뷰의 데이터 흐름은 아래와 같이 구성됩니다.

```python
class CurriculumView:
    def __init__(self):
        self.curriculums = []

    def add(self, name):
        self.curriculums.append(name)
        print(f"커리큘럼 '{name}'이 추가되었습니다.")

    def remove(self, name):
        if name in self.curriculums:
            self.curriculums.remove(name)
            print(f"커리큘럼 '{name}'이 삭제되었습니다.")
        else:
            print("커리큘럼이 존재하지 않습니다.")
```

위 `CurriculumView` 클래스는 커리큘럼 목록을 관리하기 위한 기본적인 기능을 제공합니다. `add`와 `remove` 메소드를 통해 커리큘럼을 추가하고 삭제할 수 있습니다.

---

## 결론

이번 장에서는 커리큘럼 뷰를 통해 어떻게 데이터를 조회하고, 추가하고, 삭제하며 맞춤형 커리큘럼을 생성할 수 있는지를 배웠습니다. 이를 통해 사용자 맞춤형 교육 콘텐츠를 효과적으로 관리할 수 있습니다. 다음 장에서는 [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)에 대해 설명하겠습니다. 기대해주세요!
---
# Chapter 5: 프로젝트 뷰 (Project Views)

이전 장에서는 [커리큘럼 뷰 (Curriculum Views)](04_커리큘럼_뷰__curriculum_views_.md)에 대해 배웠습니다. 이번 장에서는 `SKN_ToyProject`에서 `프로젝트 뷰 (Project Views)`에 대해 알아보도록 하겠습니다. 프로젝트 뷰는 프로젝트와 관련된 데이터를 조회하고, 새로운 프로젝트를 추가하거나, 기존 프로젝트를 수정하는 API 엔드포인트를 제공합니다. 이 장에서는 이러한 기능들을 어떻게 활용할 수 있는지를 살펴보겠습니다.

## 프로젝트 뷰란 무엇인가요?

프로젝트 뷰는 사용자가 프로젝트와 관련된 데이터를 효율적으로 관리할 수 있게 해주는 도구입니다. 예를 들어, 팀 프로젝트를 진행하는 동안 관련 정보를 효율적으로 조회하고 필요에 따라 수정할 수 있습니다.

### 프로젝트 뷰의 주요 기능

- **프로젝트 조회**: 기존 프로젝트의 정보를 확인할 수 있습니다.
- **프로젝트 추가**: 새로운 프로젝트를 데이터베이스에 저장할 수 있습니다.
- **프로젝트 수정**: 등록된 프로젝트 정보를 업데이트할 수 있습니다.

## 프로젝트 뷰 사용 방법

이제 간단한 예제를 통해 프로젝트 뷰를 어떻게 사용할 수 있는지 알아보겠습니다.

### 1. 프로젝트 조회하기

프로젝트 데이터를 조회할 수 있는 간단한 코드를 작성해 봅시다.

```python
def get_projects():
    # 프로젝트 목록 조회
    return ["프로젝트 A", "프로젝트 B", "프로젝트 C"]

# 프로젝트 목록 출력
print(get_projects())
```

위 코드에서는 `get_projects` 함수를 통해 등록된 모든 프로젝트를 조회할 수 있습니다. 이 함수는 프로젝트 이름의 리스트를 반환합니다.

### 2. 새로운 프로젝트 추가하기

다음은 새로운 프로젝트를 추가하는 방법입니다.

```python
def add_project(name):
    # 새로운 프로젝트 추가
    print(f"{name} 프로젝트가 추가되었습니다.")

# 프로젝트 추가
add_project("프로젝트 D")
```

이 코드에서 `add_project` 함수는 프로젝트 이름을 받아 새로운 프로젝트를 추가하는 기능을 수행합니다.

### 3. 기존 프로젝트 수정하기

다음으로 프로젝트 정보를 수정하는 방법을 살펴보겠습니다.

```python
def update_project(old_name, new_name):
    # 프로젝트 이름 수정
    print(f"{old_name}가 {new_name}로 변경되었습니다.")

# 프로젝트 수정
update_project("프로젝트 A", "프로젝트 Z")
```

위 코드에서는 `update_project` 함수를 사용하여 기존 프로젝트의 이름을 업데이트할 수 있습니다.

## 내부 구현 이해

프로젝트 뷰의 내부에서 발생하는 상호작용을 간단하게 설명하겠습니다. 프로젝트의 생성, 조회, 수정 과정을 시퀀스 다이어그램을 통해 이해해 봅시다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant PV as 프로젝트 뷰
    participant DB as 데이터베이스

    U->>PV: 프로젝트 조회 요청
    PV->>DB: 조회 쿼리 전송
    DB->>PV: 응답 반환
    PV->>U: 프로젝트 목록 전달

    U->>PV: 프로젝트 추가 요청
    PV->>DB: 새로운 프로젝트 저장
    DB->>PV: 저장 성공 메시지 반환
    PV->>U: 프로젝트 추가 성공 메시지 전달

    U->>PV: 프로젝트 수정 요청
    PV->>DB: 프로젝트 업데이트
    DB->>PV: 업데이트 성공 메시지 반환
    PV->>U: 프로젝트 수정 성공 메시지 전달
```

각 기능은 데이터베이스와 상호작용하여 데이터를 효율적으로 처리합니다.

### 내부 코드 구현

이제 프로젝트 뷰의 내부 구현에 대한 코드를 살펴보겠습니다.

```python
class ProjectView:
    def __init__(self):
        self.projects = []

    def add(self, name):
        self.projects.append(name)
        print(f"프로젝트 '{name}'이 추가되었습니다.")

    def update(self, old_name, new_name):
        if old_name in self.projects:
            self.projects[self.projects.index(old_name)] = new_name
            print(f"프로젝트 '{old_name}'이 '{new_name}'로 변경되었습니다.")
        else:
            print("프로젝트가 존재하지 않습니다.")
```

`ProjectView` 클래스는 프로젝트 목록을 관리하며, `add`와 `update` 메소드를 통해 프로젝트를 추가하고 수정할 수 있는 기능을 제공합니다.

## 결론

이번 장에서는 프로젝트 뷰가 제공하는 기본적인 기능을 이용해 프로젝트 데이터를 조회하고 추가 및 수정하는 방법을 배웠습니다. 이를 통해 사용자는 프로젝트와 관련된 데이터를 효율적으로 관리할 수 있습니다. 다음 장에서는 [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)에 대해 배워보겠습니다. 함께 탐구해봅시다!
---
# Chapter 6: 사용자 및 커리큘럼 관계 (User and Curriculum Relationship)

이전 장에서는 [프로젝트 뷰 (Project Views)](05_프로젝트_뷰__project_views_.md)에 대해 배웠습니다. 이제 `SKN_ToyProject`에서 사용자와 커리큘럼 간의 관계를 어떻게 정의하고 관리할 수 있는지에 대해 알아볼 차례입니다. 이는 각 사용자가 커리큘럼을 어떻게 완료했는지를 추적하고 관리할 수 있도록 도와주는 핵심 기능입니다.

## 사용자 및 커리큘럼 관계란 무엇인가요?

사용자 및 커리큘럼 관계는 사용자가 어떤 커리큘럼을 완료했는지를 추적합니다. 예를 들어, 여러분이 온라인 학습 플랫폼에서 여러 강의를 수강할 때, 이 관계를 통해 어떤 강의를 완료했는지 기록하고 확인할 수 있습니다. 이를 통해 여러분은 학습 진척도를 쉽게 관리할 수 있습니다.

### 사용자 및 커리큘럼 관계의 주요 개념

- **사용자 식별자(User ID)**: 각 사용자를 고유하게 식별합니다.
- **커리큘럼 식별자(Curriculum ID)**: 커리큘럼을 고유하게 식별합니다.
- **완료 상태(Completion Status)**: 사용자가 커리큘럼을 완료했는지 여부를 추적합니다.

## 사용자 및 커리큘럼 관계 사용 방법

이제 이 관계를 어떻게 코드로 구현하고 활용할 수 있는지 간단한 예제를 통해 살펴보겠습니다.

### 1. 사용자와 커리큘럼 간의 관계 정의하기

```python
class UserCurriculumRelation:
    def __init__(self, user_id, curriculum_id, completed=False):
        # 사용자 ID 저장
        self.user_id = user_id
        # 커리큘럼 ID 저장
        self.curriculum_id = curriculum_id
        # 완료 상태 저장
        self.completed = completed

# 관계 생성
relation = UserCurriculumRelation("user123", "curriculum456")
```

이 코드에서는 `UserCurriculumRelation` 클래스가 사용자와 커리큘럼 간의 관계를 나타냅니다. 각 관계는 사용자 ID, 커리큘럼 ID, 그리고 완료 상태를 포함합니다.

### 2. 완료 상태 업데이트하기

사용자가 커리큘럼을 완료했을 때, 완료 상태를 업데이트할 수 있습니다.

```python
def mark_complete(relation):
    # 완료 상태 업데이트
    relation.completed = True
    print(f"사용자 {relation.user_id}가 커리큘럼 {relation.curriculum_id}를 완료했습니다.")

# 완료 상태 업데이트 호출
mark_complete(relation)
```

위 함수는 `relation` 객체의 완료 상태를 `True`로 변경하며 완료 메시지를 출력합니다.

## 내부 구현 이해

이제 사용자와 커리큘럼 간의 관계가 어떻게 동작하는지 시퀀스 다이어그램을 통해 설명하겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant UR as 사용자 관계
    participant DB as 데이터베이스

    U->>UR: 커리큘럼 완료 요청
    UR->>DB: 완료 상태 업데이트
    DB->>UR: 업데이트 확인
    UR->>U: 완료 상태 확인 및 전달
```

이 다이어그램에서는 사용자가 커리큘럼을 완료한다고 요청하고, 그 상태가 데이터베이스에 업데이트 되는 과정을 보여줍니다.

### 내부 코드 분석

다음으로 `UserCurriculumRelation` 클래스의 간단한 내부 구현을 살펴보겠습니다.

```python
class UserCurriculumRelation:
    def __init__(self, user_id, curriculum_id, completed=False):
        self.user_id = user_id
        self.curriculum_id = curriculum_id
        self.completed = completed
        
    def save_to_db(self):
        # 완료 상태를 데이터베이스에 저장
        print(f"커리큘럼 '{self.curriculum_id}'의 완료 상태가 저장되었습니다.")
```

`save_to_db` 메소드는 완료 상태를 데이터베이스에 저장하는 기능을 합니다. 이는 사용자의 완벽한 학습 기록을 관리하는 데 필수적입니다.

## 결론

이번 장에서는 사용자와 커리큘럼 간의 관계를 어떻게 정의하고, 완료 상태를 추적할 수 있는지를 배웠습니다. 이는 사용자 학습의 진척도를 파악하는 데 중요한 역할을 합니다. 이후 장에서는 [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)에 대해 알아보겠습니다. 함께 배워봅시다!
---
# Chapter 7: 퀴즈 히스토리 및 분석 (Quiz History and Analysis)

이전 장에서는 [사용자 및 커리큘럼 관계 (User and Curriculum Relationship)](06_사용자_및_커리큘럼_관계__user_and_curriculum_relationship_.md)에 대해 배워보았습니다. 이번 장에서는 사용자 퀴즈 히스토리 및 성과를 분석하는 방법에 대해 알아보겠습니다. 이를 통해 사용자는 자신의 학습 진척도를 파악하고, 더 나은 학습 계획을 세울 수 있습니다.

## 문제 해결을 위한 배경

퀴즈 히스토리 및 분석 기능은 사용자가 완료한 퀴즈의 이력을 저장하고, 이를 바탕으로 성과를 평가하여 개선점을 찾을 수 있도록 돕습니다. 예를 들어, 학생이 여러 과목의 퀴즈를 푸는 동안 어떤 과목이 상대적으로 약한지를 파악할 수 있게 되는 것입니다.

## 퀴즈 히스토리의 주요 개념

### 1. 퀴즈 이력 저장
사용자가 퀴즈를 완료하면, 그 결과가 저장됩니다. 이는 나중에 분석하여 성과를 평가하는 데 사용됩니다.

### 2. 퀴즈 성과 분석
저장된 이력을 바탕으로 사용자가 어떤 퀴즈에 강하고 약한지를 분석할 수 있습니다. 이를 통해 학습 전략을 개선할 수 있습니다.

## 퀴즈 히스토리 및 분석 사용 방법

### 퀴즈 이력 저장하기

사용자가 퀴즈를 완료할 때마다 이력을 저장하는 간단한 예제입니다.

```python
class QuizHistory:
    def __init__(self):
        self.history = []

    def save_result(self, quiz_id, score):
        # 퀴즈 결과 저장
        self.history.append((quiz_id, score))
        print(f"퀴즈 {quiz_id}에 대한 점수가 저장되었습니다: {score}")

# 퀴즈 이력 저장
quiz_history = QuizHistory()
quiz_history.save_result("quiz001", 85)
```

위 코드에서는 `QuizHistory` 클래스를 통해 사용자 퀴즈 점수를 저장할 수 있습니다. `save_result` 메소드는 퀴즈 ID와 점수를 받아서 저장합니다.

### 퀴즈 성과 분석하기

저장된 결과를 기반으로 성과를 분석할 수 있습니다.

```python
def analyze_performance(history):
    # 평균 점수 계산
    total_score = sum(score for _, score in history)
    average_score = total_score / len(history) if history else 0
    print(f"평균 점수: {average_score}")

# 성과 분석
analyze_performance(quiz_history.history)
```

여기서는 퀴즈 이력의 평균 점수를 계산하여 출력합니다. 이를 통해 사용자는 전반적인 성과를 파악할 수 있습니다.

## 내부 구현 이해

퀴즈 히스토리 및 분석이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant QH as 퀴즈 히스토리
    participant DB as 데이터베이스

    U->>QH: 퀴즈 완료 결과 전송
    QH->>DB: 이력 저장
    DB->>QH: 저장 확인
    QH->>U: 저장 완료 메시지
    U->>QH: 성과 분석 요청
    QH->>U: 분석 결과 전송
```

위 다이어그램이 보여주듯이, 사용자가 퀴즈를 완료하면 결과가 저장되고, 그 결과를 바탕으로 성과를 분석해줍니다.

### 내부 코드 분석

`QuizHistory` 클래스의 내부 구현을 좀 더 살펴보겠습니다.

```python
class QuizHistory:
    def __init__(self):
        self.history = []
        
    def save_result(self, quiz_id, score):
        self.history.append((quiz_id, score))

    def analyze_performance(self):
        total_score = sum(score for _, score in self.history)
        average_score = total_score / len(self.history) if self.history else 0
        return average_score
```

이 클래스는 퀴즈 결과를 저장하고, 평균 점수를 계산하여 성과를 단순히 분석하는 메소드를 포함합니다. 이는 학습 진척도를 측정하는 데 도움이 됩니다.

## 결론

이번 장에서는 퀴즈 히스토리 및 분석의 개념과 이를 사용하여 학습 성과를 측정하고 분석하는 방법을 배웠습니다. 이를 통해 사용자는 자신의 학습 약점을 파악하고, 보다 효과적인 학습 계획을 세울 수 있습니다. 다음 장에서는 [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 8: GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)

이전 장에서는 [퀴즈 히스토리 및 분석 (Quiz History and Analysis)](07_퀴즈_히스토리_및_분석__quiz_history_and_analysis_.md)에 대해 배웠습니다. 이번 장에서는 `GPT 기반 AI 어시스턴트`를 알아보겠습니다. 이 시스템은 사용자의 자연어 쿼리를 처리하여 데이터베이스와 상호작용하며 다양한 커리큘럼 및 프로젝트 관련 데이터를 제공하는 매우 강력한 도구입니다.

## 문제 해결을 위한 배경

여러 교육 플랫폼에서 우리는 사용자가 특정 정보를 검색하거나 문의할 때 즉각적인 답변을 제공하는 것이 점점 더 중요해지고 있습니다. 예를 들어, 사용자가 "다음 주에 예정된 퀴즈가 무엇인가요?" 라고 물을 때, AI 어시스턴트는 관련 정보를 신속하게 제공할 수 있습니다.

### 주요 기능

- **자연어 처리 (NLP)**: 사용자의 쿼리를 이해하고 해석합니다.
- **데이터베이스 인터페이스**: 사용자 질문에 기반하여 필요한 데이터를 조회합니다.
- **응답 생성**: 분석된 데이터를 바탕으로 사용자가 이해하기 쉬운 응답을 생성합니다.

## GPT 기반 AI 어시스턴트 사용 방법

이제 GPT 기반 AI 어시스턴트가 어떻게 작동하는지 간단한 예제를 통해 알아보겠습니다.

### 1. 사용자 쿼리 이해하기

먼저 사용자의 자연어 쿼리를 AI가 처리하는 방법을 살펴봅니다.

```python
def process_query(query):
    # 입력된 자연어 쿼리 처리
    print(f"쿼리 처리 중: {query}")

# 예시 쿼리 처리
process_query("다음 주 퀴즈 일정은?")
```

이 코드에서는 `process_query` 함수가 사용자의 쿼리를 입력받아 처리 과정을 시작합니다.

### 2. 데이터베이스와 상호작용하기

처리된 쿼리를 바탕으로 데이터베이스에서 필요한 정보를 가져옵니다.

```python
def fetch_data_from_db(query_params):
    # 데이터베이스에서 관련 데이터를 가져옴
    print(f"데이터베이스에서 {query_params} 관련 데이터 조회")

# 쿼리 파라미터로 데이터 조회
fetch_data_from_db("퀴즈 일정")
```

여기서는 `fetch_data_from_db` 함수가 데이터베이스에서 사용자 요청에 맞는 데이터를 조회합니다.

### 3. 응답 생성하기

조회된 데이터를 바탕으로 사용자에게 적절한 응답을 제공합니다.

```python
def generate_response(data):
    # 사용자에게 전달할 응답 생성
    print(f"응답 생성: {data} 관련 정보입니다.")

# 데이터 기반 응답 생성
generate_response("다음 주 퀴즈 일정")
```

`generate_response` 함수는 얻어진 데이터를 바탕으로 사용자가 이해할 수 있는 응답을 생성하는 역할을 합니다.

## 내부 구현 이해

GPT 기반 AI 어시스턴트의 내부 과정은 다음 시퀀스 다이어그램을 통해 설명됩니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant AI as AI 어시스턴트
    participant NLP as 자연어 처리
    participant DB as 데이터베이스
    participant R as 응답 생성

    U->>AI: 자연어 쿼리 전송
    AI->>NLP: 쿼리 처리 요청
    NLP->>AI: 처리된 쿼리 반환
    AI->>DB: 데이터베이스 조회
    DB->>AI: 조회 결과 반환
    AI->>R: 응답 생성 요청
    R->>AI: 생성된 응답 반환
    AI->>U: 최종 응답 전달
```

이 다이어그램에서 사용자가 쿼리를 입력하면 AI 어시스턴트는 이를 이해하고 적절한 데이터를 조회하여 사용자에게 응답을 제공합니다.

### 내부 코드 분석

이제 GPT 기반 AI 어시스턴트의 핵심 코드를 살펴보겠습니다.

```python
class GPTAssistant:
    def __init__(self):
        self.database = {}

    def process_query(self, query):
        # 가상의 쿼리 처리
        print(f"쿼리 처리 중: {query}")
        return query

    def fetch_data(self, params):
        # 가상의 데이터 조회
        data = f"{params} 관련 데이터"
        return data

    def generate_response(self, data):
        # 응답 생성 및 반환
        response = f"응답: {data}"
        return response
```

위 `GPTAssistant` 클래스는 쿼리 처리, 데이터 조회 및 응답 생성을 담당하는 메소드를 가지고 있습니다. 이 클래스를 통해 사용자의 복잡한 요청을 이해하고 적절히 처리할 수 있습니다.

## 결론

이번 장에서는 GPT 기반 AI 어시스턴트의 기능과 이를 활용하여 사용자의 자연어 쿼리에 응답하는 방법을 배웠습니다. 이 시스템은 효율적인 정보 제공 및 사용자 경험 향상을 목표로 합니다. 다음 장에서는 [추천 시스템 (Recommendation System)](09_추천_시스템__recommendation_system_.md)에 대해 알아보겠습니다. 기대해주세요!
---
# Chapter 9: 추천 시스템 (Recommendation System)

이전 장에서는 [GPT 기반 AI 어시스턴트 (GPT-based AI Assistant)](08_gpt_기반_ai_어시스턴트__gpt_based_ai_assistant_.md)에 대해 이야기를 나눴습니다. 이제 `추천 시스템`에 대해 알아보겠습니다. 추천 시스템은 사용자가 더 나은 경험을 할 수 있도록 관련 커리큘럼이나 프로젝트를 제안하는 기술입니다.

## 문제를 해결하기 위한 배경

추천 시스템은 사용자가 필요로 하는 정보를 제공하여 궁극적으로 사용자 경험을 개선하는 데 도움을 줍니다. 예를 들어, 온라인 교육 플랫폼에서 학습자가 특정 과목을 매우 좋아한다면, 이와 유사한 다른 과목을 추천받아 학습을 지속할 수 있습니다.

### 추천 시스템의 주요 기능

- **유사 항목 추천**: 사용자의 이전 선택을 기반으로 유사한 콘텐츠를 추천합니다.
- **개인화된 학습 경로**: 사용자의 학습 기록과 선호도를 분석하여 학습 경로를 맞춤화합니다.

## 추천 시스템 사용 방법

### 1. 추천 리스트 생성하기

아래 예제는 사용자의 이전 학습 활동을 기반으로 추천 리스트를 생성하는 방법을 보여줍니다.

```python
def generate_recommendations(user_history):
    # 간단한 추천 목록 생성
    recommendations = ["과목 A", "과목 B", "과목 C"]
    return recommendations

# 사용자의 추천 리스트 생성
user_history = ["과목 X", "과목 Y"]
print(generate_recommendations(user_history))
```

이 코드는 `generate_recommendations` 함수를 통해 사용자의 학습 이력을 기반으로 추천 과목을 반환합니다.

## 내부 구현 이해

이제 추천 시스템이 어떻게 작동하는지 시퀀스 다이어그램을 통해 살펴보겠습니다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant RS as 추천 시스템
    participant DB as 데이터베이스
    participant RE as 추천 엔진

    U->>RS: 추천 요청 전송
    RS->>DB: 사용자 데이터 조회
    DB->>RS: 사용자 데이터 반환
    RS->>RE: 추천 생성 요청
    RE->>RS: 추천 리스트 반환
    RS->>U: 추천 결과 전달
```

이 다이어그램에서 사용자는 추천 요청을 하고, 시스템은 사용자 데이터를 분석하여 맞춤형 추천 결과를 제공합니다.

### 내부 코드 분석

추천 시스템의 내부 동작을 좀 더 깊이 알아보겠습니다.

```python
class RecommendationSystem:
    def __init__(self):
        self.database = {}

    def get_user_data(self, user_id):
        # 사용자 데이터를 데이터베이스에서 가져오기
        return self.database.get(user_id, [])

    def generate_recommendations(self, user_data):
        # 추천 항목 생성
        recommendations = ["과목 A", "과목 B", "과목 C"]
        return recommendations

# 인스턴스 생성 및 추천 실행
rec_sys = RecommendationSystem()
user_data = rec_sys.get_user_data("user123")
print(rec_sys.generate_recommendations(user_data))
```

위 `RecommendationSystem` 클래스는 사용자 데이터를 관리하고, 추천 목록을 생성하는 메소드를 포함합니다. 이 간단한 예제를 통해 추천 시스템이 어떻게 작동하는지를 알 수 있습니다.

## 결론

이번 장에서는 추천 시스템의 기본 개념과 이를 사용하여 개별 사용자에게 맞춤형 콘텐츠를 제공하는 방법을 배웠습니다. 이 시스템은 더 나은 사용자 경험을 제공하는 데 매우 유용합니다. 다음 장에서는 [기술 스택 관리 (Tech Stack Management)](10_기술_스택_관리__tech_stack_management_.md)에 대해 배워보겠습니다. 기대해주세요!

Relevant Code Snippets (Code itself remains unchanged):
No specific code snippets provided for this abstraction.

Instructions for the chapter (Generate content in Korean unless specified otherwise):
- Start with a clear heading (e.g., `# Chapter 10: 기술 스택 관리 (Tech Stack Management)`). Use the provided concept name.

- If this is not the first chapter, begin with a brief transition from the previous chapter (in Korean), referencing it with a proper Markdown link using its name (Use the Korean chapter title from the structure above).

- Begin with a high-level motivation explaining what problem this abstraction solves (in Korean). Start with a central use case as a concrete example. The whole chapter should guide the reader to understand how to solve this use case. Make it very minimal and friendly to beginners.

- If the abstraction is complex, break it down into key concepts. Explain each concept one-by-one in a very beginner-friendly way (in Korean).

- Explain how to use this abstraction to solve the use case (in Korean). Give example inputs and outputs for code snippets (if the output isn't values, describe at a high level what will happen (in Korean)).

- Each code block should be BELOW 10 lines! If longer code blocks are needed, break them down into smaller pieces and walk through them one-by-one. Aggresively simplify the code to make it minimal. Use comments (Translate to Korean if possible, otherwise keep minimal English for clarity) to skip non-important implementation details. Each code block should have a beginner friendly explanation right after it (in Korean).

- Describe the internal implementation to help understand what's under the hood (in Korean). First provide a non-code or code-light walkthrough on what happens step-by-step when the abstraction is called (in Korean). It's recommended to use a simple sequenceDiagram with a dummy example - keep it minimal with at most 5 participants to ensure clarity. If participant name has space, use: `participant QP as Query Processing`.  (Use Korean for labels/text if appropriate).

- Then dive deeper into code for the internal implementation with references to files. Provide example code blocks, but make them similarly simple and beginner-friendly. Explain (in Korean).

- IMPORTANT: When you need to refer to other core abstractions covered in other chapters, ALWAYS use proper Markdown links like this: [Chapter Title](filename.md). Use the Complete Tutorial Structure above to find the correct filename and the chapter title (Use the Korean chapter title from the structure above). Translate the surrounding text.

- Use mermaid diagrams to illustrate complex concepts (```mermaid``` format).  (Use Korean for labels/text if appropriate).

- Heavily use analogies and examples throughout (in Korean) to help beginners understand.

- End the chapter with a brief conclusion that summarizes what was learned (in Korean) and provides a transition to the next chapter (in Korean). If there is a next chapter, use a proper Markdown link: [Next Chapter Title](next_chapter_filename) (Use the Korean chapter title from the structure above).

- Ensure the tone is welcoming and easy for a newcomer to understand (appropriate for Korean readers).

- Output *only* the Markdown content for this chapter.

Now, directly provide a super beginner-friendly Markdown output (DON'T need ```markdown``` tags):

2025-06-29 21:04:33,027 - INFO - Using OpenAI model: gpt-4o
2025-06-29 21:04:58,765 - INFO - RESPONSE: # Chapter 10: 기술 스택 관리 (Tech Stack Management)

이전 장에서는 [추천 시스템 (Recommendation System)](09_추천_시스템__recommendation_system_.md)에 대해 알아보았습니다. 이번 장에서는 `SKN_ToyProject`에서 커리큘럼에 필요한 기술 스택을 어떻게 효율적으로 관리할 수 있는지를 배워보겠습니다. 이 정보를 통해 프로젝트의 기술 요구 사항을 명확히 하고, 일관되고 쉽고 효과적으로 유지할 수 있습니다.

## 문제 해결을 위한 배경

기술 스택 관리는 각 커리큘럼이 필요로 하는 기술을 체계적으로 정리하고 저장하여 교육 목표를 달성하는 데 도움을 줍니다. 예를 들어, 웹 개발 강의에서 여러분은 HTML, CSS, JavaScript와 같은 기술이 필요할 수 있습니다. 이러한 정보를 효과적으로 관리함으로써 키 교육 목표를 명확히 하여 효율적인 학습 환경을 제공합니다.

### 기술 스택 관리의 주요 개념

- **기술 목록**: 각 커리큘럼에 필요한 기술 리스트입니다.
- **기술 삽입 및 삭제**: 필요에 따라 기술을 커리큘럼에 추가하거나 삭제할 수 있습니다.
- **기술 조회**: 현재 커리큘럼에 등록된 기술을 손쉽게 확인할 수 있습니다.

## 기술 스택 관리 방법

이제 코드 예제를 통해 기술 스택을 어떻게 구성하고 사용할 수 있는지 살펴보겠습니다.

### 1. 기술 목록 생성

먼저, 기술 목록을 어떻게 생성할 수 있는지 알아보겠습니다.

```python
class TechStackManager:
    def __init__(self):
        # 기술 목록 초기화
        self.techs = []

# 기술 매니저 객체 생성
manager = TechStackManager()
```

위 코드에서는 `TechStackManager` 클래스를 통해 필요한 기술 목록을 저장할 준비를 합니다.

### 2. 기술 삽입

기술을 커리큘럼에 추가하는 방법입니다.

```python
def add_tech(manager, tech_name):
    # 기술 추가
    manager.techs.append(tech_name)
    print(f"{tech_name} 기술이 추가되었습니다.")

# `JavaScript` 기술 추가
add_tech(manager, "JavaScript")
```

위 함수는 기술 이름을 받아 이를 목록에 추가하며, 사용자에게 추가된 기술의 이름을 출력합니다.

### 3. 기술 조회

등록된 기술을 확인해봅니다.

```python
def list_techs(manager):
    # 기술 목록 조회
    return manager.techs

# 기술 목록 출력
print(list_techs(manager))
```

위 코드에서는 `list_techs` 함수가 사용된 기술 목록을 반환하고, 이를 통해 현재 어떤 기술이 등록되어 있는지 알 수 있습니다.

## 내부 구현 이해

이제 기술 스택 관리가 어떻게 동작하는지 시퀀스 다이어그램을 통해 이해해 봅시다.

```mermaid
sequenceDiagram
    participant U as 사용자
    participant TSM as 기술 스택 관리자
    participant DB as 데이터베이스

    U->>TSM: 새로운 기술 추가 요청
    TSM->>DB: 기술 저장 요청
    DB->>TSM: 저장 완료 응답
    TSM->>U: 추가 성공 메시지 전달

    U->>TSM: 기술 목록 조회 요청
    TSM->>DB: 기술 목록 반환 요청
    DB->>TSM: 저장된 기술 목록 반환
    TSM->>U: 기술 목록 전달
```

위 다이어그램에서는 사용자가 기술을 추가하면, 기술 스택 관리자가 데이터베이스에 이를 저장하고 결과를 사용자에게 전달하는 과정을 보여줍니다.

### 내부 코드 분석

기술 스택 관리의 내부 코드를 봅시다.

```python
class TechStackManager:
    def __init__(self):
        self.techs = []

    def add_tech(self, tech_name):
        # 기술 추가
        if tech_name not in self.techs:
            self.techs.append(tech_name)
            print(f"'{tech_name}' 기술이 추가되었습니다.")

    def list_techs(self):
        # 기술 목록 반환
        return self.techs
```

이 `TechStackManager` 클래스는 기술을 효과적으로 관리합니다. `add_tech` 메소드는 중복을 방지하면서 기술을 추가하고, `list_techs` 메소드는 현재 등록된 기술을 반환합니다.

## 결론

이번 장에서는 기술 스택 관리의 필요성과 그 방법에 대해 알아보았습니다. 기술 스택을 효율적으로 관리함으로써 각 커리큘럼의 목표를 더 잘 달성할 수 있음을 이해했습니다. 다음 장에서는 [관리 인터페이스 (Admin Interface)](01_관리_인터페이스__admin_interface_.md)로 이동하여 본 프로젝트의 시작점으로 돌아갑니다. 함께 탐구해 봅시다!
