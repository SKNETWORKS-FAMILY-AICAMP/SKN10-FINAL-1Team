{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d4676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " \n",
      "AI Train 이용 방법    \n",
      "\n",
      "AI Train 이용 방법\n",
      "서비스 신청\n",
      "\n",
      "\n",
      "    AI Train는 D1 플랫폼의 DX-DCN-CJ 존에서만 제공됩니다.\n",
      "    상품 신청 시 최초 1회는 신규 존(DX-DCN-CJ)을 생성하는 과정이 필요합니다.\n",
      "    콘솔 상단 'Platform' 메뉴를 클릭합니다.\n",
      "\n",
      "\n",
      "화면에서 D1 플랫폼과 그 하위의 DX-DCN-CJ존을 선택한 후 '신청' 버튼을 클릭합니다.\n",
      "\n",
      "D1 플랫폼의 DCN-CJ 존 최초 신청을 위한 화면으로 넘어가고, 'DCN-CJ 신청하기' 버튼을 클릭하여 존을 생성합니다.\n",
      "    존 생성은 통상 약  5분이 소요되며, 존 생성이 완료된 후 다음 단계를 진행합니다.\n",
      "\n",
      "좌측 메뉴 상단의 ‘+All Services’ 에서 “서비스 신청” 버튼을 클릭 후 AI Train상품에 대해 “신청하기”를 클릭해서  상품을 신청합니다.\n",
      "\n",
      "이제 좌측 서비스 탭에서 AI Train를 이용할 수 있습니다.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "def load_and_clean_data(file_path) :\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        soup = BeautifulSoup(file, \"html.parser\")\n",
    "        text = soup.get_text()\n",
    "        # {% ... %} 같은 Django 템플릿 태그 제거\n",
    "        text = re.sub(r\"{%.*?%}\", \"\", text)\n",
    "        return text\n",
    "print(load_and_clean_data(\"templates/product/ai_computing/AI_Train_이용_방법.html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46313f88",
   "metadata": {},
   "source": [
    "# RAG 적용 (기본 방식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f2b85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnstn\\AppData\\Local\\Temp\\ipykernel_21432\\132586360.py:15: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings()\n",
      "C:\\Users\\tnstn\\AppData\\Local\\Temp\\ipykernel_21432\\132586360.py:18: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(\n",
      "C:\\Users\\tnstn\\AppData\\Local\\Temp\\ipykernel_21432\\132586360.py:28: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0)\n",
      "C:\\Users\\tnstn\\AppData\\Local\\Temp\\ipykernel_21432\\132586360.py:46: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=prompt, output_parser=StrOutputParser())\n",
      "C:\\Users\\tnstn\\AppData\\Local\\Temp\\ipykernel_21432\\132586360.py:51: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(query)\n",
      "C:\\Users\\tnstn\\AppData\\Local\\Temp\\ipykernel_21432\\132586360.py:57: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm_chain.run({\"context\": context, \"question\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 답변 ===\n",
      "DBaaS for MySQL 8 서비스는 최신 MySQL 데이터베이스 엔진(MySQL 8.0.33)을 기반으로 한 관리형 DB 서비스를 제공합니다. 이를 통해 사용자는 MySQL Native한 클러스터 구조를 자동으로 구성하여 고 가용성과 서비스 연속성을 보장 받을 수 있습니다. 또한 UI를 통해 손쉽게 MySQL 구조를 변경할 수 있고, 다양한 관리 기능을 통해 안정적으로 DB 서비스를 이용할 수 있습니다. 따라서 DBaaS for MySQL 8은 사용자에게 편리하고 안정적인 MySQL 데이터베이스를 제공합니다.\n",
      "\n",
      "=== 참고 문서 ===\n",
      "[1] templates/product/db\\DBaaS for MySQL 8 FAQ.html\n",
      "DBaaS for MySQL 8 FAQ    \n",
      "\n",
      "\n",
      "FAQ\n",
      "FAQ\n",
      "\n",
      "DBaaS for MySQL 8은 어떤 데이터베이스를 제공하나요 ?\n",
      "\n",
      "DBaaS for MySQL 8 서비스는 최신 MySQL 데이터베이스 엔진(MySQL 8.0.33) 기반의 관리형 DB 서비스를 제공합니다.\n",
      "\n",
      "DBaaS for MySQL 8을 외부에서도 사용이 가능한가요?\n",
      "\n",
      "외부 접근 가능 (Access 설정)에 대한 옵션이 제공 되며, 해당 기능을 통해 외부에서도 접근 가능 합니다.\n",
      "\n",
      "DBaaS for MySQL 8 서비스는 어느 위치(존)에서 사용이 가능한가요?\n",
      "\n",
      "현재, kt cloud의 DX-M1, DX-Central 존과  kt gcloud의 DX-G, DX-G-YS 존에서 사용 가능합니다.\n",
      "\n",
      "DBaaS for MySQL 8에서 제공하는 DB 구성 방식(구조)은 어떤 종류가 있나요?\n",
      "---\n",
      "[2] templates/product/db\\DBaaS for MySQL 8 상품 개요.html\n",
      "DBaaS for MySQL 8 상품 개요    \n",
      "\n",
      "\n",
      "상품 개요\n",
      "목적/용도\n",
      "\n",
      "\n",
      "    DBaaS for MySQL 8은 최신 MySQL 데이터베이스를 편리하게 배포하고 운영할 수 있는 서비스입니다.\n",
      "    특히, MySQL Native한 클러스터 구조를 자동으로 구성하여 고 가용성과 서비스 연속성을 보장 받을 수 있습니다.\n",
      "    UI로 손쉽게 MySQL 구조 변경이 가능하며, 실수를 예방하고 안정적으로 DB 서비스를 이용할 수 있는 다양한 관리 기능을 제공합니다.\n",
      "\n",
      "서비스 특장점\n",
      "\n",
      "\n",
      "    ㅇ UI 기반 설정 : UI 기반의 편리한 DB 구조 변경(Standalone ←→ Cluster)\n",
      "    ㅇ 고 가용성 : MySQL Cluster의 Single/Multi Primary 구조로 Read/Write 부하 분산 기능 제공\n",
      "    ㅇ 안정성 : MySQL 장애 발생 시, 자동 Fail Over/Fail Back 수행\n",
      "    ㅇ 파라미터 그룹 관리 : 복잡한 설정을 간단히 관리하는 \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "\n",
    "# 1. 기존에 만든 chroma_db 경로\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "# 2. 임베딩 모델 (기존과 동일)\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# 3. 저장된 Chroma DB 불러오기\n",
    "vectordb = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"my_db\"\n",
    ")\n",
    "\n",
    "# 4. Retriever 준비\n",
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
    "\n",
    "# 5. LLM 준비\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# 6. 프롬프트 템플릿 작성 (검색 결과를 포함해 질문에 답변하도록 유도)\n",
    "prompt_template = \"\"\"\n",
    "다음은 사용자가 질문한 내용과 관련된 문서입니다:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "이 정보를 참고하여 자세하고 친절하게 답변해 주세요.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# 7. LLM 체인 생성 (입력: context + question, 출력: 답변)\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt, output_parser=StrOutputParser())\n",
    "\n",
    "# 8. 사용자 질문에 대해 검색 + LLM 실행 함수\n",
    "def answer_question(query: str):\n",
    "    # 8-1. Retriever로 관련 문서 검색\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    \n",
    "    # 8-2. 문서 내용 합치기 (context 생성)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    # 8-3. LLM 체인 실행 (context + 질문)\n",
    "    response = llm_chain.run({\"context\": context, \"question\": query})\n",
    "    \n",
    "    return response, docs\n",
    "\n",
    "# 9. 질문 입력 및 답변 출력 (예시)\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = input(\"질문을 입력하세요: \")\n",
    "    answer, source_docs = answer_question(user_query)\n",
    "\n",
    "    print(\"\\n=== 답변 ===\")\n",
    "    print(answer)\n",
    "    print(\"\\n=== 참고 문서 ===\")\n",
    "    for i, doc in enumerate(source_docs, 1):\n",
    "        print(f\"[{i}] {doc.metadata.get('source', '출처 없음')}\")\n",
    "        print(doc.page_content[:500])  # 문서 내용 앞부분 일부 출력\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3af8912",
   "metadata": {},
   "source": [
    "# RAG 적용 (RetrievalQA로 LANGCHAIN 만들기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d400def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문:\n",
      "Django는 뭐야?\n",
      "답변:\n",
      "Django는 Python으로 작성된 오픈 소스 웹 애플리케이션 프레임워크입니다. Django는 웹 애플리케이션을 빠르고 쉽게 개발할 수 있도록 도와주는 많은 기능과 도구를 제공합니다. 데이터베이스와의 상호작용, URL 라우팅, 템플릿 엔진, 보안 기능 등을 포함한 다양한 기능을 제공하여 개발자들이 효율적으로 웹 애플리케이션을 구축할 수 있도록 도와줍니다.\n",
      "\n",
      "참고 문서:\n",
      "- DBaaS for MySQL 8 FAQ    \n",
      "\n",
      "\n",
      "FAQ\n",
      "FAQ\n",
      "\n",
      "DBaaS for MySQL 8은 어떤 데이터베이스를 제공하나요 ?\n",
      "\n",
      "DBaaS for MySQL 8 서비스는 최신 MySQL 데이터베이스 엔진(MySQL 8.0.33) 기반의 관리형 DB 서비스를 제공합니다.\n",
      "\n",
      "DBaaS for MySQL 8을 외부에서도 사용이 가능한가요?\n",
      "\n",
      "외부 접근 가능 (Access 설정)에 대한 옵션이 제공 되며, 해당 기능을 통해 외부에서도 접근 가능 합니다.\n",
      "\n",
      "DBaaS for MySQL 8 서비스는 어느 위치(존)에서 사용이 가능한가요?\n",
      "\n",
      "현재, kt cloud의 DX-M1, DX-Central 존과  kt gcloud의 DX-G, DX-G-YS 존에서 사용 가능합니다.\n",
      "\n",
      "DBaaS for MySQL 8에서 제공하는 DB 구성 방식(구조)은 어떤 종류가 있나요?\n",
      "- DBaaS for PostgreSQL FAQ    \n",
      "\n",
      "\n",
      "FAQ\n",
      "FAQ\n",
      "\n",
      "DBaaS for PostgreSQL은 어떤 데이터베이스를 제공하나요?\n",
      "\n",
      "DBaaS for PostgreSQL은 PostgreSQL 데이터베이스 기반의 관리형 DB 서비스를 제공합니다.\n",
      "\n",
      "DBaaS for PostgreSQL을 외부에서도 사용이 가능한가요?\n",
      "\n",
      "외부 접근 가능 (Access 설정)에 대한 옵션이 제공 되며, 해당 기능을 통해 외부에서도 접근 가능 합니다.\n",
      "\n",
      "DBaaS for PostgreSQL은 어느 위치(존)에서 사용이 가능한가요?\n",
      "\n",
      "현재, kt cloud의 DX-M1, DX-Central 존과  kt gcloud의 DX-G, DX-G-YS 존에서 사용 가능합니다.\n",
      "\n",
      "DBaaS for PostgreSQL에서 제공하는 DB 구성 방식(구조)은 어떤 종류가 있나요?\n"
     ]
    }
   ],
   "source": [
    "# 필요한 패키지 설치 (처음 한 번만)\n",
    "# !pip install langchain chromadb openai\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "import os\n",
    "\n",
    "# 1. 기존에 만든 chroma_db 경로\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "# 2. 임베딩 모델 (기존과 동일해야 함)\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# 3. 저장된 Chroma DB 불러오기\n",
    "vectordb = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"my_db\"  # 기존에 만든 컬렉션 이름\n",
    ")\n",
    "\n",
    "# 5. RAG용 Chain 구성\n",
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
    "llm = ChatOpenAI(temperature=0)  # OpenAI API 호출 (GPT-4 등)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# 6. 질문 입력 & 답변 실행\n",
    "query = input()\n",
    "result = qa_chain(query)\n",
    "\n",
    "print(\"질문:\")\n",
    "print(query)\n",
    "print(\"답변:\")\n",
    "print(result['result'])\n",
    "print(\"\\n참고 문서:\")\n",
    "for doc in result['source_documents']:\n",
    "    print(\"-\", doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36ef7bc",
   "metadata": {},
   "source": [
    "# RAG 미적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01be4fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문:\n",
      "VPN 설정 작업 소요 시간은 어느정도 걸리나요?\n",
      "\n",
      "답변:\n",
      "VPN 설정 작업 소요 시간은 다양하며, 사용하는 VPN 서비스나 설정하는 환경에 따라 다를 수 있습니다. 일반적으로는 몇 분에서 30분 정도의 시간이 소요될 수 있습니다. 그러나 복잡한 설정이 필요한 경우에는 더 많은 시간이 소요될 수도 있습니다. 설정하는 방법에 대한 자세한 안내는 해당 VPN 서비스의 공식 웹사이트나 고객 지원팀에 문의하시는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# 1. LLM 준비\n",
    "llm = ChatOpenAI(temperature=0)  # GPT-4 등\n",
    "\n",
    "# 2. 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"너는 친절한 AI야. 다음 질문에 대답해줘: {question}\"\n",
    ")\n",
    "\n",
    "# 3. 출력 파서 (문자열로 결과 반환)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 4. LangChain 구성 (프롬프트 → LLM → 파서)\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# 5. 질문 입력 및 실행\n",
    "query = input(\"질문을 입력하세요: \")\n",
    "result = chain.invoke({\"question\": query})\n",
    "\n",
    "print(\"\\n질문:\")\n",
    "print(query)\n",
    "print(\"\\n답변:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7000966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# graph 객체 생성(선언)\n",
    "# simple_graph 상 데이터 전달에 사용할 객체 -> State 클래스\n",
    "class State(TypedDict):\n",
    "    input: str    # 사용자 input data\n",
    "    result: str   # Node의 result data\n",
    "graph = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d732e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_new_session(state: State) -> bool:\n",
    "    if state[\"input\"] == \"exit\" :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54f8bdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(\n",
    "        Image(\n",
    "            graph.get_graph().draw_mermaid_png()\n",
    "        )\n",
    "    )\n",
    "except:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
